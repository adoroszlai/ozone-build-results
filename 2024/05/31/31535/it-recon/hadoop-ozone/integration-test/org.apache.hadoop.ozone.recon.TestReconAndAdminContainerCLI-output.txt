2024-05-31 20:33:44,439 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(143)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-05-31 20:33:44,625 [main] INFO  reflections.Reflections (Reflections.java:scan(219)) - Reflections took 163 ms to scan 7 urls, producing 158 keys and 372 values
2024-05-31 20:33:44,758 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(143)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-05-31 20:33:44,762 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(207)) - ServiceID for StorageContainerManager is null
2024-05-31 20:33:44,776 [main] WARN  ha.SCMHANodeDetails (SCMHANodeDetails.java:validateSCMHAConfig(180)) - Default/Configured value of config ozone.scm.ratis.enable conflicts with the expected value. Default/Configured: true. Expected: false. Falling back to the expected value. Current State of SCM: SCM is running without Ratis. Ratis SCM -> Non Ratis SCM is not supported.
2024-05-31 20:33:44,778 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(212)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2024-05-31 20:33:45,276 [main] WARN  utils.HAUtils (HAUtils.java:getMetaDir(339)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-05-31 20:33:45,393 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(171)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-05-31 20:33:45,417 [main] INFO  utils.LeakDetector (LeakDetector.java:start(73)) - Starting leak detector thread ManagedRocksObject0.
2024-05-31 20:33:45,655 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [file:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/classes/network-topology-default.xml]
2024-05-31 20:33:45,658 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2024-05-31 20:33:45,704 [main] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.dropwizard3.Dm3MetricRegistriesImpl
2024-05-31 20:33:45,719 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-05-31 20:33:45,885 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(370)) - upgrade localId to 113750153625600000
2024-05-31 20:33:45,887 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(380)) - upgrade delTxnId to 0
2024-05-31 20:33:45,894 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(397)) - upgrade containerId to 0
2024-05-31 20:33:45,897 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToCertificateSequenceId(444)) - upgrade CertificateId to 2
2024-05-31 20:33:45,900 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(241)) - Init the HA SequenceIdGenerator.
2024-05-31 20:33:45,966 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(177)) - Entering startup safe mode.
2024-05-31 20:33:45,983 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2024-05-31 20:33:45,987 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2024-05-31 20:33:45,998 [main] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2024-05-31 20:33:46,014 [main] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2024-05-31 20:33:46,016 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2024-05-31 20:33:46,022 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2024-05-31 20:33:46,023 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(127)) - Starting RatisPipelineUtilsThread.
2024-05-31 20:33:46,025 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(65)) - Starting BackgroundPipelineScrubber Service.
2024-05-31 20:33:46,026 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2024-05-31 20:33:46,032 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(65)) - Starting ExpiredContainerReplicaOpScrubber Service.
2024-05-31 20:33:46,033 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2024-05-31 20:33:46,057 [main] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(80)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-05-31 20:33:46,058 [main] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(80)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-05-31 20:33:46,082 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2024-05-31 20:33:46,147 [main] INFO  replication.ReplicationManager (ReplicationManager.java:start(296)) - Starting Replication Monitor Thread.
2024-05-31 20:33:46,150 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:33:46,150 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2024-05-31 20:33:46,160 [main] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(91)) - containers with one replica threshold count 0
2024-05-31 20:33:46,164 [main] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(176)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2024-05-31 20:33:46,166 [main] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(193)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2024-05-31 20:33:46,231 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(440)) - SCM start with adminUsers: [runner]
2024-05-31 20:33:46,480 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for SCMAudit to [].
2024-05-31 20:33:46,509 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-05-31 20:33:46,539 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15002
2024-05-31 20:33:46,543 [Socket Reader #1 for port 15002] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15002
2024-05-31 20:33:46,595 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for SCMAudit to [].
2024-05-31 20:33:46,601 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-05-31 20:33:46,602 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15001
2024-05-31 20:33:46,603 [Socket Reader #1 for port 15001] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15001
2024-05-31 20:33:46,638 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for SCMAudit to [].
2024-05-31 20:33:46,649 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-05-31 20:33:46,650 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15000
2024-05-31 20:33:46,651 [Socket Reader #1 for port 15000] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15000
2024-05-31 20:33:46,724 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2024-05-31 20:33:46,726 [main] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(225)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2024-05-31 20:33:46,730 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1545)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:15000
2024-05-31 20:33:46,797 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(136)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2024-05-31 20:33:46,810 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2024-05-31 20:33:46,810 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2024-05-31 20:33:47,027 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(204)) - RPC server for Client  is listening at /0.0.0.0:15000
2024-05-31 20:33:47,028 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-05-31 20:33:47,030 [IPC Server listener on 15000] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15000: starting
2024-05-31 20:33:47,089 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1558)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:15001
2024-05-31 20:33:47,091 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(162)) - RPC server for Block Protocol is listening at /0.0.0.0:15001
2024-05-31 20:33:47,092 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-05-31 20:33:47,092 [IPC Server listener on 15001] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15001: starting
2024-05-31 20:33:47,110 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(194)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:15002
2024-05-31 20:33:47,115 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-05-31 20:33:47,118 [IPC Server listener on 15002] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15002: starting
2024-05-31 20:33:47,150 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:33:47,154 [JvmPauseMonitor0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-0de31259-7547-4ea4-9e9e-52d889559681: Started
2024-05-31 20:33:47,166 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for scm at: http://0.0.0.0:15003
2024-05-31 20:33:47,166 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-05-31 20:33:47,190 [main] INFO  util.log (Log.java:initialized(170)) - Logging initialized @4037ms to org.eclipse.jetty.util.log.Slf4jLog
2024-05-31 20:33:47,283 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-05-31 20:33:47,288 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.scm is not defined
2024-05-31 20:33:47,302 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-05-31 20:33:47,306 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2024-05-31 20:33:47,306 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-05-31 20:33:47,307 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-05-31 20:33:47,337 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/webserver
2024-05-31 20:33:47,339 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15003
2024-05-31 20:33:47,340 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 17.0.11+9
2024-05-31 20:33:47,361 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-05-31 20:33:47,362 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-05-31 20:33:47,364 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2024-05-31 20:33:47,373 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@383e6734{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-05-31 20:33:47,374 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6be80629{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2024-05-31 20:33:47,412 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@3faa55{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2024-05-31 20:33:47,418 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@8dbf0f2{HTTP/1.1, (http/1.1)}{0.0.0.0:15003}
2024-05-31 20:33:47,418 [main] INFO  server.Server (Server.java:doStart(415)) - Started @4266ms
2024-05-31 20:33:47,420 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2024-05-31 20:33:47,421 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2024-05-31 20:33:47,422 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of scm listening at http://0.0.0.0:15003
2024-05-31 20:33:47,424 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-05-31 20:33:47,485 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for OMAudit to [].
2024-05-31 20:33:47,553 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(115)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2024-05-31 20:33:47,556 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(226)) - Configuration does not have ozone.om.address set. Falling back to the default OM address /127.0.0.1:15004
2024-05-31 20:33:47,557 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(254)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2024-05-31 20:33:47,557 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(261)) - OM Node ID is not set. Setting it to the default ID: om1
2024-05-31 20:33:47,565 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-05-31 20:33:47,569 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = QUOTA (version = 6), software layout = QUOTA (version = 6)
2024-05-31 20:33:47,644 [main] INFO  reflections.Reflections (Reflections.java:scan(219)) - Reflections took 73 ms to scan 2 urls, producing 188 keys and 545 values
2024-05-31 20:33:47,648 [main] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(113)) - Skipping Upgrade Action QuotaRepairUpgradeAction since it has been finalized.
2024-05-31 20:33:47,649 [main] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(113)) - Skipping Upgrade Action MockOmUpgradeAction since it has been finalized.
2024-05-31 20:33:47,651 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-05-31 20:33:47,798 [main] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(115)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:15001]
2024-05-31 20:33:47,829 [main] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(115)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:15001]
2024-05-31 20:33:48,007 [main] INFO  om.OzoneManager (OzoneManager.java:<init>(678)) - OM start with adminUsers: [runner]
2024-05-31 20:33:48,022 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-05-31 20:33:48,043 [main] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(72)) - OmKeyInfo.getCodec ignorePipeline = true
2024-05-31 20:33:48,151 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:33:48,316 [main] INFO  om.OzoneManager (OzoneManager.java:instantiateServices(812)) - S3 Multi-Tenancy is disabled
2024-05-31 20:33:48,344 [main] INFO  om.OmSnapshotManager (OmSnapshotManager.java:<init>(179)) - Ozone filesystem snapshot feature is enabled.
2024-05-31 20:33:48,351 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.snapshot.diff.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-05-31 20:33:48,391 [main] INFO  utils.NativeLibraryLoader (NativeLibraryLoader.java:loadLibrary(111)) - Loading Library: ozone_rocksdb_tools
2024-05-31 20:33:48,394 [main] ERROR snapshot.SnapshotDiffManager (SnapshotDiffManager.java:initNativeLibraryForEfficientDiff(287)) - Native Library for raw sst file reading loading failed.
org.apache.hadoop.hdds.utils.NativeLibraryNotLoadedException: Unable to load library ozone_rocksdb_tools from both java.library.path & resource file libozone_rocksdb_tools.so from jar.
	at org.apache.hadoop.hdds.utils.db.managed.ManagedRawSSTFileReader.loadLibrary(ManagedRawSSTFileReader.java:40)
	at org.apache.hadoop.ozone.om.snapshot.SnapshotDiffManager.initNativeLibraryForEfficientDiff(SnapshotDiffManager.java:285)
	at org.apache.hadoop.ozone.om.snapshot.SnapshotDiffManager.<init>(SnapshotDiffManager.java:259)
	at org.apache.hadoop.ozone.om.OmSnapshotManager.<init>(OmSnapshotManager.java:286)
	at org.apache.hadoop.ozone.om.OzoneManager.instantiateServices(OzoneManager.java:864)
	at org.apache.hadoop.ozone.om.OzoneManager.<init>(OzoneManager.java:688)
	at org.apache.hadoop.ozone.om.OzoneManager.createOm(OzoneManager.java:775)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.createOM(MiniOzoneClusterImpl.java:689)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.createAndStartSingleOM(MiniOzoneClusterImpl.java:673)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.build(MiniOzoneClusterImpl.java:535)
	at org.apache.hadoop.ozone.recon.TestReconAndAdminContainerCLI.init(TestReconAndAdminContainerCLI.java:134)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:728)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:156)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptLifecycleMethod(TimeoutExtension.java:128)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptBeforeAllMethod(TimeoutExtension.java:70)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(InterceptingExecutableInvoker.java:103)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:93)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:92)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:86)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeBeforeAllMethods$13(ClassBasedTestDescriptor.java:412)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeBeforeAllMethods(ClassBasedTestDescriptor.java:410)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:216)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:85)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:148)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1511)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:198)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:169)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:93)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:58)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:141)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:57)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:103)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:85)
	at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:63)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2024-05-31 20:33:48,440 [main] INFO  om.OzoneManager (OzoneManager.java:addS3GVolumeToDB(4463)) - Created Volume s3v With Owner runner required for S3Gateway operations.
2024-05-31 20:33:48,479 [main] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(311)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2024-05-31 20:33:48,480 [main] WARN  utils.OzoneManagerRatisUtils (OzoneManagerRatisUtils.java:getOMRatisSnapshotDirectory(476)) - ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
2024-05-31 20:33:48,492 [main] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(311)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2024-05-31 20:33:48,511 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(167)) - Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: localhost:15007
2024-05-31 20:33:48,520 [main] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:loadSnapshotInfoFromDB(589)) - TransactionInfo not found in OM DB.
2024-05-31 20:33:48,567 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-05-31 20:33:48,575 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-05-31 20:33:48,576 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.port = 15007 (fallback to raft.grpc.server.port)
2024-05-31 20:33:48,576 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-05-31 20:33:48,576 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.port = 15007 (fallback to raft.grpc.server.port)
2024-05-31 20:33:48,577 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-05-31 20:33:48,577 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15007 (custom)
2024-05-31 20:33:48,577 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 4194304 (custom)
2024-05-31 20:33:48,578 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2024-05-31 20:33:48,579 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2024-05-31 20:33:48,580 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2024-05-31 20:33:48,587 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-05-31 20:33:48,590 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-05-31 20:33:48,590 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-05-31 20:33:48,756 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2024-05-31 20:33:48,758 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:33:48,759 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-05-31 20:33:48,759 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:33:48,760 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/ratis] (custom)
2024-05-31 20:33:48,761 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-05-31 20:33:48,761 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-05-31 20:33:48,767 [main] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - om1: addNew group-C5BA1605619E:[om1|localhost:15007] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@467f97e[Not completed]
2024-05-31 20:33:48,768 [main] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(2168)) - OzoneManager Ratis server initialized at port 15007
2024-05-31 20:33:48,771 [main] INFO  om.OzoneManager (OzoneManager.java:getRpcServer(1228)) - Creating RPC Server
2024-05-31 20:33:48,779 [om1-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - om1: new RaftServerImpl for group-C5BA1605619E:[om1|localhost:15007] with OzoneManagerStateMachine:uninitialized
2024-05-31 20:33:48,780 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2024-05-31 20:33:48,781 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 1200ms (custom)
2024-05-31 20:33:48,781 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:33:48,781 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2024-05-31 20:33:48,782 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:33:48,782 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:33:48,783 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:33:48,788 [om1-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - om1@group-C5BA1605619E: ConfigurationManager, init=-1: peers:[om1|localhost:15007]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:33:48,795 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 120s (custom)
2024-05-31 20:33:48,797 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:33:48,800 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 300s (custom)
2024-05-31 20:33:48,800 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:33:48,804 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:33:48,805 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:33:48,911 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2024-05-31 20:33:48,916 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:33:48,918 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:33:48,919 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:33:48,920 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:33:48,920 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:33:49,151 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:33:49,541 [main] INFO  reflections.Reflections (Reflections.java:scan(219)) - Reflections took 726 ms to scan 20 urls, producing 58 keys and 6607 values
2024-05-31 20:33:49,709 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-05-31 20:33:49,710 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 127.0.0.1:15004
2024-05-31 20:33:49,710 [Socket Reader #1 for port 15004] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15004
2024-05-31 20:33:49,734 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2024-05-31 20:33:49,744 [main] INFO  om.OzoneManager (OzoneManager.java:start(1650)) - OzoneManager RPC server is listening at localhost/127.0.0.1:15004
2024-05-31 20:33:49,745 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(588)) - Starting OzoneManagerRatisServer om1 at port 15007
2024-05-31 20:33:49,748 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-05-31 20:33:49,748 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-05-31 20:33:49,749 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/ratis] (custom)
2024-05-31 20:33:49,754 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2024-05-31 20:33:49,758 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 83134@fv-az1343-628
2024-05-31 20:33:49,763 [om1-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2024-05-31 20:33:49,763 [om1-impl-thread1] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/raft-meta.conf
2024-05-31 20:33:49,765 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-05-31 20:33:49,772 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-05-31 20:33:49,772 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2024-05-31 20:33:49,773 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-05-31 20:33:49,774 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-05-31 20:33:49,777 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2024-05-31 20:33:49,781 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-05-31 20:33:49,782 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-05-31 20:33:49,782 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2024-05-31 20:33:49,784 [om1-impl-thread1] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[om1@group-C5BA1605619E-cacheEviction-AwaitToRun,5,main] started
2024-05-31 20:33:49,788 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2024-05-31 20:33:49,789 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2024-05-31 20:33:49,789 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2024-05-31 20:33:49,790 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2024-05-31 20:33:49,791 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-05-31 20:33:49,791 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-05-31 20:33:49,792 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-05-31 20:33:49,792 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-05-31 20:33:49,792 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2024-05-31 20:33:49,795 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 4194312 (custom)
2024-05-31 20:33:49,796 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2024-05-31 20:33:49,796 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-05-31 20:33:49,796 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-05-31 20:33:49,797 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2024-05-31 20:33:49,800 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-05-31 20:33:49,800 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-05-31 20:33:49,801 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - om1@group-C5BA1605619E: start as a follower, conf=-1: peers:[om1|localhost:15007]|listeners:[], old=null
2024-05-31 20:33:49,802 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-05-31 20:33:49,803 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-FollowerState
2024-05-31 20:33:49,804 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2024-05-31 20:33:49,805 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-05-31 20:33:49,805 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-05-31 20:33:49,805 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2024-05-31 20:33:49,806 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2024-05-31 20:33:49,806 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = true (custom)
2024-05-31 20:33:49,808 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 1s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:33:49,808 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 1200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:33:49,810 [main] INFO  server.RaftServer (RaftServerProxy.java:startImpl(406)) - om1: start RPC server
2024-05-31 20:33:49,837 [main] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - om1: GrpcService started, listening on 15007
2024-05-31 20:33:49,838 [main] INFO  om.OzoneManager (OzoneManager.java:start(1666)) - Version File has different layout version (6) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
2024-05-31 20:33:49,840 [JvmPauseMonitor1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-om1: Started
2024-05-31 20:33:49,851 [main] INFO  client.ScmTopologyClient (ScmTopologyClient.java:start(72)) - Initial network topology fetched from SCM: /.
2024-05-31 20:33:49,852 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [file:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/classes/network-topology-default.xml]
2024-05-31 20:33:49,852 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2024-05-31 20:33:49,868 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for ozoneManager at: http://0.0.0.0:15005
2024-05-31 20:33:49,868 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-05-31 20:33:49,871 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-05-31 20:33:49,872 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.ozoneManager is not defined
2024-05-31 20:33:49,875 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-05-31 20:33:49,876 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2024-05-31 20:33:49,876 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-05-31 20:33:49,876 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-05-31 20:33:49,877 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of ozoneManager uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/webserver
2024-05-31 20:33:49,880 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15005
2024-05-31 20:33:49,880 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 17.0.11+9
2024-05-31 20:33:49,887 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-05-31 20:33:49,887 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-05-31 20:33:49,887 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2024-05-31 20:33:49,889 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7c87c960{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-05-31 20:33:49,889 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7b6bcbee{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2024-05-31 20:33:49,899 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@2027e9f9{ozoneManager,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2024-05-31 20:33:49,900 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@462ccaa8{HTTP/1.1, (http/1.1)}{0.0.0.0:15005}
2024-05-31 20:33:49,900 [main] INFO  server.Server (Server.java:doStart(415)) - Started @6747ms
2024-05-31 20:33:49,900 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-05-31 20:33:49,901 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of ozoneManager listening at http://0.0.0.0:15005
2024-05-31 20:33:49,901 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-05-31 20:33:49,902 [IPC Server listener on 15004] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15004: starting
2024-05-31 20:33:49,923 [main] INFO  om.OzoneManager (OzoneManager.java:startTrashEmptier(2121)) - Trash Interval set to 0. Files deleted won't move to trash
2024-05-31 20:33:49,995 [main] INFO  db.CodecBuffer (CodecBuffer.java:set(63)) - Successfully set constructor to org.apache.hadoop.hdds.utils.db.CodecBuffer$$Lambda$1161/0x00007f07dc7564f8@170a5bc8
2024-05-31 20:33:50,129 [main] INFO  recon.ReconServer (StringUtils.java:startupShutdownMessage(132)) - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ReconServer
STARTUP_MSG:   host = fv-az1343-628/10.1.0.26
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.5.0-SNAPSHOT
STARTUP_MSG:   classpath = /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/classes:/home/runner/work/ozone/ozone/hadoop-ozone/common/target/classes:/home/runner/.m2/repository/io/grpc/grpc-netty/1.58.0/grpc-netty-1.58.0.jar:/home/runner/.m2/repository/io/grpc/grpc-core/1.58.0/grpc-core-1.58.0.jar:/home/runner/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/runner/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.23/animal-sniffer-annotations-1.23.jar:/home/runner/.m2/repository/io/grpc/grpc-context/1.58.0/grpc-context-1.58.0.jar:/home/runner/.m2/repository/io/grpc/grpc-util/1.58.0/grpc-util-1.58.0.jar:/home/runner/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/runner/.m2/repository/io/perfmark/perfmark-api/0.26.0/perfmark-api-0.26.0.jar:/home/runner/.m2/repository/io/netty/netty-codec-http2/4.1.109.Final/netty-codec-http2-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-common/4.1.109.Final/netty-common-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-buffer/4.1.109.Final/netty-buffer-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.109.Final/netty-codec-http-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-proxy/4.1.109.Final/netty-handler-proxy-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-socks/4.1.109.Final/netty-codec-socks-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.65.Final/netty-tcnative-boringssl-static-2.0.65.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-classes/2.0.65.Final/netty-tcnative-classes-2.0.65.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.65.Final/netty-tcnative-boringssl-static-2.0.65.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.65.Final/netty-tcnative-boringssl-static-2.0.65.Final-linux-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.65.Final/netty-tcnative-boringssl-static-2.0.65.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.65.Final/netty-tcnative-boringssl-static-2.0.65.Final-osx-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.65.Final/netty-tcnative-boringssl-static-2.0.65.Final-windows-x86_64.jar:/home/runner/.m2/repository/org/apache/commons/commons-compress/1.26.0/commons-compress-1.26.0.jar:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/classes:/home/runner/work/ozone/ozone/hadoop-hdds/client/target/classes:/home/runner/work/ozone/ozone/hadoop-ozone/interface-client/target/classes:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.3.6/hadoop-hdfs-client-3.3.6.jar:/home/runner/.m2/repository/com/squareup/okhttp3/okhttp/4.12.0/okhttp-4.12.0.jar:/home/runner/.m2/repository/com/squareup/okio/okio/3.6.0/okio-3.6.0.jar:/home/runner/.m2/repository/com/squareup/okio/okio-jvm/3.6.0/okio-jvm-3.6.0.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-jdk8/1.9.24/kotlin-stdlib-jdk8-1.9.24.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-jdk7/1.9.24/kotlin-stdlib-jdk7-1.9.24.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.9.24/kotlin-stdlib-common-1.9.24.jar:/home/runner/work/ozone/ozone/hadoop-hdds/test-utils/target/classes:/home/runner/.m2/repository/org/assertj/assertj-core/3.25.3/assertj-core-3.25.3.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy/1.14.11/byte-buddy-1.14.11.jar:/home/runner/.m2/repository/com/google/guava/guava/32.1.3-jre/guava-32.1.3-jre.jar:/home/runner/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/runner/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/runner/.m2/repository/org/checkerframework/checker-qual/3.37.0/checker-qual-3.37.0.jar:/home/runner/.m2/repository/com/google/j2objc/j2objc-annotations/2.8/j2objc-annotations-2.8.jar:/home/runner/.m2/repository/commons-io/commons-io/2.16.1/commons-io-2.16.1.jar:/home/runner/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.10.2/junit-jupiter-api-5.10.2.jar:/home/runner/.m2/repository/org/opentest4j/opentest4j/1.3.0/opentest4j-1.3.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-commons/1.10.2/junit-platform-commons-1.10.2.jar:/home/runner/.m2/repository/ch/qos/reload4j/reload4j/1.2.25/reload4j-1.2.25.jar:/home/runner/.m2/repository/jakarta/annotation/jakarta.annotation-api/2.1.1/jakarta.annotation-api-2.1.1.jar:/home/runner/.m2/repository/org/slf4j/slf4j-api/2.0.13/slf4j-api-2.0.13.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-api/2.17.1/log4j-api-2.17.1.jar:/home/runner/work/ozone/ozone/hadoop-hdds/server-scm/target/classes:/home/runner/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes:/home/runner/work/ozone/ozone/hadoop-hdds/hadoop-dependency-server/target/classes:/home/runner/.m2/repository/com/nimbusds/nimbus-jose-jwt/9.37.2/nimbus-jose-jwt-9.37.2.jar:/home/runner/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.6/hadoop-hdfs-3.3.6.jar:/home/runner/.m2/repository/commons-daemon/commons-daemon/1.3.4/commons-daemon-1.3.4.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.10.5/snappy-java-1.1.10.5.jar:/home/runner/work/ozone/ozone/hadoop-hdds/framework/target/classes:/home/runner/.m2/repository/org/bouncycastle/bcprov-jdk18on/1.78.1/bcprov-jdk18on-1.78.1.jar:/home/runner/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.6/metrics-core-3.2.6.jar:/home/runner/.m2/repository/org/apache/commons/commons-text/1.11.0/commons-text-1.11.0.jar:/home/runner/work/ozone/ozone/hadoop-hdds/framework/target/test-classes:/home/runner/work/ozone/ozone/hadoop-hdds/interface-server/target/classes:/home/runner/work/ozone/ozone/hadoop-hdds/interface-admin/target/classes:/home/runner/work/ozone/ozone/hadoop-hdds/managed-rocksdb/target/classes:/home/runner/.m2/repository/org/rocksdb/rocksdbjni/7.7.3/rocksdbjni-7.7.3.jar:/home/runner/.m2/repository/org/slf4j/slf4j-reload4j/2.0.13/slf4j-reload4j-2.0.13.jar:/home/runner/.m2/repository/org/apache/commons/commons-configuration2/2.10.1/commons-configuration2-2.10.1.jar:/home/runner/.m2/repository/commons-fileupload/commons-fileupload/1.5/commons-fileupload-1.5.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-core/2.17.1/log4j-core-2.17.1.jar:/home/runner/.m2/repository/com/lmax/disruptor/3.4.4/disruptor-3.4.4.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util/9.4.54.v20240208/jetty-util-9.4.54.v20240208.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-server/9.4.54.v20240208/jetty-server-9.4.54.v20240208.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-http/9.4.54.v20240208/jetty-http-9.4.54.v20240208.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-io/9.4.54.v20240208/jetty-io-9.4.54.v20240208.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.54.v20240208/jetty-servlet-9.4.54.v20240208.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-security/9.4.54.v20240208/jetty-security-9.4.54.v20240208.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.54.v20240208/jetty-util-ajax-9.4.54.v20240208.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.54.v20240208/jetty-webapp-9.4.54.v20240208.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.54.v20240208/jetty-xml-9.4.54.v20240208.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server/3.0.1/ratis-server-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/1.0.5/ratis-thirdparty-misc-1.0.5.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-proto/3.0.1/ratis-proto-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-common/3.0.1/ratis-common-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-client/3.0.1/ratis-client-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server-api/3.0.1/ratis-server-api-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics-api/3.0.1/ratis-metrics-api-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics-dropwizard3/3.0.1/ratis-metrics-dropwizard3-3.0.1.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_dropwizard/0.16.0/simpleclient_dropwizard-0.16.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient/0.16.0/simpleclient-0.16.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_common/0.16.0/simpleclient_common-0.16.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.16.2/jackson-datatype-jsr310-2.16.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.16.2/jackson-core-2.16.2.jar:/home/runner/work/ozone/ozone/hadoop-hdds/rocksdb-checkpoint-differ/target/classes:/home/runner/.m2/repository/org/jgrapht/jgrapht-core/1.4.0/jgrapht-core-1.4.0.jar:/home/runner/.m2/repository/org/jheaps/jheaps/0.11/jheaps-0.11.jar:/home/runner/.m2/repository/org/jgrapht/jgrapht-ext/1.4.0/jgrapht-ext-1.4.0.jar:/home/runner/.m2/repository/com/github/vlsi/mxgraph/jgraphx/3.9.8.1/jgraphx-3.9.8.1.jar:/home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/target/classes:/home/runner/.m2/repository/org/aspectj/aspectjrt/1.9.7/aspectjrt-1.9.7.jar:/home/runner/.m2/repository/org/aspectj/aspectjweaver/1.9.7/aspectjweaver-1.9.7.jar:/home/runner/work/ozone/ozone/hadoop-hdds/interface-client/target/classes:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-protobuf_3_7/1.1.1/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/runner/work/ozone/ozone/hadoop-ozone/interface-storage/target/classes:/home/runner/.m2/repository/org/reflections/reflections/0.10.2/reflections-0.10.2.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-client/1.19.4/jersey-client-1.19.4.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-intg/2.3.0/ranger-intg-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-common/2.3.0/ranger-plugins-common-2.3.0.jar:/home/runner/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-cred/2.3.0/ranger-plugins-cred-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-audit/2.3.0/ranger-plugins-audit-2.3.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-client/9.4.54.v20240208/jetty-client-9.4.54.v20240208.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpmime/4.5.6/httpmime-4.5.6.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore-nio/4.4.16/httpcore-nio-4.4.16.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpasyncclient/4.1.3/httpasyncclient-4.1.3.jar:/home/runner/.m2/repository/com/carrotsearch/hppc/0.8.0/hppc-0.8.0.jar:/home/runner/.m2/repository/org/apache/orc/orc-core/1.5.8/orc-core-1.5.8.jar:/home/runner/.m2/repository/net/java/dev/jna/jna/5.2.0/jna-5.2.0.jar:/home/runner/.m2/repository/net/java/dev/jna/jna-platform/5.2.0/jna-platform-5.2.0.jar:/home/runner/.m2/repository/com/kstruct/gethostname4j/0.0.2/gethostname4j-0.0.2.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugin-classloader/2.3.0/ranger-plugin-classloader-2.3.0.jar:/home/runner/work/ozone/ozone/hadoop-hdds/rocks-native/target/classes:/home/runner/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.3.6/hadoop-minikdc-3.3.6.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/runner/.m2/repository/junit/junit/4.13.2/junit-4.13.2.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/runner/work/ozone/ozone/hadoop-ozone/s3gateway/target/classes:/home/runner/.m2/repository/org/javassist/javassist/3.30.2-GA/javassist-3.30.2-GA.jar:/home/runner/.m2/repository/org/jboss/weld/servlet/weld-servlet-shaded/3.1.9.Final/weld-servlet-shaded-3.1.9.Final.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.42/jersey-container-servlet-core-2.42.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-common/2.42/jersey-common-2.42.jar:/home/runner/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.42/jersey-cdi1x-2.42.jar:/home/runner/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.42/jersey-hk2-2.42.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.42/jersey-media-jaxb-2.42.jar:/home/runner/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-api/2.6.1/hk2-api-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-utils/2.6.1/hk2-utils-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.6.1/aopalliance-repackaged-2.6.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.16.2/jackson-dataformat-xml-2.16.2.jar:/home/runner/.m2/repository/org/codehaus/woodstox/stax2-api/4.2.2/stax2-api-4.2.2.jar:/home/runner/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.4.0/woodstox-core-5.4.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.16.2/jackson-module-jaxb-annotations-2.16.2.jar:/home/runner/.m2/repository/javax/enterprise/cdi-api/2.0/cdi-api-2.0.jar:/home/runner/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/runner/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/runner/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/runner/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.3/jakarta.xml.bind-api-2.3.3.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-runtime/2.3.9/jaxb-runtime-2.3.9.jar:/home/runner/.m2/repository/org/glassfish/jaxb/txw2/2.3.9/txw2-2.3.9.jar:/home/runner/.m2/repository/com/sun/istack/istack-commons-runtime/3.0.12/istack-commons-runtime-3.0.12.jar:/home/runner/.m2/repository/com/sun/activation/jakarta.activation/1.2.2/jakarta.activation-1.2.2.jar:/home/runner/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.2/jakarta.activation-api-1.2.2.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf/1.58.0/grpc-protobuf-1.58.0.jar:/home/runner/.m2/repository/com/google/api/grpc/proto-google-common-protos/2.22.0/proto-google-common-protos-2.22.0.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf-lite/1.58.0/grpc-protobuf-lite-1.58.0.jar:/home/runner/.m2/repository/io/grpc/grpc-stub/1.58.0/grpc-stub-1.58.0.jar:/home/runner/.m2/repository/io/netty/netty-transport/4.1.109.Final/netty-transport-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver/4.1.109.Final/netty-resolver-4.1.109.Final.jar:/home/runner/work/ozone/ozone/hadoop-ozone/csi/target/classes:/home/runner/.m2/repository/com/google/protobuf/protobuf-java-util/3.19.6/protobuf-java-util-3.19.6.jar:/home/runner/.m2/repository/com/google/code/gson/gson/2.10.1/gson-2.10.1.jar:/home/runner/work/ozone/ozone/hadoop-hdds/config/target/classes:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.109.Final/netty-transport-native-epoll-4.1.109.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.109.Final/netty-transport-classes-epoll-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.109.Final/netty-transport-native-unix-common-4.1.109.Final.jar:/home/runner/work/ozone/ozone/hadoop-ozone/recon/target/classes:/home/runner/work/ozone/ozone/hadoop-ozone/recon-codegen/target/classes:/home/runner/.m2/repository/com/google/inject/guice/6.0.0/guice-6.0.0.jar:/home/runner/.m2/repository/jakarta/inject/jakarta.inject-api/2.0.1/jakarta.inject-api-2.0.1.jar:/home/runner/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-assistedinject/6.0.0/guice-assistedinject-6.0.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-servlet/6.0.0/guice-servlet-6.0.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.42/jersey-container-servlet-2.42.jar:/home/runner/.m2/repository/org/glassfish/hk2/guice-bridge/2.6.1/guice-bridge-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-server/2.42/jersey-server-2.42.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-client/2.42/jersey-client-2.42.jar:/home/runner/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.42/jersey-media-json-jackson-2.42.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.42/jersey-entity-filtering-2.42.jar:/home/runner/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/runner/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/runner/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/runner/.m2/repository/org/xerial/sqlite-jdbc/3.44.1.0/sqlite-jdbc-3.44.1.0.jar:/home/runner/.m2/repository/org/springframework/spring-jdbc/5.3.34/spring-jdbc-5.3.34.jar:/home/runner/.m2/repository/org/springframework/spring-beans/5.3.34/spring-beans-5.3.34.jar:/home/runner/.m2/repository/org/springframework/spring-core/5.3.34/spring-core-5.3.34.jar:/home/runner/.m2/repository/org/springframework/spring-tx/5.3.34/spring-tx-5.3.34.jar:/home/runner/work/ozone/ozone/hadoop-ozone/client/target/classes:/home/runner/work/ozone/ozone/hadoop-hdds/erasurecode/target/classes:/home/runner/work/ozone/ozone/hadoop-ozone/ozonefs/target/classes:/home/runner/work/ozone/ozone/hadoop-ozone/ozonefs-common/target/classes:/home/runner/work/ozone/ozone/hadoop-ozone/tools/target/classes:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-core/1.12.661/aws-java-sdk-core-1.12.661.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpclient/4.5.14/httpclient-4.5.14.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore/4.4.16/httpcore-4.4.16.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.16.2/jackson-dataformat-cbor-2.16.2.jar:/home/runner/.m2/repository/joda-time/joda-time/2.12.7/joda-time-2.12.7.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.12.661/aws-java-sdk-s3-1.12.661.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.12.661/aws-java-sdk-kms-1.12.661.jar:/home/runner/.m2/repository/com/amazonaws/jmespath-java/1.12.661/jmespath-java-1.12.661.jar:/home/runner/.m2/repository/org/kohsuke/metainf-services/metainf-services/1.11/metainf-services-1.11.jar:/home/runner/work/ozone/ozone/hadoop-hdds/tools/target/classes:/home/runner/.m2/repository/org/apache/ratis/ratis-tools/3.0.1/ratis-tools-3.0.1.jar:/home/runner/.m2/repository/commons-cli/commons-cli/1.6.0/commons-cli-1.6.0.jar:/home/runner/.m2/repository/org/apache/commons/commons-lang3/3.14.0/commons-lang3-3.14.0.jar:/home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/target/test-classes:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/test-classes:/home/runner/work/ozone/ozone/hadoop-hdds/hadoop-dependency-client/target/classes:/home/runner/.m2/repository/info/picocli/picocli/4.7.6/picocli-4.7.6.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.16.2/jackson-annotations-2.16.2.jar:/home/runner/work/ozone/ozone/hadoop-hdds/annotations/target/classes:/home/runner/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-netty/3.0.1/ratis-netty-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-grpc/3.0.1/ratis-grpc-3.0.1.jar:/home/runner/.m2/repository/org/bouncycastle/bcpkix-jdk18on/1.78.1/bcpkix-jdk18on-1.78.1.jar:/home/runner/.m2/repository/org/bouncycastle/bcutil-jdk18on/1.78.1/bcutil-jdk18on-1.78.1.jar:/home/runner/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/runner/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/runner/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/runner/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-client/1.8.1/jaeger-client-1.8.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-thrift/1.8.1/jaeger-thrift-1.8.1.jar:/home/runner/.m2/repository/org/apache/thrift/libthrift/0.15.0/libthrift-0.15.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-core/1.8.1/jaeger-core-1.8.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.8.1/jaeger-tracerresolver-1.8.1.jar:/home/runner/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.9.24/kotlin-stdlib-1.9.24.jar:/home/runner/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/runner/.m2/repository/org/yaml/snakeyaml/2.0/snakeyaml-2.0.jar:/home/runner/.m2/repository/io/grpc/grpc-api/1.58.0/grpc-api-1.58.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-launcher/1.10.2/junit-platform-launcher-1.10.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-engine/1.10.2/junit-platform-engine-1.10.2.jar:/home/runner/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.6/hadoop-kms-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-auth/3.3.6/hadoop-auth-3.3.6.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper/3.8.4/zookeeper-3.8.4.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.8.4/zookeeper-jute-3.8.4.jar:/home/runner/.m2/repository/org/apache/yetus/audience-annotations/0.12.0/audience-annotations-0.12.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.2.0/hadoop-shaded-guava-1.2.0.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-core/1.19.4/jersey-core-1.19.4.jar:/home/runner/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-server/1.19.4/jersey-server-1.19.4.jar:/home/runner/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.6/hadoop-common-3.3.6.jar:/home/runner/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/runner/.m2/repository/commons-net/commons-net/3.10.0/commons-net-3.10.0.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-servlet/1.19.4/jersey-servlet-1.19.4.jar:/home/runner/.m2/repository/com/github/pjfanning/jersey-json/1.20/jersey-json-1.20.jar:/home/runner/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/runner/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/runner/.m2/repository/com/google/re2j/re2j/1.7/re2j-1.7.jar:/home/runner/.m2/repository/com/jcraft/jsch/0.1.55/jsch-0.1.55.jar:/home/runner/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-recipes/5.2.0/curator-recipes-5.2.0.jar:/home/runner/.m2/repository/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/home/runner/.m2/repository/dnsjava/dnsjava/2.1.9/dnsjava-2.1.9.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.16.2/jackson-databind-2.16.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.6/hadoop-kms-3.3.6-tests.jar:/home/runner/work/ozone/ozone/hadoop-hdds/server-scm/target/test-classes:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/test-classes:/home/runner/.m2/repository/com/github/luben/zstd-jni/1.5.6-3/zstd-jni-1.5.6-3.jar:/home/runner/.m2/repository/commons-codec/commons-codec/1.17.0/commons-codec-1.17.0.jar:/home/runner/.m2/repository/io/netty/netty-codec/4.1.109.Final/netty-codec-4.1.109.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler/4.1.109.Final/netty-handler-4.1.109.Final.jar:/home/runner/work/ozone/ozone/hadoop-hdds/hadoop-dependency-test/target/classes:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.6/hadoop-common-3.3.6-tests.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.6/hadoop-hdfs-3.3.6-tests.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.10.2/junit-jupiter-engine-5.10.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.10.2/junit-jupiter-params-5.10.2.jar:/home/runner/.m2/repository/org/mockito/mockito-core/4.11.0/mockito-core-4.11.0.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy-agent/1.12.19/byte-buddy-agent-1.12.19.jar:/home/runner/.m2/repository/org/objenesis/objenesis/3.3/objenesis-3.3.jar:/home/runner/.m2/repository/org/mockito/mockito-inline/4.11.0/mockito-inline-4.11.0.jar:/home/runner/.m2/repository/org/mockito/mockito-junit-jupiter/4.11.0/mockito-junit-jupiter-4.11.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.6/hadoop-distcp-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.3.6/hadoop-mapreduce-client-jobclient-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.3.6/hadoop-mapreduce-client-common-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.3.6/hadoop-yarn-common-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.3.6/hadoop-yarn-api-3.3.6.jar:/home/runner/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/runner/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19.4/jersey-guice-1.19.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.16.2/jackson-jaxrs-json-provider-2.16.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.16.2/jackson-jaxrs-base-2.16.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.3.6/hadoop-yarn-client-3.3.6.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.4.51.v20230217/websocket-client-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.4.51.v20230217/websocket-common-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.4.51.v20230217/websocket-api-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/jline/jline/3.9.0/jline-3.9.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.3.6/hadoop-mapreduce-client-core-3.3.6.jar:/home/runner/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/runner/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-annotations/3.3.6/hadoop-annotations-3.3.6.jar:/home/runner/.m2/repository/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.6/hadoop-distcp-3.3.6-tests.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest/2.2/hamcrest-2.2.jar:/home/runner/.m2/repository/org/slf4j/jul-to-slf4j/2.0.13/jul-to-slf4j-2.0.13.jar:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/gradle-enterprise/test-listeners.jar:
STARTUP_MSG:   build = https://github.com/apache/ozone/385c4ec6ca2f20b43477050f918b7a644f7569f5 ; compiled by 'runner' on 2024-05-31T20:26Z
STARTUP_MSG:   java = 17.0.11
STARTUP_MSG:   conf = {hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=false, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.chunk.write.sync=false, hdds.container.close.threshold=0.9f, hdds.container.ipc.port=9859, hdds.container.ipc.random.port=false, hdds.container.ratis.admin.port=9857, hdds.container.ratis.datastream.enabled=true, hdds.container.ratis.datastream.port=9855, hdds.container.ratis.datastream.random.port=false, hdds.container.ratis.enabled=false, hdds.container.ratis.ipc.port=9858, hdds.container.ratis.ipc.random.port=false, hdds.container.ratis.leader.pending.bytes.limit=1GB, hdds.container.ratis.log.appender.queue.byte-limit=8MB, hdds.container.ratis.log.appender.queue.num-elements=1024, hdds.container.ratis.log.purge.gap=1000000, hdds.container.ratis.log.queue.byte-limit=4GB, hdds.container.ratis.log.queue.num-elements=1024, hdds.container.ratis.num.container.op.executors=10, hdds.container.ratis.num.write.chunk.threads.per.volume=4, hdds.container.ratis.replication.level=MAJORITY, hdds.container.ratis.rpc.type=GRPC, hdds.container.ratis.segment.preallocated.size=4MB, hdds.container.ratis.segment.size=64MB, hdds.container.ratis.server.port=9856, hdds.container.ratis.statemachine.max.pending.apply-transactions=10000, hdds.container.ratis.statemachinedata.sync.timeout=10s, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=true, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=false, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.factory.classname=org.apache.hadoop.hdds.fs.MockSpaceUsageCheckFactory$None, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.datanode.http.auth.type=simple, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.replication.zerocopy.enabled=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.slow.op.warning.threshold=500ms, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=5GB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=false, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=1s, hdds.key.algo=RSA, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.leader.election.minimum.timeout.duration=5s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.ratis.server.retry-cache.timeout.duration=600000ms, hdds.ratis.snapshot.threshold=10000, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.scm.http.auth.type=simple, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/SCM.keytab, hdds.scm.kerberos.principal=SCM/_HOST@REALM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=1, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=10m, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.security.provider=BC, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneAccessAuthorizer, ozone.acl.enabled=false, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=16KB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=4MB, ozone.client.datastream.min.packet.size=256KB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=8MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.reconstruct.stripe.write.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.max.retries=3, ozone.client.read.retry.interval=1, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=1MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=2MB, ozone.client.stream.buffer.size=1MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.csi.default-volume-size=1000000000, ozone.csi.mount.command=goofys --endpoint %s %s %s, ozone.csi.s3g.address=http://localhost:9878, ozone.csi.socket=/var/lib/csi.sock, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.http.policy=HTTP_ONLY, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=0.0.0.0:9862, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.client.rpc.timeout=15m, ozone.om.client.trash.core.pool.size=5, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.group.rights=ALL, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.port=8981, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.ha.raft.server.log.appender.wait-time.min=0ms, ozone.om.ha.raft.server.retrycache.expirytime=300s, ozone.om.handler.count.key=20, ozone.om.http-address=0.0.0.0:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.om.http.auth.type=simple, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.init.default.layout.version=-1, ozone.om.kerberos.keytab.file=/etc/security/keytabs/OM.keytab, ozone.om.kerberos.principal=OM/_HOST@REALM, ozone.om.kerberos.principal.pattern=*, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.network.topology.refresh.duration=1h, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=4MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.close.threshold=60s, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.s3.grpc.server_enabled=false, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.snapshot.cache.cleanup.service.run.interval=1m, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.interval=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1s, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.finalization.ratis.based.timeout=30s, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.user.rights=ALL, ozone.om.volume.listall.allowed=true, ozone.path.deleting.limit.per.task=6000, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.recon.http.auth.type=simple, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=10m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.sql.db.auto.commit=true, ozone.recon.sql.db.conn.idle.max.age=3600s, ozone.recon.sql.db.conn.idle.test=SELECT 1, ozone.recon.sql.db.conn.idle.test.period=60s, ozone.recon.sql.db.conn.max.active=5, ozone.recon.sql.db.conn.max.age=1800s, ozone.recon.sql.db.conn.timeout=30000ms, ozone.recon.sql.db.driver=org.apache.derby.jdbc.EmbeddedDriver, ozone.recon.sql.db.jdbc.url=jdbc:derby:${ozone.recon.db.dir}/ozone_recon_derby.db, ozone.recon.sql.db.jooq.dialect=DERBY, ozone.recon.task.containercounttask.interval=60s, ozone.recon.task.missingcontainer.interval=300s, ozone.recon.task.pipelinesync.interval=300s, ozone.recon.task.safemode.wait.threshold=300s, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.s3g.http.auth.type=simple, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/_HOST@REALM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.metrics.percentiles.intervals.seconds=60, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=false, ozone.s3g.volume.name=s3v, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.handler.count.key=100, ozone.scm.block.size=4MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=1MB, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.handler.count.key=100, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=1s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=5GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.handler.count.key=100, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=1GB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=4MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=20, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=100ms, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=120s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=3, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=3, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.crypto.compliance.mode=unrestricted, ozone.security.enabled=false, ozone.security.http.kerberos.enabled=false, ozone.security.reconfigure.protocol.acl=*, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.test.test.key=value1, ozone.xceiver.client.metrics.percentiles.intervals.seconds=60, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256, test.scm.client.address=localhost, test.scm.client.bind.host=0.0.0.0, test.scm.client.class=java.lang.Object, test.scm.client.compression.enabled=true, test.scm.client.duration=1h, test.scm.client.enabled=true, test.scm.client.port=9878, test.scm.client.threshold=10, test.scm.client.wait=30m, yarn.app.mapreduce.am.container.log.backups=0, yarn.app.mapreduce.am.container.log.limit.kb=0, yarn.app.mapreduce.task.container.log.backups=0, yarn.nodemanager.container.stderr.pattern={*stderr*,*STDERR*}, yarn.nodemanager.container.stderr.tail.bytes=4096, yarn.nodemanager.windows-container.cpu-limit.enabled=false, yarn.nodemanager.windows-container.memory-limit.enabled=false, yarn.resourcemanager.container.liveness-monitor.interval-ms=600000}
************************************************************/
2024-05-31 20:33:50,139 [main] INFO  recon.ReconServer (SignalLogger.java:register(90)) - registered UNIX signal handlers for [TERM, HUP, INT]
2024-05-31 20:33:50,152 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:33:50,330 [main] INFO  reflections.Reflections (Reflections.java:scan(219)) - Reflections took 8 ms to scan 1 urls, producing 20 keys and 82 values
2024-05-31 20:33:50,486 [main] INFO  recon.ReconServer (ReconServer.java:call(116)) - Initializing Recon server...
2024-05-31 20:33:50,532 [main] INFO  persistence.DefaultDataSourceProvider (DefaultDataSourceProvider.java:get(51)) - JDBC Url for Recon : jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/recon/ozone_recon_derby.db 
2024-05-31 20:33:50,995 [om1@group-C5BA1605619E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1192987079ns, electionTimeout:1186ms
2024-05-31 20:33:50,996 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - om1: shutdown om1@group-C5BA1605619E-FollowerState
2024-05-31 20:33:50,996 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-05-31 20:33:50,998 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-05-31 20:33:50,998 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderElection1
2024-05-31 20:33:51,014 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - om1@group-C5BA1605619E-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[om1|localhost:15007]|listeners:[], old=null
2024-05-31 20:33:51,016 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - om1@group-C5BA1605619E-LeaderElection1 PRE_VOTE round 0: result PASSED (term=0)
2024-05-31 20:33:51,018 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - om1@group-C5BA1605619E-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[om1|localhost:15007]|listeners:[], old=null
2024-05-31 20:33:51,018 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - om1@group-C5BA1605619E-LeaderElection1 ELECTION round 0: result PASSED (term=1)
2024-05-31 20:33:51,018 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - om1: shutdown om1@group-C5BA1605619E-LeaderElection1
2024-05-31 20:33:51,018 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-05-31 20:33:51,022 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-05-31 20:33:51,026 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2024-05-31 20:33:51,027 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2024-05-31 20:33:51,044 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2024-05-31 20:33:51,045 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-05-31 20:33:51,045 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-05-31 20:33:51,050 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-05-31 20:33:51,057 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-05-31 20:33:51,058 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2024-05-31 20:33:51,058 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2024-05-31 20:33:51,059 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-05-31 20:33:51,061 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderStateImpl
2024-05-31 20:33:51,062 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - om1@group-C5BA1605619E: set firstElectionSinceStartup to false for becomeLeader
2024-05-31 20:33:51,064 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 2269ms
2024-05-31 20:33:51,085 [om1@group-C5BA1605619E-LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
2024-05-31 20:33:51,106 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - om1@group-C5BA1605619E: set configuration 0: peers:[om1|localhost:15007]|listeners:[], old=null
2024-05-31 20:33:51,120 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-05-31 20:33:51,125 [main] INFO  codegen.SqlDbUtils (SqlDbUtils.java:createNewDerbyDatabase(67)) - Created derby database at jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/recon/ozone_recon_derby.db.
2024-05-31 20:33:51,130 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2024-05-31 20:33:51,152 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:33:51,208 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyConfigurationChanged(212)) - Received Configuration change notification from Ratis. New Peer list:
[id: "om1"
address: "localhost:15007"
startupRole: FOLLOWER
]
2024-05-31 20:33:51,209 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-05-31 20:33:51,344 [main] INFO  impl.ReconContainerMetadataManagerImpl (ReconContainerMetadataManagerImpl.java:initializeTables(141)) - KEY_CONTAINER Table is empty, initializing from CONTAINER_KEY Table ...
2024-05-31 20:33:51,345 [main] INFO  impl.ReconContainerMetadataManagerImpl (ReconContainerMetadataManagerImpl.java:initializeKeyContainerTable(666)) - It took 0.0 seconds to initialized 0 records to KEY_CONTAINER table
2024-05-31 20:33:51,378 [main] INFO  persistence.DefaultDataSourceProvider (DefaultDataSourceProvider.java:get(51)) - JDBC Url for Recon : jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/recon/ozone_recon_derby.db 
2024-05-31 20:33:51,383 [main] INFO  codegen.SqlDbUtils (SqlDbUtils.java:createNewDerbyDatabase(67)) - Created derby database at jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/recon/ozone_recon_derby.db.
2024-05-31 20:33:51,384 [main] INFO  recon.ReconServer (ReconServer.java:call(140)) - Creating Recon Schema.
2024-05-31 20:33:51,740 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for recon at: http://0.0.0.0:15008
2024-05-31 20:33:51,741 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-05-31 20:33:51,743 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-05-31 20:33:51,744 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.recon is not defined
2024-05-31 20:33:51,746 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-05-31 20:33:51,748 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recon
2024-05-31 20:33:51,748 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-05-31 20:33:51,748 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-05-31 20:33:51,749 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of recon uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/webserver
2024-05-31 20:33:51,755 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(80)) - Registered task ContainerKeyMapperTask with controller.
2024-05-31 20:33:51,881 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(80)) - Registered task FileSizeCountTask with controller.
2024-05-31 20:33:51,888 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(80)) - Registered task OmTableInsightTask with controller.
2024-05-31 20:33:51,893 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(80)) - Registered task NSSummaryTask with controller.
2024-05-31 20:33:51,897 [main] INFO  ozone.OmUtils (OmUtils.java:getOzoneManagerServiceId(685)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2024-05-31 20:33:51,897 [main] INFO  ozone.OmUtils (OmUtils.java:getOzoneManagerServiceId(704)) - No OzoneManager ServiceID configured.
2024-05-31 20:33:52,152 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:33:52,170 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [file:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/classes/network-topology-default.xml]
2024-05-31 20:33:52,171 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2024-05-31 20:33:52,268 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-05-31 20:33:52,271 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(241)) - Init the HA SequenceIdGenerator.
2024-05-31 20:33:52,276 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(177)) - Entering startup safe mode.
2024-05-31 20:33:52,277 [main] INFO  scm.ReconNodeManager (ReconNodeManager.java:loadExistingNodes(132)) - Loaded 0 nodes from node DB.
2024-05-31 20:33:52,278 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2024-05-31 20:33:52,279 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-05-31 20:33:52,279 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15009
2024-05-31 20:33:52,280 [Socket Reader #1 for port 15009] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15009
2024-05-31 20:33:52,285 [main] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2024-05-31 20:33:52,303 [main] INFO  recon.ReconServer (ReconServer.java:call(154)) - Initializing support of Recon Features...
2024-05-31 20:33:52,305 [main] INFO  recon.ReconServer (ReconServer.java:call(156)) - Recon server initialized successfully!
2024-05-31 20:33:52,305 [main] INFO  recon.ReconServer (ReconServer.java:start(211)) - Starting Recon server
2024-05-31 20:33:52,305 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Recon metrics system started (again)
2024-05-31 20:33:52,331 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15008
2024-05-31 20:33:52,331 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 17.0.11+9
2024-05-31 20:33:52,347 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-05-31 20:33:52,347 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-05-31 20:33:52,347 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2024-05-31 20:33:52,351 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7fab8e9a{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-05-31 20:33:52,352 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@21ec7946{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/recon/target/classes/webapps/static,AVAILABLE}
2024-05-31 20:33:53,128 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@48afc94c{recon,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/recon/target/classes/webapps/recon/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/recon/target/classes/webapps/recon}
2024-05-31 20:33:53,129 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@2280c0f5{HTTP/1.1, (http/1.1)}{0.0.0.0:15008}
2024-05-31 20:33:53,129 [main] INFO  server.Server (Server.java:doStart(415)) - Started @9977ms
2024-05-31 20:33:53,129 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-05-31 20:33:53,131 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of recon listening at http://0.0.0.0:15008
2024-05-31 20:33:53,131 [main] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:start(239)) - Starting Ozone Manager Service Provider.
2024-05-31 20:33:53,139 [main] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:registerOMDBTasks(217)) - Registered OmDeltaRequest task 
2024-05-31 20:33:53,143 [main] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:registerOMDBTasks(227)) - Registered OmSnapshotRequest task 
2024-05-31 20:33:53,143 [main] INFO  recovery.ReconOmMetadataManagerImpl (ReconOmMetadataManagerImpl.java:start(82)) - Starting ReconOMMetadataManagerImpl
2024-05-31 20:33:53,144 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:start(222)) - Starting Recon Task Controller.
2024-05-31 20:33:53,150 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:start(395)) - Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:15009
2024-05-31 20:33:53,153 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:33:53,277 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:initializePipelinesFromScm(495)) - Obtained 0 pipelines from SCM.
2024-05-31 20:33:53,278 [main] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 0 pipelines in house.
2024-05-31 20:33:53,278 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:start(408)) - SCM DB initialized
2024-05-31 20:33:53,279 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(194)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:15009
2024-05-31 20:33:53,281 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-05-31 20:33:53,281 [IPC Server listener on 15009] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15009: starting
2024-05-31 20:33:54,153 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:33:55,153 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:33:56,153 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:33:57,154 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:33:58,154 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:33:59,154 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:34:00,155 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:34:01,155 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:34:02,155 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:34:03,156 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:34:04,156 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:34:04,314 [main] INFO  scm.ReconScmTask (ReconScmTask.java:register(46)) - Registered PipelineSyncTask task 
2024-05-31 20:34:04,314 [main] INFO  scm.ReconScmTask (ReconScmTask.java:start(56)) - Starting PipelineSyncTask Thread.
2024-05-31 20:34:04,317 [PipelineSyncTask] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 0 pipelines in house.
2024-05-31 20:34:04,318 [main] INFO  scm.ReconScmTask (ReconScmTask.java:register(46)) - Registered ContainerSizeCountTask task 
2024-05-31 20:34:04,318 [main] INFO  scm.ReconScmTask (ReconScmTask.java:start(56)) - Starting ContainerSizeCountTask Thread.
2024-05-31 20:34:04,321 [main] INFO  scm.ReconScmTask (ReconScmTask.java:register(46)) - Registered ContainerHealthTask task 
2024-05-31 20:34:04,321 [main] INFO  scm.ReconScmTask (ReconScmTask.java:start(56)) - Starting ContainerHealthTask Thread.
2024-05-31 20:34:04,329 [JvmPauseMonitor2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-Recon: Started
2024-05-31 20:34:04,342 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:04,378 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-05-31 20:34:04,379 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-05-31 20:34:04,379 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-05-31 20:34:04,390 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(240)) - HddsDatanodeService host:fv-az1343-628 ip:10.1.0.26
2024-05-31 20:34:04,411 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-05-31 20:34:04,413 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(299)) - Datanode State Machine Task Thread Pool size 2
2024-05-31 20:34:04,451 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(126)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/data-0/hdds of storage type : DISK capacity : 9222449699674390527
2024-05-31 20:34:04,453 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/data-0/hdds to VolumeSet
2024-05-31 20:34:04,456 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis to VolumeSet
2024-05-31 20:34:04,458 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 0ms
2024-05-31 20:34:04,505 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for DNAudit to [].
2024-05-31 20:34:04,548 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-05-31 20:34:04,549 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-05-31 20:34:04,549 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15015 (custom)
2024-05-31 20:34:04,549 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-05-31 20:34:04,549 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15014 (custom)
2024-05-31 20:34:04,549 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-05-31 20:34:04,550 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15016 (custom)
2024-05-31 20:34:04,550 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-05-31 20:34:04,550 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:04,550 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-05-31 20:34:04,550 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:04,551 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-05-31 20:34:04,551 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-05-31 20:34:04,551 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-05-31 20:34:04,553 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-05-31 20:34:04,567 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-05-31 20:34:04,567 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-05-31 20:34:04,567 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-05-31 20:34:04,568 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-05-31 20:34:04,569 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-05-31 20:34:04,571 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-05-31 20:34:04,571 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-05-31 20:34:04,572 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 2fad9ecd-4424-4a8b-880f-fd93cda6f409-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-05-31 20:34:04,573 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-05-31 20:34:04,573 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 2fad9ecd-4424-4a8b-880f-fd93cda6f409-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-05-31 20:34:04,574 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-05-31 20:34:04,575 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-05-31 20:34:04,575 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15017 (custom)
2024-05-31 20:34:04,579 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:04,579 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-05-31 20:34:04,579 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:04,579 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis] (custom)
2024-05-31 20:34:04,579 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-05-31 20:34:04,580 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-05-31 20:34:04,586 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/tmp
2024-05-31 20:34:04,587 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xcecef7ee] REGISTERED
2024-05-31 20:34:04,589 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xcecef7ee] BIND: 0.0.0.0/0.0.0.0:15017
2024-05-31 20:34:04,589 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xcecef7ee, L:/0.0.0.0:15017] ACTIVE
2024-05-31 20:34:04,588 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(269)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/tmp is not a group directory; ignoring it. 
2024-05-31 20:34:04,593 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-05-31 20:34:04,615 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-05-31 20:34:04,650 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(157)) - Initializing replication supervisor with thread count = 10
2024-05-31 20:34:04,651 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-05-31 20:34:04,703 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15011
2024-05-31 20:34:04,703 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-05-31 20:34:04,705 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-05-31 20:34:04,706 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-05-31 20:34:04,708 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-05-31 20:34:04,709 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-05-31 20:34:04,709 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-05-31 20:34:04,709 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-05-31 20:34:04,710 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/meta/webserver
2024-05-31 20:34:04,711 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15011
2024-05-31 20:34:04,711 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 17.0.11+9
2024-05-31 20:34:04,712 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-05-31 20:34:04,712 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-05-31 20:34:04,712 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2024-05-31 20:34:04,713 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@13e4b8da{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-05-31 20:34:04,714 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@3217fef1{static,/static,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/static,AVAILABLE}
2024-05-31 20:34:04,720 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@2ffed7fd{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode}
2024-05-31 20:34:04,721 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@77615884{HTTP/1.1, (http/1.1)}{0.0.0.0:15011}
2024-05-31 20:34:04,721 [main] INFO  server.Server (Server.java:doStart(415)) - Started @21569ms
2024-05-31 20:34:04,721 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-05-31 20:34:04,722 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15011
2024-05-31 20:34:04,725 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-05-31 20:34:04,726 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15012
2024-05-31 20:34:04,730 [Socket Reader #1 for port 15012] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15012
2024-05-31 20:34:04,734 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(327)) - Datanode start with admins: [runner]
2024-05-31 20:34:04,734 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15012
2024-05-31 20:34:04,734 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-05-31 20:34:04,738 [IPC Server listener on 15012] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15012: starting
2024-05-31 20:34:04,738 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(555)) - Ozone container server started.
2024-05-31 20:34:04,739 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-05-31 20:34:04,740 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-05-31 20:34:04,740 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-05-31 20:34:04,754 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(240)) - HddsDatanodeService host:fv-az1343-628 ip:10.1.0.26
2024-05-31 20:34:04,777 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-05-31 20:34:04,780 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-05-31 20:34:04,781 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(299)) - Datanode State Machine Task Thread Pool size 2
2024-05-31 20:34:04,785 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(126)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/data-0/hdds of storage type : DISK capacity : 9222449699674390527
2024-05-31 20:34:04,785 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/data-0/hdds to VolumeSet
2024-05-31 20:34:04,787 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis to VolumeSet
2024-05-31 20:34:04,787 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 0ms
2024-05-31 20:34:04,792 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-05-31 20:34:04,792 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-05-31 20:34:04,793 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15024 (custom)
2024-05-31 20:34:04,793 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-05-31 20:34:04,793 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15023 (custom)
2024-05-31 20:34:04,809 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-05-31 20:34:04,810 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15025 (custom)
2024-05-31 20:34:04,810 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-05-31 20:34:04,811 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:04,811 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-05-31 20:34:04,812 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:04,812 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-05-31 20:34:04,812 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-05-31 20:34:04,813 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-05-31 20:34:04,819 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-05-31 20:34:04,820 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-05-31 20:34:04,821 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-05-31 20:34:04,822 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-05-31 20:34:04,822 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-05-31 20:34:04,822 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-05-31 20:34:04,823 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-05-31 20:34:04,823 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-05-31 20:34:04,824 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 076ccc74-63d1-410b-8584-7a1d80cfc8c8-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-05-31 20:34:04,826 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-05-31 20:34:04,827 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 076ccc74-63d1-410b-8584-7a1d80cfc8c8-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-05-31 20:34:04,828 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-05-31 20:34:04,829 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-05-31 20:34:04,829 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15026 (custom)
2024-05-31 20:34:04,838 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:04,839 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-05-31 20:34:04,839 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:04,839 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis] (custom)
2024-05-31 20:34:04,839 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-05-31 20:34:04,839 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-05-31 20:34:04,840 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc2f84f11] REGISTERED
2024-05-31 20:34:04,840 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc2f84f11] BIND: 0.0.0.0/0.0.0.0:15026
2024-05-31 20:34:04,840 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc2f84f11, L:/0.0.0.0:15026] ACTIVE
2024-05-31 20:34:04,846 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/tmp
2024-05-31 20:34:04,846 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(269)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/tmp is not a group directory; ignoring it. 
2024-05-31 20:34:04,847 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-05-31 20:34:04,848 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-05-31 20:34:04,850 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/meta/datanode.id
2024-05-31 20:34:04,851 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(157)) - Initializing replication supervisor with thread count = 10
2024-05-31 20:34:04,852 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-05-31 20:34:04,854 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15020
2024-05-31 20:34:04,855 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-05-31 20:34:04,856 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-05-31 20:34:04,860 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-05-31 20:34:04,862 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-05-31 20:34:04,863 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-05-31 20:34:04,863 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-05-31 20:34:04,863 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-05-31 20:34:04,864 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/meta/webserver
2024-05-31 20:34:04,864 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15020
2024-05-31 20:34:04,865 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 17.0.11+9
2024-05-31 20:34:04,869 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-05-31 20:34:04,869 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-05-31 20:34:04,869 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2024-05-31 20:34:04,870 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2fdbef8d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-05-31 20:34:04,871 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@4f7b4b50{static,/static,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/static,AVAILABLE}
2024-05-31 20:34:04,876 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@2563d994{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode}
2024-05-31 20:34:04,877 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@34ee9000{HTTP/1.1, (http/1.1)}{0.0.0.0:15020}
2024-05-31 20:34:04,877 [main] INFO  server.Server (Server.java:doStart(415)) - Started @21724ms
2024-05-31 20:34:04,877 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-05-31 20:34:04,878 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15020
2024-05-31 20:34:04,878 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-05-31 20:34:04,879 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15021
2024-05-31 20:34:04,882 [Socket Reader #1 for port 15021] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15021
2024-05-31 20:34:04,887 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(327)) - Datanode start with admins: [runner]
2024-05-31 20:34:04,887 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15021
2024-05-31 20:34:04,887 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-05-31 20:34:04,890 [IPC Server listener on 15021] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15021: starting
2024-05-31 20:34:04,894 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-05-31 20:34:04,894 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-05-31 20:34:04,894 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-05-31 20:34:04,904 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(555)) - Ozone container server started.
2024-05-31 20:34:04,919 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(240)) - HddsDatanodeService host:fv-az1343-628 ip:10.1.0.26
2024-05-31 20:34:04,934 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-05-31 20:34:04,938 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/meta/datanode.id
2024-05-31 20:34:04,953 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-05-31 20:34:04,955 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(299)) - Datanode State Machine Task Thread Pool size 2
2024-05-31 20:34:04,958 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(126)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/data-0/hdds of storage type : DISK capacity : 9222449699674390527
2024-05-31 20:34:04,959 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/data-0/hdds to VolumeSet
2024-05-31 20:34:04,960 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis to VolumeSet
2024-05-31 20:34:04,960 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 0ms
2024-05-31 20:34:04,964 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-05-31 20:34:04,964 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-05-31 20:34:04,964 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15033 (custom)
2024-05-31 20:34:04,965 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-05-31 20:34:04,965 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15032 (custom)
2024-05-31 20:34:04,965 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-05-31 20:34:04,965 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15034 (custom)
2024-05-31 20:34:04,966 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-05-31 20:34:04,966 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:04,966 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-05-31 20:34:04,966 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:04,967 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-05-31 20:34:04,967 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-05-31 20:34:04,967 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-05-31 20:34:04,969 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-05-31 20:34:04,969 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-05-31 20:34:04,969 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-05-31 20:34:04,969 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-05-31 20:34:04,970 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-05-31 20:34:04,970 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-05-31 20:34:04,970 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-05-31 20:34:04,970 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-05-31 20:34:04,970 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 390bac8a-0dbf-4715-b6fd-0c75abb5c43b-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-05-31 20:34:04,971 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-05-31 20:34:04,971 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 390bac8a-0dbf-4715-b6fd-0c75abb5c43b-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-05-31 20:34:04,971 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-05-31 20:34:04,972 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-05-31 20:34:04,972 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15035 (custom)
2024-05-31 20:34:04,972 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:04,972 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-05-31 20:34:04,972 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x379f52d1] REGISTERED
2024-05-31 20:34:04,973 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x379f52d1] BIND: 0.0.0.0/0.0.0.0:15035
2024-05-31 20:34:04,973 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x379f52d1, L:/0.0.0.0:15035] ACTIVE
2024-05-31 20:34:04,973 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:04,973 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis] (custom)
2024-05-31 20:34:04,973 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-05-31 20:34:04,974 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-05-31 20:34:04,974 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/tmp
2024-05-31 20:34:04,974 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(269)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/tmp is not a group directory; ignoring it. 
2024-05-31 20:34:04,974 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-05-31 20:34:04,976 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-05-31 20:34:04,978 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(157)) - Initializing replication supervisor with thread count = 10
2024-05-31 20:34:04,978 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-05-31 20:34:04,980 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15029
2024-05-31 20:34:04,980 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-05-31 20:34:04,981 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-05-31 20:34:04,982 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-05-31 20:34:04,983 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-05-31 20:34:04,984 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-05-31 20:34:04,984 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-05-31 20:34:04,984 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-05-31 20:34:04,985 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/meta/webserver
2024-05-31 20:34:04,986 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15029
2024-05-31 20:34:04,986 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 17.0.11+9
2024-05-31 20:34:04,991 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-05-31 20:34:04,991 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-05-31 20:34:04,991 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2024-05-31 20:34:04,992 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@47e4126a{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-05-31 20:34:04,993 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@67e9ae8c{static,/static,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/static,AVAILABLE}
2024-05-31 20:34:04,997 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@77c894d5{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode}
2024-05-31 20:34:04,998 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@49b6b53{HTTP/1.1, (http/1.1)}{0.0.0.0:15029}
2024-05-31 20:34:04,998 [main] INFO  server.Server (Server.java:doStart(415)) - Started @21846ms
2024-05-31 20:34:04,998 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-05-31 20:34:04,999 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15029
2024-05-31 20:34:05,000 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-05-31 20:34:05,001 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15030
2024-05-31 20:34:05,001 [Socket Reader #1 for port 15030] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15030
2024-05-31 20:34:05,004 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(327)) - Datanode start with admins: [runner]
2024-05-31 20:34:05,004 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15030
2024-05-31 20:34:05,006 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-05-31 20:34:05,006 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(555)) - Ozone container server started.
2024-05-31 20:34:05,006 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-05-31 20:34:05,006 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-05-31 20:34:05,007 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-05-31 20:34:05,007 [IPC Server listener on 15030] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15030: starting
2024-05-31 20:34:05,012 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-05-31 20:34:05,014 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/meta/datanode.id
2024-05-31 20:34:05,018 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(240)) - HddsDatanodeService host:fv-az1343-628 ip:10.1.0.26
2024-05-31 20:34:05,032 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-05-31 20:34:05,033 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(299)) - Datanode State Machine Task Thread Pool size 2
2024-05-31 20:34:05,035 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(126)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/data-0/hdds of storage type : DISK capacity : 9222449699674390527
2024-05-31 20:34:05,035 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/data-0/hdds to VolumeSet
2024-05-31 20:34:05,035 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis to VolumeSet
2024-05-31 20:34:05,036 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 0ms
2024-05-31 20:34:05,039 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-05-31 20:34:05,040 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-05-31 20:34:05,040 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15042 (custom)
2024-05-31 20:34:05,040 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-05-31 20:34:05,040 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15041 (custom)
2024-05-31 20:34:05,040 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-05-31 20:34:05,040 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15043 (custom)
2024-05-31 20:34:05,040 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-05-31 20:34:05,041 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:05,041 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-05-31 20:34:05,041 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:05,041 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-05-31 20:34:05,041 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-05-31 20:34:05,041 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-05-31 20:34:05,044 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-05-31 20:34:05,044 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-05-31 20:34:05,045 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-05-31 20:34:05,045 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-05-31 20:34:05,045 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-05-31 20:34:05,045 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-05-31 20:34:05,045 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-05-31 20:34:05,045 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-05-31 20:34:05,045 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for b079985c-91b9-4d2e-8c89-c2e47b34f7da-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-05-31 20:34:05,046 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-05-31 20:34:05,046 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for b079985c-91b9-4d2e-8c89-c2e47b34f7da-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-05-31 20:34:05,047 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-05-31 20:34:05,047 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-05-31 20:34:05,047 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15044 (custom)
2024-05-31 20:34:05,050 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:05,050 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-05-31 20:34:05,051 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:05,051 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis] (custom)
2024-05-31 20:34:05,051 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-05-31 20:34:05,051 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-05-31 20:34:05,052 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd3564359] REGISTERED
2024-05-31 20:34:05,052 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd3564359] BIND: 0.0.0.0/0.0.0.0:15044
2024-05-31 20:34:05,052 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd3564359, L:/0.0.0.0:15044] ACTIVE
2024-05-31 20:34:05,057 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/tmp
2024-05-31 20:34:05,057 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(269)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/tmp is not a group directory; ignoring it. 
2024-05-31 20:34:05,058 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-05-31 20:34:05,059 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-05-31 20:34:05,062 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(157)) - Initializing replication supervisor with thread count = 10
2024-05-31 20:34:05,062 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-05-31 20:34:05,065 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15038
2024-05-31 20:34:05,065 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-05-31 20:34:05,067 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-05-31 20:34:05,067 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-05-31 20:34:05,069 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-05-31 20:34:05,069 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-05-31 20:34:05,069 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-05-31 20:34:05,070 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-05-31 20:34:05,070 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/meta/webserver
2024-05-31 20:34:05,070 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15038
2024-05-31 20:34:05,070 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 17.0.11+9
2024-05-31 20:34:05,072 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-05-31 20:34:05,072 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-05-31 20:34:05,072 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2024-05-31 20:34:05,072 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@50f5cec3{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-05-31 20:34:05,073 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@39a9ef9a{static,/static,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/static,AVAILABLE}
2024-05-31 20:34:05,076 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@7aaa73f6{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode}
2024-05-31 20:34:05,077 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@37988190{HTTP/1.1, (http/1.1)}{0.0.0.0:15038}
2024-05-31 20:34:05,077 [main] INFO  server.Server (Server.java:doStart(415)) - Started @21925ms
2024-05-31 20:34:05,077 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-05-31 20:34:05,077 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15038
2024-05-31 20:34:05,078 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-05-31 20:34:05,078 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15039
2024-05-31 20:34:05,078 [Socket Reader #1 for port 15039] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15039
2024-05-31 20:34:05,080 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(327)) - Datanode start with admins: [runner]
2024-05-31 20:34:05,080 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15039
2024-05-31 20:34:05,080 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-05-31 20:34:05,080 [IPC Server listener on 15039] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15039: starting
2024-05-31 20:34:05,081 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(555)) - Ozone container server started.
2024-05-31 20:34:05,081 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-05-31 20:34:05,081 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-05-31 20:34:05,081 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-05-31 20:34:05,090 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-05-31 20:34:05,091 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(240)) - HddsDatanodeService host:fv-az1343-628 ip:10.1.0.26
2024-05-31 20:34:05,092 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/meta/datanode.id
2024-05-31 20:34:05,105 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-05-31 20:34:05,106 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(299)) - Datanode State Machine Task Thread Pool size 2
2024-05-31 20:34:05,108 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(126)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/data-0/hdds of storage type : DISK capacity : 9222449699674390527
2024-05-31 20:34:05,108 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/data-0/hdds to VolumeSet
2024-05-31 20:34:05,109 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis to VolumeSet
2024-05-31 20:34:05,109 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 0ms
2024-05-31 20:34:05,112 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-05-31 20:34:05,112 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-05-31 20:34:05,112 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15051 (custom)
2024-05-31 20:34:05,112 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-05-31 20:34:05,112 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15050 (custom)
2024-05-31 20:34:05,112 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-05-31 20:34:05,112 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15052 (custom)
2024-05-31 20:34:05,112 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-05-31 20:34:05,112 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:05,113 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-05-31 20:34:05,113 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:05,113 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-05-31 20:34:05,113 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-05-31 20:34:05,113 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-05-31 20:34:05,115 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-05-31 20:34:05,115 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-05-31 20:34:05,115 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-05-31 20:34:05,116 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-05-31 20:34:05,116 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-05-31 20:34:05,116 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-05-31 20:34:05,116 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-05-31 20:34:05,116 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-05-31 20:34:05,116 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 55857a12-8529-4f00-ab69-b96d955e4226-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-05-31 20:34:05,117 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-05-31 20:34:05,117 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 55857a12-8529-4f00-ab69-b96d955e4226-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-05-31 20:34:05,118 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-05-31 20:34:05,118 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-05-31 20:34:05,118 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15053 (custom)
2024-05-31 20:34:05,118 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:05,119 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-05-31 20:34:05,119 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:05,119 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis] (custom)
2024-05-31 20:34:05,119 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-05-31 20:34:05,119 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-05-31 20:34:05,120 [55857a12-8529-4f00-ab69-b96d955e4226-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9322d365] REGISTERED
2024-05-31 20:34:05,120 [55857a12-8529-4f00-ab69-b96d955e4226-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9322d365] BIND: 0.0.0.0/0.0.0.0:15053
2024-05-31 20:34:05,120 [55857a12-8529-4f00-ab69-b96d955e4226-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9322d365, L:/0.0.0.0:15053] ACTIVE
2024-05-31 20:34:05,124 [55857a12-8529-4f00-ab69-b96d955e4226-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - 55857a12-8529-4f00-ab69-b96d955e4226: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/tmp
2024-05-31 20:34:05,124 [55857a12-8529-4f00-ab69-b96d955e4226-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(269)) - 55857a12-8529-4f00-ab69-b96d955e4226: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/tmp is not a group directory; ignoring it. 
2024-05-31 20:34:05,125 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-05-31 20:34:05,126 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-05-31 20:34:05,130 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(157)) - Initializing replication supervisor with thread count = 10
2024-05-31 20:34:05,130 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-05-31 20:34:05,134 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15047
2024-05-31 20:34:05,134 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-05-31 20:34:05,136 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-05-31 20:34:05,137 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-05-31 20:34:05,139 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-05-31 20:34:05,141 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-05-31 20:34:05,141 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-05-31 20:34:05,142 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-05-31 20:34:05,143 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/meta/webserver
2024-05-31 20:34:05,143 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15047
2024-05-31 20:34:05,144 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 17.0.11+9
2024-05-31 20:34:05,147 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-05-31 20:34:05,147 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-05-31 20:34:05,147 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2024-05-31 20:34:05,151 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6b3abb75{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-05-31 20:34:05,151 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@23e2bcbe{static,/static,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/static,AVAILABLE}
2024-05-31 20:34:05,156 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:34:05,157 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@372f64d1{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode}
2024-05-31 20:34:05,158 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@67aa514a{HTTP/1.1, (http/1.1)}{0.0.0.0:15047}
2024-05-31 20:34:05,158 [main] INFO  server.Server (Server.java:doStart(415)) - Started @22005ms
2024-05-31 20:34:05,158 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-05-31 20:34:05,159 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15047
2024-05-31 20:34:05,159 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-05-31 20:34:05,159 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15048
2024-05-31 20:34:05,159 [Socket Reader #1 for port 15048] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15048
2024-05-31 20:34:05,162 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(327)) - Datanode start with admins: [runner]
2024-05-31 20:34:05,162 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15048
2024-05-31 20:34:05,162 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-05-31 20:34:05,162 [IPC Server listener on 15048] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15048: starting
2024-05-31 20:34:05,167 [55857a12-8529-4f00-ab69-b96d955e4226-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(555)) - Ozone container server started.
2024-05-31 20:34:05,169 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 0 of 5 DN Heartbeats.
2024-05-31 20:34:05,169 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-05-31 20:34:05,169 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-05-31 20:34:05,174 [55857a12-8529-4f00-ab69-b96d955e4226-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-05-31 20:34:05,176 [55857a12-8529-4f00-ab69-b96d955e4226-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/meta/datanode.id
2024-05-31 20:34:05,344 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:06,156 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:34:06,169 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 0 of 5 DN Heartbeats.
2024-05-31 20:34:06,169 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-05-31 20:34:06,169 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-05-31 20:34:06,346 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:06,834 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-8d549ed5-de89-43e1-898f-9aeb04fe8d8b/container.db to cache
2024-05-31 20:34:06,834 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(437)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-8d549ed5-de89-43e1-898f-9aeb04fe8d8b/container.db for volume DS-8d549ed5-de89-43e1-898f-9aeb04fe8d8b
2024-05-31 20:34:06,847 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/data-0/hdds
2024-05-31 20:34:06,847 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/data-0/hdds
2024-05-31 20:34:06,848 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-05-31 20:34:06,849 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/data-0/hdds
2024-05-31 20:34:06,867 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/data-0/hdds
2024-05-31 20:34:06,870 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis
2024-05-31 20:34:06,871 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis
2024-05-31 20:34:06,872 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-05-31 20:34:06,881 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-05-31 20:34:06,884 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15018
2024-05-31 20:34:06,884 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(566)) - Starting XceiverServerRatis 2fad9ecd-4424-4a8b-880f-fd93cda6f409
2024-05-31 20:34:06,885 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-05-31 20:34:06,890 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(406)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: start RPC server
2024-05-31 20:34:06,891 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: GrpcService started, listening on 15014
2024-05-31 20:34:06,892 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: GrpcService started, listening on 15016
2024-05-31 20:34:06,893 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: GrpcService started, listening on 15015
2024-05-31 20:34:06,893 [JvmPauseMonitor3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-2fad9ecd-4424-4a8b-880f-fd93cda6f409: Started
2024-05-31 20:34:06,893 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 2fad9ecd-4424-4a8b-880f-fd93cda6f409 is started using port 15014 for RATIS
2024-05-31 20:34:06,894 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 2fad9ecd-4424-4a8b-880f-fd93cda6f409 is started using port 15015 for RATIS_ADMIN
2024-05-31 20:34:06,894 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 2fad9ecd-4424-4a8b-880f-fd93cda6f409 is started using port 15016 for RATIS_SERVER
2024-05-31 20:34:06,894 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 2fad9ecd-4424-4a8b-880f-fd93cda6f409 is started using port 15017 for RATIS_DATASTREAM
2024-05-31 20:34:06,899 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-05-31 20:34:06,955 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-2ee1248f-f02f-4ff8-a917-5c5458f58215/container.db to cache
2024-05-31 20:34:06,955 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(437)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-2ee1248f-f02f-4ff8-a917-5c5458f58215/container.db for volume DS-2ee1248f-f02f-4ff8-a917-5c5458f58215
2024-05-31 20:34:06,957 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/data-0/hdds
2024-05-31 20:34:06,957 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/data-0/hdds
2024-05-31 20:34:06,957 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-05-31 20:34:06,957 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/data-0/hdds
2024-05-31 20:34:06,958 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/data-0/hdds
2024-05-31 20:34:06,959 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis
2024-05-31 20:34:06,959 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis
2024-05-31 20:34:06,960 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-05-31 20:34:06,960 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(75)) - Trying to initialize on demand scanner a second time on a datanode.
2024-05-31 20:34:06,963 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-05-31 20:34:06,964 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-05-31 20:34:06,964 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15027
2024-05-31 20:34:06,964 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(566)) - Starting XceiverServerRatis 076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:06,965 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(406)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: start RPC server
2024-05-31 20:34:06,966 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: GrpcService started, listening on 15023
2024-05-31 20:34:06,966 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: GrpcService started, listening on 15025
2024-05-31 20:34:06,967 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: GrpcService started, listening on 15024
2024-05-31 20:34:06,967 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 076ccc74-63d1-410b-8584-7a1d80cfc8c8 is started using port 15023 for RATIS
2024-05-31 20:34:06,967 [JvmPauseMonitor4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-076ccc74-63d1-410b-8584-7a1d80cfc8c8: Started
2024-05-31 20:34:06,967 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 076ccc74-63d1-410b-8584-7a1d80cfc8c8 is started using port 15024 for RATIS_ADMIN
2024-05-31 20:34:06,967 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 076ccc74-63d1-410b-8584-7a1d80cfc8c8 is started using port 15025 for RATIS_SERVER
2024-05-31 20:34:06,967 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 076ccc74-63d1-410b-8584-7a1d80cfc8c8 is started using port 15026 for RATIS_DATASTREAM
2024-05-31 20:34:06,974 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-05-31 20:34:07,038 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-cf1e182a-4d8d-4e20-b089-121cd677328f/container.db to cache
2024-05-31 20:34:07,038 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(437)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-cf1e182a-4d8d-4e20-b089-121cd677328f/container.db for volume DS-cf1e182a-4d8d-4e20-b089-121cd677328f
2024-05-31 20:34:07,040 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/data-0/hdds
2024-05-31 20:34:07,040 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/data-0/hdds
2024-05-31 20:34:07,040 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-05-31 20:34:07,041 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/data-0/hdds
2024-05-31 20:34:07,041 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/data-0/hdds
2024-05-31 20:34:07,042 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis
2024-05-31 20:34:07,042 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis
2024-05-31 20:34:07,043 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-05-31 20:34:07,043 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(75)) - Trying to initialize on demand scanner a second time on a datanode.
2024-05-31 20:34:07,044 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-05-31 20:34:07,044 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-05-31 20:34:07,045 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15036
2024-05-31 20:34:07,045 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(566)) - Starting XceiverServerRatis 390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:07,048 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(406)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: start RPC server
2024-05-31 20:34:07,048 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: GrpcService started, listening on 15032
2024-05-31 20:34:07,049 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: GrpcService started, listening on 15034
2024-05-31 20:34:07,049 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: GrpcService started, listening on 15033
2024-05-31 20:34:07,049 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 390bac8a-0dbf-4715-b6fd-0c75abb5c43b is started using port 15032 for RATIS
2024-05-31 20:34:07,049 [JvmPauseMonitor5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-390bac8a-0dbf-4715-b6fd-0c75abb5c43b: Started
2024-05-31 20:34:07,049 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 390bac8a-0dbf-4715-b6fd-0c75abb5c43b is started using port 15033 for RATIS_ADMIN
2024-05-31 20:34:07,050 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 390bac8a-0dbf-4715-b6fd-0c75abb5c43b is started using port 15034 for RATIS_SERVER
2024-05-31 20:34:07,050 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 390bac8a-0dbf-4715-b6fd-0c75abb5c43b is started using port 15035 for RATIS_DATASTREAM
2024-05-31 20:34:07,051 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-05-31 20:34:07,110 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-bb861fdb-1577-4261-bac7-37897f3298f1/container.db to cache
2024-05-31 20:34:07,110 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(437)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-bb861fdb-1577-4261-bac7-37897f3298f1/container.db for volume DS-bb861fdb-1577-4261-bac7-37897f3298f1
2024-05-31 20:34:07,112 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/data-0/hdds
2024-05-31 20:34:07,112 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/data-0/hdds
2024-05-31 20:34:07,113 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-05-31 20:34:07,113 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/data-0/hdds
2024-05-31 20:34:07,113 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/data-0/hdds
2024-05-31 20:34:07,114 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis
2024-05-31 20:34:07,115 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis
2024-05-31 20:34:07,116 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-05-31 20:34:07,116 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(75)) - Trying to initialize on demand scanner a second time on a datanode.
2024-05-31 20:34:07,117 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-05-31 20:34:07,117 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-05-31 20:34:07,118 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15045
2024-05-31 20:34:07,118 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(566)) - Starting XceiverServerRatis b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:07,123 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(406)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: start RPC server
2024-05-31 20:34:07,123 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: GrpcService started, listening on 15041
2024-05-31 20:34:07,123 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: GrpcService started, listening on 15043
2024-05-31 20:34:07,124 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: GrpcService started, listening on 15042
2024-05-31 20:34:07,126 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis b079985c-91b9-4d2e-8c89-c2e47b34f7da is started using port 15041 for RATIS
2024-05-31 20:34:07,126 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis b079985c-91b9-4d2e-8c89-c2e47b34f7da is started using port 15042 for RATIS_ADMIN
2024-05-31 20:34:07,126 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis b079985c-91b9-4d2e-8c89-c2e47b34f7da is started using port 15043 for RATIS_SERVER
2024-05-31 20:34:07,127 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis b079985c-91b9-4d2e-8c89-c2e47b34f7da is started using port 15044 for RATIS_DATASTREAM
2024-05-31 20:34:07,126 [JvmPauseMonitor6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-b079985c-91b9-4d2e-8c89-c2e47b34f7da: Started
2024-05-31 20:34:07,136 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-05-31 20:34:07,157 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:34:07,170 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 0 of 5 DN Heartbeats.
2024-05-31 20:34:07,170 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-05-31 20:34:07,170 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-05-31 20:34:07,192 [55857a12-8529-4f00-ab69-b96d955e4226-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-5b762a84-e74e-40ce-be1b-cce11c1437d3/container.db to cache
2024-05-31 20:34:07,192 [55857a12-8529-4f00-ab69-b96d955e4226-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(437)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-5b762a84-e74e-40ce-be1b-cce11c1437d3/container.db for volume DS-5b762a84-e74e-40ce-be1b-cce11c1437d3
2024-05-31 20:34:07,194 [55857a12-8529-4f00-ab69-b96d955e4226-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/data-0/hdds
2024-05-31 20:34:07,194 [55857a12-8529-4f00-ab69-b96d955e4226-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/data-0/hdds
2024-05-31 20:34:07,195 [55857a12-8529-4f00-ab69-b96d955e4226-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-05-31 20:34:07,195 [55857a12-8529-4f00-ab69-b96d955e4226-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/data-0/hdds
2024-05-31 20:34:07,195 [55857a12-8529-4f00-ab69-b96d955e4226-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/data-0/hdds
2024-05-31 20:34:07,196 [55857a12-8529-4f00-ab69-b96d955e4226-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis
2024-05-31 20:34:07,196 [55857a12-8529-4f00-ab69-b96d955e4226-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis
2024-05-31 20:34:07,197 [55857a12-8529-4f00-ab69-b96d955e4226-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-05-31 20:34:07,197 [55857a12-8529-4f00-ab69-b96d955e4226-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(75)) - Trying to initialize on demand scanner a second time on a datanode.
2024-05-31 20:34:07,198 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-05-31 20:34:07,198 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-05-31 20:34:07,199 [55857a12-8529-4f00-ab69-b96d955e4226-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15054
2024-05-31 20:34:07,199 [55857a12-8529-4f00-ab69-b96d955e4226-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(566)) - Starting XceiverServerRatis 55857a12-8529-4f00-ab69-b96d955e4226
2024-05-31 20:34:07,199 [55857a12-8529-4f00-ab69-b96d955e4226-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(406)) - 55857a12-8529-4f00-ab69-b96d955e4226: start RPC server
2024-05-31 20:34:07,200 [55857a12-8529-4f00-ab69-b96d955e4226-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 55857a12-8529-4f00-ab69-b96d955e4226: GrpcService started, listening on 15050
2024-05-31 20:34:07,200 [55857a12-8529-4f00-ab69-b96d955e4226-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 55857a12-8529-4f00-ab69-b96d955e4226: GrpcService started, listening on 15052
2024-05-31 20:34:07,201 [55857a12-8529-4f00-ab69-b96d955e4226-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 55857a12-8529-4f00-ab69-b96d955e4226: GrpcService started, listening on 15051
2024-05-31 20:34:07,201 [55857a12-8529-4f00-ab69-b96d955e4226-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 55857a12-8529-4f00-ab69-b96d955e4226 is started using port 15050 for RATIS
2024-05-31 20:34:07,201 [JvmPauseMonitor7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-55857a12-8529-4f00-ab69-b96d955e4226: Started
2024-05-31 20:34:07,201 [55857a12-8529-4f00-ab69-b96d955e4226-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 55857a12-8529-4f00-ab69-b96d955e4226 is started using port 15051 for RATIS_ADMIN
2024-05-31 20:34:07,201 [55857a12-8529-4f00-ab69-b96d955e4226-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 55857a12-8529-4f00-ab69-b96d955e4226 is started using port 15052 for RATIS_SERVER
2024-05-31 20:34:07,201 [55857a12-8529-4f00-ab69-b96d955e4226-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 55857a12-8529-4f00-ab69-b96d955e4226 is started using port 15053 for RATIS_DATASTREAM
2024-05-31 20:34:07,207 [55857a12-8529-4f00-ab69-b96d955e4226-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-05-31 20:34:07,347 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:08,157 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:34:08,170 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 0 of 5 DN Heartbeats.
2024-05-31 20:34:08,170 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-05-31 20:34:08,170 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-05-31 20:34:08,348 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:08,755 [IPC Server handler 0 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/2fad9ecd-4424-4a8b-880f-fd93cda6f409
2024-05-31 20:34:08,755 [IPC Server handler 1 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/2fad9ecd-4424-4a8b-880f-fd93cda6f409
2024-05-31 20:34:08,757 [IPC Server handler 1 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: 2fad9ecd-4424-4a8b-880f-fd93cda6f409{ip: 127.0.0.1, host: localhost, ports: [HTTP=15011, CLIENT_RPC=15012, REPLICATION=15018, RATIS=15014, RATIS_ADMIN=15015, RATIS_SERVER=15016, RATIS_DATASTREAM=15017, STANDALONE=15013], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-05-31 20:34:08,757 [IPC Server handler 0 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: 2fad9ecd-4424-4a8b-880f-fd93cda6f409{ip: 127.0.0.1, host: localhost, ports: [HTTP=15011, CLIENT_RPC=15012, REPLICATION=15018, RATIS=15014, RATIS_ADMIN=15015, RATIS_SERVER=15016, RATIS_DATASTREAM=15017, STANDALONE=15013], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-05-31 20:34:08,759 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-05-31 20:34:08,759 [IPC Server handler 0 on default port 15009] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from true to true.
2024-05-31 20:34:08,761 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(151)) - Adding new node 2fad9ecd-4424-4a8b-880f-fd93cda6f409 to Node DB.
2024-05-31 20:34:08,762 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), {type: FCR, size: 0}
2024-05-31 20:34:08,763 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2024-05-31 20:34:08,763 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(203)) - ContainerSafeModeRule rule is successfully validated
2024-05-31 20:34:08,764 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(203)) - AtleastOneDatanodeReportedRule rule is successfully validated
2024-05-31 20:34:08,766 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=0e0510fd-577d-4847-942d-1c3c34dfe8e1 to datanode:2fad9ecd-4424-4a8b-880f-fd93cda6f409
2024-05-31 20:34:08,783 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 0e0510fd-577d-4847-942d-1c3c34dfe8e1, Nodes: 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-05-31T20:34:08.766087834Z[Etc/UTC]]
2024-05-31 20:34:08,935 [IPC Server handler 2 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:08,936 [IPC Server handler 2 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: 076ccc74-63d1-410b-8584-7a1d80cfc8c8{ip: 127.0.0.1, host: localhost, ports: [HTTP=15020, CLIENT_RPC=15021, REPLICATION=15027, RATIS=15023, RATIS_ADMIN=15024, RATIS_SERVER=15025, RATIS_DATASTREAM=15026, STANDALONE=15022], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-05-31 20:34:08,935 [IPC Server handler 1 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:08,937 [IPC Server handler 1 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: 076ccc74-63d1-410b-8584-7a1d80cfc8c8{ip: 127.0.0.1, host: localhost, ports: [HTTP=15020, CLIENT_RPC=15021, REPLICATION=15027, RATIS=15023, RATIS_ADMIN=15024, RATIS_SERVER=15025, RATIS_DATASTREAM=15026, STANDALONE=15022], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-05-31 20:34:08,937 [IPC Server handler 1 on default port 15009] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from true to true.
2024-05-31 20:34:08,936 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2024-05-31 20:34:08,936 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-05-31 20:34:08,937 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(151)) - Adding new node 076ccc74-63d1-410b-8584-7a1d80cfc8c8 to Node DB.
2024-05-31 20:34:08,938 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=c43c2b80-c72a-4420-a2bc-0ead3654c05a to datanode:076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:08,939 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: c43c2b80-c72a-4420-a2bc-0ead3654c05a, Nodes: 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-05-31T20:34:08.938323711Z[Etc/UTC]]
2024-05-31 20:34:09,013 [IPC Server handler 2 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:09,013 [IPC Server handler 2 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b{ip: 127.0.0.1, host: localhost, ports: [HTTP=15029, CLIENT_RPC=15030, REPLICATION=15036, RATIS=15032, RATIS_ADMIN=15033, RATIS_SERVER=15034, RATIS_DATASTREAM=15035, STANDALONE=15031], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-05-31 20:34:09,014 [IPC Server handler 2 on default port 15009] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from true to true.
2024-05-31 20:34:09,015 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(151)) - Adding new node 390bac8a-0dbf-4715-b6fd-0c75abb5c43b to Node DB.
2024-05-31 20:34:09,013 [IPC Server handler 3 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:09,015 [IPC Server handler 3 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b{ip: 127.0.0.1, host: localhost, ports: [HTTP=15029, CLIENT_RPC=15030, REPLICATION=15036, RATIS=15032, RATIS_ADMIN=15033, RATIS_SERVER=15034, RATIS_DATASTREAM=15035, STANDALONE=15031], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-05-31 20:34:09,015 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2024-05-31 20:34:09,015 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(203)) - DataNodeSafeModeRule rule is successfully validated
2024-05-31 20:34:09,015 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(232)) - All SCM safe mode pre check rules have passed
2024-05-31 20:34:09,015 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-05-31 20:34:09,015 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(225)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2024-05-31 20:34:09,016 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-05-31 20:34:09,016 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=2cc65240-011a-451d-b3ff-9f8ad608864b to datanode:390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:09,017 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 2cc65240-011a-451d-b3ff-9f8ad608864b, Nodes: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-05-31T20:34:09.016577388Z[Etc/UTC]]
2024-05-31 20:34:09,020 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 to datanode:076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:09,020 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 to datanode:390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:09,021 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 to datanode:2fad9ecd-4424-4a8b-880f-fd93cda6f409
2024-05-31 20:34:09,022 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 9a915894-abff-4e14-8344-4a82ed352a01, Nodes: 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-05-31T20:34:09.020812735Z[Etc/UTC]]
2024-05-31 20:34:09,090 [IPC Server handler 4 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:09,091 [IPC Server handler 4 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: b079985c-91b9-4d2e-8c89-c2e47b34f7da{ip: 127.0.0.1, host: localhost, ports: [HTTP=15038, CLIENT_RPC=15039, REPLICATION=15045, RATIS=15041, RATIS_ADMIN=15042, RATIS_SERVER=15043, RATIS_DATASTREAM=15044, STANDALONE=15040], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-05-31 20:34:09,091 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-05-31 20:34:09,092 [IPC Server handler 3 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:09,092 [IPC Server handler 3 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: b079985c-91b9-4d2e-8c89-c2e47b34f7da{ip: 127.0.0.1, host: localhost, ports: [HTTP=15038, CLIENT_RPC=15039, REPLICATION=15045, RATIS=15041, RATIS_ADMIN=15042, RATIS_SERVER=15043, RATIS_DATASTREAM=15044, STANDALONE=15040], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-05-31 20:34:09,092 [IPC Server handler 3 on default port 15009] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from true to true.
2024-05-31 20:34:09,092 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(151)) - Adding new node b079985c-91b9-4d2e-8c89-c2e47b34f7da to Node DB.
2024-05-31 20:34:09,093 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=57400ce6-6596-49c1-8fbb-8f8ee659cc7b to datanode:b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:09,094 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 57400ce6-6596-49c1-8fbb-8f8ee659cc7b, Nodes: b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-05-31T20:34:09.093334074Z[Etc/UTC]]
2024-05-31 20:34:09,157 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:34:09,171 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 4 of 5 DN Heartbeats.
2024-05-31 20:34:09,171 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-05-31 20:34:09,171 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-05-31 20:34:09,174 [IPC Server handler 4 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/55857a12-8529-4f00-ab69-b96d955e4226
2024-05-31 20:34:09,174 [IPC Server handler 4 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: 55857a12-8529-4f00-ab69-b96d955e4226{ip: 127.0.0.1, host: localhost, ports: [HTTP=15047, CLIENT_RPC=15048, REPLICATION=15054, RATIS=15050, RATIS_ADMIN=15051, RATIS_SERVER=15052, RATIS_DATASTREAM=15053, STANDALONE=15049], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-05-31 20:34:09,175 [IPC Server handler 4 on default port 15009] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from true to true.
2024-05-31 20:34:09,175 [IPC Server handler 0 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/55857a12-8529-4f00-ab69-b96d955e4226
2024-05-31 20:34:09,175 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(151)) - Adding new node 55857a12-8529-4f00-ab69-b96d955e4226 to Node DB.
2024-05-31 20:34:09,175 [IPC Server handler 0 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: 55857a12-8529-4f00-ab69-b96d955e4226{ip: 127.0.0.1, host: localhost, ports: [HTTP=15047, CLIENT_RPC=15048, REPLICATION=15054, RATIS=15050, RATIS_ADMIN=15051, RATIS_SERVER=15052, RATIS_DATASTREAM=15053, STANDALONE=15049], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-05-31 20:34:09,176 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-05-31 20:34:09,177 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=2377c6a9-74bd-4894-88f5-ac6ba249094c to datanode:55857a12-8529-4f00-ab69-b96d955e4226
2024-05-31 20:34:09,178 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 2377c6a9-74bd-4894-88f5-ac6ba249094c, Nodes: 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-05-31T20:34:09.177187281Z[Etc/UTC]]
2024-05-31 20:34:09,350 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:10,157 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:34:10,171 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-05-31 20:34:10,171 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-05-31 20:34:10,171 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-05-31 20:34:10,351 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:10,761 [IPC Server handler 0 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(245)) - Sending ReregisterCommand() for localhost
2024-05-31 20:34:10,766 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 4 millisec, 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), {type: FCR, size: 0}
2024-05-31 20:34:10,766 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 4 millisec, 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), {type: FCR, size: 0}
2024-05-31 20:34:10,936 [IPC Server handler 1 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(245)) - Sending ReregisterCommand() for localhost
2024-05-31 20:34:11,012 [IPC Server handler 2 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(245)) - Sending ReregisterCommand() for localhost
2024-05-31 20:34:11,090 [IPC Server handler 3 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(245)) - Sending ReregisterCommand() for localhost
2024-05-31 20:34:11,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:34:11,172 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-05-31 20:34:11,172 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-05-31 20:34:11,172 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-05-31 20:34:11,175 [IPC Server handler 4 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(245)) - Sending ReregisterCommand() for localhost
2024-05-31 20:34:11,352 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:11,775 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: addNew group-1C3C34DFE8E1:[2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016] returns group-1C3C34DFE8E1:java.util.concurrent.CompletableFuture@27e8e676[Not completed]
2024-05-31 20:34:11,777 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  lib.Interns (Interns.java:removeEldestEntry(50)) - Metrics intern cache overflow at 2011 for MetricsSystem={MetricsSystem=MetricsInfoImpl{name=MetricsSystem, description=MetricsSystem}, MetricsSystem record=MetricsInfoImpl{name=MetricsSystem, description=MetricsSystem record}}
2024-05-31 20:34:11,781 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: new RaftServerImpl for group-1C3C34DFE8E1:[2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016] with ContainerStateMachine:uninitialized
2024-05-31 20:34:11,781 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:11,781 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-05-31 20:34:11,781 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:34:11,781 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-05-31 20:34:11,781 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:11,781 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:34:11,782 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:11,782 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1: ConfigurationManager, init=-1: peers:[2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:34:11,782 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-05-31 20:34:11,782 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:34:11,782 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-05-31 20:34:11,782 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:34:11,782 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:34:11,782 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:34:11,788 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:11,789 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:11,789 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:34:11,789 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:34:11,789 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:34:11,789 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:34:11,789 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-05-31 20:34:11,789 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-05-31 20:34:11,790 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis] (custom)
2024-05-31 20:34:11,790 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/0e0510fd-577d-4847-942d-1c3c34dfe8e1 does not exist. Creating ...
2024-05-31 20:34:11,791 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/0e0510fd-577d-4847-942d-1c3c34dfe8e1/in_use.lock acquired by nodename 83134@fv-az1343-628
2024-05-31 20:34:11,792 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/0e0510fd-577d-4847-942d-1c3c34dfe8e1 has been successfully formatted.
2024-05-31 20:34:11,792 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/0e0510fd-577d-4847-942d-1c3c34dfe8e1/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/0e0510fd-577d-4847-942d-1c3c34dfe8e1/current/raft-meta.conf
2024-05-31 20:34:11,794 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-1C3C34DFE8E1: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-05-31 20:34:11,794 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-05-31 20:34:11,795 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-05-31 20:34:11,795 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:11,795 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-05-31 20:34:11,795 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-05-31 20:34:11,797 [IPC Server handler 1 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(286)) - Updating nodeDB for localhost
2024-05-31 20:34:11,797 [IPC Server handler 1 on default port 15009] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from true to true.
2024-05-31 20:34:11,799 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:11,800 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-05-31 20:34:11,800 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-05-31 20:34:11,800 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:11,801 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=0e0510fd-577d-4847-942d-1c3c34dfe8e1
2024-05-31 20:34:11,801 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 4 millisec, 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), {type: FCR, size: 0}
2024-05-31 20:34:11,801 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 4 millisec, 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), {type: FCR, size: 0}
2024-05-31 20:34:11,802 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=0e0510fd-577d-4847-942d-1c3c34dfe8e1. Trying to get from SCM.
2024-05-31 20:34:11,806 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-cacheEviction-AwaitToRun,5,main] started
2024-05-31 20:34:11,807 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/0e0510fd-577d-4847-942d-1c3c34dfe8e1
2024-05-31 20:34:11,807 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-05-31 20:34:11,807 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-05-31 20:34:11,807 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:11,807 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-05-31 20:34:11,807 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-05-31 20:34:11,808 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-05-31 20:34:11,808 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-05-31 20:34:11,808 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-05-31 20:34:11,807 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines []
2024-05-31 20:34:11,808 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:11,807 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(86)) - Adding new pipeline Pipeline[ Id: 0e0510fd-577d-4847-942d-1c3c34dfe8e1, Nodes: 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:2fad9ecd-4424-4a8b-880f-fd93cda6f409, CreationTimestamp2024-05-31T20:34:08.766Z[Etc/UTC]] to Recon pipeline metadata.
2024-05-31 20:34:11,817 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 1 pipelines in house.
2024-05-31 20:34:11,817 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(110)) - Adding new pipeline PipelineID=57400ce6-6596-49c1-8fbb-8f8ee659cc7b from SCM.
2024-05-31 20:34:11,809 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-05-31 20:34:11,819 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:11,819 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-05-31 20:34:11,819 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-05-31 20:34:11,820 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-05-31 20:34:11,820 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:11,820 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:11,822 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(110)) - Adding new pipeline PipelineID=2cc65240-011a-451d-b3ff-9f8ad608864b from SCM.
2024-05-31 20:34:11,823 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(110)) - Adding new pipeline PipelineID=c43c2b80-c72a-4420-a2bc-0ead3654c05a from SCM.
2024-05-31 20:34:11,824 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(110)) - Adding new pipeline PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 from SCM.
2024-05-31 20:34:11,825 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(110)) - Adding new pipeline PipelineID=2377c6a9-74bd-4894-88f5-ac6ba249094c from SCM.
2024-05-31 20:34:11,828 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1: start as a follower, conf=-1: peers:[2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null
2024-05-31 20:34:11,828 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-05-31 20:34:11,828 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: start 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-FollowerState
2024-05-31 20:34:11,835 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1C3C34DFE8E1,id=2fad9ecd-4424-4a8b-880f-fd93cda6f409
2024-05-31 20:34:11,835 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-05-31 20:34:11,835 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-05-31 20:34:11,835 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-05-31 20:34:11,835 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-05-31 20:34:11,835 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-05-31 20:34:11,841 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=0e0510fd-577d-4847-942d-1c3c34dfe8e1
2024-05-31 20:34:11,841 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:11,841 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=0e0510fd-577d-4847-942d-1c3c34dfe8e1.
2024-05-31 20:34:11,842 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: addNew group-4A82ED352A01:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016] returns group-4A82ED352A01:java.util.concurrent.CompletableFuture@40b30dcb[Not completed]
2024-05-31 20:34:11,841 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:11,843 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: new RaftServerImpl for group-4A82ED352A01:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016] with ContainerStateMachine:uninitialized
2024-05-31 20:34:11,844 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:11,844 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-05-31 20:34:11,844 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:34:11,844 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-05-31 20:34:11,844 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:11,844 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:34:11,844 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:11,844 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01: ConfigurationManager, init=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:34:11,845 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-05-31 20:34:11,845 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:34:11,845 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-05-31 20:34:11,845 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:34:11,845 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:34:11,845 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:34:11,853 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:11,853 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:11,853 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:34:11,853 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:34:11,854 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:34:11,854 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:34:11,855 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-05-31 20:34:11,855 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-05-31 20:34:11,855 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis] (custom)
2024-05-31 20:34:11,856 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/9a915894-abff-4e14-8344-4a82ed352a01 does not exist. Creating ...
2024-05-31 20:34:11,857 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/9a915894-abff-4e14-8344-4a82ed352a01/in_use.lock acquired by nodename 83134@fv-az1343-628
2024-05-31 20:34:11,858 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/9a915894-abff-4e14-8344-4a82ed352a01 has been successfully formatted.
2024-05-31 20:34:11,858 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/9a915894-abff-4e14-8344-4a82ed352a01/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/9a915894-abff-4e14-8344-4a82ed352a01/current/raft-meta.conf
2024-05-31 20:34:11,859 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-4A82ED352A01: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-05-31 20:34:11,859 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-05-31 20:34:11,859 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-05-31 20:34:11,860 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:11,860 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-05-31 20:34:11,860 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-05-31 20:34:11,861 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:11,862 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 reported by 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1)
2024-05-31 20:34:11,866 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:11,868 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-05-31 20:34:11,868 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-05-31 20:34:11,868 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:11,869 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-cacheEviction-AwaitToRun,5,main] started
2024-05-31 20:34:11,869 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/9a915894-abff-4e14-8344-4a82ed352a01
2024-05-31 20:34:11,869 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-05-31 20:34:11,869 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-05-31 20:34:11,870 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:11,870 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-05-31 20:34:11,870 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-05-31 20:34:11,870 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-05-31 20:34:11,871 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-05-31 20:34:11,871 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-05-31 20:34:11,873 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-05-31 20:34:11,875 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:11,875 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-05-31 20:34:11,875 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-05-31 20:34:11,876 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-05-31 20:34:11,876 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:11,876 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:11,877 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01: start as a follower, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null
2024-05-31 20:34:11,877 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-05-31 20:34:11,877 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: start 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-FollowerState
2024-05-31 20:34:11,878 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:11,878 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4A82ED352A01,id=2fad9ecd-4424-4a8b-880f-fd93cda6f409
2024-05-31 20:34:11,878 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-05-31 20:34:11,878 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-05-31 20:34:11,879 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-05-31 20:34:11,879 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-05-31 20:34:11,879 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-05-31 20:34:11,878 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:11,881 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=9a915894-abff-4e14-8344-4a82ed352a01
2024-05-31 20:34:11,935 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: addNew group-0EAD3654C05A:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025] returns group-0EAD3654C05A:java.util.concurrent.CompletableFuture@41ca1186[Not completed]
2024-05-31 20:34:11,937 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: new RaftServerImpl for group-0EAD3654C05A:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025] with ContainerStateMachine:uninitialized
2024-05-31 20:34:11,937 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:11,937 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-05-31 20:34:11,937 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:34:11,937 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-05-31 20:34:11,938 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:11,938 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:34:11,938 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:11,938 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A: ConfigurationManager, init=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:34:11,938 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-05-31 20:34:11,938 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:34:11,938 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-05-31 20:34:11,938 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:34:11,939 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:34:11,939 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:34:11,944 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:11,945 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:11,945 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:34:11,945 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:34:11,945 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:34:11,945 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:34:11,945 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-05-31 20:34:11,945 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-05-31 20:34:11,946 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis] (custom)
2024-05-31 20:34:11,946 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/c43c2b80-c72a-4420-a2bc-0ead3654c05a does not exist. Creating ...
2024-05-31 20:34:11,947 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/c43c2b80-c72a-4420-a2bc-0ead3654c05a/in_use.lock acquired by nodename 83134@fv-az1343-628
2024-05-31 20:34:11,949 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/c43c2b80-c72a-4420-a2bc-0ead3654c05a has been successfully formatted.
2024-05-31 20:34:11,949 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/c43c2b80-c72a-4420-a2bc-0ead3654c05a/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/c43c2b80-c72a-4420-a2bc-0ead3654c05a/current/raft-meta.conf
2024-05-31 20:34:11,949 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-0EAD3654C05A: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-05-31 20:34:11,950 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-05-31 20:34:11,950 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-05-31 20:34:11,950 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:11,950 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-05-31 20:34:11,950 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-05-31 20:34:11,953 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:11,953 [IPC Server handler 4 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(286)) - Updating nodeDB for localhost
2024-05-31 20:34:11,954 [IPC Server handler 4 on default port 15009] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from true to true.
2024-05-31 20:34:11,954 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/ONE PipelineID=c43c2b80-c72a-4420-a2bc-0ead3654c05a reported by 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)
2024-05-31 20:34:11,954 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=c43c2b80-c72a-4420-a2bc-0ead3654c05a
2024-05-31 20:34:11,954 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:11,955 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-05-31 20:34:11,955 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-05-31 20:34:11,955 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:11,958 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-cacheEviction-AwaitToRun,5,main] started
2024-05-31 20:34:11,958 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/c43c2b80-c72a-4420-a2bc-0ead3654c05a
2024-05-31 20:34:11,959 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-05-31 20:34:11,959 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-05-31 20:34:11,959 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:11,959 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-05-31 20:34:11,959 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-05-31 20:34:11,959 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-05-31 20:34:11,959 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-05-31 20:34:11,959 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-05-31 20:34:11,960 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-05-31 20:34:11,962 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:11,963 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-05-31 20:34:11,963 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-05-31 20:34:11,963 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-05-31 20:34:11,963 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:11,963 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:11,966 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A: start as a follower, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025]|listeners:[], old=null
2024-05-31 20:34:11,966 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-05-31 20:34:11,967 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: start 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-FollowerState
2024-05-31 20:34:11,970 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0EAD3654C05A,id=076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:11,971 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-05-31 20:34:11,971 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-05-31 20:34:11,971 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-05-31 20:34:11,971 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-05-31 20:34:11,971 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-05-31 20:34:11,972 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:11,972 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:11,974 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=c43c2b80-c72a-4420-a2bc-0ead3654c05a
2024-05-31 20:34:11,975 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=c43c2b80-c72a-4420-a2bc-0ead3654c05a.
2024-05-31 20:34:11,975 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: addNew group-4A82ED352A01:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016] returns group-4A82ED352A01:java.util.concurrent.CompletableFuture@45f59d67[Not completed]
2024-05-31 20:34:11,977 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: new RaftServerImpl for group-4A82ED352A01:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016] with ContainerStateMachine:uninitialized
2024-05-31 20:34:11,978 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:11,978 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-05-31 20:34:11,978 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:34:11,978 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-05-31 20:34:11,978 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:11,978 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:34:11,978 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:11,978 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01: ConfigurationManager, init=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:34:11,979 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-05-31 20:34:11,979 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:34:11,979 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-05-31 20:34:11,979 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:34:11,979 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:34:11,979 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:34:11,984 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:11,984 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:11,984 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:34:11,985 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:34:11,985 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:34:11,985 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:34:11,985 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-05-31 20:34:11,985 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-05-31 20:34:11,985 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis] (custom)
2024-05-31 20:34:11,986 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/9a915894-abff-4e14-8344-4a82ed352a01 does not exist. Creating ...
2024-05-31 20:34:11,987 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/9a915894-abff-4e14-8344-4a82ed352a01/in_use.lock acquired by nodename 83134@fv-az1343-628
2024-05-31 20:34:11,989 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/9a915894-abff-4e14-8344-4a82ed352a01 has been successfully formatted.
2024-05-31 20:34:11,989 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/9a915894-abff-4e14-8344-4a82ed352a01/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/9a915894-abff-4e14-8344-4a82ed352a01/current/raft-meta.conf
2024-05-31 20:34:11,990 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-4A82ED352A01: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-05-31 20:34:11,990 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-05-31 20:34:11,990 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-05-31 20:34:11,990 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:11,990 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-05-31 20:34:11,990 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-05-31 20:34:11,992 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 reported by 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)
2024-05-31 20:34:11,992 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:11,994 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:11,994 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-05-31 20:34:11,995 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-05-31 20:34:11,995 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:11,995 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-cacheEviction-AwaitToRun,5,main] started
2024-05-31 20:34:11,995 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/9a915894-abff-4e14-8344-4a82ed352a01
2024-05-31 20:34:11,995 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-05-31 20:34:11,995 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-05-31 20:34:11,995 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:11,995 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-05-31 20:34:11,996 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-05-31 20:34:11,996 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-05-31 20:34:11,996 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-05-31 20:34:11,996 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-05-31 20:34:11,996 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-05-31 20:34:11,999 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:11,999 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-05-31 20:34:11,999 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-05-31 20:34:11,999 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-05-31 20:34:11,999 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:11,999 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:11,999 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01: start as a follower, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null
2024-05-31 20:34:12,000 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-05-31 20:34:12,000 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: start 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-FollowerState
2024-05-31 20:34:12,000 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:12,000 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4A82ED352A01,id=076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:12,000 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:12,000 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-05-31 20:34:12,000 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-05-31 20:34:12,000 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-05-31 20:34:12,001 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-05-31 20:34:12,001 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-05-31 20:34:12,002 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=9a915894-abff-4e14-8344-4a82ed352a01
2024-05-31 20:34:12,012 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: addNew group-9F8AD608864B:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034] returns group-9F8AD608864B:java.util.concurrent.CompletableFuture@4b491916[Not completed]
2024-05-31 20:34:12,015 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: new RaftServerImpl for group-9F8AD608864B:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034] with ContainerStateMachine:uninitialized
2024-05-31 20:34:12,015 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:12,015 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-05-31 20:34:12,015 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:34:12,015 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-05-31 20:34:12,015 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:12,015 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:34:12,015 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:12,015 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B: ConfigurationManager, init=-1: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:34:12,015 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-05-31 20:34:12,015 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:34:12,016 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-05-31 20:34:12,016 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:34:12,016 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:34:12,016 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:34:12,019 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:12,019 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:12,019 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:34:12,019 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:34:12,019 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:34:12,019 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:34:12,019 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-05-31 20:34:12,020 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-05-31 20:34:12,020 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis] (custom)
2024-05-31 20:34:12,020 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/2cc65240-011a-451d-b3ff-9f8ad608864b does not exist. Creating ...
2024-05-31 20:34:12,021 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/2cc65240-011a-451d-b3ff-9f8ad608864b/in_use.lock acquired by nodename 83134@fv-az1343-628
2024-05-31 20:34:12,022 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/2cc65240-011a-451d-b3ff-9f8ad608864b has been successfully formatted.
2024-05-31 20:34:12,022 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/2cc65240-011a-451d-b3ff-9f8ad608864b/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/2cc65240-011a-451d-b3ff-9f8ad608864b/current/raft-meta.conf
2024-05-31 20:34:12,023 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-9F8AD608864B: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-05-31 20:34:12,023 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-05-31 20:34:12,023 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-05-31 20:34:12,025 [IPC Server handler 7 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(286)) - Updating nodeDB for localhost
2024-05-31 20:34:12,026 [IPC Server handler 7 on default port 15009] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from true to true.
2024-05-31 20:34:12,023 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:12,026 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-05-31 20:34:12,026 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-05-31 20:34:12,026 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/ONE PipelineID=2cc65240-011a-451d-b3ff-9f8ad608864b reported by 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)
2024-05-31 20:34:12,026 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=2cc65240-011a-451d-b3ff-9f8ad608864b
2024-05-31 20:34:12,027 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:12,032 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:12,033 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-05-31 20:34:12,033 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-05-31 20:34:12,033 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:12,033 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-cacheEviction-AwaitToRun,5,main] started
2024-05-31 20:34:12,033 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/2cc65240-011a-451d-b3ff-9f8ad608864b
2024-05-31 20:34:12,033 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-05-31 20:34:12,033 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-05-31 20:34:12,033 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:12,034 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-05-31 20:34:12,034 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-05-31 20:34:12,034 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-05-31 20:34:12,034 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-05-31 20:34:12,034 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-05-31 20:34:12,035 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-05-31 20:34:12,036 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:12,036 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-05-31 20:34:12,036 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-05-31 20:34:12,036 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-05-31 20:34:12,036 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:12,037 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:12,040 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B: start as a follower, conf=-1: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:34:12,040 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-05-31 20:34:12,040 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: start 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-FollowerState
2024-05-31 20:34:12,041 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:12,041 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9F8AD608864B,id=390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:12,041 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-05-31 20:34:12,041 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-05-31 20:34:12,041 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-05-31 20:34:12,041 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-05-31 20:34:12,042 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-05-31 20:34:12,046 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:12,047 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=2cc65240-011a-451d-b3ff-9f8ad608864b
2024-05-31 20:34:12,047 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=2cc65240-011a-451d-b3ff-9f8ad608864b.
2024-05-31 20:34:12,047 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: addNew group-4A82ED352A01:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016] returns group-4A82ED352A01:java.util.concurrent.CompletableFuture@4f7694a7[Not completed]
2024-05-31 20:34:12,048 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: new RaftServerImpl for group-4A82ED352A01:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016] with ContainerStateMachine:uninitialized
2024-05-31 20:34:12,048 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:12,048 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-05-31 20:34:12,049 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:34:12,049 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-05-31 20:34:12,049 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:12,049 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:34:12,049 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:12,049 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01: ConfigurationManager, init=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:34:12,049 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-05-31 20:34:12,049 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:34:12,049 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-05-31 20:34:12,049 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:34:12,049 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:34:12,050 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:34:12,054 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:12,055 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:12,055 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:34:12,055 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:34:12,055 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:34:12,055 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:34:12,055 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-05-31 20:34:12,055 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-05-31 20:34:12,055 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis] (custom)
2024-05-31 20:34:12,056 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/9a915894-abff-4e14-8344-4a82ed352a01 does not exist. Creating ...
2024-05-31 20:34:12,058 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/9a915894-abff-4e14-8344-4a82ed352a01/in_use.lock acquired by nodename 83134@fv-az1343-628
2024-05-31 20:34:12,059 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/9a915894-abff-4e14-8344-4a82ed352a01 has been successfully formatted.
2024-05-31 20:34:12,060 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/9a915894-abff-4e14-8344-4a82ed352a01/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/9a915894-abff-4e14-8344-4a82ed352a01/current/raft-meta.conf
2024-05-31 20:34:12,060 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-4A82ED352A01: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-05-31 20:34:12,060 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-05-31 20:34:12,060 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-05-31 20:34:12,060 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:12,061 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-05-31 20:34:12,061 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-05-31 20:34:12,063 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 reported by 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)
2024-05-31 20:34:12,063 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:12,065 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:12,066 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-05-31 20:34:12,066 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-05-31 20:34:12,066 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:12,073 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-cacheEviction-AwaitToRun,5,main] started
2024-05-31 20:34:12,074 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/9a915894-abff-4e14-8344-4a82ed352a01
2024-05-31 20:34:12,074 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-05-31 20:34:12,074 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-05-31 20:34:12,074 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:12,074 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-05-31 20:34:12,074 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-05-31 20:34:12,074 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-05-31 20:34:12,074 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-05-31 20:34:12,074 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-05-31 20:34:12,076 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-05-31 20:34:12,079 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:12,079 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-05-31 20:34:12,079 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-05-31 20:34:12,079 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-05-31 20:34:12,079 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:12,079 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:12,082 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01: start as a follower, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null
2024-05-31 20:34:12,082 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-05-31 20:34:12,083 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: start 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-FollowerState
2024-05-31 20:34:12,083 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-4A82ED352A01,id=390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:12,083 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-05-31 20:34:12,083 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-05-31 20:34:12,083 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-05-31 20:34:12,083 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-05-31 20:34:12,083 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-05-31 20:34:12,083 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:12,085 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=9a915894-abff-4e14-8344-4a82ed352a01
2024-05-31 20:34:12,085 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:12,098 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: addNew group-8F8EE659CC7B:[b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043] returns group-8F8EE659CC7B:java.util.concurrent.CompletableFuture@7f74bd00[Not completed]
2024-05-31 20:34:12,101 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: new RaftServerImpl for group-8F8EE659CC7B:[b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043] with ContainerStateMachine:uninitialized
2024-05-31 20:34:12,101 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:12,102 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-05-31 20:34:12,102 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:34:12,102 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-05-31 20:34:12,102 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:12,102 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:34:12,102 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:12,102 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B: ConfigurationManager, init=-1: peers:[b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:34:12,103 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-05-31 20:34:12,103 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:34:12,103 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-05-31 20:34:12,103 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:34:12,103 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:34:12,103 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:34:12,107 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=57400ce6-6596-49c1-8fbb-8f8ee659cc7b]
2024-05-31 20:34:12,109 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=57400ce6-6596-49c1-8fbb-8f8ee659cc7b moved to CLOSED state
2024-05-31 20:34:12,114 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 6 pipelines in house.
2024-05-31 20:34:12,116 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:12,117 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:12,118 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:34:12,119 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:34:12,120 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:34:12,122 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:34:12,122 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-05-31 20:34:12,122 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-05-31 20:34:12,123 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis] (custom)
2024-05-31 20:34:12,124 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/57400ce6-6596-49c1-8fbb-8f8ee659cc7b does not exist. Creating ...
2024-05-31 20:34:12,133 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/57400ce6-6596-49c1-8fbb-8f8ee659cc7b/in_use.lock acquired by nodename 83134@fv-az1343-628
2024-05-31 20:34:12,145 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/57400ce6-6596-49c1-8fbb-8f8ee659cc7b has been successfully formatted.
2024-05-31 20:34:12,146 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/57400ce6-6596-49c1-8fbb-8f8ee659cc7b/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/57400ce6-6596-49c1-8fbb-8f8ee659cc7b/current/raft-meta.conf
2024-05-31 20:34:12,147 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-8F8EE659CC7B: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-05-31 20:34:12,147 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-05-31 20:34:12,148 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-05-31 20:34:12,148 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:12,150 [IPC Server handler 10 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(286)) - Updating nodeDB for localhost
2024-05-31 20:34:12,150 [IPC Server handler 10 on default port 15009] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from true to true.
2024-05-31 20:34:12,150 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/ONE PipelineID=57400ce6-6596-49c1-8fbb-8f8ee659cc7b reported by b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1)
2024-05-31 20:34:12,150 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=57400ce6-6596-49c1-8fbb-8f8ee659cc7b
2024-05-31 20:34:12,151 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:12,151 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-05-31 20:34:12,152 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-05-31 20:34:12,154 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:12,155 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-05-31 20:34:12,155 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-05-31 20:34:12,155 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:12,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:34:12,160 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-cacheEviction-AwaitToRun,5,main] started
2024-05-31 20:34:12,160 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/57400ce6-6596-49c1-8fbb-8f8ee659cc7b
2024-05-31 20:34:12,160 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-05-31 20:34:12,160 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-05-31 20:34:12,160 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:12,160 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-05-31 20:34:12,161 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-05-31 20:34:12,161 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-05-31 20:34:12,161 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-05-31 20:34:12,161 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-05-31 20:34:12,161 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-05-31 20:34:12,164 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:12,164 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-05-31 20:34:12,164 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-05-31 20:34:12,164 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-05-31 20:34:12,164 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:12,164 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:12,166 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B: start as a follower, conf=-1: peers:[b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:12,166 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-05-31 20:34:12,167 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: start b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-FollowerState
2024-05-31 20:34:12,167 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8F8EE659CC7B,id=b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:12,167 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-05-31 20:34:12,167 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-05-31 20:34:12,167 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-05-31 20:34:12,168 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-05-31 20:34:12,168 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-05-31 20:34:12,168 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:12,169 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:12,169 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=57400ce6-6596-49c1-8fbb-8f8ee659cc7b
2024-05-31 20:34:12,170 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=57400ce6-6596-49c1-8fbb-8f8ee659cc7b.
2024-05-31 20:34:12,172 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-05-31 20:34:12,172 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-05-31 20:34:12,172 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-05-31 20:34:12,181 [55857a12-8529-4f00-ab69-b96d955e4226-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 55857a12-8529-4f00-ab69-b96d955e4226: addNew group-AC6BA249094C:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052] returns group-AC6BA249094C:java.util.concurrent.CompletableFuture@190f9727[Not completed]
2024-05-31 20:34:12,183 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 55857a12-8529-4f00-ab69-b96d955e4226: new RaftServerImpl for group-AC6BA249094C:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052] with ContainerStateMachine:uninitialized
2024-05-31 20:34:12,183 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:12,183 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-05-31 20:34:12,183 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:34:12,183 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-05-31 20:34:12,183 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:12,183 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:34:12,183 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:12,184 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C: ConfigurationManager, init=-1: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:34:12,184 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-05-31 20:34:12,184 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:34:12,184 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-05-31 20:34:12,184 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:34:12,184 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:34:12,184 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:34:12,195 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:12,195 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:12,195 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:34:12,195 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:34:12,195 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:34:12,196 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:34:12,196 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-05-31 20:34:12,196 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-05-31 20:34:12,196 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis] (custom)
2024-05-31 20:34:12,196 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/2377c6a9-74bd-4894-88f5-ac6ba249094c does not exist. Creating ...
2024-05-31 20:34:12,198 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/2377c6a9-74bd-4894-88f5-ac6ba249094c/in_use.lock acquired by nodename 83134@fv-az1343-628
2024-05-31 20:34:12,200 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/2377c6a9-74bd-4894-88f5-ac6ba249094c has been successfully formatted.
2024-05-31 20:34:12,200 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/2377c6a9-74bd-4894-88f5-ac6ba249094c/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/2377c6a9-74bd-4894-88f5-ac6ba249094c/current/raft-meta.conf
2024-05-31 20:34:12,200 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-AC6BA249094C: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-05-31 20:34:12,200 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-05-31 20:34:12,200 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-05-31 20:34:12,200 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:12,201 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-05-31 20:34:12,201 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-05-31 20:34:12,203 [IPC Server handler 12 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(286)) - Updating nodeDB for localhost
2024-05-31 20:34:12,203 [IPC Server handler 12 on default port 15009] INFO  recon.ReconContext (ReconContext.java:updateHealthStatus(77)) - Update healthStatus of Recon from true to true.
2024-05-31 20:34:12,203 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=2377c6a9-74bd-4894-88f5-ac6ba249094c
2024-05-31 20:34:12,203 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:12,203 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/ONE PipelineID=2377c6a9-74bd-4894-88f5-ac6ba249094c reported by 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1)
2024-05-31 20:34:12,204 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:12,204 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-05-31 20:34:12,204 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-05-31 20:34:12,204 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:12,205 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-cacheEviction-AwaitToRun,5,main] started
2024-05-31 20:34:12,205 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/2377c6a9-74bd-4894-88f5-ac6ba249094c
2024-05-31 20:34:12,205 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-05-31 20:34:12,205 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-05-31 20:34:12,205 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:12,206 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-05-31 20:34:12,206 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-05-31 20:34:12,206 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-05-31 20:34:12,206 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-05-31 20:34:12,206 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-05-31 20:34:12,206 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-05-31 20:34:12,208 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=2377c6a9-74bd-4894-88f5-ac6ba249094c]
2024-05-31 20:34:12,209 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=2377c6a9-74bd-4894-88f5-ac6ba249094c moved to CLOSED state
2024-05-31 20:34:12,211 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 6 pipelines in house.
2024-05-31 20:34:12,213 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:12,213 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-05-31 20:34:12,213 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-05-31 20:34:12,213 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-05-31 20:34:12,214 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:12,214 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:12,214 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C: start as a follower, conf=-1: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052]|listeners:[], old=null
2024-05-31 20:34:12,214 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-05-31 20:34:12,214 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 55857a12-8529-4f00-ab69-b96d955e4226: start 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-FollowerState
2024-05-31 20:34:12,217 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AC6BA249094C,id=55857a12-8529-4f00-ab69-b96d955e4226
2024-05-31 20:34:12,217 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-05-31 20:34:12,217 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-05-31 20:34:12,218 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-05-31 20:34:12,218 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-05-31 20:34:12,218 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-05-31 20:34:12,219 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:12,222 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:12,235 [55857a12-8529-4f00-ab69-b96d955e4226-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=2377c6a9-74bd-4894-88f5-ac6ba249094c
2024-05-31 20:34:12,235 [55857a12-8529-4f00-ab69-b96d955e4226-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=2377c6a9-74bd-4894-88f5-ac6ba249094c.
2024-05-31 20:34:12,354 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:12,380 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=9a915894-abff-4e14-8344-4a82ed352a01.
2024-05-31 20:34:12,382 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=9a915894-abff-4e14-8344-4a82ed352a01.
2024-05-31 20:34:12,382 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=9a915894-abff-4e14-8344-4a82ed352a01.
2024-05-31 20:34:12,861 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 reported by 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1)
2024-05-31 20:34:12,861 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:12,992 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:12,992 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 reported by 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)
2024-05-31 20:34:13,062 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:13,062 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 reported by 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)
2024-05-31 20:34:13,149 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:13,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:34:13,172 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-05-31 20:34:13,173 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-05-31 20:34:13,173 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-05-31 20:34:13,355 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:13,862 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 reported by 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1)
2024-05-31 20:34:13,862 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:14,149 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:14,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:34:14,173 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-05-31 20:34:14,173 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-05-31 20:34:14,173 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-05-31 20:34:14,202 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:14,356 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:14,992 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 reported by 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)
2024-05-31 20:34:14,992 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:15,062 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 reported by 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)
2024-05-31 20:34:15,062 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:15,063 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), {type: FCR, size: 0}
2024-05-31 20:34:15,158 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:34:15,173 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-05-31 20:34:15,173 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-05-31 20:34:15,174 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-05-31 20:34:15,201 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:15,358 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:15,862 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:15,862 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 reported by 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1)
2024-05-31 20:34:15,992 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 reported by 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)
2024-05-31 20:34:15,992 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:16,149 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:16,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:34:16,174 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-05-31 20:34:16,174 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-05-31 20:34:16,174 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-05-31 20:34:16,359 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:16,858 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5029879328ns, electionTimeout:5015ms
2024-05-31 20:34:16,858 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: shutdown 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-FollowerState
2024-05-31 20:34:16,858 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-05-31 20:34:16,859 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-05-31 20:34:16,859 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: start 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2
2024-05-31 20:34:16,859 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null
2024-05-31 20:34:16,860 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2 PRE_VOTE round 0: result PASSED (term=0)
2024-05-31 20:34:16,862 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 reported by 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1)
2024-05-31 20:34:16,863 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:16,864 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: peers:[2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null
2024-05-31 20:34:16,864 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2 ELECTION round 0: result PASSED (term=1)
2024-05-31 20:34:16,865 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: shutdown 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2
2024-05-31 20:34:16,865 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-05-31 20:34:16,866 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-05-31 20:34:16,866 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:34:16,867 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-05-31 20:34:16,868 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-05-31 20:34:16,868 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-05-31 20:34:16,868 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-05-31 20:34:16,869 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-05-31 20:34:16,869 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-05-31 20:34:16,870 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:16,870 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:34:16,870 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-05-31 20:34:16,871 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: start 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderStateImpl
2024-05-31 20:34:16,871 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1: set firstElectionSinceStartup to false for becomeLeader
2024-05-31 20:34:16,872 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-1C3C34DFE8E1 with new leaderId: 2fad9ecd-4424-4a8b-880f-fd93cda6f409
2024-05-31 20:34:16,872 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1: change Leader from null to 2fad9ecd-4424-4a8b-880f-fd93cda6f409 at term 1 for becomeLeader, leader elected after 5089ms
2024-05-31 20:34:16,873 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-SegmentedRaftLogWorker: Starting segment from index:0
2024-05-31 20:34:16,874 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-05-31 20:34:16,875 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderElection2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1: set configuration 0: peers:[2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null
2024-05-31 20:34:16,875 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 reported by 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1)
2024-05-31 20:34:16,878 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:16,881 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/0e0510fd-577d-4847-942d-1c3c34dfe8e1/current/log_inprogress_0
2024-05-31 20:34:16,884 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-05-31 20:34:16,966 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5088501751ns, electionTimeout:5086ms
2024-05-31 20:34:16,966 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: shutdown 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-FollowerState
2024-05-31 20:34:16,966 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-05-31 20:34:16,966 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-05-31 20:34:16,966 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: start 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-LeaderElection3
2024-05-31 20:34:16,967 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-LeaderElection3 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null
2024-05-31 20:34:16,972 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:16,972 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:16,973 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-LeaderElection3-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025
2024-05-31 20:34:16,973 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-LeaderElection3-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034
2024-05-31 20:34:16,983 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01: receive requestVote(PRE_VOTE, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, group-4A82ED352A01, 0, (t:0, i:0))
2024-05-31 20:34:16,985 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-FOLLOWER: reject PRE_VOTE from 2fad9ecd-4424-4a8b-880f-fd93cda6f409: our priority 1 > candidate's priority 0
2024-05-31 20:34:16,993 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01: receive requestVote(PRE_VOTE, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, group-4A82ED352A01, 0, (t:0, i:0))
2024-05-31 20:34:16,993 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-FOLLOWER: accept PRE_VOTE from 2fad9ecd-4424-4a8b-880f-fd93cda6f409: our priority 0 <= candidate's priority 0
2024-05-31 20:34:16,995 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01 replies to PRE_VOTE vote request: 2fad9ecd-4424-4a8b-880f-fd93cda6f409<-076ccc74-63d1-410b-8584-7a1d80cfc8c8#0:FAIL-t0. Peer's state: 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01:t0, leader=null, voted=, raftlog=Memoized:076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null
2024-05-31 20:34:16,995 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01 replies to PRE_VOTE vote request: 2fad9ecd-4424-4a8b-880f-fd93cda6f409<-390bac8a-0dbf-4715-b6fd-0c75abb5c43b#0:OK-t0. Peer's state: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01:t0, leader=null, voted=, raftlog=Memoized:390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null
2024-05-31 20:34:16,998 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5031792953ns, electionTimeout:5026ms
2024-05-31 20:34:16,999 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: shutdown 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-FollowerState
2024-05-31 20:34:16,999 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-05-31 20:34:16,999 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-05-31 20:34:16,999 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: start 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4
2024-05-31 20:34:17,002 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-LeaderElection3: PRE_VOTE REJECTED received 2 response(s) and 0 exception(s):
2024-05-31 20:34:17,002 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 2fad9ecd-4424-4a8b-880f-fd93cda6f409<-076ccc74-63d1-410b-8584-7a1d80cfc8c8#0:FAIL-t0
2024-05-31 20:34:17,002 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 1: 2fad9ecd-4424-4a8b-880f-fd93cda6f409<-390bac8a-0dbf-4715-b6fd-0c75abb5c43b#0:OK-t0
2024-05-31 20:34:17,002 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-LeaderElection3 PRE_VOTE round 0: result REJECTED
2024-05-31 20:34:17,002 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-LeaderElection3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2024-05-31 20:34:17,002 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: shutdown 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-LeaderElection3
2024-05-31 20:34:17,002 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: start 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-FollowerState
2024-05-31 20:34:17,006 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025]|listeners:[], old=null
2024-05-31 20:34:17,013 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4 PRE_VOTE round 0: result PASSED (term=0)
2024-05-31 20:34:17,014 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-LeaderElection3] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01: set firstElectionSinceStartup to false for REJECTED
2024-05-31 20:34:17,016 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4 ELECTION round 0: submit vote requests at term 1 for -1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025]|listeners:[], old=null
2024-05-31 20:34:17,017 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4 ELECTION round 0: result PASSED (term=1)
2024-05-31 20:34:17,017 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: shutdown 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4
2024-05-31 20:34:17,017 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-05-31 20:34:17,017 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-05-31 20:34:17,017 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:34:17,018 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-05-31 20:34:17,018 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-05-31 20:34:17,018 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-05-31 20:34:17,018 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-05-31 20:34:17,019 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-05-31 20:34:17,019 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-05-31 20:34:17,019 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:17,020 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:34:17,020 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-05-31 20:34:17,020 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: start 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderStateImpl
2024-05-31 20:34:17,020 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A: set firstElectionSinceStartup to false for becomeLeader
2024-05-31 20:34:17,021 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-0EAD3654C05A with new leaderId: 076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:17,022 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A: change Leader from null to 076ccc74-63d1-410b-8584-7a1d80cfc8c8 at term 1 for becomeLeader, leader elected after 5082ms
2024-05-31 20:34:17,022 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-SegmentedRaftLogWorker: Starting segment from index:0
2024-05-31 20:34:17,023 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-05-31 20:34:17,024 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderElection4] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A: set configuration 0: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025]|listeners:[], old=null
2024-05-31 20:34:17,027 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:17,027 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 reported by 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)
2024-05-31 20:34:17,031 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/c43c2b80-c72a-4420-a2bc-0ead3654c05a/current/log_inprogress_0
2024-05-31 20:34:17,034 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-05-31 20:34:17,066 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:17,068 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5027283647ns, electionTimeout:5021ms
2024-05-31 20:34:17,068 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-FollowerState
2024-05-31 20:34:17,068 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-05-31 20:34:17,068 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-05-31 20:34:17,068 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: start 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5
2024-05-31 20:34:17,068 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 reported by 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)
2024-05-31 20:34:17,069 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:34:17,069 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5 PRE_VOTE round 0: result PASSED (term=0)
2024-05-31 20:34:17,070 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5 ELECTION round 0: submit vote requests at term 1 for -1: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:34:17,070 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5 ELECTION round 0: result PASSED (term=1)
2024-05-31 20:34:17,070 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5
2024-05-31 20:34:17,070 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-05-31 20:34:17,070 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-05-31 20:34:17,071 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:34:17,071 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-05-31 20:34:17,072 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-05-31 20:34:17,072 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-05-31 20:34:17,072 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-05-31 20:34:17,072 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-05-31 20:34:17,072 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-05-31 20:34:17,072 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:17,072 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:34:17,072 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-05-31 20:34:17,073 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: start 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderStateImpl
2024-05-31 20:34:17,073 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B: set firstElectionSinceStartup to false for becomeLeader
2024-05-31 20:34:17,073 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-9F8AD608864B with new leaderId: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:17,073 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B: change Leader from null to 390bac8a-0dbf-4715-b6fd-0c75abb5c43b at term 1 for becomeLeader, leader elected after 5057ms
2024-05-31 20:34:17,073 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-SegmentedRaftLogWorker: Starting segment from index:0
2024-05-31 20:34:17,074 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-05-31 20:34:17,075 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:17,074 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderElection5] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B: set configuration 0: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:34:17,079 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5079670635ns, electionTimeout:5079ms
2024-05-31 20:34:17,080 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: shutdown 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-FollowerState
2024-05-31 20:34:17,080 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-05-31 20:34:17,080 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-05-31 20:34:17,080 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: start 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6
2024-05-31 20:34:17,080 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 reported by 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)
2024-05-31 20:34:17,083 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/2cc65240-011a-451d-b3ff-9f8ad608864b/current/log_inprogress_0
2024-05-31 20:34:17,086 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-05-31 20:34:17,087 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null
2024-05-31 20:34:17,090 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034
2024-05-31 20:34:17,095 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:17,095 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:17,096 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016
2024-05-31 20:34:17,100 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01: receive requestVote(PRE_VOTE, 076ccc74-63d1-410b-8584-7a1d80cfc8c8, group-4A82ED352A01, 0, (t:0, i:0))
2024-05-31 20:34:17,100 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-FOLLOWER: accept PRE_VOTE from 076ccc74-63d1-410b-8584-7a1d80cfc8c8: our priority 0 <= candidate's priority 1
2024-05-31 20:34:17,100 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01 replies to PRE_VOTE vote request: 076ccc74-63d1-410b-8584-7a1d80cfc8c8<-390bac8a-0dbf-4715-b6fd-0c75abb5c43b#0:OK-t0. Peer's state: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01:t0, leader=null, voted=, raftlog=Memoized:390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null
2024-05-31 20:34:17,102 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2024-05-31 20:34:17,102 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 076ccc74-63d1-410b-8584-7a1d80cfc8c8<-390bac8a-0dbf-4715-b6fd-0c75abb5c43b#0:OK-t0
2024-05-31 20:34:17,102 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6 PRE_VOTE round 0: result PASSED
2024-05-31 20:34:17,104 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6 ELECTION round 0: submit vote requests at term 1 for -1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null
2024-05-31 20:34:17,106 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01: receive requestVote(PRE_VOTE, 076ccc74-63d1-410b-8584-7a1d80cfc8c8, group-4A82ED352A01, 0, (t:0, i:0))
2024-05-31 20:34:17,106 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-FOLLOWER: accept PRE_VOTE from 076ccc74-63d1-410b-8584-7a1d80cfc8c8: our priority 0 <= candidate's priority 1
2024-05-31 20:34:17,106 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01 replies to PRE_VOTE vote request: 076ccc74-63d1-410b-8584-7a1d80cfc8c8<-2fad9ecd-4424-4a8b-880f-fd93cda6f409#0:OK-t0. Peer's state: 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01:t0, leader=null, voted=, raftlog=Memoized:2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null
2024-05-31 20:34:17,110 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:17,110 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:17,113 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01: receive requestVote(ELECTION, 076ccc74-63d1-410b-8584-7a1d80cfc8c8, group-4A82ED352A01, 1, (t:0, i:0))
2024-05-31 20:34:17,113 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01: receive requestVote(ELECTION, 076ccc74-63d1-410b-8584-7a1d80cfc8c8, group-4A82ED352A01, 1, (t:0, i:0))
2024-05-31 20:34:17,113 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-FOLLOWER: accept ELECTION from 076ccc74-63d1-410b-8584-7a1d80cfc8c8: our priority 0 <= candidate's priority 1
2024-05-31 20:34:17,113 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:17,113 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-FollowerState
2024-05-31 20:34:17,113 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: start 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-FollowerState
2024-05-31 20:34:17,114 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-FollowerState was interrupted
2024-05-31 20:34:17,114 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01: set firstElectionSinceStartup to false for candidate:076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:17,115 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-FOLLOWER: accept ELECTION from 076ccc74-63d1-410b-8584-7a1d80cfc8c8: our priority 0 <= candidate's priority 1
2024-05-31 20:34:17,115 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:17,115 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: shutdown 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-FollowerState
2024-05-31 20:34:17,115 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-FollowerState was interrupted
2024-05-31 20:34:17,115 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: start 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-FollowerState
2024-05-31 20:34:17,115 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01 replies to ELECTION vote request: 076ccc74-63d1-410b-8584-7a1d80cfc8c8<-390bac8a-0dbf-4715-b6fd-0c75abb5c43b#0:OK-t1. Peer's state: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01:t1, leader=null, voted=076ccc74-63d1-410b-8584-7a1d80cfc8c8, raftlog=Memoized:390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null
2024-05-31 20:34:17,118 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6: ELECTION PASSED received 1 response(s) and 0 exception(s):
2024-05-31 20:34:17,118 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 076ccc74-63d1-410b-8584-7a1d80cfc8c8<-390bac8a-0dbf-4715-b6fd-0c75abb5c43b#0:OK-t1
2024-05-31 20:34:17,118 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6 ELECTION round 0: result PASSED
2024-05-31 20:34:17,118 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: shutdown 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6
2024-05-31 20:34:17,118 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-05-31 20:34:17,118 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-05-31 20:34:17,119 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01 replies to ELECTION vote request: 076ccc74-63d1-410b-8584-7a1d80cfc8c8<-2fad9ecd-4424-4a8b-880f-fd93cda6f409#0:OK-t1. Peer's state: 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01:t1, leader=null, voted=076ccc74-63d1-410b-8584-7a1d80cfc8c8, raftlog=Memoized:2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null
2024-05-31 20:34:17,123 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:34:17,123 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-05-31 20:34:17,123 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-05-31 20:34:17,123 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-05-31 20:34:17,123 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-05-31 20:34:17,123 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-05-31 20:34:17,123 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-05-31 20:34:17,123 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:17,123 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:34:17,123 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-05-31 20:34:17,131 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-05-31 20:34:17,132 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:17,132 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2024-05-31 20:34:17,134 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0μs (custom)
2024-05-31 20:34:17,135 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-05-31 20:34:17,136 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:17,136 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-05-31 20:34:17,136 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-05-31 20:34:17,136 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-05-31 20:34:17,137 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:17,137 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-05-31 20:34:17,140 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-05-31 20:34:17,140 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:17,140 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2024-05-31 20:34:17,140 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0μs (custom)
2024-05-31 20:34:17,141 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-05-31 20:34:17,141 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:17,141 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-05-31 20:34:17,141 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-05-31 20:34:17,141 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-05-31 20:34:17,141 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:17,141 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-05-31 20:34:17,142 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: start 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderStateImpl
2024-05-31 20:34:17,142 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01: set firstElectionSinceStartup to false for becomeLeader
2024-05-31 20:34:17,142 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-4A82ED352A01 with new leaderId: 076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:17,144 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01: change Leader from null to 076ccc74-63d1-410b-8584-7a1d80cfc8c8 at term 1 for becomeLeader, leader elected after 5163ms
2024-05-31 20:34:17,144 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-SegmentedRaftLogWorker: Starting segment from index:0
2024-05-31 20:34:17,145 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderElection6] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01: set configuration 0: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null
2024-05-31 20:34:17,145 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 reported by 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)
2024-05-31 20:34:17,145 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-05-31 20:34:17,145 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-05-31 20:34:17,146 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=9a915894-abff-4e14-8344-4a82ed352a01
2024-05-31 20:34:17,149 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2024-05-31 20:34:17,149 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(203)) - HealthyPipelineSafeModeRule rule is successfully validated
2024-05-31 20:34:17,149 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(218)) - ScmSafeModeManager, all rules are successfully validated
2024-05-31 20:34:17,149 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(248)) - SCM exiting safe mode.
2024-05-31 20:34:17,149 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(225)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2024-05-31 20:34:17,150 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(258)) - Service BackgroundPipelineCreator transitions to RUNNING.
2024-05-31 20:34:17,150 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(79)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2024-05-31 20:34:17,150 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(79)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2024-05-31 20:34:17,150 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:notifyStatusChanged(247)) - notifyStatusChanged:RUNNING
2024-05-31 20:34:17,150 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(1406)) - Service ReplicationManager transitions to RUNNING.
2024-05-31 20:34:17,153 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(134)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2024-05-31 20:34:17,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:34:17,159 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/9a915894-abff-4e14-8344-4a82ed352a01/current/log_inprogress_0
2024-05-31 20:34:17,174 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-05-31 20:34:17,175 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Cluster exits safe mode
2024-05-31 20:34:17,175 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-05-31 20:34:17,175 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(59)) - No unit for hdds.scmclient.rpc.timeout(60000) assuming MILLISECONDS
2024-05-31 20:34:17,175 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(59)) - No unit for hdds.scmclient.max.retry.timeout(6000) assuming MILLISECONDS
2024-05-31 20:34:17,178 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(59)) - No unit for hdds.scmclient.rpc.timeout(60000) assuming MILLISECONDS
2024-05-31 20:34:17,178 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(59)) - No unit for hdds.scmclient.max.retry.timeout(6000) assuming MILLISECONDS
2024-05-31 20:34:17,180 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5013189047ns, electionTimeout:5010ms
2024-05-31 20:34:17,180 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: shutdown b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-FollowerState
2024-05-31 20:34:17,180 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-05-31 20:34:17,180 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-05-31 20:34:17,181 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: start b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7
2024-05-31 20:34:17,183 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:17,183 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7 PRE_VOTE round 0: result PASSED (term=0)
2024-05-31 20:34:17,185 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7 ELECTION round 0: submit vote requests at term 1 for -1: peers:[b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:17,186 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7 ELECTION round 0: result PASSED (term=1)
2024-05-31 20:34:17,186 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: shutdown b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7
2024-05-31 20:34:17,186 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-05-31 20:34:17,187 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-05-31 20:34:17,187 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:34:17,188 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-05-31 20:34:17,192 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-05-31 20:34:17,192 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-05-31 20:34:17,192 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-05-31 20:34:17,192 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-05-31 20:34:17,192 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-05-31 20:34:17,193 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:17,193 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:34:17,193 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-05-31 20:34:17,193 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: start b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderStateImpl
2024-05-31 20:34:17,193 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B: set firstElectionSinceStartup to false for becomeLeader
2024-05-31 20:34:17,193 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-8F8EE659CC7B with new leaderId: b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:17,193 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B: change Leader from null to b079985c-91b9-4d2e-8c89-c2e47b34f7da at term 1 for becomeLeader, leader elected after 5090ms
2024-05-31 20:34:17,198 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-SegmentedRaftLogWorker: Starting segment from index:0
2024-05-31 20:34:17,199 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderElection7] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B: set configuration 0: peers:[b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:17,199 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-05-31 20:34:17,201 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-4A82ED352A01 with new leaderId: 076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:17,201 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01: change Leader from null to 076ccc74-63d1-410b-8584-7a1d80cfc8c8 at term 1 for appendEntries, leader elected after 5356ms
2024-05-31 20:34:17,205 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-4A82ED352A01 with new leaderId: 076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:17,205 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01: change Leader from null to 076ccc74-63d1-410b-8584-7a1d80cfc8c8 at term 1 for appendEntries, leader elected after 5155ms
2024-05-31 20:34:17,209 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/57400ce6-6596-49c1-8fbb-8f8ee659cc7b/current/log_inprogress_0
2024-05-31 20:34:17,215 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01: set configuration 0: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null
2024-05-31 20:34:17,215 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-05-31 20:34:17,217 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-SegmentedRaftLogWorker: Starting segment from index:0
2024-05-31 20:34:17,219 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-05-31 20:34:17,230 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/9a915894-abff-4e14-8344-4a82ed352a01/current/log_inprogress_0
2024-05-31 20:34:17,231 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-server-thread3] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01: set configuration 0: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null
2024-05-31 20:34:17,232 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-server-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-SegmentedRaftLogWorker: Starting segment from index:0
2024-05-31 20:34:17,232 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-05-31 20:34:17,245 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/9a915894-abff-4e14-8344-4a82ed352a01/current/log_inprogress_0
2024-05-31 20:34:17,247 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-05-31 20:34:17,360 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:17,371 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5156736208ns, electionTimeout:5149ms
2024-05-31 20:34:17,371 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 55857a12-8529-4f00-ab69-b96d955e4226: shutdown 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-FollowerState
2024-05-31 20:34:17,371 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-05-31 20:34:17,371 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-05-31 20:34:17,372 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 55857a12-8529-4f00-ab69-b96d955e4226: start 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8
2024-05-31 20:34:17,372 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052]|listeners:[], old=null
2024-05-31 20:34:17,373 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8 PRE_VOTE round 0: result PASSED (term=0)
2024-05-31 20:34:17,374 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8 ELECTION round 0: submit vote requests at term 1 for -1: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052]|listeners:[], old=null
2024-05-31 20:34:17,375 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8 ELECTION round 0: result PASSED (term=1)
2024-05-31 20:34:17,375 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 55857a12-8529-4f00-ab69-b96d955e4226: shutdown 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8
2024-05-31 20:34:17,375 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-05-31 20:34:17,376 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-05-31 20:34:17,376 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:34:17,377 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-05-31 20:34:17,377 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-05-31 20:34:17,378 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-05-31 20:34:17,378 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-05-31 20:34:17,379 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-05-31 20:34:17,379 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-05-31 20:34:17,379 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:17,380 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:34:17,380 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-05-31 20:34:17,381 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 55857a12-8529-4f00-ab69-b96d955e4226: start 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderStateImpl
2024-05-31 20:34:17,381 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C: set firstElectionSinceStartup to false for becomeLeader
2024-05-31 20:34:17,381 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-AC6BA249094C with new leaderId: 55857a12-8529-4f00-ab69-b96d955e4226
2024-05-31 20:34:17,382 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C: change Leader from null to 55857a12-8529-4f00-ab69-b96d955e4226 at term 1 for becomeLeader, leader elected after 5197ms
2024-05-31 20:34:17,382 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-SegmentedRaftLogWorker: Starting segment from index:0
2024-05-31 20:34:17,383 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-05-31 20:34:17,386 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1), {type: FCR, size: 0}
2024-05-31 20:34:17,387 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1), {type: FCR, size: 0}
2024-05-31 20:34:17,389 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderElection8] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C: set configuration 0: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052]|listeners:[], old=null
2024-05-31 20:34:17,393 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/2377c6a9-74bd-4894-88f5-ac6ba249094c/current/log_inprogress_0
2024-05-31 20:34:17,398 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-05-31 20:34:17,507 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(472)) - Creating Volume: vol1, with user66540 as owner and space quota set to -1 bytes, counts quota set to -1
2024-05-31 20:34:17,543 [om1-OMStateMachineApplyTransactionThread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(198)) - created volume:vol1 for user:user66540
2024-05-31 20:34:17,551 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(72)) - OmKeyInfo.getCodec ignorePipeline = true
2024-05-31 20:34:17,551 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(72)) - OmKeyInfo.getCodec ignorePipeline = true
2024-05-31 20:34:17,551 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(72)) - OmKeyInfo.getCodec ignorePipeline = true
2024-05-31 20:34:17,551 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(72)) - OmKeyInfo.getCodec ignorePipeline = true
2024-05-31 20:34:17,551 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(72)) - OmKeyInfo.getCodec ignorePipeline = true
2024-05-31 20:34:17,557 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(698)) - Creating Bucket: vol1/bucket1, with bucket layout FILE_SYSTEM_OPTIMIZED, runner as owner, Versioning false, Storage Type set to DISK and Encryption set to false, Replication Type set to server-side default replication type, Namespace Quota set to -1, Space Quota set to -1 
2024-05-31 20:34:17,566 [om1-OMStateMachineApplyTransactionThread - 0] INFO  bucket.OMBucketCreateRequest (OMBucketCreateRequest.java:validateAndUpdateCache(293)) - created bucket: bucket1 of layout FILE_SYSTEM_OPTIMIZED in volume: vol1
2024-05-31 20:34:17,609 [IPC Server handler 1 on default port 15001] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(145)) - Allocate a batch for containerId, change lastId from 0 to 1000.
2024-05-31 20:34:17,616 [IPC Server handler 1 on default port 15001] WARN  ha.SequenceIdGenerator (SequenceIdGenerator.java:allocateBatch(258)) - Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 113750153625600000.
2024-05-31 20:34:17,616 [IPC Server handler 1 on default port 15001] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(145)) - Allocate a batch for localId, change lastId from 113750153625600000 to 113750153625601000.
2024-05-31 20:34:17,671 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - XceiverClientMetrics metrics system started (again)
2024-05-31 20:34:17,852 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 5 millisec, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), {type: ICR, size: 1}
2024-05-31 20:34:17,857 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:addNewContainer(246)) - Successfully added container #1 to Recon.
2024-05-31 20:34:17,857 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:addNewContainer(246)) - Successfully added container #1 to Recon.
2024-05-31 20:34:17,852 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 5 millisec, 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), {type: ICR, size: 1}
2024-05-31 20:34:17,858 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 10 millisec, 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), {type: ICR, size: 1}
2024-05-31 20:34:17,859 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 10 millisec, 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), {type: ICR, size: 1}
2024-05-31 20:34:17,868 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 20 millisec, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), {type: ICR, size: 1}
2024-05-31 20:34:17,870 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 21 millisec, 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), {type: ICR, size: 1}
2024-05-31 20:34:17,870 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 22 millisec, 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), {type: FCR, size: 0}
2024-05-31 20:34:17,870 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 22 millisec, 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), {type: FCR, size: 0}
2024-05-31 20:34:17,871 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 22 millisec, 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), {type: ICR, size: 1}
2024-05-31 20:34:17,872 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 23 millisec, 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), {type: ICR, size: 1}
Connecting to Recon: http://0.0.0.0:15008/api/v1/triggerdbsync/om ...
2024-05-31 20:34:18,052 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:18,053 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(537)) - Obtaining full snapshot from Ozone Manager
2024-05-31 20:34:18,064 [qtp862366104-412] INFO  utils.DBCheckpointServlet (DBCheckpointServlet.java:doGet(301)) - Received GET request to obtain DB checkpoint snapshot
2024-05-31 20:34:18,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:34:18,369 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:18,369 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:18,369 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:18,369 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:18,369 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:18,369 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:18,369 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:18,847 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), {type: FCR, size: 1}
2024-05-31 20:34:18,977 [qtp862366104-412] INFO  db.RDBCheckpointManager (RDBCheckpointManager.java:createCheckpoint(89)) - Created checkpoint in rocksDB at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/db.checkpoints/om.db_checkpoint_1717187658955 in 21 milliseconds
2024-05-31 20:34:18,998 [qtp862366104-412] INFO  utils.DBCheckpointServlet (DBCheckpointServlet.java:generateSnapshotCheckpoint(225)) - Time taken to write the checkpoint to response output stream: 14 milliseconds
2024-05-31 20:34:18,998 [qtp862366104-412] INFO  utils.DBCheckpointServlet (DBCheckpointServlet.java:generateSnapshotCheckpoint(228)) - Excluded SST [] from the latest checkpoint.
2024-05-31 20:34:19,024 [qtp862366104-412] INFO  db.RocksDBCheckpoint (RocksDBCheckpoint.java:cleanupCheckpoint(78)) - Cleaning up RocksDB checkpoint at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/db.checkpoints/om.db_checkpoint_1717187658955
2024-05-31 20:34:19,026 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:updateReconOmDBWithNewSnapshot(390)) - Got new checkpoint from OM : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/recon/om.snapshot.db_1717187658053
2024-05-31 20:34:19,026 [Recon-SyncOM-1] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(72)) - OmKeyInfo.getCodec ignorePipeline = true
2024-05-31 20:34:19,089 [Recon-SyncOM-1] INFO  recovery.ReconOmMetadataManagerImpl (ReconOmMetadataManagerImpl.java:initializeNewRdbStore(107)) - Created OM DB handle from snapshot at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/recon/om.snapshot.db_1717187658053.
2024-05-31 20:34:19,115 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(550)) - Calling reprocess on Recon tasks.
2024-05-31 20:34:19,159 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(373)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-05-31 20:34:19,263 [ReconTaskThread-0] INFO  impl.ReconContainerMetadataManagerImpl (ReconContainerMetadataManagerImpl.java:initializeTables(141)) - KEY_CONTAINER Table is empty, initializing from CONTAINER_KEY Table ...
2024-05-31 20:34:19,263 [ReconTaskThread-0] INFO  impl.ReconContainerMetadataManagerImpl (ReconContainerMetadataManagerImpl.java:initializeKeyContainerTable(666)) - It took 0.0 seconds to initialized 0 records to KEY_CONTAINER table
2024-05-31 20:34:19,373 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:19,373 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:19,373 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:19,374 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:19,374 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:19,374 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:19,374 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:19,847 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), {type: FCR, size: 1}
2024-05-31 20:34:19,848 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), {type: FCR, size: 1}
2024-05-31 20:34:20,160 [IPC Server handler 2 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startMaintenanceNodes(496)) - Force flag = true. Skip checking if maintenance is possible for dns: [076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)]
2024-05-31 20:34:20,160 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1) moved to HEALTHY state.
2024-05-31 20:34:20,161 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-05-31 20:34:20,161 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:34:20,161 [IPC Server handler 2 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startMaintenance(532)) - Starting Maintenance for node 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
2024-05-31 20:34:20,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@61f63faa. There are 2 pipelines
2024-05-31 20:34:20,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:20,176 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(55)) - Admin start on datanode 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1). Finalizing its pipelines [PipelineID=c43c2b80-c72a-4420-a2bc-0ead3654c05a, PipelineID=9a915894-abff-4e14-8344-4a82ed352a01]
2024-05-31 20:34:20,177 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=c43c2b80-c72a-4420-a2bc-0ead3654c05a moved to CLOSED state
2024-05-31 20:34:20,180 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(484)) - Container #1 closed for pipeline=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01
2024-05-31 20:34:20,180 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #1, current state: CLOSING
2024-05-31 20:34:20,180 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 moved to CLOSED state
2024-05-31 20:34:20,197 [qtp1026273299-461] INFO  impl.Tools (JooqLogger.java:info(338)) - Kotlin is available, but not kotlin-reflect. Add the kotlin-reflect dependency to better use Kotlin features like data classes
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-05-31 20:34:20,303 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:20,305 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:20,305 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:20,311 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:20,311 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:20,378 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:20,379 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:20,379 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:20,380 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:20,380 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:20,380 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:20,380 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:20,845 [IPC Server handler 7 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-05-31 20:34:21,162 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-05-31T20:34:20.179398245Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault} to 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1) with datanode deadline 1717188231161 and scm deadline 1717188261161
2024-05-31 20:34:21,162 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-05-31T20:34:20.179398245Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault} to 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1) with datanode deadline 1717188231162 and scm deadline 1717188261162
2024-05-31 20:34:21,162 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-05-31T20:34:20.179398245Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault} to 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1) with datanode deadline 1717188231162 and scm deadline 1717188261162
2024-05-31 20:34:21,162 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:34:21,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@61f63faa. There are 2 pipelines
2024-05-31 20:34:21,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:21,313 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:21,313 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:21,313 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:21,315 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:21,316 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:21,385 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:21,385 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:21,385 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:21,385 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:21,385 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:21,385 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:21,385 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:21,845 [IPC Server handler 6 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-05-31 20:34:21,847 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to ENTERING_MAINTENANCE, scaling executor pool size to 20
2024-05-31 20:34:21,847 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), {type: FCR, size: 1}
2024-05-31 20:34:22,163 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-05-31T20:34:20.179398245Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault} to 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1) with datanode deadline 1717188232163 and scm deadline 1717188262163
2024-05-31 20:34:22,163 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-05-31T20:34:20.179398245Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault} to 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1) with datanode deadline 1717188232163 and scm deadline 1717188262163
2024-05-31 20:34:22,163 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-05-31T20:34:20.179398245Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault} to 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1) with datanode deadline 1717188232163 and scm deadline 1717188262163
2024-05-31 20:34:22,163 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:34:22,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@61f63faa. There are 2 pipelines
2024-05-31 20:34:22,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:22,318 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:22,318 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:22,319 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:22,321 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:22,321 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:22,388 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:22,388 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:22,388 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:22,389 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:22,389 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:22,389 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:22,389 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:22,847 [IPC Server handler 2 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-05-31 20:34:22,852 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:checkContainerStateAndUpdate(199)) - Container #1 has state OPEN, but given state is CLOSING.
2024-05-31 20:34:22,853 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-CloseContainerThread-0] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-05-31 20:34:22,853 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), {type: ICR, size: 1}
2024-05-31 20:34:23,164 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-05-31T20:34:20.179398245Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault} to 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1) with datanode deadline 1717188233163 and scm deadline 1717188263163
2024-05-31 20:34:23,164 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-05-31T20:34:20.179398245Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault} to 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1) with datanode deadline 1717188233164 and scm deadline 1717188263164
2024-05-31 20:34:23,164 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-05-31T20:34:20.179398245Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault} to 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1) with datanode deadline 1717188233164 and scm deadline 1717188263164
2024-05-31 20:34:23,164 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:34:23,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@61f63faa. There are 2 pipelines
2024-05-31 20:34:23,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:23,323 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:23,324 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:23,324 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:23,326 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:23,326 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:23,393 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:23,393 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:23,393 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:23,394 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:23,394 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:23,394 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:23,394 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:23,853 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), {type: ICR, size: 1}
2024-05-31 20:34:23,853 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), {type: ICR, size: 1}
2024-05-31 20:34:23,856 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), {type: ICR, size: 1}
2024-05-31 20:34:23,856 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), {type: ICR, size: 1}
2024-05-31 20:34:23,857 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-CloseContainerThread-0] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-05-31 20:34:23,857 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-CloseContainerThread-0] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-05-31 20:34:23,859 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-ContainerOp-9a915894-abff-4e14-8344-4a82ed352a01-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-05-31 20:34:23,859 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-ContainerOp-9a915894-abff-4e14-8344-4a82ed352a01-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-05-31 20:34:23,862 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-ContainerOp-9a915894-abff-4e14-8344-4a82ed352a01-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(437)) - Container 1 is closed with bcsId 2.
2024-05-31 20:34:23,864 [FixedThreadPoolWithAffinityExecutor-8-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(312)) - Moving container #1 to CLOSED state, datanode 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1) reported CLOSED replica with index 0.
2024-05-31 20:34:23,864 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(312)) - Moving container #1 to CLOSED state, datanode 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1) reported CLOSED replica with index 0.
2024-05-31 20:34:23,866 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-CloseContainerThread-1] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-05-31 20:34:23,867 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-CloseContainerThread-2] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-05-31 20:34:23,869 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-ContainerOp-9a915894-abff-4e14-8344-4a82ed352a01-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-05-31 20:34:23,869 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-ContainerOp-9a915894-abff-4e14-8344-4a82ed352a01-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-05-31 20:34:23,870 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-ContainerOp-9a915894-abff-4e14-8344-4a82ed352a01-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-05-31 20:34:23,870 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-ContainerOp-9a915894-abff-4e14-8344-4a82ed352a01-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-05-31 20:34:23,874 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-ContainerOp-9a915894-abff-4e14-8344-4a82ed352a01-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(437)) - Container 1 is closed with bcsId 2.
2024-05-31 20:34:23,874 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-ContainerOp-9a915894-abff-4e14-8344-4a82ed352a01-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(437)) - Container 1 is closed with bcsId 2.
2024-05-31 20:34:24,166 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 2 milliseconds for processing 1 containers.
2024-05-31 20:34:24,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@61f63faa. There are 2 pipelines
2024-05-31 20:34:24,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:24,328 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:24,328 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:24,328 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:24,330 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:24,330 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:24,397 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:24,398 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:24,398 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:24,398 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:24,398 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:24,398 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:24,398 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:25,167 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:34:25,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@61f63faa. There are 2 pipelines
2024-05-31 20:34:25,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:25,332 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:25,332 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:25,332 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:25,334 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:25,334 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:25,402 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:25,402 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:25,402 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:25,402 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:25,402 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:25,402 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:25,402 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:26,032 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=c43c2b80-c72a-4420-a2bc-0ead3654c05a since it stays at CLOSED stage.
2024-05-31 20:34:26,033 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=c43c2b80-c72a-4420-a2bc-0ead3654c05a close command to datanode 076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:26,034 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: c43c2b80-c72a-4420-a2bc-0ead3654c05a, Nodes: 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:076ccc74-63d1-410b-8584-7a1d80cfc8c8, CreationTimestamp2024-05-31T20:34:08.938Z[Etc/UTC]] removed.
2024-05-31 20:34:26,034 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 since it stays at CLOSED stage.
2024-05-31 20:34:26,034 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 close command to datanode 076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:26,034 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 close command to datanode 390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:26,034 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 close command to datanode 2fad9ecd-4424-4a8b-880f-fd93cda6f409
2024-05-31 20:34:26,034 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 9a915894-abff-4e14-8344-4a82ed352a01, Nodes: 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:076ccc74-63d1-410b-8584-7a1d80cfc8c8, CreationTimestamp2024-05-31T20:34:09.020Z[Etc/UTC]] removed.
2024-05-31 20:34:26,167 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:34:26,176 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(472)) - org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@61f63faa has 1 sufficientlyReplicated, 0 deleting, 0 underReplicated and 0 unclosed containers
2024-05-31 20:34:26,176 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:putIntoMaintenance(529)) - Datanode 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1) has entered maintenance
2024-05-31 20:34:26,176 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:26,176 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1) moved to HEALTHY state.
2024-05-31 20:34:26,176 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-05-31 20:34:26,177 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=e2b2676c-1441-482f-9bbc-9048d00d16ef to datanode:2fad9ecd-4424-4a8b-880f-fd93cda6f409
2024-05-31 20:34:26,177 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=e2b2676c-1441-482f-9bbc-9048d00d16ef to datanode:b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:26,177 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=e2b2676c-1441-482f-9bbc-9048d00d16ef to datanode:390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:26,178 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: e2b2676c-1441-482f-9bbc-9048d00d16ef, Nodes: 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1)b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1)390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-05-31T20:34:26.177571526Z[Etc/UTC]]
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-05-31 20:34:26,279 [IPC Server handler 7 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startMaintenanceNodes(496)) - Force flag = true. Skip checking if maintenance is possible for dns: [390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)]
2024-05-31 20:34:26,279 [IPC Server handler 7 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startMaintenance(532)) - Starting Maintenance for node 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)
2024-05-31 20:34:26,279 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1) moved to HEALTHY state.
2024-05-31 20:34:26,280 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-05-31 20:34:26,337 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:26,337 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:26,337 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:26,339 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:26,339 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:26,405 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:26,405 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:26,405 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:26,405 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:26,405 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:26,405 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:26,406 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:26,864 [IPC Server handler 10 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2024-05-31 20:34:26,878 [IPC Server handler 15 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-05-31 20:34:26,880 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), {type: FCR, size: 1}
2024-05-31 20:34:26,880 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), {type: FCR, size: 1}
2024-05-31 20:34:27,168 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:34:27,174 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(55)) - Admin start on datanode 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1). Finalizing its pipelines [PipelineID=e2b2676c-1441-482f-9bbc-9048d00d16ef, PipelineID=2cc65240-011a-451d-b3ff-9f8ad608864b]
2024-05-31 20:34:27,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@29fc23d1. There are 2 pipelines
2024-05-31 20:34:27,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:27,175 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=e2b2676c-1441-482f-9bbc-9048d00d16ef moved to CLOSED state
2024-05-31 20:34:27,176 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=2cc65240-011a-451d-b3ff-9f8ad608864b moved to CLOSED state
2024-05-31 20:34:27,341 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:27,341 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:27,341 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:27,343 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:27,344 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:27,408 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:27,409 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:27,409 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:27,409 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:27,409 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:27,409 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:27,409 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:27,864 [IPC Server handler 12 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2024-05-31 20:34:27,865 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=c43c2b80-c72a-4420-a2bc-0ead3654c05a is not found
2024-05-31 20:34:27,865 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 is not found
2024-05-31 20:34:27,879 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to ENTERING_MAINTENANCE, scaling executor pool size to 20
2024-05-31 20:34:27,879 [IPC Server handler 12 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-05-31 20:34:27,879 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 is not found
2024-05-31 20:34:27,880 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 is not found
2024-05-31 20:34:27,881 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), {type: FCR, size: 1}
2024-05-31 20:34:27,881 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), {type: FCR, size: 1}
2024-05-31 20:34:27,891 [grpc-default-executor-3] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: remove    LEADER 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01:t1, leader=076ccc74-63d1-410b-8584-7a1d80cfc8c8, voted=076ccc74-63d1-410b-8584-7a1d80cfc8c8, raftlog=Memoized:076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-SegmentedRaftLog:OPENED:c9, conf=0: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null RUNNING
2024-05-31 20:34:27,892 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01: shutdown
2024-05-31 20:34:27,892 [grpc-default-executor-3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4A82ED352A01,id=076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:27,892 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: shutdown 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-LeaderStateImpl
2024-05-31 20:34:27,892 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01->390bac8a-0dbf-4715-b6fd-0c75abb5c43b-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01->390bac8a-0dbf-4715-b6fd-0c75abb5c43b-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-05-31 20:34:27,893 [grpc-default-executor-3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-PendingRequests: sendNotLeaderResponses
2024-05-31 20:34:27,894 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01->2fad9ecd-4424-4a8b-880f-fd93cda6f409-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01->2fad9ecd-4424-4a8b-880f-fd93cda6f409-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-05-31 20:34:27,894 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: Completed APPEND_ENTRIES, lastRequest: 076ccc74-63d1-410b-8584-7a1d80cfc8c8->390bac8a-0dbf-4715-b6fd-0c75abb5c43b#14-t1,previous=(t:1, i:7),leaderCommit=6,initializing? false,entries: size=2, first=(t:1, i:8), METADATAENTRY(c:5)
2024-05-31 20:34:27,895 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: Completed APPEND_ENTRIES, lastReply: null
2024-05-31 20:34:27,896 [grpc-default-executor-3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-StateMachineUpdater: set stopIndex = 9
2024-05-31 20:34:27,896 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-4A82ED352A01: Taking a snapshot at:(t:1, i:9) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/9a915894-abff-4e14-8344-4a82ed352a01/sm/snapshot.1_9
2024-05-31 20:34:27,897 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01->390bac8a-0dbf-4715-b6fd-0c75abb5c43b-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-05-31 20:34:27,898 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: Completed APPEND_ENTRIES, lastRequest: null
2024-05-31 20:34:27,898 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: Completed APPEND_ENTRIES, lastRequest: 076ccc74-63d1-410b-8584-7a1d80cfc8c8->2fad9ecd-4424-4a8b-880f-fd93cda6f409#17-t1,previous=(t:1, i:7),leaderCommit=7,initializing? false,entries: size=2, first=(t:1, i:8), METADATAENTRY(c:5)
2024-05-31 20:34:27,898 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: Completed APPEND_ENTRIES, lastReply: null
2024-05-31 20:34:27,899 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: Completed APPEND_ENTRIES, lastRequest: null
2024-05-31 20:34:27,899 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "076ccc74-63d1-410b-8584-7a1d80cfc8c8"
  replyId: "390bac8a-0dbf-4715-b6fd-0c75abb5c43b"
  raftGroupId {
    id: "\232\221X\224\253\377N\024\203DJ\202\3555*\001"
  }
  callId: 19
  success: true
}
term: 1
nextIndex: 10
followerCommit: 9
matchIndex: 18446744073709551615
isHearbeat: true

2024-05-31 20:34:27,899 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "076ccc74-63d1-410b-8584-7a1d80cfc8c8"
  replyId: "2fad9ecd-4424-4a8b-880f-fd93cda6f409"
  raftGroupId {
    id: "\232\221X\224\253\377N\024\203DJ\202\3555*\001"
  }
  callId: 21
  success: true
}
term: 1
nextIndex: 10
followerCommit: 9
matchIndex: 18446744073709551615
isHearbeat: true

2024-05-31 20:34:27,900 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01->2fad9ecd-4424-4a8b-880f-fd93cda6f409-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-05-31 20:34:27,900 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01->2fad9ecd-4424-4a8b-880f-fd93cda6f409-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-05-31 20:34:27,901 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01->390bac8a-0dbf-4715-b6fd-0c75abb5c43b-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-05-31 20:34:27,935 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-4A82ED352A01: Finished taking a snapshot at:(t:1, i:9) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/9a915894-abff-4e14-8344-4a82ed352a01/sm/snapshot.1_9 took: 40 ms
2024-05-31 20:34:27,937 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-StateMachineUpdater: Took a snapshot at index 9
2024-05-31 20:34:27,937 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 9
2024-05-31 20:34:27,939 [grpc-default-executor-3] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01: applyIndex: 9
2024-05-31 20:34:27,939 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-05-31 20:34:28,169 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:34:28,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@29fc23d1. There are 2 pipelines
2024-05-31 20:34:28,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:28,195 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: addNew group-9048D00D16EF:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043] returns group-9048D00D16EF:java.util.concurrent.CompletableFuture@7b4b2636[Not completed]
2024-05-31 20:34:28,196 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: new RaftServerImpl for group-9048D00D16EF:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043] with ContainerStateMachine:uninitialized
2024-05-31 20:34:28,196 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:28,196 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-05-31 20:34:28,196 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:34:28,196 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-05-31 20:34:28,196 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:28,196 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:34:28,196 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:28,196 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF: ConfigurationManager, init=-1: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:34:28,196 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-05-31 20:34:28,196 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:34:28,197 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-05-31 20:34:28,197 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:34:28,197 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:34:28,197 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:34:28,200 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:28,200 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:28,200 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:34:28,200 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:34:28,200 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:34:28,200 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:34:28,201 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-05-31 20:34:28,201 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-05-31 20:34:28,201 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis] (custom)
2024-05-31 20:34:28,201 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef does not exist. Creating ...
2024-05-31 20:34:28,202 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef/in_use.lock acquired by nodename 83134@fv-az1343-628
2024-05-31 20:34:28,203 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef has been successfully formatted.
2024-05-31 20:34:28,203 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef/current/raft-meta.conf
2024-05-31 20:34:28,204 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-9048D00D16EF: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-05-31 20:34:28,204 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-05-31 20:34:28,204 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-05-31 20:34:28,204 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:28,204 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-05-31 20:34:28,204 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=e2b2676c-1441-482f-9bbc-9048d00d16ef. Trying to get from SCM.
2024-05-31 20:34:28,204 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-05-31 20:34:28,207 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:28,207 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(86)) - Adding new pipeline Pipeline[ Id: e2b2676c-1441-482f-9bbc-9048d00d16ef, Nodes: 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1)b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1)390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:, CreationTimestamp2024-05-31T20:34:26.177Z[Etc/UTC]] to Recon pipeline metadata.
2024-05-31 20:34:28,207 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-05-31 20:34:28,207 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-05-31 20:34:28,208 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:28,208 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-cacheEviction-AwaitToRun,5,main] started
2024-05-31 20:34:28,208 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef
2024-05-31 20:34:28,208 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-05-31 20:34:28,208 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-05-31 20:34:28,208 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:28,208 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-05-31 20:34:28,208 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-05-31 20:34:28,208 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-05-31 20:34:28,208 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-05-31 20:34:28,208 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-05-31 20:34:28,209 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-05-31 20:34:28,210 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:28,210 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-05-31 20:34:28,210 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-05-31 20:34:28,210 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-05-31 20:34:28,211 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:28,211 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:28,211 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF: start as a follower, conf=-1: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:28,211 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-05-31 20:34:28,211 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: start b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-FollowerState
2024-05-31 20:34:28,211 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:28,211 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9048D00D16EF,id=b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:28,212 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-05-31 20:34:28,212 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-05-31 20:34:28,212 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-05-31 20:34:28,212 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-05-31 20:34:28,212 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-05-31 20:34:28,213 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:28,213 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=e2b2676c-1441-482f-9bbc-9048d00d16ef
2024-05-31 20:34:28,221 [grpc-default-executor-5] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: addNew group-9048D00D16EF:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043] returns group-9048D00D16EF:java.util.concurrent.CompletableFuture@724306bd[Not completed]
2024-05-31 20:34:28,222 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: new RaftServerImpl for group-9048D00D16EF:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043] with ContainerStateMachine:uninitialized
2024-05-31 20:34:28,222 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:28,222 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-05-31 20:34:28,222 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:34:28,222 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-05-31 20:34:28,222 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:28,222 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:34:28,222 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:28,223 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF: ConfigurationManager, init=-1: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:34:28,223 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-05-31 20:34:28,223 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:34:28,223 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-05-31 20:34:28,223 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:34:28,223 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:34:28,223 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:34:28,226 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:28,226 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:28,226 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:34:28,226 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:34:28,226 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:34:28,226 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:34:28,226 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-05-31 20:34:28,226 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-05-31 20:34:28,226 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis] (custom)
2024-05-31 20:34:28,227 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef does not exist. Creating ...
2024-05-31 20:34:28,227 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef/in_use.lock acquired by nodename 83134@fv-az1343-628
2024-05-31 20:34:28,228 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef has been successfully formatted.
2024-05-31 20:34:28,228 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef/current/raft-meta.conf
2024-05-31 20:34:28,229 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-9048D00D16EF: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-05-31 20:34:28,229 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-05-31 20:34:28,229 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-05-31 20:34:28,229 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:28,229 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-05-31 20:34:28,229 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-05-31 20:34:28,231 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 is not found
2024-05-31 20:34:28,232 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:28,232 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-05-31 20:34:28,232 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-05-31 20:34:28,232 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:28,232 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-cacheEviction-AwaitToRun,5,main] started
2024-05-31 20:34:28,233 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef
2024-05-31 20:34:28,233 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-05-31 20:34:28,233 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-05-31 20:34:28,233 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:28,233 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-05-31 20:34:28,233 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-05-31 20:34:28,233 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-05-31 20:34:28,233 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-05-31 20:34:28,233 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-05-31 20:34:28,233 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-05-31 20:34:28,235 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:28,235 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-05-31 20:34:28,235 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-05-31 20:34:28,235 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-05-31 20:34:28,235 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:28,235 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:28,235 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF: start as a follower, conf=-1: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:28,235 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-05-31 20:34:28,235 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: start 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-FollowerState
2024-05-31 20:34:28,236 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9048D00D16EF,id=2fad9ecd-4424-4a8b-880f-fd93cda6f409
2024-05-31 20:34:28,236 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-05-31 20:34:28,236 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-05-31 20:34:28,236 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-05-31 20:34:28,236 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-05-31 20:34:28,236 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-05-31 20:34:28,236 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:28,237 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:28,254 [grpc-default-executor-5] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: addNew group-9048D00D16EF:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043] returns group-9048D00D16EF:java.util.concurrent.CompletableFuture@16220727[Not completed]
2024-05-31 20:34:28,255 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: new RaftServerImpl for group-9048D00D16EF:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043] with ContainerStateMachine:uninitialized
2024-05-31 20:34:28,255 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:28,255 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-05-31 20:34:28,255 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:34:28,255 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-05-31 20:34:28,255 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:28,255 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:34:28,255 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:28,255 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF: ConfigurationManager, init=-1: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:34:28,255 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-05-31 20:34:28,255 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:34:28,256 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-05-31 20:34:28,256 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:34:28,256 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:34:28,256 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:34:28,259 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:28,259 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:28,259 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:34:28,259 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:34:28,259 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:34:28,260 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:34:28,260 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-05-31 20:34:28,260 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-05-31 20:34:28,260 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis] (custom)
2024-05-31 20:34:28,260 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef does not exist. Creating ...
2024-05-31 20:34:28,261 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef/in_use.lock acquired by nodename 83134@fv-az1343-628
2024-05-31 20:34:28,262 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef has been successfully formatted.
2024-05-31 20:34:28,262 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef/current/raft-meta.conf
2024-05-31 20:34:28,263 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-9048D00D16EF: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-05-31 20:34:28,263 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-05-31 20:34:28,263 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-05-31 20:34:28,263 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:28,263 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-05-31 20:34:28,263 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-05-31 20:34:28,266 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 is not found
2024-05-31 20:34:28,267 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:28,267 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-05-31 20:34:28,268 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-05-31 20:34:28,268 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:28,268 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-cacheEviction-AwaitToRun,5,main] started
2024-05-31 20:34:28,268 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef
2024-05-31 20:34:28,268 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-05-31 20:34:28,268 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-05-31 20:34:28,268 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:28,268 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-05-31 20:34:28,268 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-05-31 20:34:28,269 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-05-31 20:34:28,269 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-05-31 20:34:28,269 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-05-31 20:34:28,269 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-05-31 20:34:28,271 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:28,271 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-05-31 20:34:28,272 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-05-31 20:34:28,272 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-05-31 20:34:28,272 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:28,272 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:28,272 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF: start as a follower, conf=-1: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:28,272 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-05-31 20:34:28,273 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: start 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-FollowerState
2024-05-31 20:34:28,273 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:28,273 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9048D00D16EF,id=390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:28,273 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:28,273 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-05-31 20:34:28,273 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-05-31 20:34:28,273 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-05-31 20:34:28,273 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-05-31 20:34:28,274 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-05-31 20:34:28,282 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=e2b2676c-1441-482f-9bbc-9048d00d16ef.
2024-05-31 20:34:28,345 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:28,346 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:28,346 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:28,348 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:28,348 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:28,422 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:28,422 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:28,422 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:28,422 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:28,422 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	TOTAL_KEYS -> 1 , CONTAINER_COUNT -> 1 , TOTAL_USED_BYTES -> 7 , 
2024-05-31 20:34:28,422 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:28,423 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:28,863 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: remove    LEADER 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A:t1, leader=076ccc74-63d1-410b-8584-7a1d80cfc8c8, voted=076ccc74-63d1-410b-8584-7a1d80cfc8c8, raftlog=Memoized:076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-SegmentedRaftLog:OPENED:c0, conf=0: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025]|listeners:[], old=null RUNNING
2024-05-31 20:34:28,863 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A: shutdown
2024-05-31 20:34:28,864 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-0EAD3654C05A,id=076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:28,864 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: shutdown 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-LeaderStateImpl
2024-05-31 20:34:28,864 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-PendingRequests: sendNotLeaderResponses
2024-05-31 20:34:28,865 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-StateMachineUpdater: set stopIndex = 0
2024-05-31 20:34:28,865 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-0EAD3654C05A: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/c43c2b80-c72a-4420-a2bc-0ead3654c05a/sm/snapshot.1_0
2024-05-31 20:34:28,865 [grpc-default-executor-3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01-SegmentedRaftLogWorker close()
2024-05-31 20:34:28,865 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_MAINTENANCE, scaling executor pool size to 20
2024-05-31 20:34:28,865 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-0EAD3654C05A: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/c43c2b80-c72a-4420-a2bc-0ead3654c05a/sm/snapshot.1_0 took: 0 ms
2024-05-31 20:34:28,866 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-StateMachineUpdater: Took a snapshot at index 0
2024-05-31 20:34:28,866 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-05-31 20:34:28,866 [IPC Server handler 10 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1) as the reported value (IN_MAINTENANCE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-05-31 20:34:28,866 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A: applyIndex: 0
2024-05-31 20:34:28,867 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-05-31 20:34:28,868 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), {type: FCR, size: 1}
2024-05-31 20:34:28,868 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-4A82ED352A01: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/9a915894-abff-4e14-8344-4a82ed352a01
2024-05-31 20:34:28,869 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), {type: FCR, size: 1}
2024-05-31 20:34:28,869 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), {type: FCR, size: 1}
2024-05-31 20:34:28,869 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), {type: FCR, size: 1}
2024-05-31 20:34:28,877 [grpc-default-executor-3] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: remove  FOLLOWER 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01:t1, leader=076ccc74-63d1-410b-8584-7a1d80cfc8c8, voted=076ccc74-63d1-410b-8584-7a1d80cfc8c8, raftlog=Memoized:2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-SegmentedRaftLog:OPENED:c9, conf=0: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null RUNNING
2024-05-31 20:34:28,877 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01: shutdown
2024-05-31 20:34:28,877 [grpc-default-executor-3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4A82ED352A01,id=2fad9ecd-4424-4a8b-880f-fd93cda6f409
2024-05-31 20:34:28,878 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: shutdown 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-FollowerState
2024-05-31 20:34:28,878 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-FollowerState was interrupted
2024-05-31 20:34:28,878 [grpc-default-executor-3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-StateMachineUpdater: set stopIndex = 9
2024-05-31 20:34:28,879 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-4A82ED352A01: Taking a snapshot at:(t:1, i:9) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/9a915894-abff-4e14-8344-4a82ed352a01/sm/snapshot.1_9
2024-05-31 20:34:28,880 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-4A82ED352A01: Finished taking a snapshot at:(t:1, i:9) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/9a915894-abff-4e14-8344-4a82ed352a01/sm/snapshot.1_9 took: 1 ms
2024-05-31 20:34:28,880 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-StateMachineUpdater: Took a snapshot at index 9
2024-05-31 20:34:28,880 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 9
2024-05-31 20:34:28,881 [grpc-default-executor-3] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01: applyIndex: 9
2024-05-31 20:34:28,881 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-05-31 20:34:28,883 [grpc-default-executor-5] WARN  server.RaftServer (RaftServerProxy.java:remove(106)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: does not contain group: group-4A82ED352A01
2024-05-31 20:34:28,893 [grpc-default-executor-5] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: remove  FOLLOWER 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01:t1, leader=076ccc74-63d1-410b-8584-7a1d80cfc8c8, voted=076ccc74-63d1-410b-8584-7a1d80cfc8c8, raftlog=Memoized:390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-SegmentedRaftLog:OPENED:c9, conf=0: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null RUNNING
2024-05-31 20:34:28,893 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01: shutdown
2024-05-31 20:34:28,893 [grpc-default-executor-5] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4A82ED352A01,id=390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:28,894 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-FollowerState
2024-05-31 20:34:28,894 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-FollowerState was interrupted
2024-05-31 20:34:28,894 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-4A82ED352A01: Taking a snapshot at:(t:1, i:9) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/9a915894-abff-4e14-8344-4a82ed352a01/sm/snapshot.1_9
2024-05-31 20:34:28,894 [grpc-default-executor-5] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-StateMachineUpdater: set stopIndex = 9
2024-05-31 20:34:28,895 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-4A82ED352A01: Finished taking a snapshot at:(t:1, i:9) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/9a915894-abff-4e14-8344-4a82ed352a01/sm/snapshot.1_9 took: 1 ms
2024-05-31 20:34:28,895 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-StateMachineUpdater: Took a snapshot at index 9
2024-05-31 20:34:28,895 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 9
2024-05-31 20:34:28,896 [grpc-default-executor-5] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01: applyIndex: 9
2024-05-31 20:34:28,896 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-05-31 20:34:29,034 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A-SegmentedRaftLogWorker close()
2024-05-31 20:34:29,035 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-0EAD3654C05A: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/c43c2b80-c72a-4420-a2bc-0ead3654c05a
2024-05-31 20:34:29,035 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(140)) - Close Pipeline PipelineID=c43c2b80-c72a-4420-a2bc-0ead3654c05a command on datanode 076ccc74-63d1-410b-8584-7a1d80cfc8c8.
2024-05-31 20:34:29,159 [UnderReplicatedProcessor] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:chooseNodeInternal(672)) - No available node in (scope="/" excludedScope="[/default-rack/390bac8a-0dbf-4715-b6fd-0c75abb5c43b, /default-rack/2fad9ecd-4424-4a8b-880f-fd93cda6f409, /default-rack/076ccc74-63d1-410b-8584-7a1d80cfc8c8]" excludedNodes="[390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)]"  ancestorGen="1").
2024-05-31 20:34:29,160 [UnderReplicatedProcessor] WARN  algorithms.SCMContainerPlacementRackAware (SCMContainerPlacementRackAware.java:chooseNode(485)) - Failed to find the datanode for container. excludedNodes:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)], affinityNode:
2024-05-31 20:34:29,161 [UnderReplicatedProcessor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [replicateContainerCommand: containerId=1, replicaIndex=0, targetNode=b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1), priority=NORMAL] for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-05-31T20:34:23.864421440Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault} to 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1) with datanode deadline 1717188239161 and scm deadline 1717188269161
2024-05-31 20:34:29,161 [UnderReplicatedProcessor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(138)) - Processed 1 containers with health state counts {UNDER_REPLICATED=1}, failed processing 0, deferred due to load 0
2024-05-31 20:34:29,169 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:34:29,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@29fc23d1. There are 2 pipelines
2024-05-31 20:34:29,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:29,231 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 is not found
2024-05-31 20:34:29,350 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:29,350 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:29,350 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:29,352 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:29,352 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:29,427 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:29,427 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:29,427 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:29,427 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:29,427 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:29,427 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:29,427 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:29,865 [grpc-default-executor-5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01-SegmentedRaftLogWorker close()
2024-05-31 20:34:29,867 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-4A82ED352A01: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/9a915894-abff-4e14-8344-4a82ed352a01
2024-05-31 20:34:29,869 [grpc-default-executor-3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01-SegmentedRaftLogWorker close()
2024-05-31 20:34:29,870 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-PipelineCommandHandlerThread-0] WARN  server.RaftServer (RaftServerProxy.java:remove(106)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: does not contain group: group-4A82ED352A01
2024-05-31 20:34:29,871 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-4A82ED352A01: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/9a915894-abff-4e14-8344-4a82ed352a01
2024-05-31 20:34:29,874 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] WARN  server.RaftServer (RaftServerProxy.java:remove(106)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: does not contain group: group-4A82ED352A01
2024-05-31 20:34:29,880 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-ContainerReplicationThread-0] INFO  replication.PushReplicator (PushReplicator.java:replicate(58)) - Starting replication of container 1 to b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1) using NO_COMPRESSION
2024-05-31 20:34:29,905 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-ContainerReplicationThread-0] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(116)) - Sent 16384 bytes for container 1
2024-05-31 20:34:29,909 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-ReplicationContainerReader-1] INFO  replication.SendContainerRequestHandler (SendContainerRequestHandler.java:onNext(96)) - Accepting container 1
2024-05-31 20:34:29,910 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-ReplicationContainerReader-1] INFO  replication.SendContainerRequestHandler (SendContainerRequestHandler.java:onCompleted(131)) - Container 1 is downloaded with size 16384, starting to import.
2024-05-31 20:34:29,951 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-ReplicationContainerReader-1] INFO  replication.SendContainerRequestHandler (SendContainerRequestHandler.java:onCompleted(137)) - Container 1 is replicated successfully
2024-05-31 20:34:29,955 [grpc-default-executor-2] INFO  replication.GrpcContainerUploader (GrpcContainerUploader.java:onCompleted(132)) - Finished uploading container 1 to b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1)
2024-05-31 20:34:29,955 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(369)) - Successful DONE replicateContainerCommand: containerId=1, replicaIndex=0, targetNode=b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1), priority=NORMAL, transferred 16384 bytes
2024-05-31 20:34:30,170 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:34:30,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@29fc23d1. There are 2 pipelines
2024-05-31 20:34:30,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:30,354 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:30,355 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:30,355 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:30,357 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:30,357 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:30,430 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:processExistingDBRecords(299)) - DELETED existing unhealthy container record...for Container: 1
2024-05-31 20:34:30,441 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:30,441 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:30,441 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:30,441 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:30,441 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:30,441 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:30,441 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:31,171 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:34:31,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@29fc23d1. There are 2 pipelines
2024-05-31 20:34:31,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:31,359 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:31,359 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:31,359 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:31,361 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:31,361 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:31,444 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:31,445 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:31,445 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:31,445 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:31,445 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:31,445 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:31,445 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:32,171 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:34:32,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@29fc23d1. There are 2 pipelines
2024-05-31 20:34:32,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:32,363 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:32,363 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:32,363 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:32,366 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:32,366 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:32,448 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:32,448 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:32,448 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:32,448 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:32,448 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:32,448 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:32,448 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:33,172 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:34:33,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@29fc23d1. There are 2 pipelines
2024-05-31 20:34:33,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:33,319 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5046675782ns, electionTimeout:5046ms
2024-05-31 20:34:33,319 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-FollowerState
2024-05-31 20:34:33,320 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-05-31 20:34:33,320 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-05-31 20:34:33,320 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: start 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-LeaderElection9
2024-05-31 20:34:33,320 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-LeaderElection9 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:33,321 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-LeaderElection9-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016
2024-05-31 20:34:33,321 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-LeaderElection9-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043
2024-05-31 20:34:33,321 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:33,321 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:33,327 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF: receive requestVote(PRE_VOTE, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, group-9048D00D16EF, 0, (t:0, i:0))
2024-05-31 20:34:33,327 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-FOLLOWER: reject PRE_VOTE from 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: our priority 1 > candidate's priority 0
2024-05-31 20:34:33,327 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF replies to PRE_VOTE vote request: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b<-b079985c-91b9-4d2e-8c89-c2e47b34f7da#0:FAIL-t0. Peer's state: b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF:t0, leader=null, voted=, raftlog=Memoized:b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:33,329 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-LeaderElection9: PRE_VOTE REJECTED received 1 response(s) and 0 exception(s):
2024-05-31 20:34:33,329 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b<-b079985c-91b9-4d2e-8c89-c2e47b34f7da#0:FAIL-t0
2024-05-31 20:34:33,329 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-LeaderElection9 PRE_VOTE round 0: result REJECTED
2024-05-31 20:34:33,329 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-LeaderElection9] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2024-05-31 20:34:33,329 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-LeaderElection9
2024-05-31 20:34:33,329 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: start 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-FollowerState
2024-05-31 20:34:33,329 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-LeaderElection9] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF: set firstElectionSinceStartup to false for REJECTED
2024-05-31 20:34:33,331 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF: receive requestVote(PRE_VOTE, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, group-9048D00D16EF, 0, (t:0, i:0))
2024-05-31 20:34:33,331 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-FOLLOWER: accept PRE_VOTE from 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: our priority 0 <= candidate's priority 0
2024-05-31 20:34:33,332 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF replies to PRE_VOTE vote request: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b<-2fad9ecd-4424-4a8b-880f-fd93cda6f409#0:OK-t0. Peer's state: 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF:t0, leader=null, voted=, raftlog=Memoized:2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:33,339 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:33,339 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:33,368 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:33,368 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:33,368 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:33,368 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5156654149ns, electionTimeout:5155ms
2024-05-31 20:34:33,368 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: shutdown b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-FollowerState
2024-05-31 20:34:33,368 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-05-31 20:34:33,368 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-05-31 20:34:33,368 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: start b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10
2024-05-31 20:34:33,370 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:33,370 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:33,370 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:33,371 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034
2024-05-31 20:34:33,371 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016
2024-05-31 20:34:33,371 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:33,371 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:33,376 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF: receive requestVote(PRE_VOTE, b079985c-91b9-4d2e-8c89-c2e47b34f7da, group-9048D00D16EF, 0, (t:0, i:0))
2024-05-31 20:34:33,377 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-FOLLOWER: accept PRE_VOTE from b079985c-91b9-4d2e-8c89-c2e47b34f7da: our priority 0 <= candidate's priority 1
2024-05-31 20:34:33,377 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF replies to PRE_VOTE vote request: b079985c-91b9-4d2e-8c89-c2e47b34f7da<-390bac8a-0dbf-4715-b6fd-0c75abb5c43b#0:OK-t0. Peer's state: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF:t0, leader=null, voted=, raftlog=Memoized:390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:33,377 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF: receive requestVote(PRE_VOTE, b079985c-91b9-4d2e-8c89-c2e47b34f7da, group-9048D00D16EF, 0, (t:0, i:0))
2024-05-31 20:34:33,377 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-FOLLOWER: accept PRE_VOTE from b079985c-91b9-4d2e-8c89-c2e47b34f7da: our priority 0 <= candidate's priority 1
2024-05-31 20:34:33,378 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF replies to PRE_VOTE vote request: b079985c-91b9-4d2e-8c89-c2e47b34f7da<-2fad9ecd-4424-4a8b-880f-fd93cda6f409#0:OK-t0. Peer's state: 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF:t0, leader=null, voted=, raftlog=Memoized:2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:33,378 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2024-05-31 20:34:33,378 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: b079985c-91b9-4d2e-8c89-c2e47b34f7da<-390bac8a-0dbf-4715-b6fd-0c75abb5c43b#0:OK-t0
2024-05-31 20:34:33,378 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10 PRE_VOTE round 0: result PASSED
2024-05-31 20:34:33,379 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10 ELECTION round 0: submit vote requests at term 1 for -1: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:33,380 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:33,380 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:33,381 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF: receive requestVote(ELECTION, b079985c-91b9-4d2e-8c89-c2e47b34f7da, group-9048D00D16EF, 1, (t:0, i:0))
2024-05-31 20:34:33,381 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-FOLLOWER: accept ELECTION from b079985c-91b9-4d2e-8c89-c2e47b34f7da: our priority 0 <= candidate's priority 1
2024-05-31 20:34:33,381 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:33,381 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-FollowerState
2024-05-31 20:34:33,381 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: start 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-FollowerState
2024-05-31 20:34:33,381 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-FollowerState was interrupted
2024-05-31 20:34:33,383 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF: receive requestVote(ELECTION, b079985c-91b9-4d2e-8c89-c2e47b34f7da, group-9048D00D16EF, 1, (t:0, i:0))
2024-05-31 20:34:33,383 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-FOLLOWER: accept ELECTION from b079985c-91b9-4d2e-8c89-c2e47b34f7da: our priority 0 <= candidate's priority 1
2024-05-31 20:34:33,383 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:33,383 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: shutdown 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-FollowerState
2024-05-31 20:34:33,383 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF replies to ELECTION vote request: b079985c-91b9-4d2e-8c89-c2e47b34f7da<-390bac8a-0dbf-4715-b6fd-0c75abb5c43b#0:OK-t1. Peer's state: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF:t1, leader=null, voted=b079985c-91b9-4d2e-8c89-c2e47b34f7da, raftlog=Memoized:390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:33,383 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-FollowerState was interrupted
2024-05-31 20:34:33,383 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: start 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-FollowerState
2024-05-31 20:34:33,384 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10: ELECTION PASSED received 1 response(s) and 0 exception(s):
2024-05-31 20:34:33,384 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: b079985c-91b9-4d2e-8c89-c2e47b34f7da<-390bac8a-0dbf-4715-b6fd-0c75abb5c43b#0:OK-t1
2024-05-31 20:34:33,384 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10 ELECTION round 0: result PASSED
2024-05-31 20:34:33,384 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: shutdown b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10
2024-05-31 20:34:33,384 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-05-31 20:34:33,385 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-05-31 20:34:33,384 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF: set firstElectionSinceStartup to false for candidate:b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:33,385 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:34:33,385 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-05-31 20:34:33,385 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-05-31 20:34:33,385 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-05-31 20:34:33,386 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-05-31 20:34:33,386 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-05-31 20:34:33,386 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-05-31 20:34:33,386 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:33,386 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:34:33,386 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-05-31 20:34:33,386 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF replies to ELECTION vote request: b079985c-91b9-4d2e-8c89-c2e47b34f7da<-2fad9ecd-4424-4a8b-880f-fd93cda6f409#0:OK-t1. Peer's state: 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF:t1, leader=null, voted=b079985c-91b9-4d2e-8c89-c2e47b34f7da, raftlog=Memoized:2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:33,387 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-05-31 20:34:33,387 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:33,387 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2024-05-31 20:34:33,387 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0μs (custom)
2024-05-31 20:34:33,387 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-05-31 20:34:33,388 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:33,388 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-05-31 20:34:33,388 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-05-31 20:34:33,388 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-05-31 20:34:33,388 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:33,388 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-05-31 20:34:33,390 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-05-31 20:34:33,390 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:33,390 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2024-05-31 20:34:33,390 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0μs (custom)
2024-05-31 20:34:33,390 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-05-31 20:34:33,390 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:33,390 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-05-31 20:34:33,390 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-05-31 20:34:33,390 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-05-31 20:34:33,390 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:33,390 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-05-31 20:34:33,391 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: start b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderStateImpl
2024-05-31 20:34:33,391 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF: set firstElectionSinceStartup to false for becomeLeader
2024-05-31 20:34:33,391 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-9048D00D16EF with new leaderId: b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:33,391 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF: change Leader from null to b079985c-91b9-4d2e-8c89-c2e47b34f7da at term 1 for becomeLeader, leader elected after 5194ms
2024-05-31 20:34:33,391 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-SegmentedRaftLogWorker: Starting segment from index:0
2024-05-31 20:34:33,392 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderElection10] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF: set configuration 0: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:33,392 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-05-31 20:34:33,402 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef/current/log_inprogress_0
2024-05-31 20:34:33,409 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-9048D00D16EF with new leaderId: b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:33,410 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF: change Leader from null to b079985c-91b9-4d2e-8c89-c2e47b34f7da at term 1 for appendEntries, leader elected after 5186ms
2024-05-31 20:34:33,412 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-9048D00D16EF with new leaderId: b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:33,413 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF: set configuration 0: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:33,413 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-SegmentedRaftLogWorker: Starting segment from index:0
2024-05-31 20:34:33,413 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF: change Leader from null to b079985c-91b9-4d2e-8c89-c2e47b34f7da at term 1 for appendEntries, leader elected after 5156ms
2024-05-31 20:34:33,413 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-05-31 20:34:33,418 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF: set configuration 0: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:33,419 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-SegmentedRaftLogWorker: Starting segment from index:0
2024-05-31 20:34:33,420 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-05-31 20:34:33,422 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef/current/log_inprogress_0
2024-05-31 20:34:33,428 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-05-31 20:34:33,428 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef/current/log_inprogress_0
2024-05-31 20:34:33,451 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:33,451 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:33,452 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:33,452 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:33,452 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:33,452 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:33,452 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:34,035 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=e2b2676c-1441-482f-9bbc-9048d00d16ef since it stays at CLOSED stage.
2024-05-31 20:34:34,035 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=e2b2676c-1441-482f-9bbc-9048d00d16ef close command to datanode 2fad9ecd-4424-4a8b-880f-fd93cda6f409
2024-05-31 20:34:34,036 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=e2b2676c-1441-482f-9bbc-9048d00d16ef close command to datanode b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:34,036 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=e2b2676c-1441-482f-9bbc-9048d00d16ef close command to datanode 390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:34,036 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: e2b2676c-1441-482f-9bbc-9048d00d16ef, Nodes: 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1)b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1)390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:b079985c-91b9-4d2e-8c89-c2e47b34f7da, CreationTimestamp2024-05-31T20:34:26.177Z[Etc/UTC]] removed.
2024-05-31 20:34:34,036 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=2cc65240-011a-451d-b3ff-9f8ad608864b since it stays at CLOSED stage.
2024-05-31 20:34:34,036 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=2cc65240-011a-451d-b3ff-9f8ad608864b close command to datanode 390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:34,036 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 2cc65240-011a-451d-b3ff-9f8ad608864b, Nodes: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:390bac8a-0dbf-4715-b6fd-0c75abb5c43b, CreationTimestamp2024-05-31T20:34:09.016Z[Etc/UTC]] removed.
2024-05-31 20:34:34,172 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:34:34,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(472)) - org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@29fc23d1 has 1 sufficientlyReplicated, 0 deleting, 0 underReplicated and 0 unclosed containers
2024-05-31 20:34:34,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:putIntoMaintenance(529)) - Datanode 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1) has entered maintenance
2024-05-31 20:34:34,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:34,175 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1) moved to HEALTHY state.
2024-05-31 20:34:34,175 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-05-31 20:34:34,176 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=81e6b01c-7968-4b55-acde-dd6f8777dcc0 to datanode:55857a12-8529-4f00-ab69-b96d955e4226
2024-05-31 20:34:34,176 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=81e6b01c-7968-4b55-acde-dd6f8777dcc0 to datanode:2fad9ecd-4424-4a8b-880f-fd93cda6f409
2024-05-31 20:34:34,176 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=81e6b01c-7968-4b55-acde-dd6f8777dcc0 to datanode:b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:34,177 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 81e6b01c-7968-4b55-acde-dd6f8777dcc0, Nodes: 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1)2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1)b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-05-31T20:34:34.176290382Z[Etc/UTC]]
2024-05-31 20:34:34,265 [IPC Server handler 5 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2024-05-31 20:34:34,266 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=e2b2676c-1441-482f-9bbc-9048d00d16ef is not found
2024-05-31 20:34:34,266 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=2cc65240-011a-451d-b3ff-9f8ad608864b is not found
2024-05-31 20:34:34,316 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, b079985c-91b9-4d2e-8c89-c2e47b34f7da]
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-05-31 20:34:34,339 [IPC Server handler 13 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:recommission(476)) - Queued node 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1) for recommission
2024-05-31 20:34:34,339 [IPC Server handler 13 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:recommission(476)) - Queued node 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1) for recommission
2024-05-31 20:34:34,373 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:34,373 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:34,373 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:34,375 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:34,375 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:34,392 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=e2b2676c-1441-482f-9bbc-9048d00d16ef is not found
2024-05-31 20:34:34,456 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:34,456 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:34,456 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:34,456 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:34,456 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:34,456 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:34,456 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:35,173 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:34:35,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:processCancelledNodes(292)) - Recommissioned node org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@61f63faa
2024-05-31 20:34:35,174 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1) moved to HEALTHY state.
2024-05-31 20:34:35,175 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-05-31 20:34:35,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:processCancelledNodes(292)) - Recommissioned node org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@29fc23d1
2024-05-31 20:34:35,175 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1) moved to HEALTHY state.
2024-05-31 20:34:35,175 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-05-31 20:34:35,176 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=13364d75-4ec1-47d6-8b5b-a35eb7b01fa0 to datanode:076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:35,177 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 13364d75-4ec1-47d6-8b5b-a35eb7b01fa0, Nodes: 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-05-31T20:34:35.176127051Z[Etc/UTC]]
2024-05-31 20:34:35,177 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=3166dcd9-053f-42c3-b8ea-1d0408d68c02 to datanode:390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:35,177 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 3166dcd9-053f-42c3-b8ea-1d0408d68c02, Nodes: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-05-31T20:34:35.177461328Z[Etc/UTC]]
2024-05-31 20:34:35,232 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=e2b2676c-1441-482f-9bbc-9048d00d16ef is not found
2024-05-31 20:34:35,265 [IPC Server handler 8 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-05-31 20:34:35,374 [IPC Server handler 17 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:decommissionNodes(321)) - Force flag = false. Checking if decommission is possible for dns: [2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1)]
2024-05-31 20:34:35,374 [IPC Server handler 17 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startDecommission(376)) - Starting Decommission for node 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1)
2024-05-31 20:34:35,374 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1) moved to HEALTHY state.
2024-05-31 20:34:35,374 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
2024-05-31 20:34:35,377 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:35,377 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:35,377 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:35,378 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:35,378 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-05-31 20:34:35,393 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=e2b2676c-1441-482f-9bbc-9048d00d16ef is not found
2024-05-31 20:34:35,402 [grpc-default-executor-5] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: remove  FOLLOWER 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF:t1, leader=b079985c-91b9-4d2e-8c89-c2e47b34f7da, voted=b079985c-91b9-4d2e-8c89-c2e47b34f7da, raftlog=Memoized:390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-SegmentedRaftLog:OPENED:c-1, conf=0: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null RUNNING
2024-05-31 20:34:35,402 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF: shutdown
2024-05-31 20:34:35,402 [grpc-default-executor-5] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-9048D00D16EF,id=390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:35,402 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-FollowerState
2024-05-31 20:34:35,403 [grpc-default-executor-5] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-StateMachineUpdater: set stopIndex = -1
2024-05-31 20:34:35,403 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-FollowerState was interrupted
2024-05-31 20:34:35,403 [grpc-default-executor-5] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF: applyIndex: -1
2024-05-31 20:34:35,403 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-05-31 20:34:35,429 [grpc-default-executor-5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF-SegmentedRaftLogWorker close()
2024-05-31 20:34:35,430 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9048D00D16EF: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef
2024-05-31 20:34:35,439 [grpc-default-executor-5] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: remove  FOLLOWER 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF:t1, leader=b079985c-91b9-4d2e-8c89-c2e47b34f7da, voted=b079985c-91b9-4d2e-8c89-c2e47b34f7da, raftlog=Memoized:2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-SegmentedRaftLog:OPENED:c-1, conf=0: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null RUNNING
2024-05-31 20:34:35,439 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF: shutdown
2024-05-31 20:34:35,440 [grpc-default-executor-5] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-9048D00D16EF,id=2fad9ecd-4424-4a8b-880f-fd93cda6f409
2024-05-31 20:34:35,440 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: shutdown 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-FollowerState
2024-05-31 20:34:35,440 [grpc-default-executor-5] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-StateMachineUpdater: set stopIndex = -1
2024-05-31 20:34:35,440 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-FollowerState was interrupted
2024-05-31 20:34:35,440 [grpc-default-executor-5] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF: applyIndex: -1
2024-05-31 20:34:35,440 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-05-31 20:34:35,460 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:35,460 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:35,460 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:35,460 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:35,460 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:35,461 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:35,461 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:35,865 [IPC Server handler 10 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1) as the reported value (IN_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-05-31 20:34:36,173 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:34:36,174 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(55)) - Admin start on datanode 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1). Finalizing its pipelines [PipelineID=81e6b01c-7968-4b55-acde-dd6f8777dcc0, PipelineID=0e0510fd-577d-4847-942d-1c3c34dfe8e1]
2024-05-31 20:34:36,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@2e20dddc. There are 2 pipelines
2024-05-31 20:34:36,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:36,175 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=81e6b01c-7968-4b55-acde-dd6f8777dcc0 moved to CLOSED state
2024-05-31 20:34:36,176 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=0e0510fd-577d-4847-942d-1c3c34dfe8e1 moved to CLOSED state
2024-05-31 20:34:36,230 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: addNew group-DD6F8777DCC0:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043] returns group-DD6F8777DCC0:java.util.concurrent.CompletableFuture@7a07dbe6[Not completed]
2024-05-31 20:34:36,231 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: new RaftServerImpl for group-DD6F8777DCC0:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043] with ContainerStateMachine:uninitialized
2024-05-31 20:34:36,231 [IPC Server handler 7 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (DECOMMISSIONING, 0)
2024-05-31 20:34:36,231 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:36,232 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-05-31 20:34:36,232 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:34:36,232 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-05-31 20:34:36,232 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:36,232 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:34:36,232 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:36,232 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0: ConfigurationManager, init=-1: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:34:36,232 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-05-31 20:34:36,232 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:34:36,232 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-05-31 20:34:36,232 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:34:36,233 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:34:36,233 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:34:36,236 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:36,236 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:36,236 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:34:36,236 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:34:36,236 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:34:36,236 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:34:36,236 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-05-31 20:34:36,236 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-05-31 20:34:36,236 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis] (custom)
2024-05-31 20:34:36,237 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0 does not exist. Creating ...
2024-05-31 20:34:36,238 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0/in_use.lock acquired by nodename 83134@fv-az1343-628
2024-05-31 20:34:36,239 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0 has been successfully formatted.
2024-05-31 20:34:36,239 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0/current/raft-meta.conf
2024-05-31 20:34:36,239 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-DD6F8777DCC0: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-05-31 20:34:36,239 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-05-31 20:34:36,240 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-05-31 20:34:36,240 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:36,240 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-05-31 20:34:36,240 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-05-31 20:34:36,240 [IPC Server handler 5 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (DECOMMISSIONING, 0)
2024-05-31 20:34:36,241 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=81e6b01c-7968-4b55-acde-dd6f8777dcc0. Trying to get from SCM.
2024-05-31 20:34:36,242 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(86)) - Adding new pipeline Pipeline[ Id: 81e6b01c-7968-4b55-acde-dd6f8777dcc0, Nodes: 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1)2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1)b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:, CreationTimestamp2024-05-31T20:34:34.176Z[Etc/UTC]] to Recon pipeline metadata.
2024-05-31 20:34:36,243 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:36,243 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-05-31 20:34:36,243 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-05-31 20:34:36,243 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:36,243 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-cacheEviction-AwaitToRun,5,main] started
2024-05-31 20:34:36,243 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0
2024-05-31 20:34:36,244 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-05-31 20:34:36,244 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-05-31 20:34:36,244 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:36,244 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-05-31 20:34:36,244 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-05-31 20:34:36,244 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-05-31 20:34:36,244 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-05-31 20:34:36,244 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-05-31 20:34:36,245 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-05-31 20:34:36,247 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:36,247 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-05-31 20:34:36,247 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-05-31 20:34:36,247 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-05-31 20:34:36,247 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:36,247 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:36,247 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0: start as a follower, conf=-1: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:36,248 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-05-31 20:34:36,248 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: start 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-FollowerState
2024-05-31 20:34:36,248 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:36,248 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:36,248 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DD6F8777DCC0,id=2fad9ecd-4424-4a8b-880f-fd93cda6f409
2024-05-31 20:34:36,248 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-05-31 20:34:36,248 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-05-31 20:34:36,248 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-05-31 20:34:36,248 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-05-31 20:34:36,248 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-05-31 20:34:36,249 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=81e6b01c-7968-4b55-acde-dd6f8777dcc0
2024-05-31 20:34:36,256 [grpc-default-executor-2] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 55857a12-8529-4f00-ab69-b96d955e4226: addNew group-DD6F8777DCC0:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043] returns group-DD6F8777DCC0:java.util.concurrent.CompletableFuture@2dc742b3[Not completed]
2024-05-31 20:34:36,258 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 55857a12-8529-4f00-ab69-b96d955e4226: new RaftServerImpl for group-DD6F8777DCC0:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043] with ContainerStateMachine:uninitialized
2024-05-31 20:34:36,258 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:36,258 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-05-31 20:34:36,258 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:34:36,258 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-05-31 20:34:36,258 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:36,258 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:34:36,258 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:36,258 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0: ConfigurationManager, init=-1: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:34:36,258 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-05-31 20:34:36,258 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:34:36,258 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-05-31 20:34:36,258 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:34:36,258 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:34:36,258 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:34:36,261 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:36,261 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:36,261 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:34:36,261 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:34:36,261 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:34:36,261 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:34:36,261 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-05-31 20:34:36,262 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-05-31 20:34:36,262 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis] (custom)
2024-05-31 20:34:36,262 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0 does not exist. Creating ...
2024-05-31 20:34:36,263 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0/in_use.lock acquired by nodename 83134@fv-az1343-628
2024-05-31 20:34:36,264 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0 has been successfully formatted.
2024-05-31 20:34:36,264 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: remove    LEADER 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B:t1, leader=390bac8a-0dbf-4715-b6fd-0c75abb5c43b, voted=390bac8a-0dbf-4715-b6fd-0c75abb5c43b, raftlog=Memoized:390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-SegmentedRaftLog:OPENED:c0, conf=0: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null RUNNING
2024-05-31 20:34:36,265 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B: shutdown
2024-05-31 20:34:36,265 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-9F8AD608864B,id=390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:36,265 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-LeaderStateImpl
2024-05-31 20:34:36,265 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-PendingRequests: sendNotLeaderResponses
2024-05-31 20:34:36,265 [IPC Server handler 8 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-05-31 20:34:36,265 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-StateMachineUpdater: set stopIndex = 0
2024-05-31 20:34:36,266 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0/current/raft-meta.conf
2024-05-31 20:34:36,266 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_MAINTENANCE, scaling executor pool size to 20
2024-05-31 20:34:36,266 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-9F8AD608864B: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/2cc65240-011a-451d-b3ff-9f8ad608864b/sm/snapshot.1_0
2024-05-31 20:34:36,266 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=2cc65240-011a-451d-b3ff-9f8ad608864b is not found
2024-05-31 20:34:36,268 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-9F8AD608864B: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/2cc65240-011a-451d-b3ff-9f8ad608864b/sm/snapshot.1_0 took: 2 ms
2024-05-31 20:34:36,268 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-StateMachineUpdater: Took a snapshot at index 0
2024-05-31 20:34:36,268 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-05-31 20:34:36,269 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-DD6F8777DCC0: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-05-31 20:34:36,269 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-05-31 20:34:36,269 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-05-31 20:34:36,269 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:36,269 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B: applyIndex: 0
2024-05-31 20:34:36,269 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-05-31 20:34:36,269 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-05-31 20:34:36,269 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-05-31 20:34:36,269 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-05-31 20:34:36,272 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:36,272 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-05-31 20:34:36,272 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-05-31 20:34:36,272 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:36,272 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-cacheEviction-AwaitToRun,5,main] started
2024-05-31 20:34:36,273 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0
2024-05-31 20:34:36,273 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-05-31 20:34:36,273 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-05-31 20:34:36,273 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:36,273 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-05-31 20:34:36,273 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-05-31 20:34:36,273 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-05-31 20:34:36,273 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-05-31 20:34:36,273 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-05-31 20:34:36,274 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-05-31 20:34:36,275 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:36,276 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-05-31 20:34:36,276 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-05-31 20:34:36,276 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-05-31 20:34:36,276 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:36,276 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:36,276 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0: start as a follower, conf=-1: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:36,276 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-05-31 20:34:36,276 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 55857a12-8529-4f00-ab69-b96d955e4226: start 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-FollowerState
2024-05-31 20:34:36,277 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DD6F8777DCC0,id=55857a12-8529-4f00-ab69-b96d955e4226
2024-05-31 20:34:36,277 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-05-31 20:34:36,277 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-05-31 20:34:36,277 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-05-31 20:34:36,277 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-05-31 20:34:36,277 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-05-31 20:34:36,278 [55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:36,279 [55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:36,295 [grpc-default-executor-2] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: addNew group-DD6F8777DCC0:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043] returns group-DD6F8777DCC0:java.util.concurrent.CompletableFuture@15d099c9[Not completed]
2024-05-31 20:34:36,296 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: new RaftServerImpl for group-DD6F8777DCC0:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043] with ContainerStateMachine:uninitialized
2024-05-31 20:34:36,296 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:36,296 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-05-31 20:34:36,296 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:34:36,296 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-05-31 20:34:36,296 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:36,296 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:34:36,296 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:36,296 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0: ConfigurationManager, init=-1: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:34:36,296 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-05-31 20:34:36,296 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:34:36,296 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-05-31 20:34:36,297 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:34:36,297 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:34:36,297 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:34:36,299 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:36,299 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:36,299 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:34:36,299 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:34:36,299 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:34:36,299 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:34:36,299 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-05-31 20:34:36,299 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-05-31 20:34:36,299 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis] (custom)
2024-05-31 20:34:36,300 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0 does not exist. Creating ...
2024-05-31 20:34:36,300 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0/in_use.lock acquired by nodename 83134@fv-az1343-628
2024-05-31 20:34:36,302 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0 has been successfully formatted.
2024-05-31 20:34:36,302 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0/current/raft-meta.conf
2024-05-31 20:34:36,302 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-DD6F8777DCC0: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-05-31 20:34:36,302 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-05-31 20:34:36,304 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=e2b2676c-1441-482f-9bbc-9048d00d16ef is not found
2024-05-31 20:34:36,305 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-05-31 20:34:36,305 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:36,305 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-05-31 20:34:36,305 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-05-31 20:34:36,306 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:36,307 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-05-31 20:34:36,307 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-05-31 20:34:36,307 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:36,310 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-cacheEviction-AwaitToRun,5,main] started
2024-05-31 20:34:36,310 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0
2024-05-31 20:34:36,310 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-05-31 20:34:36,310 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-05-31 20:34:36,311 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:36,311 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-05-31 20:34:36,311 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-05-31 20:34:36,311 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-05-31 20:34:36,311 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-05-31 20:34:36,311 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-05-31 20:34:36,311 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-05-31 20:34:36,313 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:36,314 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-05-31 20:34:36,314 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-05-31 20:34:36,314 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-05-31 20:34:36,314 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:36,314 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:36,315 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0: start as a follower, conf=-1: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:36,315 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-05-31 20:34:36,315 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: start b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-FollowerState
2024-05-31 20:34:36,315 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:36,315 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:36,316 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DD6F8777DCC0,id=b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:36,316 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-05-31 20:34:36,316 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-05-31 20:34:36,316 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-05-31 20:34:36,316 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-05-31 20:34:36,316 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-05-31 20:34:36,328 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=81e6b01c-7968-4b55-acde-dd6f8777dcc0.
2024-05-31 20:34:36,380 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:36,381 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:36,381 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:36,383 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:36,383 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:36,423 [grpc-default-executor-5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF-SegmentedRaftLogWorker close()
2024-05-31 20:34:36,424 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-9048D00D16EF: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef
2024-05-31 20:34:36,427 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: remove    LEADER b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF:t1, leader=b079985c-91b9-4d2e-8c89-c2e47b34f7da, voted=b079985c-91b9-4d2e-8c89-c2e47b34f7da, raftlog=Memoized:b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-SegmentedRaftLog:OPENED:c0, conf=0: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null RUNNING
2024-05-31 20:34:36,427 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF: shutdown
2024-05-31 20:34:36,428 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-9048D00D16EF,id=b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:36,428 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: shutdown b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-LeaderStateImpl
2024-05-31 20:34:36,428 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF->390bac8a-0dbf-4715-b6fd-0c75abb5c43b-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF->390bac8a-0dbf-4715-b6fd-0c75abb5c43b-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-05-31 20:34:36,428 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF->2fad9ecd-4424-4a8b-880f-fd93cda6f409-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF->2fad9ecd-4424-4a8b-880f-fd93cda6f409-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-05-31 20:34:36,429 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: Completed APPEND_ENTRIES, lastRequest: null
2024-05-31 20:34:36,429 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: Completed APPEND_ENTRIES, lastRequest: null
2024-05-31 20:34:36,428 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-PendingRequests: sendNotLeaderResponses
2024-05-31 20:34:36,430 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-StateMachineUpdater: set stopIndex = 0
2024-05-31 20:34:36,430 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: Completed APPEND_ENTRIES, lastRequest: b079985c-91b9-4d2e-8c89-c2e47b34f7da->2fad9ecd-4424-4a8b-880f-fd93cda6f409#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "390bac8a-0dbf-4715-b6fd-0c75abb5c43b"
address: "127.0.0.1:15034"
dataStreamAddress: "127.0.0.1:15035"
clientAddress: "127.0.0.1:15032"
adminAddress: "127.0.0.1:15033"
startupRole: FOLLOWER
,id: "2fad9ecd-4424-4a8b-880f-fd93cda6f409"
address: "127.0.0.1:15016"
dataStreamAddress: "127.0.0.1:15017"
clientAddress: "127.0.0.1:15014"
adminAddress: "127.0.0.1:15015"
startupRole: FOLLOWER
,id: "b079985c-91b9-4d2e-8c89-c2e47b34f7da"
address: "127.0.0.1:15043"
priority: 1
dataStreamAddress: "127.0.0.1:15044"
clientAddress: "127.0.0.1:15041"
adminAddress: "127.0.0.1:15042"
startupRole: FOLLOWER
, old:)
2024-05-31 20:34:36,430 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: Completed APPEND_ENTRIES, lastReply: null
2024-05-31 20:34:36,430 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: Completed APPEND_ENTRIES, lastRequest: b079985c-91b9-4d2e-8c89-c2e47b34f7da->390bac8a-0dbf-4715-b6fd-0c75abb5c43b#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "390bac8a-0dbf-4715-b6fd-0c75abb5c43b"
address: "127.0.0.1:15034"
dataStreamAddress: "127.0.0.1:15035"
clientAddress: "127.0.0.1:15032"
adminAddress: "127.0.0.1:15033"
startupRole: FOLLOWER
,id: "2fad9ecd-4424-4a8b-880f-fd93cda6f409"
address: "127.0.0.1:15016"
dataStreamAddress: "127.0.0.1:15017"
clientAddress: "127.0.0.1:15014"
adminAddress: "127.0.0.1:15015"
startupRole: FOLLOWER
,id: "b079985c-91b9-4d2e-8c89-c2e47b34f7da"
address: "127.0.0.1:15043"
priority: 1
dataStreamAddress: "127.0.0.1:15044"
clientAddress: "127.0.0.1:15041"
adminAddress: "127.0.0.1:15042"
startupRole: FOLLOWER
, old:)
2024-05-31 20:34:36,430 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-9048D00D16EF: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef/sm/snapshot.1_0
2024-05-31 20:34:36,431 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: Completed APPEND_ENTRIES, lastReply: null
2024-05-31 20:34:36,431 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF->2fad9ecd-4424-4a8b-880f-fd93cda6f409-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-05-31 20:34:36,431 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-9048D00D16EF: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef/sm/snapshot.1_0 took: 2 ms
2024-05-31 20:34:36,432 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF->390bac8a-0dbf-4715-b6fd-0c75abb5c43b-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-05-31 20:34:36,432 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-StateMachineUpdater: Took a snapshot at index 0
2024-05-31 20:34:36,432 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-05-31 20:34:36,432 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF: applyIndex: 0
2024-05-31 20:34:36,432 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-05-31 20:34:36,464 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:36,464 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:36,464 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:36,464 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:36,464 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:36,464 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:36,464 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:36,864 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: addNew group-A35EB7B01FA0:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025] returns group-A35EB7B01FA0:java.util.concurrent.CompletableFuture@50448c7a[Not completed]
2024-05-31 20:34:36,865 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-05-31 20:34:36,867 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: new RaftServerImpl for group-A35EB7B01FA0:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025] with ContainerStateMachine:uninitialized
2024-05-31 20:34:36,867 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:36,867 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-05-31 20:34:36,867 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:34:36,867 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-05-31 20:34:36,867 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:36,867 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:34:36,867 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:36,867 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0: ConfigurationManager, init=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:34:36,867 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-05-31 20:34:36,867 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:34:36,867 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-05-31 20:34:36,868 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:34:36,868 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:34:36,868 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:34:36,878 [IPC Server handler 11 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2024-05-31 20:34:36,878 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:36,878 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:36,878 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:34:36,879 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:34:36,879 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:34:36,879 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:34:36,879 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-05-31 20:34:36,879 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-05-31 20:34:36,879 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis] (custom)
2024-05-31 20:34:36,879 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/13364d75-4ec1-47d6-8b5b-a35eb7b01fa0 does not exist. Creating ...
2024-05-31 20:34:36,880 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/13364d75-4ec1-47d6-8b5b-a35eb7b01fa0/in_use.lock acquired by nodename 83134@fv-az1343-628
2024-05-31 20:34:36,881 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/13364d75-4ec1-47d6-8b5b-a35eb7b01fa0 has been successfully formatted.
2024-05-31 20:34:36,882 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/13364d75-4ec1-47d6-8b5b-a35eb7b01fa0/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/13364d75-4ec1-47d6-8b5b-a35eb7b01fa0/current/raft-meta.conf
2024-05-31 20:34:36,882 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-A35EB7B01FA0: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-05-31 20:34:36,882 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-05-31 20:34:36,882 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-05-31 20:34:36,891 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:36,891 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-05-31 20:34:36,891 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-05-31 20:34:36,892 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=13364d75-4ec1-47d6-8b5b-a35eb7b01fa0. Trying to get from SCM.
2024-05-31 20:34:36,892 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:36,892 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=13364d75-4ec1-47d6-8b5b-a35eb7b01fa0
2024-05-31 20:34:36,893 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-05-31 20:34:36,893 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-05-31 20:34:36,893 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:36,894 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(86)) - Adding new pipeline Pipeline[ Id: 13364d75-4ec1-47d6-8b5b-a35eb7b01fa0, Nodes: 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:076ccc74-63d1-410b-8584-7a1d80cfc8c8, CreationTimestamp2024-05-31T20:34:35.176Z[Etc/UTC]] to Recon pipeline metadata.
2024-05-31 20:34:36,895 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-cacheEviction-AwaitToRun,5,main] started
2024-05-31 20:34:36,895 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/13364d75-4ec1-47d6-8b5b-a35eb7b01fa0
2024-05-31 20:34:36,895 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-05-31 20:34:36,895 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-05-31 20:34:36,895 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:36,895 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-05-31 20:34:36,895 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-05-31 20:34:36,895 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-05-31 20:34:36,895 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-05-31 20:34:36,895 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-05-31 20:34:36,896 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-05-31 20:34:36,899 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:36,899 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-05-31 20:34:36,899 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-05-31 20:34:36,899 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-05-31 20:34:36,899 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:36,899 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:36,900 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0: start as a follower, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025]|listeners:[], old=null
2024-05-31 20:34:36,900 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-05-31 20:34:36,900 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: start 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-FollowerState
2024-05-31 20:34:36,906 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A35EB7B01FA0,id=076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:36,906 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-05-31 20:34:36,907 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-05-31 20:34:36,907 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-05-31 20:34:36,907 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-05-31 20:34:36,907 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-05-31 20:34:36,907 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:36,908 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:36,908 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=13364d75-4ec1-47d6-8b5b-a35eb7b01fa0
2024-05-31 20:34:36,908 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=13364d75-4ec1-47d6-8b5b-a35eb7b01fa0.
2024-05-31 20:34:37,086 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B-SegmentedRaftLogWorker close()
2024-05-31 20:34:37,087 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-9F8AD608864B: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/2cc65240-011a-451d-b3ff-9f8ad608864b
2024-05-31 20:34:37,087 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(140)) - Close Pipeline PipelineID=2cc65240-011a-451d-b3ff-9f8ad608864b command on datanode 390bac8a-0dbf-4715-b6fd-0c75abb5c43b.
2024-05-31 20:34:37,087 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: addNew group-1D0408D68C02:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034] returns group-1D0408D68C02:java.util.concurrent.CompletableFuture@18310db3[Not completed]
2024-05-31 20:34:37,088 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: new RaftServerImpl for group-1D0408D68C02:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034] with ContainerStateMachine:uninitialized
2024-05-31 20:34:37,088 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:37,088 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-05-31 20:34:37,088 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:34:37,089 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-05-31 20:34:37,089 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:37,089 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:34:37,089 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:37,089 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02: ConfigurationManager, init=-1: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:34:37,089 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-05-31 20:34:37,089 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:34:37,089 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-05-31 20:34:37,089 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:34:37,089 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:34:37,089 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:34:37,091 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:37,091 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:37,091 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:34:37,091 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:34:37,092 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:34:37,092 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:34:37,092 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-05-31 20:34:37,092 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-05-31 20:34:37,092 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis] (custom)
2024-05-31 20:34:37,092 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/3166dcd9-053f-42c3-b8ea-1d0408d68c02 does not exist. Creating ...
2024-05-31 20:34:37,093 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/3166dcd9-053f-42c3-b8ea-1d0408d68c02/in_use.lock acquired by nodename 83134@fv-az1343-628
2024-05-31 20:34:37,094 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/3166dcd9-053f-42c3-b8ea-1d0408d68c02 has been successfully formatted.
2024-05-31 20:34:37,094 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/3166dcd9-053f-42c3-b8ea-1d0408d68c02/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/3166dcd9-053f-42c3-b8ea-1d0408d68c02/current/raft-meta.conf
2024-05-31 20:34:37,094 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-1D0408D68C02: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-05-31 20:34:37,095 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-05-31 20:34:37,095 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-05-31 20:34:37,095 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:37,095 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-05-31 20:34:37,095 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-05-31 20:34:37,096 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:37,096 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=3166dcd9-053f-42c3-b8ea-1d0408d68c02
2024-05-31 20:34:37,097 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-05-31 20:34:37,097 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-05-31 20:34:37,097 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:37,097 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-cacheEviction-AwaitToRun,5,main] started
2024-05-31 20:34:37,097 [IPC Server handler 15 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-05-31 20:34:37,097 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/3166dcd9-053f-42c3-b8ea-1d0408d68c02
2024-05-31 20:34:37,097 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-05-31 20:34:37,097 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-05-31 20:34:37,097 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:37,097 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-05-31 20:34:37,098 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-05-31 20:34:37,098 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-05-31 20:34:37,098 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-05-31 20:34:37,098 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=3166dcd9-053f-42c3-b8ea-1d0408d68c02. Trying to get from SCM.
2024-05-31 20:34:37,098 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-05-31 20:34:37,098 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-05-31 20:34:37,099 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(86)) - Adding new pipeline Pipeline[ Id: 3166dcd9-053f-42c3-b8ea-1d0408d68c02, Nodes: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:390bac8a-0dbf-4715-b6fd-0c75abb5c43b, CreationTimestamp2024-05-31T20:34:35.177Z[Etc/UTC]] to Recon pipeline metadata.
2024-05-31 20:34:37,100 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:37,100 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-05-31 20:34:37,101 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-05-31 20:34:37,101 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-05-31 20:34:37,101 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:37,101 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:37,101 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02: start as a follower, conf=-1: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:34:37,101 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-05-31 20:34:37,101 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: start 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-FollowerState
2024-05-31 20:34:37,101 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:37,102 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:37,102 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1D0408D68C02,id=390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:37,102 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-05-31 20:34:37,102 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-05-31 20:34:37,102 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-05-31 20:34:37,102 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-05-31 20:34:37,102 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-05-31 20:34:37,103 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=3166dcd9-053f-42c3-b8ea-1d0408d68c02
2024-05-31 20:34:37,103 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=3166dcd9-053f-42c3-b8ea-1d0408d68c02.
2024-05-31 20:34:37,174 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:34:37,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@2e20dddc. There are 2 pipelines
2024-05-31 20:34:37,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:37,241 [IPC Server handler 8 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (DECOMMISSIONING, 0)
2024-05-31 20:34:37,385 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:37,385 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:37,385 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:37,387 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:37,387 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:37,403 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF-SegmentedRaftLogWorker close()
2024-05-31 20:34:37,404 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/e2b2676c-1441-482f-9bbc-9048d00d16ef
2024-05-31 20:34:37,404 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(140)) - Close Pipeline PipelineID=e2b2676c-1441-482f-9bbc-9048d00d16ef command on datanode b079985c-91b9-4d2e-8c89-c2e47b34f7da.
2024-05-31 20:34:37,469 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:37,469 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:37,469 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:37,469 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:37,469 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:37,469 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	TOTAL_KEYS -> 1 , CONTAINER_COUNT -> 1 , TOTAL_USED_BYTES -> 7 , 
2024-05-31 20:34:37,469 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:38,156 [OverReplicatedProcessor] INFO  replication.RatisOverReplicationHandler (RatisOverReplicationHandler.java:processAndSendCommands(115)) - Container #1 is over replicated. Actual replica count is 4, with 0 pending delete(s). Expected replica count is 3.
2024-05-31 20:34:38,157 [OverReplicatedProcessor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [deleteContainerCommand: containerID: 1, replicaIndex: 0, force: true] for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-05-31T20:34:23.864421440Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault} to b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1) with datanode deadline 1717188248157 and scm deadline 1717188278157
2024-05-31 20:34:38,157 [OverReplicatedProcessor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(138)) - Processed 1 containers with health state counts {OVER_REPLICATED=1}, failed processing 0, deferred due to load 0
2024-05-31 20:34:38,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@2e20dddc. There are 2 pipelines
2024-05-31 20:34:38,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:38,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:34:38,231 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to DECOMMISSIONING, scaling executor pool size to 20
2024-05-31 20:34:38,241 [IPC Server handler 19 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1) as the reported value (DECOMMISSIONING, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-05-31 20:34:38,389 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:38,389 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:38,389 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:38,391 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:38,391 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:38,471 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:processExistingDBRecords(299)) - DELETED existing unhealthy container record...for Container: 1
2024-05-31 20:34:38,473 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:38,473 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:38,473 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:38,474 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:38,474 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:38,474 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:38,474 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:39,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@2e20dddc. There are 2 pipelines
2024-05-31 20:34:39,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:39,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:34:39,307 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-DeleteContainerThread-0] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:markContainerForDelete(424)) - Moving container /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/current/containerDir0/1 to state DELETED from state:CLOSED
2024-05-31 20:34:39,393 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:39,393 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:39,393 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:39,395 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:39,395 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:39,479 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:39,479 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:39,479 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:39,479 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:39,479 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	TOTAL_KEYS -> 1 , CONTAINER_COUNT -> 1 , TOTAL_USED_BYTES -> 7 , 
2024-05-31 20:34:39,479 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:39,479 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:40,163 [UnderReplicatedProcessor] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:chooseNodeInternal(672)) - No available node in (scope="/" excludedScope="[/default-rack/2fad9ecd-4424-4a8b-880f-fd93cda6f409, /default-rack/390bac8a-0dbf-4715-b6fd-0c75abb5c43b, /default-rack/076ccc74-63d1-410b-8584-7a1d80cfc8c8]" excludedNodes="[390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)]"  ancestorGen="1").
2024-05-31 20:34:40,163 [UnderReplicatedProcessor] WARN  algorithms.SCMContainerPlacementRackAware (SCMContainerPlacementRackAware.java:chooseNode(485)) - Failed to find the datanode for container. excludedNodes:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)], affinityNode:
2024-05-31 20:34:40,164 [UnderReplicatedProcessor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [replicateContainerCommand: containerId=1, replicaIndex=0, targetNode=55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1), priority=NORMAL] for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-05-31T20:34:23.864421440Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault} to 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1) with datanode deadline 1717188250164 and scm deadline 1717188280164
2024-05-31 20:34:40,164 [UnderReplicatedProcessor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(138)) - Processed 1 containers with health state counts {UNDER_REPLICATED=1}, failed processing 0, deferred due to load 0
2024-05-31 20:34:40,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@2e20dddc. There are 2 pipelines
2024-05-31 20:34:40,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:40,175 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:34:40,397 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:40,397 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:40,397 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:40,399 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:40,400 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:40,483 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:40,483 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:40,483 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:40,483 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:40,483 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:40,483 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:40,483 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:41,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@2e20dddc. There are 2 pipelines
2024-05-31 20:34:41,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:41,176 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:34:41,256 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5008463677ns, electionTimeout:5008ms
2024-05-31 20:34:41,256 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: shutdown 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-FollowerState
2024-05-31 20:34:41,256 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-05-31 20:34:41,257 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-05-31 20:34:41,257 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: start 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-LeaderElection11
2024-05-31 20:34:41,257 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-LeaderElection11 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:41,257 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-LeaderElection11-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052
2024-05-31 20:34:41,258 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-LeaderElection11-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043
2024-05-31 20:34:41,257 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:41,258 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:41,263 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0: receive requestVote(PRE_VOTE, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, group-DD6F8777DCC0, 0, (t:0, i:0))
2024-05-31 20:34:41,263 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-FOLLOWER: reject PRE_VOTE from 2fad9ecd-4424-4a8b-880f-fd93cda6f409: our priority 1 > candidate's priority 0
2024-05-31 20:34:41,263 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0 replies to PRE_VOTE vote request: 2fad9ecd-4424-4a8b-880f-fd93cda6f409<-b079985c-91b9-4d2e-8c89-c2e47b34f7da#0:FAIL-t0. Peer's state: b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0:t0, leader=null, voted=, raftlog=Memoized:b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:41,263 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0: receive requestVote(PRE_VOTE, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, group-DD6F8777DCC0, 0, (t:0, i:0))
2024-05-31 20:34:41,263 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-FOLLOWER: accept PRE_VOTE from 2fad9ecd-4424-4a8b-880f-fd93cda6f409: our priority 0 <= candidate's priority 0
2024-05-31 20:34:41,264 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0 replies to PRE_VOTE vote request: 2fad9ecd-4424-4a8b-880f-fd93cda6f409<-55857a12-8529-4f00-ab69-b96d955e4226#0:OK-t0. Peer's state: 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0:t0, leader=null, voted=, raftlog=Memoized:55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:41,265 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-LeaderElection11: PRE_VOTE REJECTED received 2 response(s) and 0 exception(s):
2024-05-31 20:34:41,265 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 2fad9ecd-4424-4a8b-880f-fd93cda6f409<-55857a12-8529-4f00-ab69-b96d955e4226#0:OK-t0
2024-05-31 20:34:41,265 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 1: 2fad9ecd-4424-4a8b-880f-fd93cda6f409<-b079985c-91b9-4d2e-8c89-c2e47b34f7da#0:FAIL-t0
2024-05-31 20:34:41,266 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-LeaderElection11 PRE_VOTE round 0: result REJECTED
2024-05-31 20:34:41,266 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-LeaderElection11] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2024-05-31 20:34:41,266 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: shutdown 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-LeaderElection11
2024-05-31 20:34:41,266 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: start 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-FollowerState
2024-05-31 20:34:41,266 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-LeaderElection11] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0: set firstElectionSinceStartup to false for REJECTED
2024-05-31 20:34:41,401 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:41,402 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:41,402 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:41,404 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:41,404 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:41,429 [55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:41,429 [55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:41,446 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5131530471ns, electionTimeout:5131ms
2024-05-31 20:34:41,447 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: shutdown b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-FollowerState
2024-05-31 20:34:41,447 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-05-31 20:34:41,447 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-05-31 20:34:41,447 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: start b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12
2024-05-31 20:34:41,447 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:41,448 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052
2024-05-31 20:34:41,448 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:41,448 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:41,450 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0: receive requestVote(PRE_VOTE, b079985c-91b9-4d2e-8c89-c2e47b34f7da, group-DD6F8777DCC0, 0, (t:0, i:0))
2024-05-31 20:34:41,450 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-FOLLOWER: accept PRE_VOTE from b079985c-91b9-4d2e-8c89-c2e47b34f7da: our priority 0 <= candidate's priority 1
2024-05-31 20:34:41,450 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0 replies to PRE_VOTE vote request: b079985c-91b9-4d2e-8c89-c2e47b34f7da<-2fad9ecd-4424-4a8b-880f-fd93cda6f409#0:OK-t0. Peer's state: 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0:t0, leader=null, voted=, raftlog=Memoized:2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:41,451 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2024-05-31 20:34:41,452 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: b079985c-91b9-4d2e-8c89-c2e47b34f7da<-2fad9ecd-4424-4a8b-880f-fd93cda6f409#0:OK-t0
2024-05-31 20:34:41,452 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12 PRE_VOTE round 0: result PASSED
2024-05-31 20:34:41,453 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0: receive requestVote(PRE_VOTE, b079985c-91b9-4d2e-8c89-c2e47b34f7da, group-DD6F8777DCC0, 0, (t:0, i:0))
2024-05-31 20:34:41,453 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-FOLLOWER: accept PRE_VOTE from b079985c-91b9-4d2e-8c89-c2e47b34f7da: our priority 0 <= candidate's priority 1
2024-05-31 20:34:41,453 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0 replies to PRE_VOTE vote request: b079985c-91b9-4d2e-8c89-c2e47b34f7da<-55857a12-8529-4f00-ab69-b96d955e4226#0:OK-t0. Peer's state: 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0:t0, leader=null, voted=, raftlog=Memoized:55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:41,454 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12 ELECTION round 0: submit vote requests at term 1 for -1: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:41,455 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:41,455 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:41,456 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0: receive requestVote(ELECTION, b079985c-91b9-4d2e-8c89-c2e47b34f7da, group-DD6F8777DCC0, 1, (t:0, i:0))
2024-05-31 20:34:41,456 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-FOLLOWER: accept ELECTION from b079985c-91b9-4d2e-8c89-c2e47b34f7da: our priority 0 <= candidate's priority 1
2024-05-31 20:34:41,456 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:41,456 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 55857a12-8529-4f00-ab69-b96d955e4226: shutdown 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-FollowerState
2024-05-31 20:34:41,456 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 55857a12-8529-4f00-ab69-b96d955e4226: start 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-FollowerState
2024-05-31 20:34:41,456 [55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-FollowerState was interrupted
2024-05-31 20:34:41,456 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0: receive requestVote(ELECTION, b079985c-91b9-4d2e-8c89-c2e47b34f7da, group-DD6F8777DCC0, 1, (t:0, i:0))
2024-05-31 20:34:41,456 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-FOLLOWER: accept ELECTION from b079985c-91b9-4d2e-8c89-c2e47b34f7da: our priority 0 <= candidate's priority 1
2024-05-31 20:34:41,457 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:41,457 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: shutdown 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-FollowerState
2024-05-31 20:34:41,457 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: start 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-FollowerState
2024-05-31 20:34:41,457 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-FollowerState was interrupted
2024-05-31 20:34:41,457 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0: set firstElectionSinceStartup to false for candidate:b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:41,458 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0 replies to ELECTION vote request: b079985c-91b9-4d2e-8c89-c2e47b34f7da<-55857a12-8529-4f00-ab69-b96d955e4226#0:OK-t1. Peer's state: 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0:t1, leader=null, voted=b079985c-91b9-4d2e-8c89-c2e47b34f7da, raftlog=Memoized:55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:41,459 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0 replies to ELECTION vote request: b079985c-91b9-4d2e-8c89-c2e47b34f7da<-2fad9ecd-4424-4a8b-880f-fd93cda6f409#0:OK-t1. Peer's state: 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0:t1, leader=null, voted=b079985c-91b9-4d2e-8c89-c2e47b34f7da, raftlog=Memoized:2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:41,460 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12: ELECTION PASSED received 1 response(s) and 0 exception(s):
2024-05-31 20:34:41,460 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: b079985c-91b9-4d2e-8c89-c2e47b34f7da<-55857a12-8529-4f00-ab69-b96d955e4226#0:OK-t1
2024-05-31 20:34:41,460 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12 ELECTION round 0: result PASSED
2024-05-31 20:34:41,460 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: shutdown b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12
2024-05-31 20:34:41,460 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-05-31 20:34:41,460 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-05-31 20:34:41,460 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:34:41,461 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-05-31 20:34:41,461 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-05-31 20:34:41,461 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-05-31 20:34:41,461 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-05-31 20:34:41,461 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-05-31 20:34:41,461 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-05-31 20:34:41,461 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:41,461 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:34:41,461 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-05-31 20:34:41,462 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-05-31 20:34:41,462 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:41,462 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2024-05-31 20:34:41,462 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0μs (custom)
2024-05-31 20:34:41,462 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-05-31 20:34:41,462 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:41,462 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-05-31 20:34:41,462 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-05-31 20:34:41,462 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-05-31 20:34:41,463 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:41,463 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-05-31 20:34:41,463 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-05-31 20:34:41,463 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:41,463 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2024-05-31 20:34:41,464 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0μs (custom)
2024-05-31 20:34:41,464 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-05-31 20:34:41,464 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:41,464 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-05-31 20:34:41,464 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-05-31 20:34:41,464 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-05-31 20:34:41,464 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:41,464 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-05-31 20:34:41,464 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: start b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderStateImpl
2024-05-31 20:34:41,464 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0: set firstElectionSinceStartup to false for becomeLeader
2024-05-31 20:34:41,464 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-DD6F8777DCC0 with new leaderId: b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:41,465 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0: change Leader from null to b079985c-91b9-4d2e-8c89-c2e47b34f7da at term 1 for becomeLeader, leader elected after 5167ms
2024-05-31 20:34:41,465 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-SegmentedRaftLogWorker: Starting segment from index:0
2024-05-31 20:34:41,465 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderElection12] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0: set configuration 0: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:41,465 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-05-31 20:34:41,473 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0/current/log_inprogress_0
2024-05-31 20:34:41,475 [55857a12-8529-4f00-ab69-b96d955e4226-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-DD6F8777DCC0 with new leaderId: b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:41,475 [55857a12-8529-4f00-ab69-b96d955e4226-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0: change Leader from null to b079985c-91b9-4d2e-8c89-c2e47b34f7da at term 1 for appendEntries, leader elected after 5216ms
2024-05-31 20:34:41,476 [55857a12-8529-4f00-ab69-b96d955e4226-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0: set configuration 0: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:41,477 [55857a12-8529-4f00-ab69-b96d955e4226-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-SegmentedRaftLogWorker: Starting segment from index:0
2024-05-31 20:34:41,478 [55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-05-31 20:34:41,482 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-server-thread2] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-DD6F8777DCC0 with new leaderId: b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:41,482 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0: change Leader from null to b079985c-91b9-4d2e-8c89-c2e47b34f7da at term 1 for appendEntries, leader elected after 5249ms
2024-05-31 20:34:41,482 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0: set configuration 0: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:41,483 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-SegmentedRaftLogWorker: Starting segment from index:0
2024-05-31 20:34:41,483 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-05-31 20:34:41,488 [55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0/current/log_inprogress_0
2024-05-31 20:34:41,488 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:41,488 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:41,488 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:41,488 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:41,488 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:41,488 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:41,489 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:41,493 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-05-31 20:34:41,493 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0/current/log_inprogress_0
2024-05-31 20:34:42,037 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=81e6b01c-7968-4b55-acde-dd6f8777dcc0 since it stays at CLOSED stage.
2024-05-31 20:34:42,037 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=81e6b01c-7968-4b55-acde-dd6f8777dcc0 close command to datanode 55857a12-8529-4f00-ab69-b96d955e4226
2024-05-31 20:34:42,038 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=81e6b01c-7968-4b55-acde-dd6f8777dcc0 close command to datanode 2fad9ecd-4424-4a8b-880f-fd93cda6f409
2024-05-31 20:34:42,038 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=81e6b01c-7968-4b55-acde-dd6f8777dcc0 close command to datanode b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:42,038 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 81e6b01c-7968-4b55-acde-dd6f8777dcc0, Nodes: 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1)2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1)b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:b079985c-91b9-4d2e-8c89-c2e47b34f7da, CreationTimestamp2024-05-31T20:34:34.176Z[Etc/UTC]] removed.
2024-05-31 20:34:42,038 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=0e0510fd-577d-4847-942d-1c3c34dfe8e1 since it stays at CLOSED stage.
2024-05-31 20:34:42,038 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=0e0510fd-577d-4847-942d-1c3c34dfe8e1 close command to datanode 2fad9ecd-4424-4a8b-880f-fd93cda6f409
2024-05-31 20:34:42,038 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 0e0510fd-577d-4847-942d-1c3c34dfe8e1, Nodes: 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:2fad9ecd-4424-4a8b-880f-fd93cda6f409, CreationTimestamp2024-05-31T20:34:08.766Z[Etc/UTC]] removed.
2024-05-31 20:34:42,055 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5154922760ns, electionTimeout:5147ms
2024-05-31 20:34:42,055 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: shutdown 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-FollowerState
2024-05-31 20:34:42,055 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-05-31 20:34:42,055 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-05-31 20:34:42,055 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: start 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13
2024-05-31 20:34:42,056 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025]|listeners:[], old=null
2024-05-31 20:34:42,056 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13 PRE_VOTE round 0: result PASSED (term=0)
2024-05-31 20:34:42,057 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13 ELECTION round 0: submit vote requests at term 1 for -1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025]|listeners:[], old=null
2024-05-31 20:34:42,057 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13 ELECTION round 0: result PASSED (term=1)
2024-05-31 20:34:42,057 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: shutdown 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13
2024-05-31 20:34:42,057 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-05-31 20:34:42,057 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-05-31 20:34:42,057 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:34:42,057 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-05-31 20:34:42,058 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-05-31 20:34:42,058 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-05-31 20:34:42,058 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-05-31 20:34:42,058 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-05-31 20:34:42,058 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-05-31 20:34:42,058 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:42,058 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:34:42,058 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-05-31 20:34:42,059 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: start 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderStateImpl
2024-05-31 20:34:42,059 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0: set firstElectionSinceStartup to false for becomeLeader
2024-05-31 20:34:42,059 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-A35EB7B01FA0 with new leaderId: 076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:42,059 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0: change Leader from null to 076ccc74-63d1-410b-8584-7a1d80cfc8c8 at term 1 for becomeLeader, leader elected after 5191ms
2024-05-31 20:34:42,059 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-SegmentedRaftLogWorker: Starting segment from index:0
2024-05-31 20:34:42,060 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-05-31 20:34:42,060 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderElection13] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0: set configuration 0: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025]|listeners:[], old=null
2024-05-31 20:34:42,068 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/13364d75-4ec1-47d6-8b5b-a35eb7b01fa0/current/log_inprogress_0
2024-05-31 20:34:42,069 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-05-31 20:34:42,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(463)) - Under Replicated Container #1 Container State: CLOSED Replica Count: 3 Healthy (I/D/M): 2/1/0 Unhealthy (I/D/M): 0/0/0 inFlightAdd: 1 inFightDel: 0 ReplicationFactor: 3 minMaintenance: 2; Replicas{ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), placeOfBirth=390bac8a-0dbf-4715-b6fd-0c75abb5c43b, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false},ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), placeOfBirth=2fad9ecd-4424-4a8b-880f-fd93cda6f409, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false},ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), placeOfBirth=076ccc74-63d1-410b-8584-7a1d80cfc8c8, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}}
2024-05-31 20:34:42,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(472)) - org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@2e20dddc has 0 sufficientlyReplicated, 0 deleting, 1 underReplicated and 0 unclosed containers
2024-05-31 20:34:42,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:42,176 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:34:42,211 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5109439226ns, electionTimeout:5109ms
2024-05-31 20:34:42,211 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-FollowerState
2024-05-31 20:34:42,211 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-05-31 20:34:42,211 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-05-31 20:34:42,211 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: start 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14
2024-05-31 20:34:42,212 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:34:42,212 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14 PRE_VOTE round 0: result PASSED (term=0)
2024-05-31 20:34:42,213 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14 ELECTION round 0: submit vote requests at term 1 for -1: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:34:42,213 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14 ELECTION round 0: result PASSED (term=1)
2024-05-31 20:34:42,213 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14
2024-05-31 20:34:42,213 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-05-31 20:34:42,213 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-05-31 20:34:42,213 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:34:42,213 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-05-31 20:34:42,214 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-05-31 20:34:42,214 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-05-31 20:34:42,214 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-05-31 20:34:42,214 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-05-31 20:34:42,214 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-05-31 20:34:42,214 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:42,214 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:34:42,214 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-05-31 20:34:42,214 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: start 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderStateImpl
2024-05-31 20:34:42,214 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02: set firstElectionSinceStartup to false for becomeLeader
2024-05-31 20:34:42,214 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-1D0408D68C02 with new leaderId: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:42,215 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02: change Leader from null to 390bac8a-0dbf-4715-b6fd-0c75abb5c43b at term 1 for becomeLeader, leader elected after 5125ms
2024-05-31 20:34:42,215 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-SegmentedRaftLogWorker: Starting segment from index:0
2024-05-31 20:34:42,215 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderElection14] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02: set configuration 0: peers:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:34:42,215 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-05-31 20:34:42,222 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/3166dcd9-053f-42c3-b8ea-1d0408d68c02/current/log_inprogress_0
2024-05-31 20:34:42,224 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-05-31 20:34:42,242 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=81e6b01c-7968-4b55-acde-dd6f8777dcc0 is not found
2024-05-31 20:34:42,242 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=0e0510fd-577d-4847-942d-1c3c34dfe8e1 is not found
2024-05-31 20:34:42,269 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=81e6b01c-7968-4b55-acde-dd6f8777dcc0 is not found
2024-05-31 20:34:42,405 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:42,406 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:42,406 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:42,408 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:42,408 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:42,467 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=81e6b01c-7968-4b55-acde-dd6f8777dcc0 is not found
2024-05-31 20:34:42,492 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:42,492 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:42,492 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:42,492 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:42,492 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:42,492 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:42,492 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:43,097 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-ContainerReplicationThread-1] INFO  replication.PushReplicator (PushReplicator.java:replicate(58)) - Starting replication of container 1 to 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1) using NO_COMPRESSION
2024-05-31 20:34:43,112 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-ContainerReplicationThread-1] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(116)) - Sent 16384 bytes for container 1
2024-05-31 20:34:43,113 [55857a12-8529-4f00-ab69-b96d955e4226-ReplicationContainerReader-1] INFO  replication.SendContainerRequestHandler (SendContainerRequestHandler.java:onNext(96)) - Accepting container 1
2024-05-31 20:34:43,113 [55857a12-8529-4f00-ab69-b96d955e4226-ReplicationContainerReader-1] INFO  replication.SendContainerRequestHandler (SendContainerRequestHandler.java:onCompleted(131)) - Container 1 is downloaded with size 16384, starting to import.
2024-05-31 20:34:43,131 [55857a12-8529-4f00-ab69-b96d955e4226-ReplicationContainerReader-1] INFO  replication.SendContainerRequestHandler (SendContainerRequestHandler.java:onCompleted(137)) - Container 1 is replicated successfully
2024-05-31 20:34:43,132 [grpc-default-executor-5] INFO  replication.GrpcContainerUploader (GrpcContainerUploader.java:onCompleted(132)) - Finished uploading container 1 to 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1)
2024-05-31 20:34:43,134 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-ContainerReplicationThread-1] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(369)) - Successful DONE replicateContainerCommand: containerId=1, replicaIndex=0, targetNode=55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1), priority=NORMAL, transferred 16384 bytes
2024-05-31 20:34:43,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(472)) - org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@2e20dddc has 1 sufficientlyReplicated, 0 deleting, 0 underReplicated and 0 unclosed containers
2024-05-31 20:34:43,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:completeDecommission(522)) - Datanode 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1) has completed the admin workflow. The operational state has been set to DECOMMISSIONED
2024-05-31 20:34:43,175 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1) moved to HEALTHY state.
2024-05-31 20:34:43,175 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-05-31 20:34:43,176 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:34:43,177 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 to datanode:b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:43,177 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 to datanode:390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:43,177 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 to datanode:076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:43,178 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: aec5ddb5-3d25-444a-adb9-62cabd985b58, Nodes: b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1)390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-05-31T20:34:43.177010060Z[Etc/UTC]]
2024-05-31 20:34:43,198 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
2024-05-31 20:34:43,233 [main] INFO  recon.TestReconAndAdminContainerCLI (TestReconAndAdminContainerCLI.java:assertReportsMatch(344)) - Reports do not match (yet): expected: <0> but was: <1>
2024-05-31 20:34:43,242 [IPC Server handler 5 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1) as the reported value (DECOMMISSIONING, 0) does not match the value stored in SCM (DECOMMISSIONED, 0)
2024-05-31 20:34:43,247 [grpc-default-executor-5] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 55857a12-8529-4f00-ab69-b96d955e4226: remove  FOLLOWER 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0:t1, leader=b079985c-91b9-4d2e-8c89-c2e47b34f7da, voted=b079985c-91b9-4d2e-8c89-c2e47b34f7da, raftlog=Memoized:55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-SegmentedRaftLog:OPENED:c-1, conf=0: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null RUNNING
2024-05-31 20:34:43,247 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0: shutdown
2024-05-31 20:34:43,247 [grpc-default-executor-5] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DD6F8777DCC0,id=55857a12-8529-4f00-ab69-b96d955e4226
2024-05-31 20:34:43,247 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 55857a12-8529-4f00-ab69-b96d955e4226: shutdown 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-FollowerState
2024-05-31 20:34:43,248 [grpc-default-executor-5] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-StateMachineUpdater: set stopIndex = -1
2024-05-31 20:34:43,248 [55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-FollowerState was interrupted
2024-05-31 20:34:43,248 [grpc-default-executor-5] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0: applyIndex: -1
2024-05-31 20:34:43,248 [55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-05-31 20:34:43,410 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:43,410 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:43,410 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:43,412 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:43,412 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:43,468 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=81e6b01c-7968-4b55-acde-dd6f8777dcc0 is not found
2024-05-31 20:34:43,468 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1), {type: FCR, size: 0}
2024-05-31 20:34:43,468 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1), {type: FCR, size: 0}
2024-05-31 20:34:43,472 [grpc-default-executor-3] WARN  server.RaftServer (RaftServerProxy.java:remove(106)) - 55857a12-8529-4f00-ab69-b96d955e4226: does not contain group: group-DD6F8777DCC0
2024-05-31 20:34:43,483 [grpc-default-executor-3] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: remove  FOLLOWER 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0:t1, leader=b079985c-91b9-4d2e-8c89-c2e47b34f7da, voted=b079985c-91b9-4d2e-8c89-c2e47b34f7da, raftlog=Memoized:2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-SegmentedRaftLog:OPENED:c-1, conf=0: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null RUNNING
2024-05-31 20:34:43,483 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0: shutdown
2024-05-31 20:34:43,483 [grpc-default-executor-3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DD6F8777DCC0,id=2fad9ecd-4424-4a8b-880f-fd93cda6f409
2024-05-31 20:34:43,483 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: shutdown 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-FollowerState
2024-05-31 20:34:43,483 [grpc-default-executor-3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-StateMachineUpdater: set stopIndex = -1
2024-05-31 20:34:43,483 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-FollowerState was interrupted
2024-05-31 20:34:43,484 [grpc-default-executor-3] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0: applyIndex: -1
2024-05-31 20:34:43,484 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-05-31 20:34:43,489 [grpc-default-executor-5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0-SegmentedRaftLogWorker close()
2024-05-31 20:34:43,490 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-DD6F8777DCC0: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0
2024-05-31 20:34:43,494 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:processExistingDBRecords(299)) - DELETED existing unhealthy container record...for Container: 1
2024-05-31 20:34:43,496 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:43,496 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:43,496 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:43,496 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:43,497 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:43,497 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:43,497 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:43,497 [grpc-default-executor-3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0-SegmentedRaftLogWorker close()
2024-05-31 20:34:43,498 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-DD6F8777DCC0: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0
2024-05-31 20:34:43,500 [grpc-default-executor-5] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: remove    LEADER b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0:t1, leader=b079985c-91b9-4d2e-8c89-c2e47b34f7da, voted=b079985c-91b9-4d2e-8c89-c2e47b34f7da, raftlog=Memoized:b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-SegmentedRaftLog:OPENED:c0, conf=0: peers:[55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null RUNNING
2024-05-31 20:34:43,500 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0: shutdown
2024-05-31 20:34:43,500 [grpc-default-executor-5] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DD6F8777DCC0,id=b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:43,500 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: shutdown b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-LeaderStateImpl
2024-05-31 20:34:43,500 [grpc-default-executor-5] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-PendingRequests: sendNotLeaderResponses
2024-05-31 20:34:43,500 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0->55857a12-8529-4f00-ab69-b96d955e4226-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0->55857a12-8529-4f00-ab69-b96d955e4226-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-05-31 20:34:43,500 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0->2fad9ecd-4424-4a8b-880f-fd93cda6f409-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0->2fad9ecd-4424-4a8b-880f-fd93cda6f409-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-05-31 20:34:43,501 [grpc-default-executor-5] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-StateMachineUpdater: set stopIndex = 0
2024-05-31 20:34:43,501 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-DD6F8777DCC0: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0/sm/snapshot.1_0
2024-05-31 20:34:43,502 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-DD6F8777DCC0: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0/sm/snapshot.1_0 took: 1 ms
2024-05-31 20:34:43,502 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 55857a12-8529-4f00-ab69-b96d955e4226: Completed APPEND_ENTRIES, lastRequest: null
2024-05-31 20:34:43,503 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 55857a12-8529-4f00-ab69-b96d955e4226: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "b079985c-91b9-4d2e-8c89-c2e47b34f7da"
  replyId: "55857a12-8529-4f00-ab69-b96d955e4226"
  raftGroupId {
    id: "\201\346\260\034yhKU\254\336\335o\207w\334\300"
  }
  success: true
}
term: 1
nextIndex: 1
followerCommit: 18446744073709551615
matchIndex: 18446744073709551615
isHearbeat: true

2024-05-31 20:34:43,503 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-StateMachineUpdater: Took a snapshot at index 0
2024-05-31 20:34:43,503 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-05-31 20:34:43,504 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: Completed APPEND_ENTRIES, lastRequest: b079985c-91b9-4d2e-8c89-c2e47b34f7da->2fad9ecd-4424-4a8b-880f-fd93cda6f409#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "55857a12-8529-4f00-ab69-b96d955e4226"
address: "127.0.0.1:15052"
dataStreamAddress: "127.0.0.1:15053"
clientAddress: "127.0.0.1:15050"
adminAddress: "127.0.0.1:15051"
startupRole: FOLLOWER
,id: "2fad9ecd-4424-4a8b-880f-fd93cda6f409"
address: "127.0.0.1:15016"
dataStreamAddress: "127.0.0.1:15017"
clientAddress: "127.0.0.1:15014"
adminAddress: "127.0.0.1:15015"
startupRole: FOLLOWER
,id: "b079985c-91b9-4d2e-8c89-c2e47b34f7da"
address: "127.0.0.1:15043"
priority: 1
dataStreamAddress: "127.0.0.1:15044"
clientAddress: "127.0.0.1:15041"
adminAddress: "127.0.0.1:15042"
startupRole: FOLLOWER
, old:)
2024-05-31 20:34:43,504 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: Completed APPEND_ENTRIES, lastReply: null
2024-05-31 20:34:43,504 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 55857a12-8529-4f00-ab69-b96d955e4226: Completed APPEND_ENTRIES, lastRequest: b079985c-91b9-4d2e-8c89-c2e47b34f7da->55857a12-8529-4f00-ab69-b96d955e4226#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "55857a12-8529-4f00-ab69-b96d955e4226"
address: "127.0.0.1:15052"
dataStreamAddress: "127.0.0.1:15053"
clientAddress: "127.0.0.1:15050"
adminAddress: "127.0.0.1:15051"
startupRole: FOLLOWER
,id: "2fad9ecd-4424-4a8b-880f-fd93cda6f409"
address: "127.0.0.1:15016"
dataStreamAddress: "127.0.0.1:15017"
clientAddress: "127.0.0.1:15014"
adminAddress: "127.0.0.1:15015"
startupRole: FOLLOWER
,id: "b079985c-91b9-4d2e-8c89-c2e47b34f7da"
address: "127.0.0.1:15043"
priority: 1
dataStreamAddress: "127.0.0.1:15044"
clientAddress: "127.0.0.1:15041"
adminAddress: "127.0.0.1:15042"
startupRole: FOLLOWER
, old:)
2024-05-31 20:34:43,504 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 55857a12-8529-4f00-ab69-b96d955e4226: Completed APPEND_ENTRIES, lastReply: null
2024-05-31 20:34:43,504 [grpc-default-executor-5] INFO  server.RaftServer$Division (ServerState.java:close(427)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0: applyIndex: 0
2024-05-31 20:34:43,504 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-05-31 20:34:43,505 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0->2fad9ecd-4424-4a8b-880f-fd93cda6f409-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-05-31 20:34:43,505 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0->55857a12-8529-4f00-ab69-b96d955e4226-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-05-31 20:34:43,505 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: Completed APPEND_ENTRIES, lastRequest: null
2024-05-31 20:34:43,506 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0->55857a12-8529-4f00-ab69-b96d955e4226-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-05-31 20:34:43,506 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "b079985c-91b9-4d2e-8c89-c2e47b34f7da"
  replyId: "2fad9ecd-4424-4a8b-880f-fd93cda6f409"
  raftGroupId {
    id: "\201\346\260\034yhKU\254\336\335o\207w\334\300"
  }
  success: true
}
term: 1
nextIndex: 1
followerCommit: 18446744073709551615
matchIndex: 18446744073709551615
isHearbeat: true

2024-05-31 20:34:43,506 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0->2fad9ecd-4424-4a8b-880f-fd93cda6f409-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-05-31 20:34:43,508 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] WARN  server.RaftServer (RaftServerProxy.java:remove(106)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: does not contain group: group-DD6F8777DCC0
2024-05-31 20:34:44,177 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:34:44,215 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: addNew group-62CABD985B58:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043] returns group-62CABD985B58:java.util.concurrent.CompletableFuture@6aa38337[Not completed]
2024-05-31 20:34:44,219 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: new RaftServerImpl for group-62CABD985B58:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043] with ContainerStateMachine:uninitialized
2024-05-31 20:34:44,219 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:44,219 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-05-31 20:34:44,219 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:34:44,219 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-05-31 20:34:44,219 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:44,219 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:34:44,219 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:44,219 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58: ConfigurationManager, init=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:34:44,219 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-05-31 20:34:44,220 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:34:44,220 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-05-31 20:34:44,220 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:34:44,221 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:34:44,221 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:34:44,223 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:44,223 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:44,223 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:34:44,223 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:34:44,223 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:34:44,223 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:34:44,223 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-05-31 20:34:44,224 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-05-31 20:34:44,224 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis] (custom)
2024-05-31 20:34:44,224 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58 does not exist. Creating ...
2024-05-31 20:34:44,225 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58/in_use.lock acquired by nodename 83134@fv-az1343-628
2024-05-31 20:34:44,226 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58 has been successfully formatted.
2024-05-31 20:34:44,226 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58/current/raft-meta.conf
2024-05-31 20:34:44,227 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-62CABD985B58: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-05-31 20:34:44,227 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-05-31 20:34:44,227 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-05-31 20:34:44,227 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:44,227 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58. Trying to get from SCM.
2024-05-31 20:34:44,227 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-05-31 20:34:44,227 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-05-31 20:34:44,229 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:44,229 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(86)) - Adding new pipeline Pipeline[ Id: aec5ddb5-3d25-444a-adb9-62cabd985b58, Nodes: b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1)390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-05-31T20:34:43.177Z[Etc/UTC]] to Recon pipeline metadata.
2024-05-31 20:34:44,229 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-05-31 20:34:44,229 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-05-31 20:34:44,229 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:44,229 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-cacheEviction-AwaitToRun,5,main] started
2024-05-31 20:34:44,229 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58
2024-05-31 20:34:44,229 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-05-31 20:34:44,229 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-05-31 20:34:44,230 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:44,230 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-05-31 20:34:44,230 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-05-31 20:34:44,230 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-05-31 20:34:44,230 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 reported by 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)
2024-05-31 20:34:44,230 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-05-31 20:34:44,230 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-05-31 20:34:44,230 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-05-31 20:34:44,232 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:44,232 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-05-31 20:34:44,233 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-05-31 20:34:44,233 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-05-31 20:34:44,233 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:44,233 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:44,233 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58: start as a follower, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:44,233 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-05-31 20:34:44,233 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: start 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-FollowerState
2024-05-31 20:34:44,234 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-62CABD985B58,id=390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:44,234 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-05-31 20:34:44,235 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-05-31 20:34:44,235 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-05-31 20:34:44,235 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-05-31 20:34:44,235 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
2024-05-31 20:34:44,235 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:44,236 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:44,236 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58
2024-05-31 20:34:44,246 [IPC Server handler 9 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1) as the reported value (DECOMMISSIONING, 0) does not match the value stored in SCM (DECOMMISSIONED, 0)
2024-05-31 20:34:44,247 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=0e0510fd-577d-4847-942d-1c3c34dfe8e1 is not found
2024-05-31 20:34:44,248 [grpc-default-executor-3] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: addNew group-62CABD985B58:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043] returns group-62CABD985B58:java.util.concurrent.CompletableFuture@6efc3da6[Not completed]
2024-05-31 20:34:44,249 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: new RaftServerImpl for group-62CABD985B58:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043] with ContainerStateMachine:uninitialized
2024-05-31 20:34:44,249 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:44,250 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-05-31 20:34:44,250 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:34:44,250 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-05-31 20:34:44,250 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:44,250 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:34:44,250 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:44,250 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58: ConfigurationManager, init=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:34:44,250 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-05-31 20:34:44,250 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:34:44,250 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-05-31 20:34:44,250 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:34:44,250 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:34:44,250 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:34:44,252 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:44,252 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:44,252 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:34:44,252 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:34:44,252 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:34:44,252 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:34:44,252 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-05-31 20:34:44,252 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-05-31 20:34:44,252 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis] (custom)
2024-05-31 20:34:44,253 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58 does not exist. Creating ...
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-05-31 20:34:44,254 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58/in_use.lock acquired by nodename 83134@fv-az1343-628
2024-05-31 20:34:44,256 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58 has been successfully formatted.
2024-05-31 20:34:44,257 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58/current/raft-meta.conf
2024-05-31 20:34:44,257 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-62CABD985B58: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-05-31 20:34:44,257 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-05-31 20:34:44,257 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-05-31 20:34:44,257 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:44,257 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-05-31 20:34:44,257 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-05-31 20:34:44,259 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:44,259 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-05-31 20:34:44,259 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-05-31 20:34:44,259 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:44,260 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 reported by b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1)
2024-05-31 20:34:44,261 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-cacheEviction-AwaitToRun,5,main] started
2024-05-31 20:34:44,261 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58
2024-05-31 20:34:44,261 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-05-31 20:34:44,261 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-05-31 20:34:44,261 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:44,261 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-05-31 20:34:44,261 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-05-31 20:34:44,261 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-05-31 20:34:44,262 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-05-31 20:34:44,262 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-05-31 20:34:44,262 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-05-31 20:34:44,264 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:44,264 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-05-31 20:34:44,264 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-05-31 20:34:44,264 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-05-31 20:34:44,264 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:44,264 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:44,265 [IPC Server handler 10 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:decommissionNodes(321)) - Force flag = false. Checking if decommission is possible for dns: [b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1)]
2024-05-31 20:34:44,265 [IPC Server handler 10 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startDecommission(376)) - Starting Decommission for node b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1)
2024-05-31 20:34:44,266 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1) moved to HEALTHY state.
2024-05-31 20:34:44,266 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
2024-05-31 20:34:44,270 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58: start as a follower, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:44,270 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-05-31 20:34:44,271 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: start b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-FollowerState
2024-05-31 20:34:44,284 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-62CABD985B58,id=b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:44,284 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-05-31 20:34:44,284 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-05-31 20:34:44,284 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-05-31 20:34:44,284 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-05-31 20:34:44,284 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-05-31 20:34:44,284 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:44,285 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:44,307 [grpc-default-executor-3] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: addNew group-62CABD985B58:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043] returns group-62CABD985B58:java.util.concurrent.CompletableFuture@6eae49e7[Not completed]
2024-05-31 20:34:44,308 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: new RaftServerImpl for group-62CABD985B58:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043] with ContainerStateMachine:uninitialized
2024-05-31 20:34:44,308 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:44,308 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-05-31 20:34:44,308 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:34:44,308 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-05-31 20:34:44,308 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:44,308 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:34:44,308 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:44,308 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58: ConfigurationManager, init=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:34:44,308 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-05-31 20:34:44,308 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:34:44,308 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-05-31 20:34:44,309 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:34:44,309 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:34:44,309 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:34:44,311 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:44,311 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:44,311 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:34:44,311 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:34:44,311 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:34:44,311 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:34:44,311 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-05-31 20:34:44,311 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-05-31 20:34:44,311 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis] (custom)
2024-05-31 20:34:44,311 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58 does not exist. Creating ...
2024-05-31 20:34:44,312 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58/in_use.lock acquired by nodename 83134@fv-az1343-628
2024-05-31 20:34:44,313 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58 has been successfully formatted.
2024-05-31 20:34:44,313 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58/current/raft-meta.conf
2024-05-31 20:34:44,313 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-62CABD985B58: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-05-31 20:34:44,313 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-05-31 20:34:44,315 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 reported by 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)
2024-05-31 20:34:44,315 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-05-31 20:34:44,316 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:44,316 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-05-31 20:34:44,316 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-05-31 20:34:44,317 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:44,317 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-05-31 20:34:44,317 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-05-31 20:34:44,317 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:44,317 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-cacheEviction-AwaitToRun,5,main] started
2024-05-31 20:34:44,318 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58
2024-05-31 20:34:44,318 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-05-31 20:34:44,318 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-05-31 20:34:44,318 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:44,318 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-05-31 20:34:44,318 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-05-31 20:34:44,318 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-05-31 20:34:44,318 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-05-31 20:34:44,318 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-05-31 20:34:44,318 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-05-31 20:34:44,320 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:44,320 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-05-31 20:34:44,320 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-05-31 20:34:44,320 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-05-31 20:34:44,320 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:44,320 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:44,322 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58: start as a follower, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:44,322 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-05-31 20:34:44,323 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: start 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-FollowerState
2024-05-31 20:34:44,323 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:44,323 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:44,323 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-62CABD985B58,id=076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:44,323 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-05-31 20:34:44,324 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-05-31 20:34:44,324 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-05-31 20:34:44,324 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-05-31 20:34:44,324 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-05-31 20:34:44,327 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58.
2024-05-31 20:34:44,414 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:44,414 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:44,414 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:44,416 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:44,416 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:44,475 [grpc-default-executor-5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0-SegmentedRaftLogWorker close()
2024-05-31 20:34:44,476 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-DD6F8777DCC0: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/81e6b01c-7968-4b55-acde-dd6f8777dcc0
2024-05-31 20:34:44,480 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-PipelineCommandHandlerThread-0] WARN  server.RaftServer (RaftServerProxy.java:remove(106)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: does not contain group: group-DD6F8777DCC0
2024-05-31 20:34:44,480 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: remove    LEADER 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1:t1, leader=2fad9ecd-4424-4a8b-880f-fd93cda6f409, voted=2fad9ecd-4424-4a8b-880f-fd93cda6f409, raftlog=Memoized:2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-SegmentedRaftLog:OPENED:c0, conf=0: peers:[2fad9ecd-4424-4a8b-880f-fd93cda6f409|127.0.0.1:15016]|listeners:[], old=null RUNNING
2024-05-31 20:34:44,480 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1: shutdown
2024-05-31 20:34:44,480 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1C3C34DFE8E1,id=2fad9ecd-4424-4a8b-880f-fd93cda6f409
2024-05-31 20:34:44,480 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: shutdown 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-LeaderStateImpl
2024-05-31 20:34:44,480 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-PendingRequests: sendNotLeaderResponses
2024-05-31 20:34:44,481 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-StateMachineUpdater: set stopIndex = 0
2024-05-31 20:34:44,481 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-1C3C34DFE8E1: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/0e0510fd-577d-4847-942d-1c3c34dfe8e1/sm/snapshot.1_0
2024-05-31 20:34:44,481 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-1C3C34DFE8E1: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/0e0510fd-577d-4847-942d-1c3c34dfe8e1/sm/snapshot.1_0 took: 1 ms
2024-05-31 20:34:44,482 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-StateMachineUpdater: Took a snapshot at index 0
2024-05-31 20:34:44,482 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-05-31 20:34:44,482 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1: applyIndex: 0
2024-05-31 20:34:44,482 [2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-05-31 20:34:44,500 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:44,500 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:44,500 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:44,500 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:44,500 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:44,500 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:44,500 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:44,894 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1-SegmentedRaftLogWorker close()
2024-05-31 20:34:44,895 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409@group-1C3C34DFE8E1: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/ratis/0e0510fd-577d-4847-942d-1c3c34dfe8e1
2024-05-31 20:34:44,895 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-PipelineCommandHandlerThread-0] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(140)) - Close Pipeline PipelineID=0e0510fd-577d-4847-942d-1c3c34dfe8e1 command on datanode 2fad9ecd-4424-4a8b-880f-fd93cda6f409.
2024-05-31 20:34:45,174 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(55)) - Admin start on datanode b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1). Finalizing its pipelines [PipelineID=57400ce6-6596-49c1-8fbb-8f8ee659cc7b, PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58]
2024-05-31 20:34:45,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d67de04c. There are 2 pipelines
2024-05-31 20:34:45,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:45,175 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=57400ce6-6596-49c1-8fbb-8f8ee659cc7b moved to CLOSED state
2024-05-31 20:34:45,176 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 moved to CLOSED state
2024-05-31 20:34:45,177 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:34:45,229 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 reported by 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)
2024-05-31 20:34:45,242 [IPC Server handler 9 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1) as the reported value (DECOMMISSIONING, 0) does not match the value stored in SCM (DECOMMISSIONED, 0)
2024-05-31 20:34:45,243 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to DECOMMISSIONED, scaling executor pool size to 20
2024-05-31 20:34:45,260 [IPC Server handler 6 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (DECOMMISSIONING, 0)
2024-05-31 20:34:45,261 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 reported by b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1)
2024-05-31 20:34:45,315 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 reported by 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)
2024-05-31 20:34:45,418 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:45,418 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:45,418 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:45,420 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:45,420 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:45,466 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to DECOMMISSIONING, scaling executor pool size to 20
2024-05-31 20:34:45,503 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:45,503 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:45,503 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:45,503 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:45,503 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:45,503 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:45,503 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:46,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d67de04c. There are 2 pipelines
2024-05-31 20:34:46,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:46,178 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:34:46,242 [IPC Server handler 18 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1) as the reported value (DECOMMISSIONED, 0) does not match the value stored in SCM (DECOMMISSIONING, 0)
2024-05-31 20:34:46,260 [IPC Server handler 21 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1) as the reported value (DECOMMISSIONING, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-05-31 20:34:46,260 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 reported by b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1)
2024-05-31 20:34:46,422 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:46,422 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:46,422 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:46,424 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:46,424 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:46,506 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:46,506 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:46,506 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:46,506 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:46,506 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:46,506 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:46,506 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:47,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d67de04c. There are 2 pipelines
2024-05-31 20:34:47,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:47,178 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:34:47,228 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 reported by 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)
2024-05-31 20:34:47,260 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 reported by b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1)
2024-05-31 20:34:47,316 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 reported by 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)
2024-05-31 20:34:47,426 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:47,426 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:47,426 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:47,428 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:47,428 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:47,509 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:47,509 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:47,509 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:47,509 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:47,509 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:47,509 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:47,509 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:48,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d67de04c. There are 2 pipelines
2024-05-31 20:34:48,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:48,179 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:34:48,230 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), {type: FCR, size: 1}
2024-05-31 20:34:48,230 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), {type: FCR, size: 1}
2024-05-31 20:34:48,259 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 reported by b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1)
2024-05-31 20:34:48,430 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:48,430 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:48,430 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:48,432 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:48,432 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:48,512 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:48,512 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:48,512 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:48,512 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:48,512 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:48,512 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:48,512 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:49,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d67de04c. There are 2 pipelines
2024-05-31 20:34:49,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:49,179 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:34:49,228 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 reported by 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)
2024-05-31 20:34:49,260 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 reported by b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1)
2024-05-31 20:34:49,315 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 reported by 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)
2024-05-31 20:34:49,351 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5117311085ns, electionTimeout:5115ms
2024-05-31 20:34:49,351 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-FollowerState
2024-05-31 20:34:49,351 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-05-31 20:34:49,351 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-05-31 20:34:49,351 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: start 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-LeaderElection15
2024-05-31 20:34:49,351 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-LeaderElection15] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-LeaderElection15 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:49,352 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-LeaderElection15-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025
2024-05-31 20:34:49,352 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:49,352 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-LeaderElection15] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:49,354 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58: receive requestVote(PRE_VOTE, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, group-62CABD985B58, 0, (t:0, i:0))
2024-05-31 20:34:49,354 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-FOLLOWER: reject PRE_VOTE from 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: our priority 1 > candidate's priority 0
2024-05-31 20:34:49,354 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58 replies to PRE_VOTE vote request: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b<-b079985c-91b9-4d2e-8c89-c2e47b34f7da#0:FAIL-t0. Peer's state: b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58:t0, leader=null, voted=, raftlog=Memoized:b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:49,355 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-LeaderElection15] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-LeaderElection15: PRE_VOTE REJECTED received 1 response(s) and 0 exception(s):
2024-05-31 20:34:49,355 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-LeaderElection15] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b<-b079985c-91b9-4d2e-8c89-c2e47b34f7da#0:FAIL-t0
2024-05-31 20:34:49,356 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-LeaderElection15] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-LeaderElection15 PRE_VOTE round 0: result REJECTED
2024-05-31 20:34:49,356 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-LeaderElection15] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2024-05-31 20:34:49,356 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-LeaderElection15
2024-05-31 20:34:49,356 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-LeaderElection15] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: start 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-FollowerState
2024-05-31 20:34:49,357 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-LeaderElection15] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58: set firstElectionSinceStartup to false for REJECTED
2024-05-31 20:34:49,357 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58: receive requestVote(PRE_VOTE, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, group-62CABD985B58, 0, (t:0, i:0))
2024-05-31 20:34:49,357 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-FOLLOWER: accept PRE_VOTE from 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: our priority 0 <= candidate's priority 0
2024-05-31 20:34:49,357 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58 replies to PRE_VOTE vote request: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b<-076ccc74-63d1-410b-8584-7a1d80cfc8c8#0:OK-t0. Peer's state: 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58:t0, leader=null, voted=, raftlog=Memoized:076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:49,434 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:49,434 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:49,434 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:49,436 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:49,436 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:49,444 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:49,444 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:49,475 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5204815741ns, electionTimeout:5188ms
2024-05-31 20:34:49,475 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: shutdown b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-FollowerState
2024-05-31 20:34:49,476 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-05-31 20:34:49,476 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-05-31 20:34:49,476 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: start b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16
2024-05-31 20:34:49,476 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:49,477 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025
2024-05-31 20:34:49,477 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:49,478 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:49,478 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58: receive requestVote(PRE_VOTE, b079985c-91b9-4d2e-8c89-c2e47b34f7da, group-62CABD985B58, 0, (t:0, i:0))
2024-05-31 20:34:49,479 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-FOLLOWER: accept PRE_VOTE from b079985c-91b9-4d2e-8c89-c2e47b34f7da: our priority 0 <= candidate's priority 1
2024-05-31 20:34:49,479 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58 replies to PRE_VOTE vote request: b079985c-91b9-4d2e-8c89-c2e47b34f7da<-390bac8a-0dbf-4715-b6fd-0c75abb5c43b#0:OK-t0. Peer's state: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58:t0, leader=null, voted=, raftlog=Memoized:390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:49,480 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2024-05-31 20:34:49,480 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: b079985c-91b9-4d2e-8c89-c2e47b34f7da<-390bac8a-0dbf-4715-b6fd-0c75abb5c43b#0:OK-t0
2024-05-31 20:34:49,480 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16 PRE_VOTE round 0: result PASSED
2024-05-31 20:34:49,483 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16 ELECTION round 0: submit vote requests at term 1 for -1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:49,483 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:49,483 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:49,484 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58: receive requestVote(PRE_VOTE, b079985c-91b9-4d2e-8c89-c2e47b34f7da, group-62CABD985B58, 0, (t:0, i:0))
2024-05-31 20:34:49,484 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-FOLLOWER: accept PRE_VOTE from b079985c-91b9-4d2e-8c89-c2e47b34f7da: our priority 0 <= candidate's priority 1
2024-05-31 20:34:49,485 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58 replies to PRE_VOTE vote request: b079985c-91b9-4d2e-8c89-c2e47b34f7da<-076ccc74-63d1-410b-8584-7a1d80cfc8c8#0:OK-t0. Peer's state: 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58:t0, leader=null, voted=, raftlog=Memoized:076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:49,485 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58: receive requestVote(ELECTION, b079985c-91b9-4d2e-8c89-c2e47b34f7da, group-62CABD985B58, 1, (t:0, i:0))
2024-05-31 20:34:49,485 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58: receive requestVote(ELECTION, b079985c-91b9-4d2e-8c89-c2e47b34f7da, group-62CABD985B58, 1, (t:0, i:0))
2024-05-31 20:34:49,485 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-FOLLOWER: accept ELECTION from b079985c-91b9-4d2e-8c89-c2e47b34f7da: our priority 0 <= candidate's priority 1
2024-05-31 20:34:49,485 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:49,485 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: shutdown 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-FollowerState
2024-05-31 20:34:49,485 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: start 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-FollowerState
2024-05-31 20:34:49,485 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-FOLLOWER: accept ELECTION from b079985c-91b9-4d2e-8c89-c2e47b34f7da: our priority 0 <= candidate's priority 1
2024-05-31 20:34:49,485 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-FollowerState was interrupted
2024-05-31 20:34:49,486 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:49,486 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-FollowerState
2024-05-31 20:34:49,486 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: start 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-FollowerState
2024-05-31 20:34:49,486 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-FollowerState was interrupted
2024-05-31 20:34:49,487 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58 replies to ELECTION vote request: b079985c-91b9-4d2e-8c89-c2e47b34f7da<-390bac8a-0dbf-4715-b6fd-0c75abb5c43b#0:OK-t1. Peer's state: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58:t1, leader=null, voted=b079985c-91b9-4d2e-8c89-c2e47b34f7da, raftlog=Memoized:390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:49,488 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16: ELECTION PASSED received 1 response(s) and 0 exception(s):
2024-05-31 20:34:49,488 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: b079985c-91b9-4d2e-8c89-c2e47b34f7da<-390bac8a-0dbf-4715-b6fd-0c75abb5c43b#0:OK-t1
2024-05-31 20:34:49,488 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16 ELECTION round 0: result PASSED
2024-05-31 20:34:49,488 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: shutdown b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16
2024-05-31 20:34:49,488 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-05-31 20:34:49,488 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-05-31 20:34:49,488 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:34:49,488 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-05-31 20:34:49,489 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-05-31 20:34:49,489 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-05-31 20:34:49,489 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-05-31 20:34:49,489 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-05-31 20:34:49,489 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-05-31 20:34:49,489 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:49,489 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:34:49,489 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-05-31 20:34:49,490 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-05-31 20:34:49,490 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:49,490 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2024-05-31 20:34:49,490 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0μs (custom)
2024-05-31 20:34:49,490 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-05-31 20:34:49,490 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:49,490 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58: set firstElectionSinceStartup to false for candidate:b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:49,490 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-05-31 20:34:49,491 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-05-31 20:34:49,491 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-05-31 20:34:49,491 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:49,491 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-05-31 20:34:49,491 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58 replies to ELECTION vote request: b079985c-91b9-4d2e-8c89-c2e47b34f7da<-076ccc74-63d1-410b-8584-7a1d80cfc8c8#0:OK-t1. Peer's state: 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58:t1, leader=null, voted=b079985c-91b9-4d2e-8c89-c2e47b34f7da, raftlog=Memoized:076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:49,492 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-05-31 20:34:49,492 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:49,492 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2024-05-31 20:34:49,492 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0μs (custom)
2024-05-31 20:34:49,493 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-05-31 20:34:49,493 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:49,493 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-05-31 20:34:49,493 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-05-31 20:34:49,493 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-05-31 20:34:49,493 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:49,493 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-05-31 20:34:49,493 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: start b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderStateImpl
2024-05-31 20:34:49,493 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58: set firstElectionSinceStartup to false for becomeLeader
2024-05-31 20:34:49,493 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-62CABD985B58 with new leaderId: b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:49,494 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58: change Leader from null to b079985c-91b9-4d2e-8c89-c2e47b34f7da at term 1 for becomeLeader, leader elected after 5243ms
2024-05-31 20:34:49,494 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-SegmentedRaftLogWorker: Starting segment from index:0
2024-05-31 20:34:49,494 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-05-31 20:34:49,497 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 reported by b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1)
2024-05-31 20:34:49,498 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderElection16] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58: set configuration 0: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:49,501 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58/current/log_inprogress_0
2024-05-31 20:34:49,503 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-62CABD985B58 with new leaderId: b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:49,503 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-62CABD985B58 with new leaderId: b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:49,503 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58: change Leader from null to b079985c-91b9-4d2e-8c89-c2e47b34f7da at term 1 for appendEntries, leader elected after 5194ms
2024-05-31 20:34:49,503 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58: change Leader from null to b079985c-91b9-4d2e-8c89-c2e47b34f7da at term 1 for appendEntries, leader elected after 5283ms
2024-05-31 20:34:49,505 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58: set configuration 0: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:49,505 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-SegmentedRaftLogWorker: Starting segment from index:0
2024-05-31 20:34:49,505 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-05-31 20:34:49,505 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58: set configuration 0: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null
2024-05-31 20:34:49,505 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-SegmentedRaftLogWorker: Starting segment from index:0
2024-05-31 20:34:49,506 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-05-31 20:34:49,515 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:49,515 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:49,515 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:49,515 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:49,515 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:49,515 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:49,515 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:49,516 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58/current/log_inprogress_0
2024-05-31 20:34:49,518 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58/current/log_inprogress_0
2024-05-31 20:34:49,518 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-05-31 20:34:50,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d67de04c. There are 2 pipelines
2024-05-31 20:34:50,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:50,180 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:34:50,438 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:50,438 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:50,438 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:50,440 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:50,440 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:50,519 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:50,519 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:50,519 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:50,519 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:50,519 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:50,519 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:50,519 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:51,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d67de04c. There are 2 pipelines
2024-05-31 20:34:51,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-05-31 20:34:51,180 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:34:51,442 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:51,442 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:51,442 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:51,444 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:51,444 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:51,522 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:51,522 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:51,522 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:51,522 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:51,522 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:51,522 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:51,522 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:52,039 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=57400ce6-6596-49c1-8fbb-8f8ee659cc7b since it stays at CLOSED stage.
2024-05-31 20:34:52,040 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=57400ce6-6596-49c1-8fbb-8f8ee659cc7b close command to datanode b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:52,040 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 57400ce6-6596-49c1-8fbb-8f8ee659cc7b, Nodes: b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:b079985c-91b9-4d2e-8c89-c2e47b34f7da, CreationTimestamp2024-05-31T20:34:09.093Z[Etc/UTC]] removed.
2024-05-31 20:34:52,040 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 since it stays at CLOSED stage.
2024-05-31 20:34:52,040 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 close command to datanode b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:52,040 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 close command to datanode 390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:52,040 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 close command to datanode 076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:52,040 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: aec5ddb5-3d25-444a-adb9-62cabd985b58, Nodes: b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1)390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:b079985c-91b9-4d2e-8c89-c2e47b34f7da, CreationTimestamp2024-05-31T20:34:43.177Z[Etc/UTC]] removed.
2024-05-31 20:34:52,174 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(472)) - org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d67de04c has 0 sufficientlyReplicated, 0 deleting, 0 underReplicated and 0 unclosed containers
2024-05-31 20:34:52,175 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:completeDecommission(522)) - Datanode b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1) has completed the admin workflow. The operational state has been set to DECOMMISSIONED
2024-05-31 20:34:52,175 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1) moved to HEALTHY state.
2024-05-31 20:34:52,175 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-05-31 20:34:52,176 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 to datanode:076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:52,176 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 to datanode:390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:52,176 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 to datanode:55857a12-8529-4f00-ab69-b96d955e4226
2024-05-31 20:34:52,177 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: a8ad8d20-97c9-407a-9fb4-2c253653b299, Nodes: 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-05-31T20:34:52.176145692Z[Etc/UTC]]
2024-05-31 20:34:52,181 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:34:52,298 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:52,446 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:52,446 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:52,446 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:52,448 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:52,448 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:52,494 [IPC Server handler 13 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1) as the reported value (DECOMMISSIONING, 0) does not match the value stored in SCM (DECOMMISSIONED, 0)
2024-05-31 20:34:52,495 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=57400ce6-6596-49c1-8fbb-8f8ee659cc7b is not found
2024-05-31 20:34:52,496 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 is not found
2024-05-31 20:34:52,498 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:52,531 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:52,531 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:52,531 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:52,531 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:52,531 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:52,531 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:52,531 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:52,699 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:52,899 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:53,099 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:53,181 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:34:53,228 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 is not found
2024-05-31 20:34:53,232 [grpc-default-executor-3] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: remove  FOLLOWER 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58:t1, leader=b079985c-91b9-4d2e-8c89-c2e47b34f7da, voted=b079985c-91b9-4d2e-8c89-c2e47b34f7da, raftlog=Memoized:076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-SegmentedRaftLog:OPENED:c0, conf=0: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null RUNNING
2024-05-31 20:34:53,233 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58: shutdown
2024-05-31 20:34:53,233 [grpc-default-executor-3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-62CABD985B58,id=076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:53,233 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: shutdown 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-FollowerState
2024-05-31 20:34:53,233 [grpc-default-executor-3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-StateMachineUpdater: set stopIndex = 0
2024-05-31 20:34:53,233 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-62CABD985B58: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58/sm/snapshot.1_0
2024-05-31 20:34:53,233 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-FollowerState was interrupted
2024-05-31 20:34:53,234 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-62CABD985B58: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58/sm/snapshot.1_0 took: 1 ms
2024-05-31 20:34:53,234 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-StateMachineUpdater: Took a snapshot at index 0
2024-05-31 20:34:53,234 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-05-31 20:34:53,234 [grpc-default-executor-3] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58: applyIndex: 0
2024-05-31 20:34:53,234 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-05-31 20:34:53,285 [Recon-SyncSCMContainerInfo-0] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:syncWithSCMContainerInfo(564)) - Got list of containers from SCM : 1
2024-05-31 20:34:53,300 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:53,314 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: addNew group-2C253653B299:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034] returns group-2C253653B299:java.util.concurrent.CompletableFuture@6488c189[Not completed]
2024-05-31 20:34:53,315 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: new RaftServerImpl for group-2C253653B299:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034] with ContainerStateMachine:uninitialized
2024-05-31 20:34:53,315 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:53,315 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 is not found
2024-05-31 20:34:53,315 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-05-31 20:34:53,316 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:34:53,316 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-05-31 20:34:53,316 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:53,316 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:34:53,316 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:53,316 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299: ConfigurationManager, init=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:34:53,316 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-05-31 20:34:53,316 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:34:53,316 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-05-31 20:34:53,316 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:34:53,316 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:34:53,317 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:34:53,318 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:53,318 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:53,318 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:34:53,318 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:34:53,318 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:34:53,318 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:34:53,318 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-05-31 20:34:53,318 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-05-31 20:34:53,319 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis] (custom)
2024-05-31 20:34:53,319 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299 does not exist. Creating ...
2024-05-31 20:34:53,320 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299/in_use.lock acquired by nodename 83134@fv-az1343-628
2024-05-31 20:34:53,320 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299 has been successfully formatted.
2024-05-31 20:34:53,321 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299/current/raft-meta.conf
2024-05-31 20:34:53,321 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-2C253653B299: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-05-31 20:34:53,321 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-05-31 20:34:53,321 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-05-31 20:34:53,321 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:53,321 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-05-31 20:34:53,321 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-05-31 20:34:53,322 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:53,322 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299. Trying to get from SCM.
2024-05-31 20:34:53,323 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-05-31 20:34:53,323 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-05-31 20:34:53,323 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:53,323 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-cacheEviction-AwaitToRun,5,main] started
2024-05-31 20:34:53,323 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299
2024-05-31 20:34:53,323 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-05-31 20:34:53,323 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-05-31 20:34:53,323 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:53,323 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-05-31 20:34:53,323 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-05-31 20:34:53,324 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-05-31 20:34:53,324 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-05-31 20:34:53,324 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-05-31 20:34:53,324 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-05-31 20:34:53,325 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:53,325 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-05-31 20:34:53,325 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-05-31 20:34:53,325 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-05-31 20:34:53,326 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:53,326 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:53,326 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299: start as a follower, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:34:53,326 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-05-31 20:34:53,326 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: start 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-FollowerState
2024-05-31 20:34:53,326 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(86)) - Adding new pipeline Pipeline[ Id: a8ad8d20-97c9-407a-9fb4-2c253653b299, Nodes: 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-05-31T20:34:52.176Z[Etc/UTC]] to Recon pipeline metadata.
2024-05-31 20:34:53,326 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:53,326 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2C253653B299,id=076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:34:53,327 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-05-31 20:34:53,327 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-05-31 20:34:53,327 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-05-31 20:34:53,327 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-05-31 20:34:53,327 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-05-31 20:34:53,327 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 reported by 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)
2024-05-31 20:34:53,327 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:53,328 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299
2024-05-31 20:34:53,333 [grpc-default-executor-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: addNew group-2C253653B299:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034] returns group-2C253653B299:java.util.concurrent.CompletableFuture@79432572[Not completed]
2024-05-31 20:34:53,334 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: new RaftServerImpl for group-2C253653B299:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034] with ContainerStateMachine:uninitialized
2024-05-31 20:34:53,334 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:53,334 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-05-31 20:34:53,334 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:34:53,334 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-05-31 20:34:53,334 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:53,334 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:34:53,334 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:53,335 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299: ConfigurationManager, init=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:34:53,335 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-05-31 20:34:53,335 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:34:53,335 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-05-31 20:34:53,335 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:34:53,335 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:34:53,335 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:34:53,336 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:53,336 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:53,336 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:34:53,336 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:34:53,336 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:34:53,336 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:34:53,336 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-05-31 20:34:53,337 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-05-31 20:34:53,337 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis] (custom)
2024-05-31 20:34:53,337 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299 does not exist. Creating ...
2024-05-31 20:34:53,338 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299/in_use.lock acquired by nodename 83134@fv-az1343-628
2024-05-31 20:34:53,339 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299 has been successfully formatted.
2024-05-31 20:34:53,339 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299/current/raft-meta.conf
2024-05-31 20:34:53,339 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-2C253653B299: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-05-31 20:34:53,339 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-05-31 20:34:53,340 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 is not found
2024-05-31 20:34:53,340 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 reported by 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)
2024-05-31 20:34:53,340 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-05-31 20:34:53,340 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:53,340 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-05-31 20:34:53,340 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-05-31 20:34:53,341 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:53,342 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-05-31 20:34:53,342 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-05-31 20:34:53,342 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:53,342 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-cacheEviction-AwaitToRun,5,main] started
2024-05-31 20:34:53,342 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299
2024-05-31 20:34:53,342 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-05-31 20:34:53,342 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-05-31 20:34:53,343 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:53,343 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-05-31 20:34:53,343 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-05-31 20:34:53,343 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-05-31 20:34:53,343 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-05-31 20:34:53,343 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-05-31 20:34:53,343 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-05-31 20:34:53,345 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:53,346 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-05-31 20:34:53,346 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-05-31 20:34:53,346 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-05-31 20:34:53,346 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:53,346 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:53,346 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299: start as a follower, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:34:53,346 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-05-31 20:34:53,347 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: start 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FollowerState
2024-05-31 20:34:53,347 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:53,347 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2C253653B299,id=390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:53,347 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-05-31 20:34:53,347 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-05-31 20:34:53,347 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-05-31 20:34:53,347 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-05-31 20:34:53,347 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-05-31 20:34:53,347 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:53,361 [grpc-default-executor-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 55857a12-8529-4f00-ab69-b96d955e4226: addNew group-2C253653B299:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034] returns group-2C253653B299:java.util.concurrent.CompletableFuture@5d75242b[Not completed]
2024-05-31 20:34:53,362 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 55857a12-8529-4f00-ab69-b96d955e4226: new RaftServerImpl for group-2C253653B299:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034] with ContainerStateMachine:uninitialized
2024-05-31 20:34:53,362 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:53,362 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-05-31 20:34:53,362 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:34:53,362 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-05-31 20:34:53,362 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:34:53,362 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:34:53,362 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:34:53,362 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299: ConfigurationManager, init=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:34:53,362 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-05-31 20:34:53,362 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:34:53,362 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-05-31 20:34:53,362 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:34:53,362 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:34:53,362 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:34:53,364 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:53,364 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:53,364 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:34:53,364 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:34:53,364 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:34:53,364 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:34:53,364 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-05-31 20:34:53,364 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-05-31 20:34:53,364 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis] (custom)
2024-05-31 20:34:53,364 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299 does not exist. Creating ...
2024-05-31 20:34:53,365 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299/in_use.lock acquired by nodename 83134@fv-az1343-628
2024-05-31 20:34:53,366 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299 has been successfully formatted.
2024-05-31 20:34:53,367 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299/current/raft-meta.conf
2024-05-31 20:34:53,367 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-2C253653B299: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-05-31 20:34:53,367 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-05-31 20:34:53,367 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-05-31 20:34:53,367 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:53,367 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-05-31 20:34:53,367 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-05-31 20:34:53,368 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 reported by 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1)
2024-05-31 20:34:53,368 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:53,369 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-05-31 20:34:53,369 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-05-31 20:34:53,369 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:53,370 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-cacheEviction-AwaitToRun,5,main] started
2024-05-31 20:34:53,370 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299
2024-05-31 20:34:53,370 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-05-31 20:34:53,370 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-05-31 20:34:53,370 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-05-31 20:34:53,370 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-05-31 20:34:53,370 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-05-31 20:34:53,370 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-05-31 20:34:53,370 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-05-31 20:34:53,370 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 30 (custom)
2024-05-31 20:34:53,371 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-05-31 20:34:53,374 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:53,374 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-05-31 20:34:53,374 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-05-31 20:34:53,374 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-05-31 20:34:53,374 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:53,374 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-05-31 20:34:53,374 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299: start as a follower, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:34:53,374 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-05-31 20:34:53,375 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 55857a12-8529-4f00-ab69-b96d955e4226: start 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-FollowerState
2024-05-31 20:34:53,378 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:53,378 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2C253653B299,id=55857a12-8529-4f00-ab69-b96d955e4226
2024-05-31 20:34:53,378 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:53,378 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-05-31 20:34:53,378 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-05-31 20:34:53,378 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-05-31 20:34:53,378 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-05-31 20:34:53,378 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-05-31 20:34:53,384 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299.
2024-05-31 20:34:53,450 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:53,450 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:53,450 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:53,452 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:53,452 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:53,495 [IPC Server handler 17 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1) as the reported value (DECOMMISSIONING, 0) does not match the value stored in SCM (DECOMMISSIONED, 0)
2024-05-31 20:34:53,495 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=57400ce6-6596-49c1-8fbb-8f8ee659cc7b is not found
2024-05-31 20:34:53,495 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 is not found
2024-05-31 20:34:53,500 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:53,519 [grpc-default-executor-3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58-SegmentedRaftLogWorker close()
2024-05-31 20:34:53,520 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-62CABD985B58: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58
2024-05-31 20:34:53,527 [grpc-default-executor-3] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: remove    LEADER b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58:t1, leader=b079985c-91b9-4d2e-8c89-c2e47b34f7da, voted=b079985c-91b9-4d2e-8c89-c2e47b34f7da, raftlog=Memoized:b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-SegmentedRaftLog:OPENED:c0, conf=0: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null RUNNING
2024-05-31 20:34:53,527 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58: shutdown
2024-05-31 20:34:53,527 [grpc-default-executor-3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-62CABD985B58,id=b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:53,527 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: shutdown b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-LeaderStateImpl
2024-05-31 20:34:53,528 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58->076ccc74-63d1-410b-8584-7a1d80cfc8c8-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58->076ccc74-63d1-410b-8584-7a1d80cfc8c8-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-05-31 20:34:53,528 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58->390bac8a-0dbf-4715-b6fd-0c75abb5c43b-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58->390bac8a-0dbf-4715-b6fd-0c75abb5c43b-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-05-31 20:34:53,528 [grpc-default-executor-3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-PendingRequests: sendNotLeaderResponses
2024-05-31 20:34:53,529 [grpc-default-executor-3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-StateMachineUpdater: set stopIndex = 0
2024-05-31 20:34:53,529 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-62CABD985B58: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58/sm/snapshot.1_0
2024-05-31 20:34:53,530 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: Completed APPEND_ENTRIES, lastRequest: null
2024-05-31 20:34:53,530 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-62CABD985B58: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58/sm/snapshot.1_0 took: 1 ms
2024-05-31 20:34:53,530 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-StateMachineUpdater: Took a snapshot at index 0
2024-05-31 20:34:53,530 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-05-31 20:34:53,531 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: Completed APPEND_ENTRIES, lastRequest: null
2024-05-31 20:34:53,531 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "b079985c-91b9-4d2e-8c89-c2e47b34f7da"
  replyId: "390bac8a-0dbf-4715-b6fd-0c75abb5c43b"
  raftGroupId {
    id: "\256\305\335\265=%DJ\255\271b\312\275\230[X"
  }
  callId: 3
  success: true
}
term: 1
nextIndex: 1
matchIndex: 18446744073709551615
isHearbeat: true

2024-05-31 20:34:53,531 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "b079985c-91b9-4d2e-8c89-c2e47b34f7da"
  replyId: "076ccc74-63d1-410b-8584-7a1d80cfc8c8"
  raftGroupId {
    id: "\256\305\335\265=%DJ\255\271b\312\275\230[X"
  }
  callId: 4
  success: true
}
term: 1
nextIndex: 1
matchIndex: 18446744073709551615
isHearbeat: true

2024-05-31 20:34:53,531 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: Completed APPEND_ENTRIES, lastRequest: b079985c-91b9-4d2e-8c89-c2e47b34f7da->390bac8a-0dbf-4715-b6fd-0c75abb5c43b#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "076ccc74-63d1-410b-8584-7a1d80cfc8c8"
address: "127.0.0.1:15025"
dataStreamAddress: "127.0.0.1:15026"
clientAddress: "127.0.0.1:15023"
adminAddress: "127.0.0.1:15024"
startupRole: FOLLOWER
,id: "390bac8a-0dbf-4715-b6fd-0c75abb5c43b"
address: "127.0.0.1:15034"
dataStreamAddress: "127.0.0.1:15035"
clientAddress: "127.0.0.1:15032"
adminAddress: "127.0.0.1:15033"
startupRole: FOLLOWER
,id: "b079985c-91b9-4d2e-8c89-c2e47b34f7da"
address: "127.0.0.1:15043"
priority: 1
dataStreamAddress: "127.0.0.1:15044"
clientAddress: "127.0.0.1:15041"
adminAddress: "127.0.0.1:15042"
startupRole: FOLLOWER
, old:)
2024-05-31 20:34:53,531 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: Completed APPEND_ENTRIES, lastReply: null
2024-05-31 20:34:53,533 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: Completed APPEND_ENTRIES, lastRequest: b079985c-91b9-4d2e-8c89-c2e47b34f7da->076ccc74-63d1-410b-8584-7a1d80cfc8c8#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "076ccc74-63d1-410b-8584-7a1d80cfc8c8"
address: "127.0.0.1:15025"
dataStreamAddress: "127.0.0.1:15026"
clientAddress: "127.0.0.1:15023"
adminAddress: "127.0.0.1:15024"
startupRole: FOLLOWER
,id: "390bac8a-0dbf-4715-b6fd-0c75abb5c43b"
address: "127.0.0.1:15034"
dataStreamAddress: "127.0.0.1:15035"
clientAddress: "127.0.0.1:15032"
adminAddress: "127.0.0.1:15033"
startupRole: FOLLOWER
,id: "b079985c-91b9-4d2e-8c89-c2e47b34f7da"
address: "127.0.0.1:15043"
priority: 1
dataStreamAddress: "127.0.0.1:15044"
clientAddress: "127.0.0.1:15041"
adminAddress: "127.0.0.1:15042"
startupRole: FOLLOWER
, old:)
2024-05-31 20:34:53,533 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: Completed APPEND_ENTRIES, lastReply: null
2024-05-31 20:34:53,534 [grpc-default-executor-3] INFO  server.RaftServer$Division (ServerState.java:close(427)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58: applyIndex: 0
2024-05-31 20:34:53,534 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58->076ccc74-63d1-410b-8584-7a1d80cfc8c8-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-05-31 20:34:53,534 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58->390bac8a-0dbf-4715-b6fd-0c75abb5c43b-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-05-31 20:34:53,534 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-05-31 20:34:53,535 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58->390bac8a-0dbf-4715-b6fd-0c75abb5c43b-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-05-31 20:34:53,535 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58->076ccc74-63d1-410b-8584-7a1d80cfc8c8-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-05-31 20:34:53,535 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:53,535 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:53,535 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:53,535 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:53,535 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:53,535 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:53,535 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:53,701 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:53,901 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:54,101 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:54,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:34:54,302 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:54,368 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 reported by 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1)
2024-05-31 20:34:54,454 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:54,454 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:54,454 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:54,456 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:54,456 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:54,494 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: remove    LEADER b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B:t1, leader=b079985c-91b9-4d2e-8c89-c2e47b34f7da, voted=b079985c-91b9-4d2e-8c89-c2e47b34f7da, raftlog=Memoized:b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-SegmentedRaftLog:OPENED:c0, conf=0: peers:[b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null RUNNING
2024-05-31 20:34:54,495 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B: shutdown
2024-05-31 20:34:54,495 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-8F8EE659CC7B,id=b079985c-91b9-4d2e-8c89-c2e47b34f7da
2024-05-31 20:34:54,495 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: shutdown b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-LeaderStateImpl
2024-05-31 20:34:54,495 [IPC Server handler 17 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1) as the reported value (DECOMMISSIONING, 0) does not match the value stored in SCM (DECOMMISSIONED, 0)
2024-05-31 20:34:54,495 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-PendingRequests: sendNotLeaderResponses
2024-05-31 20:34:54,495 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to DECOMMISSIONED, scaling executor pool size to 20
2024-05-31 20:34:54,496 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=57400ce6-6596-49c1-8fbb-8f8ee659cc7b is not found
2024-05-31 20:34:54,496 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-8F8EE659CC7B: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/57400ce6-6596-49c1-8fbb-8f8ee659cc7b/sm/snapshot.1_0
2024-05-31 20:34:54,496 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-StateMachineUpdater: set stopIndex = 0
2024-05-31 20:34:54,497 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-8F8EE659CC7B: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/57400ce6-6596-49c1-8fbb-8f8ee659cc7b/sm/snapshot.1_0 took: 1 ms
2024-05-31 20:34:54,497 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-StateMachineUpdater: Took a snapshot at index 0
2024-05-31 20:34:54,497 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-05-31 20:34:54,497 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B: applyIndex: 0
2024-05-31 20:34:54,497 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1), {type: FCR, size: 0}
2024-05-31 20:34:54,497 [b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-05-31 20:34:54,497 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1), {type: FCR, size: 0}
2024-05-31 20:34:54,502 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:54,503 [grpc-default-executor-3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58-SegmentedRaftLogWorker close()
2024-05-31 20:34:54,504 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-62CABD985B58: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58
2024-05-31 20:34:54,506 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: remove  FOLLOWER 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58:t1, leader=b079985c-91b9-4d2e-8c89-c2e47b34f7da, voted=b079985c-91b9-4d2e-8c89-c2e47b34f7da, raftlog=Memoized:390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-SegmentedRaftLog:OPENED:c0, conf=0: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034, b079985c-91b9-4d2e-8c89-c2e47b34f7da|127.0.0.1:15043]|listeners:[], old=null RUNNING
2024-05-31 20:34:54,506 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58: shutdown
2024-05-31 20:34:54,506 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-62CABD985B58,id=390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:34:54,506 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-FollowerState
2024-05-31 20:34:54,506 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-StateMachineUpdater: set stopIndex = 0
2024-05-31 20:34:54,506 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-62CABD985B58: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58/sm/snapshot.1_0
2024-05-31 20:34:54,506 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-FollowerState was interrupted
2024-05-31 20:34:54,507 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-62CABD985B58: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58/sm/snapshot.1_0 took: 0 ms
2024-05-31 20:34:54,507 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-StateMachineUpdater: Took a snapshot at index 0
2024-05-31 20:34:54,507 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-05-31 20:34:54,508 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58: applyIndex: 0
2024-05-31 20:34:54,508 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-05-31 20:34:54,517 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58-SegmentedRaftLogWorker close()
2024-05-31 20:34:54,518 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-62CABD985B58: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/aec5ddb5-3d25-444a-adb9-62cabd985b58
2024-05-31 20:34:54,518 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(140)) - Close Pipeline PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 command on datanode 390bac8a-0dbf-4715-b6fd-0c75abb5c43b.
2024-05-31 20:34:54,538 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:54,538 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:54,538 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:54,539 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:54,539 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:54,539 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:54,539 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:54,702 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:54,903 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:55,103 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:55,182 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:34:55,214 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B-SegmentedRaftLogWorker close()
2024-05-31 20:34:55,214 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-8F8EE659CC7B: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/ratis/57400ce6-6596-49c1-8fbb-8f8ee659cc7b
2024-05-31 20:34:55,214 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(140)) - Close Pipeline PipelineID=57400ce6-6596-49c1-8fbb-8f8ee659cc7b command on datanode b079985c-91b9-4d2e-8c89-c2e47b34f7da.
2024-05-31 20:34:55,304 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:55,322 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 reported by 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)
2024-05-31 20:34:55,340 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 reported by 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)
2024-05-31 20:34:55,458 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:55,458 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:55,458 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:55,459 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:55,460 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:55,495 [IPC Server handler 7 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1) as the reported value (DECOMMISSIONED, 0) does not match the value stored in SCM (DECOMMISSIONING, 0)
2024-05-31 20:34:55,504 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:55,542 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:55,542 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:55,542 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:55,542 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:55,542 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:55,542 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:55,542 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:55,704 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:55,905 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:56,105 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:56,183 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:34:56,306 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:56,368 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 reported by 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1)
2024-05-31 20:34:56,461 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:56,462 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:56,462 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:56,463 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:56,463 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:56,506 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:56,545 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:56,545 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:56,545 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:56,545 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:56,545 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:56,545 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:56,545 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:56,707 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:56,907 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:57,107 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:57,183 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:34:57,308 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:57,322 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 reported by 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)
2024-05-31 20:34:57,340 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 reported by 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)
2024-05-31 20:34:57,367 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 reported by 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1)
2024-05-31 20:34:57,465 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:57,465 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:57,465 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:57,467 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:57,467 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:57,508 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:57,548 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:57,548 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:57,548 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:57,548 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:57,548 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:57,549 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:57,549 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:57,709 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:57,909 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:58,109 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:58,184 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:34:58,310 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:58,364 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5017283847ns, electionTimeout:5016ms
2024-05-31 20:34:58,364 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FollowerState
2024-05-31 20:34:58,364 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-05-31 20:34:58,364 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-05-31 20:34:58,364 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: start 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-LeaderElection17
2024-05-31 20:34:58,365 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-LeaderElection17] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-LeaderElection17 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:34:58,365 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:58,365 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-LeaderElection17-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052
2024-05-31 20:34:58,366 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-LeaderElection17] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:58,367 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299: receive requestVote(PRE_VOTE, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, group-2C253653B299, 0, (t:0, i:0))
2024-05-31 20:34:58,369 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-FOLLOWER: accept PRE_VOTE from 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: our priority 0 <= candidate's priority 0
2024-05-31 20:34:58,369 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299 replies to PRE_VOTE vote request: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b<-076ccc74-63d1-410b-8584-7a1d80cfc8c8#0:OK-t0. Peer's state: 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299:t0, leader=null, voted=, raftlog=Memoized:076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:34:58,372 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299: receive requestVote(PRE_VOTE, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, group-2C253653B299, 0, (t:0, i:0))
2024-05-31 20:34:58,372 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-FOLLOWER: reject PRE_VOTE from 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: our priority 1 > candidate's priority 0
2024-05-31 20:34:58,372 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299 replies to PRE_VOTE vote request: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b<-55857a12-8529-4f00-ab69-b96d955e4226#0:FAIL-t0. Peer's state: 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299:t0, leader=null, voted=, raftlog=Memoized:55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:34:58,373 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-LeaderElection17] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-LeaderElection17: PRE_VOTE REJECTED received 2 response(s) and 0 exception(s):
2024-05-31 20:34:58,373 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-LeaderElection17] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b<-076ccc74-63d1-410b-8584-7a1d80cfc8c8#0:OK-t0
2024-05-31 20:34:58,373 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-LeaderElection17] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 1: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b<-55857a12-8529-4f00-ab69-b96d955e4226#0:FAIL-t0
2024-05-31 20:34:58,374 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-LeaderElection17] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-LeaderElection17 PRE_VOTE round 0: result REJECTED
2024-05-31 20:34:58,374 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-LeaderElection17] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2024-05-31 20:34:58,374 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-LeaderElection17
2024-05-31 20:34:58,374 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-LeaderElection17] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: start 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FollowerState
2024-05-31 20:34:58,374 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-LeaderElection17] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299: set firstElectionSinceStartup to false for REJECTED
2024-05-31 20:34:58,400 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5025508943ns, electionTimeout:5022ms
2024-05-31 20:34:58,400 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 55857a12-8529-4f00-ab69-b96d955e4226: shutdown 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-FollowerState
2024-05-31 20:34:58,400 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-05-31 20:34:58,400 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-05-31 20:34:58,401 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 55857a12-8529-4f00-ab69-b96d955e4226: start 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18
2024-05-31 20:34:58,401 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:34:58,401 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025
2024-05-31 20:34:58,401 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034
2024-05-31 20:34:58,401 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:58,402 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:58,406 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299: receive requestVote(PRE_VOTE, 55857a12-8529-4f00-ab69-b96d955e4226, group-2C253653B299, 0, (t:0, i:0))
2024-05-31 20:34:58,407 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299: receive requestVote(PRE_VOTE, 55857a12-8529-4f00-ab69-b96d955e4226, group-2C253653B299, 0, (t:0, i:0))
2024-05-31 20:34:58,407 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-FOLLOWER: accept PRE_VOTE from 55857a12-8529-4f00-ab69-b96d955e4226: our priority 0 <= candidate's priority 1
2024-05-31 20:34:58,407 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FOLLOWER: accept PRE_VOTE from 55857a12-8529-4f00-ab69-b96d955e4226: our priority 0 <= candidate's priority 1
2024-05-31 20:34:58,407 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299 replies to PRE_VOTE vote request: 55857a12-8529-4f00-ab69-b96d955e4226<-076ccc74-63d1-410b-8584-7a1d80cfc8c8#0:OK-t0. Peer's state: 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299:t0, leader=null, voted=, raftlog=Memoized:076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:34:58,407 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299 replies to PRE_VOTE vote request: 55857a12-8529-4f00-ab69-b96d955e4226<-390bac8a-0dbf-4715-b6fd-0c75abb5c43b#0:OK-t0. Peer's state: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299:t0, leader=null, voted=, raftlog=Memoized:390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:34:58,408 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2024-05-31 20:34:58,408 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 55857a12-8529-4f00-ab69-b96d955e4226<-076ccc74-63d1-410b-8584-7a1d80cfc8c8#0:OK-t0
2024-05-31 20:34:58,408 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18 PRE_VOTE round 0: result PASSED
2024-05-31 20:34:58,409 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18 ELECTION round 0: submit vote requests at term 1 for -1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:34:58,410 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-05-31 20:34:58,410 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-05-31 20:34:58,411 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299: receive requestVote(ELECTION, 55857a12-8529-4f00-ab69-b96d955e4226, group-2C253653B299, 1, (t:0, i:0))
2024-05-31 20:34:58,411 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-FOLLOWER: accept ELECTION from 55857a12-8529-4f00-ab69-b96d955e4226: our priority 0 <= candidate's priority 1
2024-05-31 20:34:58,411 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:55857a12-8529-4f00-ab69-b96d955e4226
2024-05-31 20:34:58,411 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: shutdown 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-FollowerState
2024-05-31 20:34:58,411 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: start 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-FollowerState
2024-05-31 20:34:58,411 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-FollowerState was interrupted
2024-05-31 20:34:58,412 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299: set firstElectionSinceStartup to false for candidate:55857a12-8529-4f00-ab69-b96d955e4226
2024-05-31 20:34:58,412 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299: receive requestVote(ELECTION, 55857a12-8529-4f00-ab69-b96d955e4226, group-2C253653B299, 1, (t:0, i:0))
2024-05-31 20:34:58,412 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FOLLOWER: accept ELECTION from 55857a12-8529-4f00-ab69-b96d955e4226: our priority 0 <= candidate's priority 1
2024-05-31 20:34:58,412 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:55857a12-8529-4f00-ab69-b96d955e4226
2024-05-31 20:34:58,412 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FollowerState
2024-05-31 20:34:58,412 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: start 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FollowerState
2024-05-31 20:34:58,412 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FollowerState was interrupted
2024-05-31 20:34:58,413 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299 replies to ELECTION vote request: 55857a12-8529-4f00-ab69-b96d955e4226<-076ccc74-63d1-410b-8584-7a1d80cfc8c8#0:OK-t1. Peer's state: 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299:t1, leader=null, voted=55857a12-8529-4f00-ab69-b96d955e4226, raftlog=Memoized:076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:34:58,414 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18: ELECTION PASSED received 1 response(s) and 0 exception(s):
2024-05-31 20:34:58,414 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 55857a12-8529-4f00-ab69-b96d955e4226<-076ccc74-63d1-410b-8584-7a1d80cfc8c8#0:OK-t1
2024-05-31 20:34:58,414 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18 ELECTION round 0: result PASSED
2024-05-31 20:34:58,414 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 55857a12-8529-4f00-ab69-b96d955e4226: shutdown 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18
2024-05-31 20:34:58,414 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-05-31 20:34:58,414 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-05-31 20:34:58,415 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:34:58,415 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-05-31 20:34:58,415 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-05-31 20:34:58,415 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-05-31 20:34:58,415 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-05-31 20:34:58,415 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299 replies to ELECTION vote request: 55857a12-8529-4f00-ab69-b96d955e4226<-390bac8a-0dbf-4715-b6fd-0c75abb5c43b#0:OK-t1. Peer's state: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299:t1, leader=null, voted=55857a12-8529-4f00-ab69-b96d955e4226, raftlog=Memoized:390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:34:58,415 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-05-31 20:34:58,415 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-05-31 20:34:58,415 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:34:58,415 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:34:58,416 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-05-31 20:34:58,416 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-05-31 20:34:58,416 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:58,416 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2024-05-31 20:34:58,416 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0μs (custom)
2024-05-31 20:34:58,416 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-05-31 20:34:58,417 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:58,417 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-05-31 20:34:58,417 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-05-31 20:34:58,417 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-05-31 20:34:58,417 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:58,417 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-05-31 20:34:58,417 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-05-31 20:34:58,417 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:34:58,418 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2024-05-31 20:34:58,418 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0μs (custom)
2024-05-31 20:34:58,418 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-05-31 20:34:58,418 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:34:58,418 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-05-31 20:34:58,418 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-05-31 20:34:58,418 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-05-31 20:34:58,418 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:34:58,418 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-05-31 20:34:58,418 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 55857a12-8529-4f00-ab69-b96d955e4226: start 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderStateImpl
2024-05-31 20:34:58,418 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299: set firstElectionSinceStartup to false for becomeLeader
2024-05-31 20:34:58,418 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-2C253653B299 with new leaderId: 55857a12-8529-4f00-ab69-b96d955e4226
2024-05-31 20:34:58,419 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299: change Leader from null to 55857a12-8529-4f00-ab69-b96d955e4226 at term 1 for becomeLeader, leader elected after 5056ms
2024-05-31 20:34:58,419 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-SegmentedRaftLogWorker: Starting segment from index:0
2024-05-31 20:34:58,420 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-05-31 20:34:58,420 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 reported by 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1)
2024-05-31 20:34:58,421 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299
2024-05-31 20:34:58,422 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderElection18] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299: set configuration 0: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:34:58,427 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299/current/log_inprogress_0
2024-05-31 20:34:58,428 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-2C253653B299 with new leaderId: 55857a12-8529-4f00-ab69-b96d955e4226
2024-05-31 20:34:58,428 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299: change Leader from null to 55857a12-8529-4f00-ab69-b96d955e4226 at term 1 for appendEntries, leader elected after 5093ms
2024-05-31 20:34:58,430 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299: set configuration 0: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:34:58,430 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-SegmentedRaftLogWorker: Starting segment from index:0
2024-05-31 20:34:58,430 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-2C253653B299 with new leaderId: 55857a12-8529-4f00-ab69-b96d955e4226
2024-05-31 20:34:58,431 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299: change Leader from null to 55857a12-8529-4f00-ab69-b96d955e4226 at term 1 for appendEntries, leader elected after 5114ms
2024-05-31 20:34:58,431 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-05-31 20:34:58,435 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299: set configuration 0: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:34:58,436 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-SegmentedRaftLogWorker: Starting segment from index:0
2024-05-31 20:34:58,436 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-05-31 20:34:58,448 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299/current/log_inprogress_0
2024-05-31 20:34:58,448 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299/current/log_inprogress_0
2024-05-31 20:34:58,451 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-05-31 20:34:58,469 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:58,469 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:58,469 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:58,471 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:58,471 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:58,510 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:58,552 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:58,552 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:58,552 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:58,552 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:58,552 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:58,552 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:58,552 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:58,711 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:58,911 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:59,111 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:59,184 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:34:59,312 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:59,472 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:34:59,472 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:34:59,472 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:34:59,474 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:34:59,474 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:34:59,512 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:59,555 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:34:59,555 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:34:59,555 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:34:59,555 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:59,555 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:59,555 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:34:59,555 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:34:59,713 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:34:59,913 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:00,113 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:00,185 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:35:00,314 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:00,476 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:00,476 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:00,476 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:35:00,478 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:00,478 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:00,514 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:00,558 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:00,558 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:00,559 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:00,559 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:00,559 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:00,559 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:00,559 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:00,715 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:00,915 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:01,115 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:01,186 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:35:01,316 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:01,480 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:01,480 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:01,480 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:35:01,482 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:01,482 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:01,516 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:01,562 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:01,562 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:01,562 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:01,562 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:01,562 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:01,562 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:01,562 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:01,717 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:01,917 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:02,117 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:02,186 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:35:02,318 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:02,484 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:02,484 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:02,484 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:35:02,486 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:02,486 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:02,518 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:02,565 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:02,566 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:02,566 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:02,566 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:02,566 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:02,566 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:02,566 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:02,719 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:02,919 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:03,119 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:03,187 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:35:03,320 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:03,487 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:03,488 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:03,488 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:35:03,489 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:03,489 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:03,520 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:03,569 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:03,569 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:03,569 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:03,569 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:03,569 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:03,569 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:03,569 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:03,721 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:03,921 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:04,121 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:04,187 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:35:04,322 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:04,491 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:04,492 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:04,497 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:35:04,499 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:04,499 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:04,500 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1), {type: FCR, size: 0}
2024-05-31 20:35:04,500 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1), {type: FCR, size: 0}
2024-05-31 20:35:04,522 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:04,575 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:04,575 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:04,575 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:04,575 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:04,575 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:04,575 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:04,575 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:04,723 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:04,923 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:05,124 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:05,188 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:35:05,324 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:05,501 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:05,501 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:05,501 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:35:05,503 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:05,503 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:05,524 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:05,577 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:05,577 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:05,578 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:05,578 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:05,578 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:05,578 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:05,578 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:05,725 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:05,925 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:06,126 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:06,189 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:35:06,326 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:06,505 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:06,505 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:06,505 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:35:06,507 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:06,507 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:06,526 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:06,581 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:06,581 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:06,581 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:06,581 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:06,581 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:06,582 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:06,582 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:06,727 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:06,899 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-05-31 20:35:06,927 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:06,975 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-05-31 20:35:07,051 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-05-31 20:35:07,127 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:07,136 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-05-31 20:35:07,189 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:35:07,208 [55857a12-8529-4f00-ab69-b96d955e4226-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-05-31 20:35:07,328 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:07,508 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:07,508 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:07,508 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:35:07,510 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:07,510 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:07,528 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:07,584 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:07,584 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:07,584 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:07,584 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:07,584 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:07,584 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:07,585 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:07,728 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:07,929 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:08,129 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:08,190 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:35:08,330 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:08,512 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:08,512 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:08,512 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:35:08,513 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:08,513 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:08,530 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:08,587 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:08,587 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:08,587 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:08,587 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:08,587 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:08,587 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:08,587 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:08,730 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:08,931 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:09,131 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:09,190 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:35:09,331 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:09,515 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:09,515 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:09,515 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:35:09,517 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:09,517 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:09,532 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:09,590 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:09,590 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:09,590 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:09,590 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:09,590 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:09,590 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:09,590 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:09,732 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:09,932 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:10,133 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:10,191 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:35:10,333 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:10,519 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:10,519 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:10,519 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:35:10,521 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:10,521 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:10,534 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:10,593 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:10,593 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:10,593 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:10,593 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:10,593 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:10,593 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:10,593 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:10,734 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:10,934 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:11,135 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:11,191 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:35:11,335 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:11,522 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:11,523 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:11,523 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:35:11,524 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:11,525 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:11,535 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:11,596 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:11,596 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:11,596 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:11,596 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:11,596 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:11,596 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:11,596 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:11,736 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:11,936 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:12,136 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:12,192 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:35:12,337 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:12,526 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:12,526 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:12,526 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:35:12,528 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:12,528 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:12,537 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:12,599 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:12,599 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:12,599 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:12,599 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:12,599 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:12,599 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:12,599 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:12,737 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:12,938 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:13,138 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:13,192 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:35:13,326 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), {type: FCR, size: 1}
2024-05-31 20:35:13,327 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), {type: FCR, size: 1}
2024-05-31 20:35:13,330 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 5 millisec, 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), {type: FCR, size: 1}
2024-05-31 20:35:13,330 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 5 millisec, 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), {type: FCR, size: 1}
2024-05-31 20:35:13,339 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:13,530 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:13,530 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:13,530 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:35:13,532 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:13,532 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:13,539 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:13,602 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:13,602 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:13,602 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:13,602 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:13,602 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:13,602 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:13,602 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:13,739 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:13,940 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:14,140 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:14,193 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:35:14,340 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:14,533 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:14,534 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:14,534 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:35:14,535 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:14,535 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:14,541 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:14,605 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:14,605 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:14,605 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:14,605 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:14,605 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:14,605 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:14,605 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:14,741 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:14,941 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:15,142 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:15,193 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:35:15,342 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:15,537 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:15,537 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:15,537 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:35:15,539 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:15,539 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:15,543 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:15,608 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:15,608 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:15,608 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:15,608 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:15,608 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:15,608 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:15,608 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:15,743 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:15,943 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:16,144 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:16,194 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:35:16,344 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:16,540 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:16,540 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:16,540 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:35:16,542 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:16,542 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:16,544 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:16,610 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:16,610 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:16,610 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:16,611 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:16,611 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:16,611 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:16,611 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:16,745 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:16,945 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:17,146 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:17,194 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:35:17,346 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:17,544 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:17,544 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:17,544 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:35:17,546 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:17,546 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:17,547 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:17,614 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:17,614 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:17,614 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:17,614 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:17,614 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:17,614 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:17,614 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:17,747 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:17,947 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:18,148 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:18,195 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:35:18,348 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:18,547 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:18,547 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:18,547 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:35:18,548 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:18,549 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:18,549 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:18,616 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:18,616 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:18,616 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:18,617 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:18,617 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:18,617 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:18,617 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:18,749 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:18,949 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:19,149 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:19,196 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:35:19,350 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:19,550 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:19,551 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:19,551 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:19,551 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:35:19,552 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:19,552 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:19,619 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:19,619 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:19,619 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:19,619 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:19,619 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:19,619 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:19,619 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:19,751 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:19,951 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:20,151 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:20,196 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:35:20,352 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:20,552 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:20,554 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:20,554 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:20,554 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:35:20,556 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:20,556 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:20,622 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:20,622 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:20,622 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:20,622 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:20,622 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:20,622 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:20,622 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:20,753 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:20,953 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:21,153 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:21,197 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-05-31 20:35:21,354 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:21,554 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:21,558 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:21,558 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:21,558 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:35:21,559 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:21,559 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:21,625 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:21,625 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:21,625 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:21,625 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:21,625 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:21,625 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:21,625 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:21,755 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:21,955 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:22,155 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:22,197 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-05-31 20:35:22,356 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [076ccc74-63d1-410b-8584-7a1d80cfc8c8, 2fad9ecd-4424-4a8b-880f-fd93cda6f409, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b, 55857a12-8529-4f00-ab69-b96d955e4226]
====> [2] DECOMMISSIONING, DECOMMISSIONED, false TIMED OUT. PRINTING THREAD DUMP. <====

Timestamp: 2024-05-31 08:35:22,425

"Timer for 'StorageContainerManager' metrics system" daemon prio=5 tid=59 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-DeleteContainerThread-0"  prio=5 tid=1164 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=51 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp66611632-618" daemon prio=5 tid=618 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Session-HouseKeeper-47d054db-1"  prio=5 tid=621 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 15 on default port 15002" daemon prio=5 tid=275 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 55 on default port 15002" daemon prio=5 tid=315 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1@group-C5BA1605619E-SegmentedRaftLogWorker"  prio=5 tid=390 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$1129/0x00007f07dc7152a0.run(Unknown Source)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1281 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 26 on default port 15002" daemon prio=5 tid=286 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 18 on default port 15009" daemon prio=5 tid=491 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 27 on default port 15000" daemon prio=5 tid=87 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 80 on default port 15002" daemon prio=5 tid=340 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 51 on default port 15009" daemon prio=5 tid=524 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-PeriodicHDDSVolumeChecker" daemon prio=5 tid=785 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=56 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Reference Handler" daemon prio=10 tid=2 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/java.lang.ref.Reference.waitForReferencePendingList(Native Method)
        at java.base@17.0.11/java.lang.ref.Reference.processPendingReferences(Reference.java:253)
        at java.base@17.0.11/java.lang.ref.Reference$ReferenceHandler.run(Reference.java:215)
"IPC Server handler 86 on default port 15000" daemon prio=5 tid=146 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1715823878-364" daemon prio=5 tid=364 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$787/0x00007f07dc53d0d0.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"om1-OpenKeyCleanupService#0" daemon prio=5 tid=401 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-SegmentedRaftLogWorker"  prio=5 tid=1243 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$1129/0x00007f07dc7152a0.run(Unknown Source)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=798 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp66611632-616" daemon prio=5 tid=616 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 39 on default port 15002" daemon prio=5 tid=299 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 83 on default port 15009" daemon prio=5 tid=556 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 76 on default port 15002" daemon prio=5 tid=336 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-DatanodeStateMachineDaemonThread" daemon prio=5 tid=684 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:369)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:556)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1626/0x00007f07dcc25c28.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 93 on default port 15001" daemon prio=5 tid=253 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 9 on default port 15002" daemon prio=5 tid=269 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-DatanodeReportManager-0" daemon prio=5 tid=657 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 7 on default port 15004" daemon prio=5 tid=423 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15000"  prio=5 tid=45 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 7 on default port 15001" daemon prio=5 tid=167 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 62 on default port 15000" daemon prio=5 tid=122 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp862366104-413" daemon prio=5 tid=413 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"pool-176-thread-1" daemon prio=5 tid=787 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 25 on default port 15009" daemon prio=5 tid=498 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-DatanodeReportManager-1" daemon prio=5 tid=658 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"JvmPauseMonitor5" daemon prio=5 tid=775 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at java.base@17.0.11/java.lang.Thread.sleep(Thread.java:344)
        at java.base@17.0.11/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at app//org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at app//org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at app//org.apache.ratis.util.JvmPauseMonitor$$Lambda$747/0x00007f07dc4e0000.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp532734552-647" daemon prio=5 tid=647 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp892107577-675" daemon prio=5 tid=675 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-ChunkReader-ELG-0" daemon prio=5 tid=796 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 27 on default port 15001" daemon prio=5 tid=187 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"55857a12-8529-4f00-ab69-b96d955e4226-PipelineCommandHandlerThread-0"  prio=5 tid=876 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=760 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"JvmPauseMonitor1" daemon prio=5 tid=394 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at java.base@17.0.11/java.lang.Thread.sleep(Thread.java:344)
        at java.base@17.0.11/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at app//org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at app//org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at app//org.apache.ratis.util.JvmPauseMonitor$$Lambda$747/0x00007f07dc4e0000.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"55857a12-8529-4f00-ab69-b96d955e4226-DatanodeReportManager-4" daemon prio=5 tid=717 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 6 on default port 15001" daemon prio=5 tid=166 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 15 on default port 15004" daemon prio=5 tid=431 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-CloseContainerThread-1"  prio=5 tid=1059 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 81 on default port 15001" daemon prio=5 tid=241 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 1 on default port 15000" daemon prio=5 tid=61 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-193-thread-1"  prio=5 tid=668 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 30 on default port 15000" daemon prio=5 tid=90 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp114325689-697" daemon prio=5 tid=697 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$787/0x00007f07dc53d0d0.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 72 on default port 15009" daemon prio=5 tid=545 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-DatanodeStateMachineTaskThread-0"  prio=5 tid=607 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 35 on default port 15009" daemon prio=5 tid=508 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 69 on default port 15000" daemon prio=5 tid=129 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server idle connection scanner for port 15001" daemon prio=5 tid=41 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"IPC Server handler 64 on default port 15001" daemon prio=5 tid=224 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-BlockDeletingService#2" daemon prio=5 tid=1278 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 60 on default port 15009" daemon prio=5 tid=533 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SCMBlockDeletingService#0" daemon prio=5 tid=360 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler" daemon prio=5 tid=1049 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@4f5950e6" daemon prio=5 tid=639 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"ForkJoinPool.commonPool-worker-3" daemon prio=5 tid=23 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1724)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1623)
        at java.base@17.0.11/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
"IPC Server handler 15 on default port 15009" daemon prio=5 tid=488 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-DatanodeStateMachineTaskThread-0"  prio=5 tid=635 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 16 on default port 15000" daemon prio=5 tid=76 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 46 on default port 15000" daemon prio=5 tid=106 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp892107577-670" daemon prio=5 tid=670 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$787/0x00007f07dc53d0d0.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server idle connection scanner for port 15048" daemon prio=5 tid=708 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"Recon-FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=457 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 38 on default port 15002" daemon prio=5 tid=298 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"55857a12-8529-4f00-ab69-b96d955e4226-ReplicationContainerReader-0" daemon prio=5 tid=1189 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=820 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 94 on default port 15000" daemon prio=5 tid=154 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-worker-ELG-3-3" daemon prio=5 tid=864 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:312)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:376)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-server-thread1" daemon prio=5 tid=1272 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-ChunkReader-ELG-0" daemon prio=5 tid=738 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"om1-OMStateMachineApplyTransactionThread - 0" daemon prio=5 tid=939 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 13 on default port 15004" daemon prio=5 tid=429 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 79 on default port 15001" daemon prio=5 tid=239 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15021" daemon prio=5 tid=627 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"55857a12-8529-4f00-ab69-b96d955e4226-ChunkWriter-1-0" daemon prio=5 tid=811 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp1026273299-465" daemon prio=5 tid=465 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at app//org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.reservedWait(ReservedThreadExecutor.java:324)
        at app//org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:399)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp1026273299-460" daemon prio=5 tid=460 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 52 on default port 15001" daemon prio=5 tid=212 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 82 on default port 15001" daemon prio=5 tid=242 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"junit-jupiter-timeout-watcher"  prio=10 tid=1045 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 78 on default port 15001" daemon prio=5 tid=238 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-worker-ELG-3-2" daemon prio=5 tid=860 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:312)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:376)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server listener on 15012" daemon prio=5 tid=594 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"qtp907063731-591" daemon prio=5 tid=591 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Session-HouseKeeper-5296c192-1"  prio=5 tid=677 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 96 on default port 15002" daemon prio=5 tid=356 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 60 on default port 15001" daemon prio=5 tid=220 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 91 on default port 15001" daemon prio=5 tid=251 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 93 on default port 15009" daemon prio=5 tid=566 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 34 on default port 15002" daemon prio=5 tid=294 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 69 on default port 15001" daemon prio=5 tid=229 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp114325689-701" daemon prio=5 tid=701 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"55857a12-8529-4f00-ab69-b96d955e4226-groupManagement"  prio=5 tid=877 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 46 on default port 15002" daemon prio=5 tid=306 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 18 on default port 15004" daemon prio=5 tid=434 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 80 on default port 15001" daemon prio=5 tid=240 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"PartialTableCache-Cleanup-0" daemon prio=5 tid=959 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=58 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Socket Reader #1 for port 15039"  prio=5 tid=679 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"JvmPauseMonitor3" daemon prio=5 tid=737 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at java.base@17.0.11/java.lang.Thread.sleep(Thread.java:344)
        at java.base@17.0.11/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at app//org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at app//org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at app//org.apache.ratis.util.JvmPauseMonitor$$Lambda$747/0x00007f07dc4e0000.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"SSL Certificates Store Monitor" daemon prio=5 tid=442 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.lang.Object.wait(Object.java:338)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:537)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"IPC Server handler 56 on default port 15002" daemon prio=5 tid=316 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15002" daemon prio=5 tid=260 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 44 on default port 15000" daemon prio=5 tid=104 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 79 on default port 15000" daemon prio=5 tid=139 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-CloseContainerThread-1"  prio=5 tid=1058 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 94 on default port 15009" daemon prio=5 tid=567 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp907063731-585" daemon prio=5 tid=585 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$787/0x00007f07dc53d0d0.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 89 on default port 15002" daemon prio=5 tid=349 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 64 on default port 15009" daemon prio=5 tid=537 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"main"  prio=5 tid=1 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/java.lang.Thread.dumpThreads(Native Method)
        at java.base@17.0.11/java.lang.Thread.getAllStackTraces(Thread.java:1671)
        at app//org.apache.ozone.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:83)
        at app//org.apache.ozone.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:69)
        at app//org.apache.ozone.test.TimedOutTestsListener.lambda$executionFinished$0(TimedOutTestsListener.java:55)
        at app//org.apache.ozone.test.TimedOutTestsListener$$Lambda$2622/0x00007f07dcf8f6d8.accept(Unknown Source)
        at java.base@17.0.11/java.util.Optional.ifPresent(Optional.java:178)
        at app//org.apache.ozone.test.TimedOutTestsListener.executionFinished(TimedOutTestsListener.java:51)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener.lambda$executionFinished$10(CompositeTestExecutionListener.java:73)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener$$Lambda$2581/0x00007f07dcf6bcf8.accept(Unknown Source)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener.lambda$notifyEach$19(CompositeTestExecutionListener.java:102)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener$$Lambda$299/0x00007f07dc0b88a8.accept(Unknown Source)
        at app//org.junit.platform.commons.util.CollectionUtils.forEachInReverseOrder(CollectionUtils.java:221)
        at app//org.junit.platform.launcher.core.IterationOrder$2.forEach(IterationOrder.java:30)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener.notifyEach(CompositeTestExecutionListener.java:100)
        at app//org.junit.platform.launcher.core.CompositeTestExecutionListener.executionFinished(CompositeTestExecutionListener.java:72)
        at app//org.junit.platform.launcher.core.ExecutionListenerAdapter.executionFinished(ExecutionListenerAdapter.java:56)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener.lambda$executionFinished$6(CompositeEngineExecutionListener.java:59)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener$$Lambda$2572/0x00007f07dcf6a920.accept(Unknown Source)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener.lambda$notifyEach$11(CompositeEngineExecutionListener.java:74)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener$$Lambda$350/0x00007f07dc111ae0.accept(Unknown Source)
        at app//org.junit.platform.commons.util.CollectionUtils.forEachInReverseOrder(CollectionUtils.java:221)
        at app//org.junit.platform.launcher.core.IterationOrder$2.forEach(IterationOrder.java:30)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener.notifyEach(CompositeEngineExecutionListener.java:72)
        at app//org.junit.platform.launcher.core.CompositeEngineExecutionListener.executionFinished(CompositeEngineExecutionListener.java:58)
        at app//org.junit.platform.launcher.core.DelegatingEngineExecutionListener.executionFinished(DelegatingEngineExecutionListener.java:46)
        at app//org.junit.platform.launcher.core.StackTracePruningEngineExecutionListener.executionFinished(StackTracePruningEngineExecutionListener.java:46)
        at app//org.junit.platform.launcher.core.DelegatingEngineExecutionListener.executionFinished(DelegatingEngineExecutionListener.java:46)
        at app//org.junit.platform.launcher.core.OutcomeDelayingEngineExecutionListener.executionFinished(OutcomeDelayingEngineExecutionListener.java:63)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.reportCompletion(NodeTestTask.java:195)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100)
        at app//org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:226)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:204)
        at app//org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:142)
        at app//org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.lambda$execute$2(TestTemplateTestDescriptor.java:110)
        at app//org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor$$Lambda$2318/0x00007f07dcef46d8.accept(Unknown Source)
        at java.base@17.0.11/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:179)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@17.0.11/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@17.0.11/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@17.0.11/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:992)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@17.0.11/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:992)
        at java.base@17.0.11/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
        at java.base@17.0.11/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
        at java.base@17.0.11/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
        at java.base@17.0.11/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
        at java.base@17.0.11/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
        at java.base@17.0.11/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)
        at java.base@17.0.11/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1625)
        at java.base@17.0.11/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
        at java.base@17.0.11/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
        at java.base@17.0.11/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
        at java.base@17.0.11/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
        at java.base@17.0.11/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
        at java.base@17.0.11/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
        at java.base@17.0.11/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:276)
        at java.base@17.0.11/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1625)
        at java.base@17.0.11/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
        at java.base@17.0.11/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
        at java.base@17.0.11/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
        at java.base@17.0.11/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
        at java.base@17.0.11/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
        at java.base@17.0.11/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
        at app//org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:110)
        at app//org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:44)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$373/0x00007f07dc11ec88.execute(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$372/0x00007f07dc11ea60.invoke(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$371/0x00007f07dc11e638.execute(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at app//org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService$$Lambda$377/0x00007f07dc11fc30.accept(Unknown Source)
        at java.base@17.0.11/java.util.ArrayList.forEach(ArrayList.java:1511)
        at app//org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$373/0x00007f07dc11ec88.execute(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$372/0x00007f07dc11ea60.invoke(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$371/0x00007f07dc11e638.execute(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at app//org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService$$Lambda$377/0x00007f07dc11fc30.accept(Unknown Source)
        at java.base@17.0.11/java.util.ArrayList.forEach(ArrayList.java:1511)
        at app//org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$373/0x00007f07dc11ec88.execute(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$372/0x00007f07dc11ea60.invoke(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$371/0x00007f07dc11e638.execute(Unknown Source)
        at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at app//org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
        at app//org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
        at app//org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:198)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:169)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:93)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:58)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator$$Lambda$287/0x00007f07dc0b6480.accept(Unknown Source)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:141)
        at app//org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:57)
        at app//org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:103)
        at app//org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:85)
        at app//org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
        at app//org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:63)
        at app//org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
        at app//org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
        at app//org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
        at app//org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
        at app//org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
        at app//org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
"IPC Server handler 83 on default port 15002" daemon prio=5 tid=343 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 99 on default port 15009" daemon prio=5 tid=572 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=637 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-CloseContainerThread-1"  prio=5 tid=1073 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 11 on default port 15004" daemon prio=5 tid=427 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 32 on default port 15000" daemon prio=5 tid=92 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 84 on default port 15000" daemon prio=5 tid=144 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 50 on default port 15000" daemon prio=5 tid=110 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=37 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:141)
        at app//org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at app//org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"JvmPauseMonitor7" daemon prio=5 tid=814 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at java.base@17.0.11/java.lang.Thread.sleep(Thread.java:344)
        at java.base@17.0.11/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at app//org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at app//org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at app//org.apache.ratis.util.JvmPauseMonitor$$Lambda$747/0x00007f07dc4e0000.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 98 on default port 15009" daemon prio=5 tid=571 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"55857a12-8529-4f00-ab69-b96d955e4226-BlockDeletingService#2" daemon prio=5 tid=1286 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 14 on default port 15000" daemon prio=5 tid=74 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-DatanodeReportManager-4" daemon prio=5 tid=605 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 43 on default port 15001" daemon prio=5 tid=203 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 3 on default port 15009" daemon prio=5 tid=476 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 62 on default port 15009" daemon prio=5 tid=535 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/data-0/hdds)" daemon prio=5 tid=770 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=782 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server idle connection scanner for port 15012" daemon prio=5 tid=596 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-SegmentedRaftLogWorker"  prio=5 tid=879 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$1129/0x00007f07dc7152a0.run(Unknown Source)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp862366104-411" daemon prio=5 tid=411 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
        at app//org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"55857a12-8529-4f00-ab69-b96d955e4226-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=803 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-ChunkReader-ELG-0" daemon prio=5 tid=776 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 47 on default port 15001" daemon prio=5 tid=207 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp532734552-644" daemon prio=5 tid=644 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server listener on 15048" daemon prio=5 tid=706 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-cacheEviction-AwaitToRun" daemon prio=5 tid=1160 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at app//org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 84 on default port 15001" daemon prio=5 tid=244 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 20 on default port 15001" daemon prio=5 tid=180 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-groupManagement"  prio=5 tid=844 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 67 on default port 15001" daemon prio=5 tid=227 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15002"  prio=5 tid=35 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 7 on default port 15000" daemon prio=5 tid=67 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 71 on default port 15001" daemon prio=5 tid=231 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 56 on default port 15000" daemon prio=5 tid=116 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-SyncOM-1"  prio=5 tid=965 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 51 on default port 15000" daemon prio=5 tid=111 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=48 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 16 on default port 15009" daemon prio=5 tid=489 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FullTableCache-Cleanup-0" daemon prio=5 tid=941 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"DatanodeAdminManager-0" daemon prio=5 tid=32 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 38 on default port 15001" daemon prio=5 tid=198 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1-SnapshotDeletingService#0" daemon prio=5 tid=403 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"ForkJoinPool.commonPool-worker-1" daemon prio=5 tid=21 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1724)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1623)
        at java.base@17.0.11/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
"qtp114325689-704" daemon prio=5 tid=704 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"55857a12-8529-4f00-ab69-b96d955e4226-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=693 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=780 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"grpc-default-executor-3" daemon prio=5 tid=928 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 19 on default port 15004" daemon prio=5 tid=435 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 40 on default port 15000" daemon prio=5 tid=100 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 17 on default port 15000" daemon prio=5 tid=77 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 8 on default port 15000" daemon prio=5 tid=68 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 60 on default port 15000" daemon prio=5 tid=120 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-BlockDeletingService#2" daemon prio=5 tid=1284 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule" daemon prio=5 tid=823 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-CloseContainerThread-2"  prio=5 tid=1063 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp532734552-641" daemon prio=5 tid=641 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$787/0x00007f07dc53d0d0.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server Responder" daemon prio=5 tid=681 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:141)
        at app//org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at app//org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-DatanodeStateMachineTaskThread-1"  prio=5 tid=720 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 54 on default port 15001" daemon prio=5 tid=214 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=764 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"grpc-default-worker-ELG-3-1" daemon prio=5 tid=859 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:312)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:376)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 30 on default port 15009" daemon prio=5 tid=503 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=830 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 95 on default port 15001" daemon prio=5 tid=255 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 97 on default port 15002" daemon prio=5 tid=357 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 42 on default port 15001" daemon prio=5 tid=202 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 83 on default port 15001" daemon prio=5 tid=243 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=799 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Session-HouseKeeper-66dad66f-1"  prio=5 tid=415 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-DatanodeReportManager-1" daemon prio=5 tid=630 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0"  prio=5 tid=843 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-SegmentedRaftLogWorker"  prio=5 tid=1161 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$1129/0x00007f07dc7152a0.run(Unknown Source)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"EventQueue-DatanodeCommandQueueUpdatedForDatanodeCommandCountUpdatedHandler" daemon prio=5 tid=828 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"55857a12-8529-4f00-ab69-b96d955e4226-ReplicationContainerReader-1" daemon prio=5 tid=1190 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 83 on default port 15000" daemon prio=5 tid=143 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Client (1377194794) connection to 0.0.0.0/0.0.0.0:15002 from runner" daemon prio=5 tid=723 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at app//org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1026)
        at app//org.apache.hadoop.ipc.Client$Connection.run(Client.java:1077)
"ContainerMetadataScanner" daemon prio=5 tid=808 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"FullTableCache-Cleanup-0" daemon prio=5 tid=940 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server idle connection scanner for port 15000" daemon prio=5 tid=46 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"IPC Server handler 85 on default port 15002" daemon prio=5 tid=345 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1026273299-466" daemon prio=5 tid=466 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
        at app//org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 12 on default port 15009" daemon prio=5 tid=485 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-CloseContainerThread-2"  prio=5 tid=1074 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 94 on default port 15001" daemon prio=5 tid=254 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=459 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 77 on default port 15009" daemon prio=5 tid=550 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 90 on default port 15009" daemon prio=5 tid=563 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"55857a12-8529-4f00-ab69-b96d955e4226-PeriodicHDDSVolumeChecker" daemon prio=5 tid=805 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server idle connection scanner for port 15030" daemon prio=5 tid=652 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderStateImpl" daemon prio=5 tid=936 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:762)
"IPC Server handler 23 on default port 15002" daemon prio=5 tid=283 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-BlockDeletingService#0" daemon prio=5 tid=797 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-ChunkWriter-2-0" daemon prio=5 tid=793 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"grpc-default-executor-0" daemon prio=5 tid=861 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Recon-EventQueue-NewNodeForReconNewNodeHandler" daemon prio=5 tid=821 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-BlockDeletingService#0" daemon prio=5 tid=777 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 22 on default port 15000" daemon prio=5 tid=82 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=50 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-DatanodeReportManager-3" daemon prio=5 tid=604 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"om1-DirectoryDeletingService#0" daemon prio=5 tid=400 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 77 on default port 15002" daemon prio=5 tid=337 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"55857a12-8529-4f00-ab69-b96d955e4226-DatanodeStateMachineTaskThread-1"  prio=5 tid=801 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp862366104-410-acceptor-0@5986cd76-ServerConnector@462ccaa8{HTTP/1.1, (http/1.1)}{0.0.0.0:15005}" daemon prio=3 tid=410 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.Net.accept(Native Method)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.implAccept(ServerSocketChannelImpl.java:425)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:391)
        at app//org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at app//org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 85 on default port 15000" daemon prio=5 tid=145 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1715823878-365" daemon prio=5 tid=365 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$787/0x00007f07dc53d0d0.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 0 on default port 15009" daemon prio=5 tid=473 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 50 on default port 15001" daemon prio=5 tid=210 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-BlockDeletingService#1" daemon prio=5 tid=779 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Recon-FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=450 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler" daemon prio=5 tid=1048 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"55857a12-8529-4f00-ab69-b96d955e4226-BlockDeletingService#1" daemon prio=5 tid=819 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"55857a12-8529-4f00-ab69-b96d955e4226-DatanodeStateMachineTaskThread-0"  prio=5 tid=719 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 87 on default port 15000" daemon prio=5 tid=147 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 34 on default port 15000" daemon prio=5 tid=94 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 10 on default port 15000" daemon prio=5 tid=70 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=386 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:141)
        at app//org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at app//org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@70961c7b" daemon prio=5 tid=611 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 57 on default port 15001" daemon prio=5 tid=217 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 36 on default port 15000" daemon prio=5 tid=96 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 78 on default port 15000" daemon prio=5 tid=138 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-DatanodeCommandForSCMNodeManager"  prio=5 tid=827 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 71 on default port 15002" daemon prio=5 tid=331 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1715823878-370" daemon prio=5 tid=370 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-PipelineCommandHandlerThread-0"  prio=5 tid=831 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"ForkJoinPool.commonPool-worker-2" daemon prio=5 tid=22 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkUntil(LockSupport.java:410)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.awaitWork(ForkJoinPool.java:1726)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1623)
        at java.base@17.0.11/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
"IPC Server handler 38 on default port 15000" daemon prio=5 tid=98 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 95 on default port 15002" daemon prio=5 tid=355 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 78 on default port 15002" daemon prio=5 tid=338 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 36 on default port 15009" daemon prio=5 tid=509 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@604f8e79" daemon prio=5 tid=667 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 94 on default port 15002" daemon prio=5 tid=354 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-BlockDeletingService#1" daemon prio=5 tid=800 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 92 on default port 15002" daemon prio=5 tid=352 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15021"  prio=5 tid=623 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 36 on default port 15001" daemon prio=5 tid=196 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-ChunkWriter-1-0" daemon prio=5 tid=772 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-CloseContainerThread-2"  prio=5 tid=1060 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"pool-219-thread-1"  prio=5 tid=696 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 55 on default port 15001" daemon prio=5 tid=215 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 2 on default port 15001" daemon prio=5 tid=162 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 61 on default port 15001" daemon prio=5 tid=221 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-BlockDeletingService#2" daemon prio=5 tid=1280 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"BackgroundPipelineScrubber" daemon prio=5 tid=27 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at app//org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:107)
        at app//org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$664/0x00007f07dc3a38c8.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 8 on default port 15004" daemon prio=5 tid=424 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Session-HouseKeeper-133420f8-1"  prio=5 tid=593 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 10 on default port 15004" daemon prio=5 tid=426 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 70 on default port 15001" daemon prio=5 tid=230 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 1 on default port 15009" daemon prio=5 tid=474 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 11 on default port 15001" daemon prio=5 tid=171 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 73 on default port 15001" daemon prio=5 tid=233 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=458 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"ReconTaskThread-0"  prio=5 tid=1042 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-DatanodeStateMachineTaskThread-1"  prio=5 tid=781 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 59 on default port 15002" daemon prio=5 tid=319 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 32 on default port 15009" daemon prio=5 tid=505 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderStateImpl" daemon prio=5 tid=1187 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:762)
"om1-MultipartUploadCleanupService#0" daemon prio=5 tid=405 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp907063731-586" daemon prio=5 tid=586 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$787/0x00007f07dc53d0d0.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 90 on default port 15001" daemon prio=5 tid=250 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 60 on default port 15002" daemon prio=5 tid=320 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 30 on default port 15001" daemon prio=5 tid=190 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerMetadataScanner" daemon prio=5 tid=750 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"Recon-EventQueue-PipelineReportForReconPipelineReportHandler" daemon prio=5 tid=822 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 79 on default port 15009" daemon prio=5 tid=552 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-EventQueue-StaleNodeForReconStaleNodeHandler" daemon prio=5 tid=834 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server listener on 15009" daemon prio=5 tid=445 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=43 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"pool-97-thread-1" daemon prio=5 tid=730 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 31 on default port 15009" daemon prio=5 tid=504 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-StateMachineUpdater" daemon prio=5 tid=1159 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1759)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 65 on default port 15009" daemon prio=5 tid=538 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Notification Thread" daemon prio=9 tid=13 runnable
java.lang.Thread.State: RUNNABLE
"IPC Server handler 43 on default port 15009" daemon prio=5 tid=516 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 81 on default port 15009" daemon prio=5 tid=554 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15012" daemon prio=5 tid=599 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 19 on default port 15000" daemon prio=5 tid=79 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 7 on default port 15009" daemon prio=5 tid=480 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 81 on default port 15000" daemon prio=5 tid=141 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-cacheEviction-AwaitToRun" daemon prio=5 tid=878 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at app//org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 73 on default port 15009" daemon prio=5 tid=546 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-executor-1" daemon prio=5 tid=863 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=57 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-cacheEviction-AwaitToRun" daemon prio=5 tid=1238 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at app//org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=817 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"55857a12-8529-4f00-ab69-b96d955e4226-CommandProcessorThread" daemon prio=5 tid=718 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:684)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1628/0x00007f07dcc26278.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 75 on default port 15001" daemon prio=5 tid=235 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=52 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 71 on default port 15000" daemon prio=5 tid=131 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 63 on default port 15001" daemon prio=5 tid=223 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"55857a12-8529-4f00-ab69-b96d955e4226-DatanodeStateMachineDaemonThread" daemon prio=5 tid=712 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:369)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:556)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1626/0x00007f07dcc25c28.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"EventQueue-OpenPipelineForHealthyPipelineSafeModeRule" daemon prio=5 tid=835 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 51 on default port 15002" daemon prio=5 tid=311 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp907063731-587-acceptor-0@134f73d7-ServerConnector@77615884{HTTP/1.1, (http/1.1)}{0.0.0.0:15011}" daemon prio=3 tid=587 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.Net.accept(Native Method)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.implAccept(ServerSocketChannelImpl.java:425)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:391)
        at app//org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at app//org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Connector-Scheduler-462ccaa8-1"  prio=5 tid=968 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1170)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 75 on default port 15000" daemon prio=5 tid=135 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=449 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-BlockDeletingService#2" daemon prio=5 tid=1282 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/data-0/hdds)" daemon prio=5 tid=751 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server handler 15 on default port 15001" daemon prio=5 tid=175 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 21 on default port 15009" daemon prio=5 tid=494 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 24 on default port 15002" daemon prio=5 tid=284 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-FollowerState" daemon prio=5 tid=1267 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at java.base@17.0.11/java.lang.Thread.sleep(Thread.java:344)
        at java.base@17.0.11/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at app//org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"IPC Server handler 73 on default port 15002" daemon prio=5 tid=333 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-ChunkWriter-0-0" daemon prio=5 tid=752 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 10 on default port 15009" daemon prio=5 tid=483 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1-OMDoubleBufferFlushThread" daemon prio=5 tid=380 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at app//org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.canFlush(OzoneManagerDoubleBuffer.java:570)
        at app//org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.flushTransactions(OzoneManagerDoubleBuffer.java:294)
        at app//org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer$$Lambda$905/0x00007f07dc62d288.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 39 on default port 15009" daemon prio=5 tid=512 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=609 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp1715823878-366-acceptor-0@59669e2f-ServerConnector@8dbf0f2{HTTP/1.1, (http/1.1)}{0.0.0.0:15003}" daemon prio=3 tid=366 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.Net.accept(Native Method)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.implAccept(ServerSocketChannelImpl.java:425)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:391)
        at app//org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at app//org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp114325689-703" daemon prio=5 tid=703 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-CloseContainerThread-0"  prio=5 tid=1056 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 48 on default port 15009" daemon prio=5 tid=521 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-StateMachineUpdater" daemon prio=5 tid=881 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1759)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-DatanodeReportManager-4" daemon prio=5 tid=689 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderStateImpl" daemon prio=5 tid=1269 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:762)
"qtp1026273299-464" daemon prio=5 tid=464 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
        at app//org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"om1@group-C5BA1605619E-cacheEviction-AwaitToRun" daemon prio=5 tid=389 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at app//org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 47 on default port 15002" daemon prio=5 tid=307 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 48 on default port 15002" daemon prio=5 tid=308 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 24 on default port 15001" daemon prio=5 tid=184 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-StateMachineUpdater" daemon prio=5 tid=1252 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1759)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp892107577-671-acceptor-0@7d78ff0b-ServerConnector@37988190{HTTP/1.1, (http/1.1)}{0.0.0.0:15038}" daemon prio=3 tid=671 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.Net.accept(Native Method)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.implAccept(ServerSocketChannelImpl.java:425)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:391)
        at app//org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at app//org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=580 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"pool-202-thread-1" daemon prio=5 tid=807 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"ReplicationMonitor" daemon prio=5 tid=29 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at app//org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:934)
        at app//org.apache.hadoop.hdds.scm.container.replication.ReplicationManager$$Lambda$678/0x00007f07dc3bd750.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"NetworkTopologyPoller" daemon prio=5 tid=398 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 2 on default port 15000" daemon prio=5 tid=62 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 19 on default port 15009" daemon prio=5 tid=492 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=456 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 38 on default port 15009" daemon prio=5 tid=511 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 86 on default port 15009" daemon prio=5 tid=559 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server listener on 15021" daemon prio=5 tid=622 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 75 on default port 15009" daemon prio=5 tid=548 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 43 on default port 15000" daemon prio=5 tid=103 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1715823878-368" daemon prio=5 tid=368 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=654 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 4 on default port 15001" daemon prio=5 tid=164 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 72 on default port 15000" daemon prio=5 tid=132 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 24 on default port 15000" daemon prio=5 tid=84 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1285 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@61725c0e" daemon prio=5 tid=695 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 35 on default port 15002" daemon prio=5 tid=295 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-ChunkReader-ELG-0" daemon prio=5 tid=757 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-ReplicationContainerReader-0" daemon prio=5 tid=1106 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-StateMachineUpdater" daemon prio=5 tid=1241 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1759)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299->390bac8a-0dbf-4715-b6fd-0c75abb5c43b-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=1271 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1759)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at app//org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:286)
        at app//org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:254)
        at app//org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:80)
        at app//org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1859/0x00007f07dcd6aec8.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-CommandProcessorThread" daemon prio=5 tid=690 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:684)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1628/0x00007f07dcc26278.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 49 on default port 15001" daemon prio=5 tid=209 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp907063731-588" daemon prio=5 tid=588 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 14 on default port 15001" daemon prio=5 tid=174 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 50 on default port 15009" daemon prio=5 tid=523 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FollowerState" daemon prio=5 tid=1268 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at java.base@17.0.11/java.lang.Thread.sleep(Thread.java:344)
        at java.base@17.0.11/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at app//org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"IPC Parameter Sending Thread for localhost/127.0.0.1:15004" daemon prio=5 tid=967 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferQueue.transfer(SynchronousQueue.java:704)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at app//org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1105)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 49 on default port 15002" daemon prio=5 tid=309 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 40 on default port 15002" daemon prio=5 tid=300 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 70 on default port 15000" daemon prio=5 tid=130 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 58 on default port 15002" daemon prio=5 tid=318 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 15 on default port 15000" daemon prio=5 tid=75 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-141-thread-1"  prio=5 tid=612 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 73 on default port 15000" daemon prio=5 tid=133 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 97 on default port 15009" daemon prio=5 tid=570 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"UnderReplicatedProcessor" daemon prio=5 tid=30 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at app//org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:174)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 59 on default port 15001" daemon prio=5 tid=219 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=722 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-ChunkWriter-1-0" daemon prio=5 tid=753 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"55857a12-8529-4f00-ab69-b96d955e4226-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=802 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-SegmentedRaftLogWorker"  prio=5 tid=1239 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$1129/0x00007f07dc7152a0.run(Unknown Source)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 53 on default port 15009" daemon prio=5 tid=526 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 3 on default port 15002" daemon prio=5 tid=263 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 23 on default port 15001" daemon prio=5 tid=183 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-DatanodeStateMachineTaskThread-1"  prio=5 tid=762 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server idle connection scanner for port 15002" daemon prio=5 tid=36 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-PeriodicHDDSVolumeChecker" daemon prio=5 tid=728 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"timer4" daemon prio=5 tid=927 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"IPC Server handler 28 on default port 15001" daemon prio=5 tid=188 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 19 on default port 15002" daemon prio=5 tid=279 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 40 on default port 15009" daemon prio=5 tid=513 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-DatanodeStateMachineDaemonThread" daemon prio=5 tid=628 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:369)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:556)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1626/0x00007f07dcc25c28.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 91 on default port 15000" daemon prio=5 tid=151 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15030"  prio=5 tid=651 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"surefire-forkedjvm-command-thread" daemon prio=5 tid=14 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/java.io.FileInputStream.readBytes(Native Method)
        at java.base@17.0.11/java.io.FileInputStream.read(FileInputStream.java:276)
        at java.base@17.0.11/java.io.BufferedInputStream.fill(BufferedInputStream.java:244)
        at java.base@17.0.11/java.io.BufferedInputStream.read(BufferedInputStream.java:263)
        at java.base@17.0.11/java.io.DataInputStream.readInt(DataInputStream.java:381)
        at app//org.apache.maven.surefire.booter.MasterProcessCommand.decode(MasterProcessCommand.java:113)
        at app//org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:383)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 37 on default port 15001" daemon prio=5 tid=197 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 10 on default port 15002" daemon prio=5 tid=270 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 37 on default port 15009" daemon prio=5 tid=510 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-DatanodeReportManager-2" daemon prio=5 tid=631 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"EventQueue-PipelineReportForPipelineReportHandler" daemon prio=5 tid=826 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 87 on default port 15001" daemon prio=5 tid=247 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Session-HouseKeeper-50fc7fff-1"  prio=5 tid=649 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp1026273299-461" daemon prio=5 tid=461 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 75 on default port 15002" daemon prio=5 tid=335 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerSizeCountTask" daemon prio=5 tid=576 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at app//org.apache.hadoop.ozone.recon.tasks.ContainerSizeCountTask.run(ContainerSizeCountTask.java:94)
        at app//org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda$1538/0x00007f07dcbcf588.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"pool-124-thread-1" daemon prio=5 tid=749 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 97 on default port 15000" daemon prio=5 tid=157 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 29 on default port 15002" daemon prio=5 tid=289 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1026273299-463" daemon prio=5 tid=463 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server listener on 15030" daemon prio=5 tid=650 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 34 on default port 15009" daemon prio=5 tid=507 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 41 on default port 15001" daemon prio=5 tid=201 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-ReplicationContainerReader-1" daemon prio=5 tid=1107 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 10 on default port 15001" daemon prio=5 tid=170 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=710 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 42 on default port 15009" daemon prio=5 tid=515 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"55857a12-8529-4f00-ab69-b96d955e4226-ReplicationContainerReader-2" daemon prio=5 tid=1191 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-ChunkWriter-2-0" daemon prio=5 tid=735 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 14 on default port 15009" daemon prio=5 tid=487 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-StateMachineUpdater" daemon prio=5 tid=1245 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1759)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 6 on default port 15004" daemon prio=5 tid=422 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/data-0/hdds)" daemon prio=5 tid=790 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PipelineCommandHandlerThread-0"  prio=5 tid=853 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 35 on default port 15000" daemon prio=5 tid=95 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 29 on default port 15000" daemon prio=5 tid=89 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp66611632-619" daemon prio=5 tid=619 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-DatanodeStateMachineTaskThread-0"  prio=5 tid=691 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 41 on default port 15000" daemon prio=5 tid=101 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 40 on default port 15001" daemon prio=5 tid=200 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 45 on default port 15000" daemon prio=5 tid=105 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"timer7" daemon prio=5 tid=950 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"IPC Server Responder" daemon prio=5 tid=42 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:141)
        at app//org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at app//org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"IPC Server handler 48 on default port 15000" daemon prio=5 tid=108 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Common-Cleaner" daemon prio=8 tid=11 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:155)
        at java.base@17.0.11/jdk.internal.ref.CleanerImpl.run(CleanerImpl.java:140)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
        at java.base@17.0.11/jdk.internal.misc.InnocuousThread.run(InnocuousThread.java:162)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-ChunkWriter-0-0" daemon prio=5 tid=771 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-StateMachineUpdater" daemon prio=5 tid=1163 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1759)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp66611632-614" daemon prio=5 tid=614 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$787/0x00007f07dc53d0d0.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 20 on default port 15009" daemon prio=5 tid=493 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 9 on default port 15001" daemon prio=5 tid=169 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 96 on default port 15001" daemon prio=5 tid=256 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 52 on default port 15009" daemon prio=5 tid=525 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"55857a12-8529-4f00-ab69-b96d955e4226-DatanodeReportManager-2" daemon prio=5 tid=715 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-BlockDeletingService#1" daemon prio=5 tid=742 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server listener on 15002" daemon prio=5 tid=34 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 82 on default port 15009" daemon prio=5 tid=555 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 5 on default port 15002" daemon prio=5 tid=265 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 11 on default port 15002" daemon prio=5 tid=271 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 82 on default port 15002" daemon prio=5 tid=342 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"PipelineSyncTask" daemon prio=5 tid=573 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.recon.scm.PipelineSyncTask.run(PipelineSyncTask.java:76)
        at app//org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda$1538/0x00007f07dcbcf588.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Recon-FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=455 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=626 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 96 on default port 15000" daemon prio=5 tid=156 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 47 on default port 15000" daemon prio=5 tid=107 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp114325689-698" daemon prio=5 tid=698 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$787/0x00007f07dc53d0d0.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 86 on default port 15001" daemon prio=5 tid=246 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=682 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 32 on default port 15002" daemon prio=5 tid=292 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 59 on default port 15000" daemon prio=5 tid=119 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=709 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:141)
        at app//org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at app//org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-DatanodeStateMachineDaemonThread" daemon prio=5 tid=600 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:369)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:556)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1626/0x00007f07dcc25c28.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 32 on default port 15001" daemon prio=5 tid=192 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-CloseContainerThread-0"  prio=5 tid=1054 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 57 on default port 15009" daemon prio=5 tid=530 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-ChunkWriter-3-0" daemon prio=5 tid=794 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 93 on default port 15002" daemon prio=5 tid=353 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 66 on default port 15009" daemon prio=5 tid=539 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"gradle-enterprise-test-client-gradle-enterprise-test-listener"  prio=5 tid=18 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:420)
        at app//com.gradle.maven.scan.extension.test.listener.obfuscated.k.a.a(SourceFile:130)
        at app//com.gradle.maven.scan.extension.test.listener.obfuscated.k.a.b(SourceFile:93)
        at app//com.gradle.maven.scan.extension.test.listener.obfuscated.k.a$$Lambda$308/0x00007f07dc104b90.run(Unknown Source)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 90 on default port 15002" daemon prio=5 tid=350 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 87 on default port 15009" daemon prio=5 tid=560 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp862366104-408" daemon prio=5 tid=408 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-DatanodeReportManager-3" daemon prio=5 tid=688 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 84 on default port 15002" daemon prio=5 tid=344 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-executor-4" daemon prio=5 tid=1079 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 67 on default port 15009" daemon prio=5 tid=540 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 89 on default port 15001" daemon prio=5 tid=249 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule" daemon prio=5 tid=825 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 85 on default port 15009" daemon prio=5 tid=558 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 12 on default port 15000" daemon prio=5 tid=72 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=452 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=741 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Timer-0"  prio=5 tid=395 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"pool-64-thread-1"  prio=5 tid=406 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"EventQueue-CloseContainerForCloseContainerEventHandler" daemon prio=5 tid=1051 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 3 on default port 15001" daemon prio=5 tid=163 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-SyncSCMContainerInfo-0"  prio=5 tid=472 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"JvmPauseMonitor4" daemon prio=5 tid=756 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at java.base@17.0.11/java.lang.Thread.sleep(Thread.java:344)
        at java.base@17.0.11/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at app//org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at app//org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at app//org.apache.ratis.util.JvmPauseMonitor$$Lambda$747/0x00007f07dc4e0000.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp1026273299-467" daemon prio=5 tid=467 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at app//org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.reservedWait(ReservedThreadExecutor.java:324)
        at app//org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:399)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 74 on default port 15009" daemon prio=5 tid=547 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp862366104-407" daemon prio=5 tid=407 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$787/0x00007f07dc53d0d0.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-cacheEviction-AwaitToRun" daemon prio=5 tid=1249 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at app//org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 28 on default port 15009" daemon prio=5 tid=501 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 45 on default port 15002" daemon prio=5 tid=305 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=783 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 0 on default port 15004" daemon prio=5 tid=416 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 87 on default port 15002" daemon prio=5 tid=347 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"55857a12-8529-4f00-ab69-b96d955e4226-ChunkWriter-3-0" daemon prio=5 tid=813 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 55 on default port 15000" daemon prio=5 tid=115 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"timer1" daemon prio=5 tid=922 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"IPC Server handler 93 on default port 15000" daemon prio=5 tid=153 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 68 on default port 15001" daemon prio=5 tid=228 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp862366104-409" daemon prio=5 tid=409 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-ContainerReplicationThread-0" daemon prio=5 tid=1105 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.PriorityBlockingQueue.take(PriorityBlockingQueue.java:535)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server idle connection scanner for port 15039" daemon prio=5 tid=680 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"Recon-FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=453 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"ContainerMetadataScanner" daemon prio=5 tid=731 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"JvmPauseMonitor0" daemon prio=5 tid=362 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at java.base@17.0.11/java.lang.Thread.sleep(Thread.java:344)
        at java.base@17.0.11/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at app//org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at app//org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at app//org.apache.ratis.util.JvmPauseMonitor$$Lambda$747/0x00007f07dc4e0000.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"LeaseManager#LeaseMonitor" daemon prio=5 tid=361 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(AbstractQueuedSynchronizer.java:717)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1074)
        at java.base@17.0.11/java.util.concurrent.Semaphore.tryAcquire(Semaphore.java:415)
        at app//org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:284)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 26 on default port 15001" daemon prio=5 tid=186 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 19 on default port 15001" daemon prio=5 tid=179 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"client-write-TID-0" daemon prio=5 tid=958 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack$SNode.block(SynchronousQueue.java:288)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:397)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:886)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 41 on default port 15009" daemon prio=5 tid=514 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 25 on default port 15001" daemon prio=5 tid=185 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 66 on default port 15000" daemon prio=5 tid=126 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1-SnapshotDiffCleanupService#0" daemon prio=5 tid=378 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-DatanodeStateMachineTaskThread-1"  prio=5 tid=743 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-DatanodeReportManager-1" daemon prio=5 tid=686 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Socket Reader #1 for port 15004"  prio=5 tid=384 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 68 on default port 15002" daemon prio=5 tid=328 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=745 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/data-0/hdds)" daemon prio=5 tid=809 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server handler 37 on default port 15000" daemon prio=5 tid=97 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 88 on default port 15000" daemon prio=5 tid=148 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 89 on default port 15009" daemon prio=5 tid=562 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 98 on default port 15000" daemon prio=5 tid=158 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 67 on default port 15002" daemon prio=5 tid=327 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-71-thread-1"  prio=5 tid=441 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 65 on default port 15001" daemon prio=5 tid=225 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 82 on default port 15000" daemon prio=5 tid=142 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 16 on default port 15004" daemon prio=5 tid=432 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-DatanodeReportManager-4" daemon prio=5 tid=633 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=38 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server listener on 15039" daemon prio=5 tid=678 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"qtp1715823878-369" daemon prio=5 tid=369 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 26 on default port 15000" daemon prio=5 tid=86 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 76 on default port 15009" daemon prio=5 tid=549 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1-groupManagement"  prio=5 tid=382 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 74 on default port 15000" daemon prio=5 tid=134 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 76 on default port 15001" daemon prio=5 tid=236 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=721 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Session-HouseKeeper-1847e32d-1"  prio=5 tid=705 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 16 on default port 15002" daemon prio=5 tid=276 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"LeakDetector-ManagedRocksObject0" daemon prio=5 tid=24 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:155)
        at java.base@17.0.11/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:176)
        at app//org.apache.hadoop.hdds.utils.LeakDetector.run(LeakDetector.java:80)
        at app//org.apache.hadoop.hdds.utils.LeakDetector$$Lambda$581/0x00007f07dc28f690.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 12 on default port 15004" daemon prio=5 tid=428 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1@group-C5BA1605619E-LeaderStateImpl" daemon prio=5 tid=440 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:762)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-PeriodicHDDSVolumeChecker" daemon prio=5 tid=766 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-DatanodeStateMachineDaemonThread" daemon prio=5 tid=656 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:369)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:556)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1626/0x00007f07dcc25c28.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-DatanodeReportManager-0" daemon prio=5 tid=629 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 54 on default port 15009" daemon prio=5 tid=527 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-cacheEviction-AwaitToRun" daemon prio=5 tid=1242 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at app//org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 66 on default port 15001" daemon prio=5 tid=226 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 42 on default port 15002" daemon prio=5 tid=302 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1-SnapshotDirectoryCleaningService#0" daemon prio=5 tid=404 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-CloseContainerThread-0"  prio=5 tid=1057 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 77 on default port 15001" daemon prio=5 tid=237 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 54 on default port 15000" daemon prio=5 tid=114 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 6 on default port 15000" daemon prio=5 tid=66 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-DatanodeReportManager-4" daemon prio=5 tid=661 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=665 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"timer3" daemon prio=5 tid=926 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"grpc-default-boss-ELG-1-1" daemon prio=5 tid=393 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 8 on default port 15001" daemon prio=5 tid=168 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 22 on default port 15009" daemon prio=5 tid=495 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/data-0/hdds)" daemon prio=5 tid=732 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server handler 9 on default port 15009" daemon prio=5 tid=482 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"55857a12-8529-4f00-ab69-b96d955e4226-ChunkReader-ELG-0" daemon prio=5 tid=815 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 33 on default port 15002" daemon prio=5 tid=293 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 16 on default port 15001" daemon prio=5 tid=176 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-ChunkWriter-0-0" daemon prio=5 tid=733 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 63 on default port 15002" daemon prio=5 tid=323 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=55 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 17 on default port 15002" daemon prio=5 tid=277 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Client (1377194794) connection to 0.0.0.0/0.0.0.0:15009 from runner" daemon prio=5 tid=725 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at app//org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1026)
        at app//org.apache.hadoop.ipc.Client$Connection.run(Client.java:1077)
"55857a12-8529-4f00-ab69-b96d955e4226-ChunkWriter-0-0" daemon prio=5 tid=810 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 45 on default port 15001" daemon prio=5 tid=205 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 56 on default port 15009" daemon prio=5 tid=529 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"MutableQuantiles-0" daemon prio=5 tid=582 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server idle connection scanner for port 15021" daemon prio=5 tid=624 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"IPC Server handler 95 on default port 15000" daemon prio=5 tid=155 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 91 on default port 15002" daemon prio=5 tid=351 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 59 on default port 15009" daemon prio=5 tid=532 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp862366104-412" daemon prio=5 tid=412 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 39 on default port 15001" daemon prio=5 tid=199 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Finalizer" daemon prio=8 tid=3 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:155)
        at java.base@17.0.11/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:176)
        at java.base@17.0.11/java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:172)
"IPC Server handler 55 on default port 15009" daemon prio=5 tid=528 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-ChunkWriter-0-0" daemon prio=5 tid=791 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"om1-KeyDeletingService#0" daemon prio=5 tid=399 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-DatanodeReportManager-0" daemon prio=5 tid=601 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 61 on default port 15000" daemon prio=5 tid=121 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 48 on default port 15001" daemon prio=5 tid=208 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 84 on default port 15009" daemon prio=5 tid=557 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Signal Dispatcher" daemon prio=9 tid=4 runnable
java.lang.Thread.State: RUNNABLE
"IPC Server handler 4 on default port 15004" daemon prio=5 tid=420 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=625 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:141)
        at app//org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at app//org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-DatanodeReportManager-2" daemon prio=5 tid=687 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 2 on default port 15004" daemon prio=5 tid=418 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp66611632-613" daemon prio=5 tid=613 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$787/0x00007f07dc53d0d0.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 8 on default port 15009" daemon prio=5 tid=481 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 71 on default port 15009" daemon prio=5 tid=544 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=763 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 92 on default port 15001" daemon prio=5 tid=252 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-BlockDeletingService#0" daemon prio=5 tid=739 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp114325689-699-acceptor-0@53c34403-ServerConnector@67aa514a{HTTP/1.1, (http/1.1)}{0.0.0.0:15047}" daemon prio=3 tid=699 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.Net.accept(Native Method)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.implAccept(ServerSocketChannelImpl.java:425)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:391)
        at app//org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at app//org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"timer0" daemon prio=5 tid=951 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=53 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp532734552-645" daemon prio=5 tid=645 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-ContainerReplicationThread-1" daemon prio=5 tid=1188 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.PriorityBlockingQueue.take(PriorityBlockingQueue.java:535)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"pool-150-thread-1" daemon prio=5 tid=768 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 5 on default port 15001" daemon prio=5 tid=165 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 1 on default port 15002" daemon prio=5 tid=261 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp907063731-589" daemon prio=5 tid=589 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 23 on default port 15009" daemon prio=5 tid=496 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=597 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:141)
        at app//org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at app//org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"IPC Server handler 11 on default port 15000" daemon prio=5 tid=71 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp114325689-700" daemon prio=5 tid=700 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Connector-Scheduler-2280c0f5-1"  prio=5 tid=964 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp532734552-646" daemon prio=5 tid=646 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-ChunkWriter-3-0" daemon prio=5 tid=774 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 95 on default port 15009" daemon prio=5 tid=568 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"55857a12-8529-4f00-ab69-b96d955e4226-DatanodeReportManager-3" daemon prio=5 tid=716 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-ChunkWriter-3-0" daemon prio=5 tid=736 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"55857a12-8529-4f00-ab69-b96d955e4226-BlockDeletingService#0" daemon prio=5 tid=816 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 13 on default port 15000" daemon prio=5 tid=73 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-SegmentedRaftLogWorker"  prio=5 tid=1157 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$1129/0x00007f07dc7152a0.run(Unknown Source)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Socket Reader #1 for port 15009"  prio=5 tid=446 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"55857a12-8529-4f00-ab69-b96d955e4226-DatanodeReportManager-0" daemon prio=5 tid=713 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"CompactionDagPruningService" daemon prio=5 tid=376 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 97 on default port 15001" daemon prio=5 tid=257 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Session-HouseKeeper-1eb52131-1"  prio=5 tid=372 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 25 on default port 15002" daemon prio=5 tid=285 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 44 on default port 15009" daemon prio=5 tid=517 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 5 on default port 15009" daemon prio=5 tid=478 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 18 on default port 15000" daemon prio=5 tid=78 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 66 on default port 15002" daemon prio=5 tid=326 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 92 on default port 15009" daemon prio=5 tid=565 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp907063731-590" daemon prio=5 tid=590 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Parameter Sending Thread for 0.0.0.0/0.0.0.0:15002" daemon prio=5 tid=724 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferQueue.transfer(SynchronousQueue.java:704)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at app//org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1105)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-DatanodeStateMachineTaskThread-0"  prio=5 tid=663 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 8 on default port 15002" daemon prio=5 tid=268 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 53 on default port 15001" daemon prio=5 tid=213 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 13 on default port 15002" daemon prio=5 tid=273 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 4 on default port 15009" daemon prio=5 tid=477 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 45 on default port 15009" daemon prio=5 tid=518 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerMetadataScanner" daemon prio=5 tid=769 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server handler 57 on default port 15000" daemon prio=5 tid=117 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15012"  prio=5 tid=595 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"qtp532734552-642" daemon prio=5 tid=642 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$787/0x00007f07dc53d0d0.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp892107577-669" daemon prio=5 tid=669 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at app//org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at app//org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at app//org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at app//org.eclipse.jetty.io.ManagedSelector$$Lambda$787/0x00007f07dc53d0d0.run(Unknown Source)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-DatanodeReportManager-3" daemon prio=5 tid=632 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server Responder" daemon prio=5 tid=47 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:141)
        at app//org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at app//org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-CommandProcessorThread" daemon prio=5 tid=606 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:684)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1628/0x00007f07dcc26278.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 62 on default port 15002" daemon prio=5 tid=322 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 14 on default port 15002" daemon prio=5 tid=274 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"derby.rawStoreDaemon" daemon prio=5 tid=438 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.rest(Unknown Source)
        at app//org.apache.derby.impl.services.daemon.BasicDaemon.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"grpc-default-worker-ELG-3-4" daemon prio=5 tid=865 runnable
java.lang.Thread.State: RUNNABLE
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:312)
        at app//org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:376)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at app//org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at app//org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 98 on default port 15001" daemon prio=5 tid=258 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 67 on default port 15000" daemon prio=5 tid=127 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 31 on default port 15000" daemon prio=5 tid=91 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"timer5" daemon prio=5 tid=946 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"qtp66611632-615-acceptor-0@7b5b43c-ServerConnector@34ee9000{HTTP/1.1, (http/1.1)}{0.0.0.0:15020}" daemon prio=3 tid=615 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.Net.accept(Native Method)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.implAccept(ServerSocketChannelImpl.java:425)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:391)
        at app//org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at app//org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 99 on default port 15000" daemon prio=5 tid=159 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 77 on default port 15000" daemon prio=5 tid=137 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-server-thread3" daemon prio=5 tid=1276 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"timer6" daemon prio=5 tid=949 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"IPC Server handler 22 on default port 15001" daemon prio=5 tid=182 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 76 on default port 15000" daemon prio=5 tid=136 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 58 on default port 15000" daemon prio=5 tid=118 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-server-thread2" daemon prio=5 tid=1273 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"PartialTableCache-Cleanup-0" daemon prio=5 tid=944 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 68 on default port 15009" daemon prio=5 tid=541 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-ChunkWriter-1-0" daemon prio=5 tid=734 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 42 on default port 15000" daemon prio=5 tid=102 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 17 on default port 15004" daemon prio=5 tid=433 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp66611632-617" daemon prio=5 tid=617 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-DatanodeReportManager-2" daemon prio=5 tid=659 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 64 on default port 15000" daemon prio=5 tid=124 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-server-thread2" daemon prio=5 tid=1275 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 21 on default port 15001" daemon prio=5 tid=181 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"55857a12-8529-4f00-ab69-b96d955e4226-ChunkWriter-2-0" daemon prio=5 tid=812 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 54 on default port 15002" daemon prio=5 tid=314 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 18 on default port 15002" daemon prio=5 tid=278 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 57 on default port 15002" daemon prio=5 tid=317 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server idle connection scanner for port 15009" daemon prio=5 tid=447 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"IPC Server handler 91 on default port 15009" daemon prio=5 tid=564 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 30 on default port 15002" daemon prio=5 tid=290 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 1 on default port 15004" daemon prio=5 tid=417 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp114325689-702" daemon prio=5 tid=702 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-groupManagement"  prio=5 tid=832 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=387 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Parameter Sending Thread for 0.0.0.0/0.0.0.0:15009" daemon prio=5 tid=726 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferQueue.transfer(SynchronousQueue.java:704)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at app//org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1105)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-PipelineCommandHandlerThread-0"  prio=5 tid=869 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 63 on default port 15009" daemon prio=5 tid=536 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"surefire-forkedjvm-ping-30s" daemon prio=5 tid=15 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 12 on default port 15001" daemon prio=5 tid=172 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 35 on default port 15001" daemon prio=5 tid=195 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 58 on default port 15009" daemon prio=5 tid=531 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-executor-5" daemon prio=5 tid=1080 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"SSL Certificates Store Monitor" daemon prio=5 tid=443 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.lang.Object.wait(Object.java:338)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:537)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"qtp532734552-648" daemon prio=5 tid=648 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"om1@group-C5BA1605619E-StateMachineUpdater" daemon prio=5 tid=392 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1759)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at app//org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Recon-EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=829 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 61 on default port 15009" daemon prio=5 tid=534 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=759 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 72 on default port 15001" daemon prio=5 tid=232 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-ChunkWriter-1-0" daemon prio=5 tid=792 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 33 on default port 15001" daemon prio=5 tid=193 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 98 on default port 15002" daemon prio=5 tid=358 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 65 on default port 15002" daemon prio=5 tid=325 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 65 on default port 15000" daemon prio=5 tid=125 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server listener on 15001" daemon prio=5 tid=39 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 56 on default port 15001" daemon prio=5 tid=216 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Session-HouseKeeper-2f5185ec-1"  prio=5 tid=468 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-BlockDeletingService#0" daemon prio=5 tid=758 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 86 on default port 15002" daemon prio=5 tid=346 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 23 on default port 15000" daemon prio=5 tid=83 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 7 on default port 15002" daemon prio=5 tid=267 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 62 on default port 15001" daemon prio=5 tid=222 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-115-thread-1"  prio=5 tid=584 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp892107577-672" daemon prio=5 tid=672 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=598 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp1715823878-371" daemon prio=5 tid=371 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"grpc-default-executor-2" daemon prio=5 tid=870 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-ChunkWriter-3-0" daemon prio=5 tid=755 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 90 on default port 15000" daemon prio=5 tid=150 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 13 on default port 15001" daemon prio=5 tid=173 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 72 on default port 15002" daemon prio=5 tid=332 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1026273299-462-acceptor-0@559e9aa-ServerConnector@2280c0f5{HTTP/1.1, (http/1.1)}{0.0.0.0:15008}" daemon prio=3 tid=462 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.Net.accept(Native Method)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.implAccept(ServerSocketChannelImpl.java:425)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:391)
        at app//org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at app//org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 9 on default port 15004" daemon prio=5 tid=425 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 46 on default port 15009" daemon prio=5 tid=519 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 49 on default port 15009" daemon prio=5 tid=522 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 36 on default port 15002" daemon prio=5 tid=296 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=818 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 78 on default port 15009" daemon prio=5 tid=551 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 68 on default port 15000" daemon prio=5 tid=128 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"process reaper" daemon prio=10 tid=16 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 81 on default port 15002" daemon prio=5 tid=341 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 46 on default port 15001" daemon prio=5 tid=206 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15030" daemon prio=5 tid=655 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 28 on default port 15000" daemon prio=5 tid=88 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp532734552-643-acceptor-0@177f6bfe-ServerConnector@49b6b53{HTTP/1.1, (http/1.1)}{0.0.0.0:15029}" daemon prio=3 tid=643 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.Net.accept(Native Method)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.implAccept(ServerSocketChannelImpl.java:425)
        at java.base@17.0.11/sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:391)
        at app//org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at app//org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 4 on default port 15000" daemon prio=5 tid=64 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule" daemon prio=5 tid=824 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"ContainerHealthTask" daemon prio=5 tid=577 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.recon.fsck.ContainerHealthTask.run(ContainerHealthTask.java:111)
        at app//org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda$1538/0x00007f07dcbcf588.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"om1-SstFilteringService#0" daemon prio=5 tid=402 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 74 on default port 15001" daemon prio=5 tid=234 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 61 on default port 15002" daemon prio=5 tid=321 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 50 on default port 15002" daemon prio=5 tid=310 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 79 on default port 15002" daemon prio=5 tid=339 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=448 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:141)
        at app//org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at app//org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"SCMHeartbeatProcessor-0" daemon prio=5 tid=444 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderStateImpl" daemon prio=5 tid=1185 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at app//org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:762)
"IPC Server handler 51 on default port 15001" daemon prio=5 tid=211 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1715823878-367" daemon prio=5 tid=367 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp892107577-673" daemon prio=5 tid=673 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-DatanodeReportManager-1" daemon prio=5 tid=602 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server listener on 15000" daemon prio=5 tid=44 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 99 on default port 15001" daemon prio=5 tid=259 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 37 on default port 15002" daemon prio=5 tid=297 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp862366104-414" daemon prio=5 tid=414 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at app//org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.reservedWait(ReservedThreadExecutor.java:324)
        at app//org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:399)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 29 on default port 15001" daemon prio=5 tid=189 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-DatanodeReportManager-3" daemon prio=5 tid=660 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 88 on default port 15001" daemon prio=5 tid=248 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-server-thread1" daemon prio=5 tid=1274 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:401)
        at java.base@17.0.11/java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:903)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1061)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 26 on default port 15009" daemon prio=5 tid=499 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 25 on default port 15000" daemon prio=5 tid=85 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=778 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 70 on default port 15009" daemon prio=5 tid=543 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 99 on default port 15002" daemon prio=5 tid=359 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-ChunkWriter-2-0" daemon prio=5 tid=773 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 41 on default port 15002" daemon prio=5 tid=301 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"prometheus" daemon prio=5 tid=373 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.lang.Object.wait(Object.java:338)
        at app//org.apache.hadoop.metrics2.impl.SinkQueue.waitForData(SinkQueue.java:114)
        at app//org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:83)
        at app//org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:135)
        at app//org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:89)
"FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=54 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 63 on default port 15000" daemon prio=5 tid=123 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 85 on default port 15001" daemon prio=5 tid=245 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-CommandProcessorThread" daemon prio=5 tid=662 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:684)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1628/0x00007f07dcc26278.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-SegmentedRaftLogWorker"  prio=5 tid=1250 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at app//org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$1129/0x00007f07dc7152a0.run(Unknown Source)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1279 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 89 on default port 15000" daemon prio=5 tid=149 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=454 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-DatanodeReportManager-0" daemon prio=5 tid=685 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp907063731-592" daemon prio=5 tid=592 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 0 on default port 15048" daemon prio=5 tid=711 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-ReplicationContainerReader-2" daemon prio=5 tid=1108 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 31 on default port 15002" daemon prio=5 tid=291 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 27 on default port 15002" daemon prio=5 tid=287 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 58 on default port 15001" daemon prio=5 tid=218 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 2 on default port 15002" daemon prio=5 tid=262 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp892107577-674" daemon prio=5 tid=674 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"qtp892107577-676" daemon prio=5 tid=676 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 34 on default port 15001" daemon prio=5 tid=194 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15001"  prio=5 tid=40 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"ContainerMetadataScanner" daemon prio=5 tid=789 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at app//org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-ChunkWriter-2-0" daemon prio=5 tid=754 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:485)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:673)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"RatisPipelineUtilsThread-0"  prio=5 tid=26 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at app//org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.run(BackgroundPipelineCreator.java:179)
        at app//org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator$$Lambda$662/0x00007f07dc3a2fd0.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299->076ccc74-63d1-410b-8584-7a1d80cfc8c8-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=1270 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1759)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at app//org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:286)
        at app//org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:254)
        at app//org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:80)
        at app//org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1859/0x00007f07dcd6aec8.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 0 on default port 15000" daemon prio=5 tid=60 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 64 on default port 15002" daemon prio=5 tid=324 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 80 on default port 15009" daemon prio=5 tid=553 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 14 on default port 15004" daemon prio=5 tid=430 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 12 on default port 15002" daemon prio=5 tid=272 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server listener on 15004" daemon prio=5 tid=383 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@66f02ece" daemon prio=5 tid=583 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 3 on default port 15004" daemon prio=5 tid=419 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 44 on default port 15002" daemon prio=5 tid=304 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 17 on default port 15009" daemon prio=5 tid=490 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 74 on default port 15002" daemon prio=5 tid=334 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 53 on default port 15000" daemon prio=5 tid=113 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 2 on default port 15009" daemon prio=5 tid=475 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 17 on default port 15001" daemon prio=5 tid=177 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-BlockDeletingService#1" daemon prio=5 tid=761 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-PeriodicHDDSVolumeChecker" daemon prio=5 tid=747 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"ExpiredContainerReplicaOpScrubber" daemon prio=5 tid=28 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at app//org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:107)
        at app//org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$664/0x00007f07dc3a38c8.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 28 on default port 15002" daemon prio=5 tid=288 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 13 on default port 15009" daemon prio=5 tid=486 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 20 on default port 15002" daemon prio=5 tid=280 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=653 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:141)
        at app//org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at app//org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"SCMHeartbeatProcessor-0" daemon prio=5 tid=25 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 24 on default port 15009" daemon prio=5 tid=497 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 21 on default port 15000" daemon prio=5 tid=81 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-167-thread-1"  prio=5 tid=640 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-cacheEviction-AwaitToRun" daemon prio=5 tid=1156 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at app//org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at app//org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 88 on default port 15002" daemon prio=5 tid=348 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15039" daemon prio=5 tid=683 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 52 on default port 15000" daemon prio=5 tid=112 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"PartialTableCache-Cleanup-0" daemon prio=5 tid=945 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"PartialTableCache-Cleanup-0" daemon prio=5 tid=960 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 53 on default port 15002" daemon prio=5 tid=313 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 20 on default port 15000" daemon prio=5 tid=80 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"JvmPauseMonitor6" daemon prio=5 tid=795 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at java.base@17.0.11/java.lang.Thread.sleep(Thread.java:344)
        at java.base@17.0.11/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at app//org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at app//org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at app//org.apache.ratis.util.JvmPauseMonitor$$Lambda$747/0x00007f07dc4e0000.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"390bac8a-0dbf-4715-b6fd-0c75abb5c43b-groupManagement"  prio=5 tid=854 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 29 on default port 15009" daemon prio=5 tid=502 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1277 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 22 on default port 15002" daemon prio=5 tid=282 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 88 on default port 15009" daemon prio=5 tid=561 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp66611632-620" daemon prio=5 tid=620 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at app//org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at app//org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"Timer-1" daemon prio=5 tid=437 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.lang.Object.wait(Object.java:338)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:537)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"IPC Client (1377194794) connection to localhost/127.0.0.1:15004 from runner" daemon prio=5 tid=966 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at app//org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1026)
        at app//org.apache.hadoop.ipc.Client$Connection.run(Client.java:1077)
"IPC Server handler 6 on default port 15009" daemon prio=5 tid=479 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-CommandProcessorThread" daemon prio=5 tid=634 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:684)
        at app//org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1628/0x00007f07dcc26278.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"b079985c-91b9-4d2e-8c89-c2e47b34f7da-groupManagement"  prio=5 tid=871 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 43 on default port 15002" daemon prio=5 tid=303 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 96 on default port 15009" daemon prio=5 tid=569 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 69 on default port 15002" daemon prio=5 tid=329 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 6 on default port 15002" daemon prio=5 tid=266 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SnapshotCacheCleanupService" daemon prio=5 tid=377 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=49 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"pool-34-thread-1"  prio=5 tid=363 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 49 on default port 15000" daemon prio=5 tid=109 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 44 on default port 15001" daemon prio=5 tid=204 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 21 on default port 15002" daemon prio=5 tid=281 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1283 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 33 on default port 15009" daemon prio=5 tid=506 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 31 on default port 15001" daemon prio=5 tid=191 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 9 on default port 15000" daemon prio=5 tid=69 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 33 on default port 15000" daemon prio=5 tid=93 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15048"  prio=5 tid=707 runnable
java.lang.Thread.State: RUNNABLE
        at java.base@17.0.11/sun.nio.ch.EPoll.wait(Native Method)
        at java.base@17.0.11/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
        at java.base@17.0.11/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:146)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at app//org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 39 on default port 15000" daemon prio=5 tid=99 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=451 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at app//org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at app//org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.base@17.0.11/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
        at java.base@17.0.11/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 3 on default port 15000" daemon prio=5 tid=63 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 52 on default port 15002" daemon prio=5 tid=312 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 47 on default port 15009" daemon prio=5 tid=520 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 92 on default port 15000" daemon prio=5 tid=152 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 70 on default port 15002" daemon prio=5 tid=330 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 69 on default port 15009" daemon prio=5 tid=542 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"55857a12-8529-4f00-ab69-b96d955e4226-DatanodeReportManager-1" daemon prio=5 tid=714 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 80 on default port 15000" daemon prio=5 tid=140 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"076ccc74-63d1-410b-8584-7a1d80cfc8c8-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=744 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 11 on default port 15009" daemon prio=5 tid=484 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 5 on default port 15004" daemon prio=5 tid=421 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"OverReplicatedProcessor" daemon prio=5 tid=31 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at app//org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:174)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 4 on default port 15002" daemon prio=5 tid=264 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15001" daemon prio=5 tid=160 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 5 on default port 15000" daemon prio=5 tid=65 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"timer2" daemon prio=5 tid=924 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=740 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server idle connection scanner for port 15004" daemon prio=5 tid=385 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Object.wait(Native Method)
        at java.base@17.0.11/java.util.TimerThread.mainLoop(Timer.java:563)
        at java.base@17.0.11/java.util.TimerThread.run(Timer.java:516)
"JvmPauseMonitor2" daemon prio=5 tid=578 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/java.lang.Thread.sleep(Native Method)
        at java.base@17.0.11/java.lang.Thread.sleep(Thread.java:344)
        at java.base@17.0.11/java.util.concurrent.TimeUnit.sleep(TimeUnit.java:446)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at app//org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at app//org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at app//org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at app//org.apache.ratis.util.JvmPauseMonitor$$Lambda$747/0x00007f07dc4e0000.run(Unknown Source)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)
"IPC Server handler 27 on default port 15009" daemon prio=5 tid=500 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 1 on default port 15001" daemon prio=5 tid=161 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 18 on default port 15001" daemon prio=5 tid=178 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1674)
        at java.base@17.0.11/java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:460)
        at app//org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at app//org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"2fad9ecd-4424-4a8b-880f-fd93cda6f409-DatanodeReportManager-2" daemon prio=5 tid=603 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.base@17.0.11/jdk.internal.misc.Unsafe.park(Native Method)
        at java.base@17.0.11/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3465)
        at java.base@17.0.11/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3436)
        at java.base@17.0.11/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1625)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1177)
        at java.base@17.0.11/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
        at java.base@17.0.11/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base@17.0.11/java.lang.Thread.run(Thread.java:840)

2024-05-31 20:35:22,532 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:addNewContainer(246)) - Successfully added container #2 to Recon.
2024-05-31 20:35:22,533 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 9 millisec, 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1), {type: ICR, size: 1}
Connecting to Recon: http://0.0.0.0:15008/api/v1/triggerdbsync/om ...
2024-05-31 20:35:22,557 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:22,557 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:22,557 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-05-31 20:35:22,577 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 2, SequenceNumber diff: 7, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:22,578 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 7 records
2024-05-31 20:35:22,628 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:22,628 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:22,628 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:22,628 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:22,628 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:22,629 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:22,629 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:23,198 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-05-31 20:35:23,561 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-05-31 20:35:23,562 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-05-31 20:35:23,562 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-05-31 20:35:23,562 [main] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/data-0/hdds) is shutting down. 
2024-05-31 20:35:23,562 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-05-31 20:35:23,562 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/data-0/hdds, DS-5b762a84-e74e-40ce-be1b-cce11c1437d3) exiting.
2024-05-31 20:35:23,562 [main] INFO  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:shutdownScanner(206)) - On-demand container scanner is shutting down.
2024-05-31 20:35:23,568 [main] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(416)) - 55857a12-8529-4f00-ab69-b96d955e4226: close
2024-05-31 20:35:23,569 [55857a12-8529-4f00-ab69-b96d955e4226-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299: shutdown
2024-05-31 20:35:23,569 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 55857a12-8529-4f00-ab69-b96d955e4226: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-05-31 20:35:23,569 [55857a12-8529-4f00-ab69-b96d955e4226-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C: shutdown
2024-05-31 20:35:23,569 [55857a12-8529-4f00-ab69-b96d955e4226-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-2C253653B299,id=55857a12-8529-4f00-ab69-b96d955e4226
2024-05-31 20:35:23,569 [55857a12-8529-4f00-ab69-b96d955e4226-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 55857a12-8529-4f00-ab69-b96d955e4226: shutdown 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-LeaderStateImpl
2024-05-31 20:35:23,569 [55857a12-8529-4f00-ab69-b96d955e4226-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-AC6BA249094C,id=55857a12-8529-4f00-ab69-b96d955e4226
2024-05-31 20:35:23,570 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299->390bac8a-0dbf-4715-b6fd-0c75abb5c43b-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299->390bac8a-0dbf-4715-b6fd-0c75abb5c43b-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-05-31 20:35:23,570 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299->076ccc74-63d1-410b-8584-7a1d80cfc8c8-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299->076ccc74-63d1-410b-8584-7a1d80cfc8c8-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-05-31 20:35:23,570 [55857a12-8529-4f00-ab69-b96d955e4226-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-PendingRequests: sendNotLeaderResponses
2024-05-31 20:35:23,571 [55857a12-8529-4f00-ab69-b96d955e4226-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-StateMachineUpdater: set stopIndex = 0
2024-05-31 20:35:23,572 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: Completed APPEND_ENTRIES, lastRequest: 55857a12-8529-4f00-ab69-b96d955e4226->076ccc74-63d1-410b-8584-7a1d80cfc8c8#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "076ccc74-63d1-410b-8584-7a1d80cfc8c8"
address: "127.0.0.1:15025"
dataStreamAddress: "127.0.0.1:15026"
clientAddress: "127.0.0.1:15023"
adminAddress: "127.0.0.1:15024"
startupRole: FOLLOWER
,id: "55857a12-8529-4f00-ab69-b96d955e4226"
address: "127.0.0.1:15052"
priority: 1
dataStreamAddress: "127.0.0.1:15053"
clientAddress: "127.0.0.1:15050"
adminAddress: "127.0.0.1:15051"
startupRole: FOLLOWER
,id: "390bac8a-0dbf-4715-b6fd-0c75abb5c43b"
address: "127.0.0.1:15034"
dataStreamAddress: "127.0.0.1:15035"
clientAddress: "127.0.0.1:15032"
adminAddress: "127.0.0.1:15033"
startupRole: FOLLOWER
, old:)
2024-05-31 20:35:23,572 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: Completed APPEND_ENTRIES, lastReply: null
2024-05-31 20:35:23,572 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: Completed APPEND_ENTRIES, lastRequest: 55857a12-8529-4f00-ab69-b96d955e4226->390bac8a-0dbf-4715-b6fd-0c75abb5c43b#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "076ccc74-63d1-410b-8584-7a1d80cfc8c8"
address: "127.0.0.1:15025"
dataStreamAddress: "127.0.0.1:15026"
clientAddress: "127.0.0.1:15023"
adminAddress: "127.0.0.1:15024"
startupRole: FOLLOWER
,id: "55857a12-8529-4f00-ab69-b96d955e4226"
address: "127.0.0.1:15052"
priority: 1
dataStreamAddress: "127.0.0.1:15053"
clientAddress: "127.0.0.1:15050"
adminAddress: "127.0.0.1:15051"
startupRole: FOLLOWER
,id: "390bac8a-0dbf-4715-b6fd-0c75abb5c43b"
address: "127.0.0.1:15034"
dataStreamAddress: "127.0.0.1:15035"
clientAddress: "127.0.0.1:15032"
adminAddress: "127.0.0.1:15033"
startupRole: FOLLOWER
, old:)
2024-05-31 20:35:23,572 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: Completed APPEND_ENTRIES, lastReply: null
2024-05-31 20:35:23,572 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299->076ccc74-63d1-410b-8584-7a1d80cfc8c8-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-05-31 20:35:23,573 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-2C253653B299: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299/sm/snapshot.1_0
2024-05-31 20:35:23,570 [55857a12-8529-4f00-ab69-b96d955e4226-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 55857a12-8529-4f00-ab69-b96d955e4226: shutdown 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-LeaderStateImpl
2024-05-31 20:35:23,574 [55857a12-8529-4f00-ab69-b96d955e4226-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-PendingRequests: sendNotLeaderResponses
2024-05-31 20:35:23,574 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-2C253653B299: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299/sm/snapshot.1_0 took: 1 ms
2024-05-31 20:35:23,574 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-StateMachineUpdater: Took a snapshot at index 0
2024-05-31 20:35:23,574 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-05-31 20:35:23,575 [55857a12-8529-4f00-ab69-b96d955e4226-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299: applyIndex: 0
2024-05-31 20:35:23,575 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: Completed APPEND_ENTRIES, lastRequest: null
2024-05-31 20:35:23,575 [55857a12-8529-4f00-ab69-b96d955e4226-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-StateMachineUpdater: set stopIndex = 3
2024-05-31 20:35:23,575 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "55857a12-8529-4f00-ab69-b96d955e4226"
  replyId: "390bac8a-0dbf-4715-b6fd-0c75abb5c43b"
  raftGroupId {
    id: "\250\255\215 \227\311@z\237\264,%6S\262\231"
  }
  callId: 13
  success: true
}
term: 1
nextIndex: 1
matchIndex: 18446744073709551615
isHearbeat: true

2024-05-31 20:35:23,575 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: Completed APPEND_ENTRIES, lastRequest: null
2024-05-31 20:35:23,575 [55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-05-31 20:35:23,576 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-AC6BA249094C: Taking a snapshot at:(t:1, i:3) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/2377c6a9-74bd-4894-88f5-ac6ba249094c/sm/snapshot.1_3
2024-05-31 20:35:23,577 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-AC6BA249094C: Finished taking a snapshot at:(t:1, i:3) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/2377c6a9-74bd-4894-88f5-ac6ba249094c/sm/snapshot.1_3 took: 1 ms
2024-05-31 20:35:23,577 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-StateMachineUpdater: Took a snapshot at index 3
2024-05-31 20:35:23,577 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 3
2024-05-31 20:35:23,577 [55857a12-8529-4f00-ab69-b96d955e4226-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C: applyIndex: 3
2024-05-31 20:35:23,577 [55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-05-31 20:35:23,578 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299->390bac8a-0dbf-4715-b6fd-0c75abb5c43b-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-05-31 20:35:23,577 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "55857a12-8529-4f00-ab69-b96d955e4226"
  replyId: "076ccc74-63d1-410b-8584-7a1d80cfc8c8"
  raftGroupId {
    id: "\250\255\215 \227\311@z\237\264,%6S\262\231"
  }
  callId: 12
  success: true
}
term: 1
nextIndex: 1
matchIndex: 18446744073709551615
isHearbeat: true

2024-05-31 20:35:23,578 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299->076ccc74-63d1-410b-8584-7a1d80cfc8c8-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-05-31 20:35:23,582 [Thread-1028] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8 Close channels
2024-05-31 20:35:23,582 [Thread-1030] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b Close channels
2024-05-31 20:35:23,583 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299->390bac8a-0dbf-4715-b6fd-0c75abb5c43b-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-05-31 20:35:23,583 [grpc-default-executor-1] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(226)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299->390bac8a-0dbf-4715-b6fd-0c75abb5c43b-GrpcLogAppender: Failed to getClient for 390bac8a-0dbf-4715-b6fd-0c75abb5c43b
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 55857a12-8529-4f00-ab69-b96d955e4226 is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:65)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:114)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:196)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:201)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$800(GrpcLogAppender.java:62)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:547)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:479)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:567)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:71)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:735)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:716)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
2024-05-31 20:35:23,586 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 55857a12-8529-4f00-ab69-b96d955e4226: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-05-31 20:35:23,587 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 55857a12-8529-4f00-ab69-b96d955e4226: shutdown server GrpcServerProtocolService now
2024-05-31 20:35:23,594 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 55857a12-8529-4f00-ab69-b96d955e4226: shutdown server GrpcServerProtocolService successfully
2024-05-31 20:35:23,594 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 55857a12-8529-4f00-ab69-b96d955e4226: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-05-31 20:35:23,595 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 55857a12-8529-4f00-ab69-b96d955e4226: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-05-31 20:35:23,602 [55857a12-8529-4f00-ab69-b96d955e4226-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9322d365, L:/0.0.0.0:15053] CLOSE
2024-05-31 20:35:23,602 [55857a12-8529-4f00-ab69-b96d955e4226-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9322d365, L:/0.0.0.0:15053] INACTIVE
2024-05-31 20:35:23,602 [55857a12-8529-4f00-ab69-b96d955e4226-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9322d365, L:/0.0.0.0:15053] UNREGISTERED
2024-05-31 20:35:23,631 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:23,631 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:23,631 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:23,631 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:23,631 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:23,631 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:23,631 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:23,689 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:23,689 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:23,689 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-05-31 20:35:23,691 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:23,691 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:24,199 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-05-31 20:35:24,438 [55857a12-8529-4f00-ab69-b96d955e4226-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299-SegmentedRaftLogWorker close()
2024-05-31 20:35:24,524 [55857a12-8529-4f00-ab69-b96d955e4226-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C-SegmentedRaftLogWorker close()
2024-05-31 20:35:24,525 [JvmPauseMonitor7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-55857a12-8529-4f00-ab69-b96d955e4226: Stopped
2024-05-31 20:35:24,634 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:24,634 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:24,635 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:24,635 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:24,635 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:24,635 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:24,635 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:24,692 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:24,692 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:24,692 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-05-31 20:35:24,694 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:24,694 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:25,199 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-05-31 20:35:25,637 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:25,638 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:25,638 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:25,638 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:25,638 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:25,638 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:25,638 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:25,696 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:25,696 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:25,696 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-05-31 20:35:25,697 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:25,698 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:26,200 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-05-31 20:35:26,534 [main] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-8d549ed5-de89-43e1-898f-9aeb04fe8d8b/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-2ee1248f-f02f-4ff8-a917-5c5458f58215/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-cf1e182a-4d8d-4e20-b089-121cd677328f/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-bb861fdb-1577-4261-bac7-37897f3298f1/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-5b762a84-e74e-40ce-be1b-cce11c1437d3/container.db]
2024-05-31 20:35:26,539 [main] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-5b762a84-e74e-40ce-be1b-cce11c1437d3/container.db from cache
2024-05-31 20:35:26,539 [main] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(470)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-5b762a84-e74e-40ce-be1b-cce11c1437d3/container.db for volume DS-5b762a84-e74e-40ce-be1b-cce11c1437d3
2024-05-31 20:35:26,539 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-05-31 20:35:26,542 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-05-31 20:35:26,543 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(638)) - Ozone container server stopped.
2024-05-31 20:35:26,546 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@372f64d1{hddsDatanode,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode}
2024-05-31 20:35:26,547 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@67aa514a{HTTP/1.1, (http/1.1)}{0.0.0.0:15047}
2024-05-31 20:35:26,548 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-05-31 20:35:26,548 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@23e2bcbe{static,/static,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/static,STOPPED}
2024-05-31 20:35:26,548 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@6b3abb75{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-05-31 20:35:26,549 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-05-31 20:35:26,549 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15048
2024-05-31 20:35:26,550 [IPC Server listener on 15048] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15048
2024-05-31 20:35:26,550 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-05-31 20:35:26,551 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:26,590 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299, PipelineID=2377c6a9-74bd-4894-88f5-ac6ba249094c]
2024-05-31 20:35:26,590 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=81e6b01c-7968-4b55-acde-dd6f8777dcc0, PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299, PipelineID=2377c6a9-74bd-4894-88f5-ac6ba249094c]
2024-05-31 20:35:26,591 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 moved to CLOSED state
2024-05-31 20:35:26,592 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 moved to CLOSED state
2024-05-31 20:35:26,592 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(484)) - Container #2 closed for pipeline=PipelineID=2377c6a9-74bd-4894-88f5-ac6ba249094c
2024-05-31 20:35:26,592 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #2, current state: CLOSING
2024-05-31 20:35:26,592 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=2377c6a9-74bd-4894-88f5-ac6ba249094c moved to CLOSED state
2024-05-31 20:35:26,593 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(484)) - Container #2 closed for pipeline=PipelineID=2377c6a9-74bd-4894-88f5-ac6ba249094c
2024-05-31 20:35:26,593 [Recon-EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #2, current state: CLOSING
2024-05-31 20:35:26,593 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=2377c6a9-74bd-4894-88f5-ac6ba249094c moved to CLOSED state
2024-05-31 20:35:26,593 [Recon-EventQueue-DatanodeCommandForReconNodeManager] DEBUG scm.ReconNodeManager (ReconNodeManager.java:onMessage(226)) - Ignoring unsupported command closeContainerCommand for Datanode 55857a12-8529-4f00-ab69-b96d955e4226.
2024-05-31 20:35:26,594 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 12 pipelines in house.
2024-05-31 20:35:26,595 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(152)) - Removing invalid pipeline PipelineID=81e6b01c-7968-4b55-acde-dd6f8777dcc0 from Recon.
2024-05-31 20:35:26,596 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 81e6b01c-7968-4b55-acde-dd6f8777dcc0, Nodes: 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1)2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1)b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:b079985c-91b9-4d2e-8c89-c2e47b34f7da, CreationTimestamp2024-05-31T20:34:34.176Z[Etc/UTC]] removed.
2024-05-31 20:35:26,596 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(152)) - Removing invalid pipeline PipelineID=57400ce6-6596-49c1-8fbb-8f8ee659cc7b from Recon.
2024-05-31 20:35:26,597 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 57400ce6-6596-49c1-8fbb-8f8ee659cc7b, Nodes: b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:b079985c-91b9-4d2e-8c89-c2e47b34f7da, CreationTimestamp2024-05-31T20:34:09.093Z[Etc/UTC]] removed.
2024-05-31 20:35:26,597 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(152)) - Removing invalid pipeline PipelineID=e2b2676c-1441-482f-9bbc-9048d00d16ef from Recon.
2024-05-31 20:35:26,597 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: e2b2676c-1441-482f-9bbc-9048d00d16ef, Nodes: 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1)b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1)390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:b079985c-91b9-4d2e-8c89-c2e47b34f7da, CreationTimestamp2024-05-31T20:34:26.177Z[Etc/UTC]] removed.
2024-05-31 20:35:26,597 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(152)) - Removing invalid pipeline PipelineID=c43c2b80-c72a-4420-a2bc-0ead3654c05a from Recon.
2024-05-31 20:35:26,598 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: c43c2b80-c72a-4420-a2bc-0ead3654c05a, Nodes: 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:076ccc74-63d1-410b-8584-7a1d80cfc8c8, CreationTimestamp2024-05-31T20:34:08.938Z[Etc/UTC]] removed.
2024-05-31 20:35:26,598 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(152)) - Removing invalid pipeline PipelineID=aec5ddb5-3d25-444a-adb9-62cabd985b58 from Recon.
2024-05-31 20:35:26,599 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: aec5ddb5-3d25-444a-adb9-62cabd985b58, Nodes: b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1)390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:b079985c-91b9-4d2e-8c89-c2e47b34f7da, CreationTimestamp2024-05-31T20:34:43.177Z[Etc/UTC]] removed.
2024-05-31 20:35:26,599 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(152)) - Removing invalid pipeline PipelineID=0e0510fd-577d-4847-942d-1c3c34dfe8e1 from Recon.
2024-05-31 20:35:26,599 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 0e0510fd-577d-4847-942d-1c3c34dfe8e1, Nodes: 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:2fad9ecd-4424-4a8b-880f-fd93cda6f409, CreationTimestamp2024-05-31T20:34:08.766Z[Etc/UTC]] removed.
2024-05-31 20:35:26,600 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(152)) - Removing invalid pipeline PipelineID=2cc65240-011a-451d-b3ff-9f8ad608864b from Recon.
2024-05-31 20:35:26,600 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 2cc65240-011a-451d-b3ff-9f8ad608864b, Nodes: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:390bac8a-0dbf-4715-b6fd-0c75abb5c43b, CreationTimestamp2024-05-31T20:34:09.016Z[Etc/UTC]] removed.
2024-05-31 20:35:26,601 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(152)) - Removing invalid pipeline PipelineID=9a915894-abff-4e14-8344-4a82ed352a01 from Recon.
2024-05-31 20:35:26,601 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 9a915894-abff-4e14-8344-4a82ed352a01, Nodes: 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:076ccc74-63d1-410b-8584-7a1d80cfc8c8, CreationTimestamp2024-05-31T20:34:09.020Z[Etc/UTC]] removed.
2024-05-31 20:35:26,640 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:26,640 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:26,640 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:26,640 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:26,640 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:26,640 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:26,641 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:26,699 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:26,699 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:26,699 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-05-31 20:35:26,701 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:26,701 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:26,751 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:26,952 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:27,152 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:27,201 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [closeContainerCommand: containerID: 2, pipelineID: PipelineID=2377c6a9-74bd-4894-88f5-ac6ba249094c, force: false] for container ContainerInfo{id=#2, state=CLOSING, stateEnterTime=2024-05-31T20:35:26.591964773Z, pipelineID=PipelineID=2377c6a9-74bd-4894-88f5-ac6ba249094c, owner=omServiceIdDefault} to 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1) with datanode deadline 1717188297201 and scm deadline 1717188327201
2024-05-31 20:35:27,201 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-05-31 20:35:27,352 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:27,553 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:27,643 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:27,643 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:27,643 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:27,643 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:27,643 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:27,643 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:27,643 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:27,703 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:27,703 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:27,703 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-05-31 20:35:27,705 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:27,705 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:27,753 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:27,953 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:28,154 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:28,202 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [closeContainerCommand: containerID: 2, pipelineID: PipelineID=2377c6a9-74bd-4894-88f5-ac6ba249094c, force: false] for container ContainerInfo{id=#2, state=CLOSING, stateEnterTime=2024-05-31T20:35:26.591964773Z, pipelineID=PipelineID=2377c6a9-74bd-4894-88f5-ac6ba249094c, owner=omServiceIdDefault} to 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1) with datanode deadline 1717188298201 and scm deadline 1717188328201
2024-05-31 20:35:28,202 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-05-31 20:35:28,354 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:28,555 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:28,646 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:28,646 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:28,646 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:28,646 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:28,647 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:28,647 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:28,647 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:28,707 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:28,707 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:28,707 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-05-31 20:35:28,709 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:28,709 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:28,755 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:28,914 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5439863400ns, electionTimeout:5043ms
2024-05-31 20:35:28,914 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: shutdown 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-FollowerState
2024-05-31 20:35:28,914 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2024-05-31 20:35:28,914 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-05-31 20:35:28,915 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: start 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19
2024-05-31 20:35:28,915 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299: change Leader from 55857a12-8529-4f00-ab69-b96d955e4226 to null at term 1 for PRE_VOTE
2024-05-31 20:35:28,915 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19 PRE_VOTE round 0: submit vote requests at term 1 for 0: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:35:28,915 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052
2024-05-31 20:35:28,917 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299: receive requestVote(PRE_VOTE, 076ccc74-63d1-410b-8584-7a1d80cfc8c8, group-2C253653B299, 1, (t:1, i:0))
2024-05-31 20:35:28,918 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FOLLOWER: accept PRE_VOTE from 076ccc74-63d1-410b-8584-7a1d80cfc8c8: our priority 0 <= candidate's priority 0
2024-05-31 20:35:28,918 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299 replies to PRE_VOTE vote request: 076ccc74-63d1-410b-8584-7a1d80cfc8c8<-390bac8a-0dbf-4715-b6fd-0c75abb5c43b#0:OK-t1. Peer's state: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299:t1, leader=55857a12-8529-4f00-ab69-b96d955e4226, voted=55857a12-8529-4f00-ab69-b96d955e4226, raftlog=Memoized:390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-SegmentedRaftLog:OPENED:c0, conf=0: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:35:28,923 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(136)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-05-31 20:35:28,923 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19: PRE_VOTE PASSED received 1 response(s) and 1 exception(s):
2024-05-31 20:35:28,923 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 076ccc74-63d1-410b-8584-7a1d80cfc8c8<-390bac8a-0dbf-4715-b6fd-0c75abb5c43b#0:OK-t1
2024-05-31 20:35:28,923 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(136)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-05-31 20:35:28,923 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19 PRE_VOTE round 0: result PASSED
2024-05-31 20:35:28,924 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19 ELECTION round 0: submit vote requests at term 2 for 0: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:35:28,925 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(136)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-05-31 20:35:28,926 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299: receive requestVote(ELECTION, 076ccc74-63d1-410b-8584-7a1d80cfc8c8, group-2C253653B299, 2, (t:1, i:0))
2024-05-31 20:35:28,926 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FOLLOWER: accept ELECTION from 076ccc74-63d1-410b-8584-7a1d80cfc8c8: our priority 0 <= candidate's priority 0
2024-05-31 20:35:28,926 [grpc-default-executor-1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299: change Leader from 55857a12-8529-4f00-ab69-b96d955e4226 to null at term 2 for updateCurrentTerm
2024-05-31 20:35:28,927 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:35:28,927 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FollowerState
2024-05-31 20:35:28,927 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: start 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FollowerState
2024-05-31 20:35:28,927 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FollowerState was interrupted
2024-05-31 20:35:28,928 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299 replies to ELECTION vote request: 076ccc74-63d1-410b-8584-7a1d80cfc8c8<-390bac8a-0dbf-4715-b6fd-0c75abb5c43b#0:OK-t2. Peer's state: 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299:t2, leader=null, voted=076ccc74-63d1-410b-8584-7a1d80cfc8c8, raftlog=Memoized:390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-SegmentedRaftLog:OPENED:c0, conf=0: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:35:28,929 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19: ELECTION PASSED received 1 response(s) and 1 exception(s):
2024-05-31 20:35:28,929 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 076ccc74-63d1-410b-8584-7a1d80cfc8c8<-390bac8a-0dbf-4715-b6fd-0c75abb5c43b#0:OK-t2
2024-05-31 20:35:28,929 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(136)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-05-31 20:35:28,929 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19 ELECTION round 0: result PASSED
2024-05-31 20:35:28,929 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: shutdown 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19
2024-05-31 20:35:28,929 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2024-05-31 20:35:28,929 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-05-31 20:35:28,929 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:35:28,929 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-05-31 20:35:28,930 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-05-31 20:35:28,930 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-05-31 20:35:28,930 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-05-31 20:35:28,930 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-05-31 20:35:28,930 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-05-31 20:35:28,930 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:35:28,930 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-05-31 20:35:28,930 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-05-31 20:35:28,931 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-05-31 20:35:28,931 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:35:28,931 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2024-05-31 20:35:28,931 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0μs (custom)
2024-05-31 20:35:28,931 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-05-31 20:35:28,931 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:35:28,931 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-05-31 20:35:28,931 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-05-31 20:35:28,931 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-05-31 20:35:28,931 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:35:28,931 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-05-31 20:35:28,932 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-05-31 20:35:28,932 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:35:28,932 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1024 (custom)
2024-05-31 20:35:28,932 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0μs (custom)
2024-05-31 20:35:28,932 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-05-31 20:35:28,932 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:35:28,932 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-05-31 20:35:28,932 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-05-31 20:35:28,933 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-05-31 20:35:28,933 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:35:28,933 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-05-31 20:35:28,933 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: start 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderStateImpl
2024-05-31 20:35:28,933 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-2C253653B299 with new leaderId: 076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:35:28,933 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299: change Leader from null to 076ccc74-63d1-410b-8584-7a1d80cfc8c8 at term 2 for becomeLeader, leader elected after 18ms
2024-05-31 20:35:28,934 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(435)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2024-05-31 20:35:28,935 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderElection19] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299: set configuration 1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:35:28,935 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(591)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-SegmentedRaftLogWorker: Rolled log segment from /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299/current/log_inprogress_0 to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299/current/log_0-0
2024-05-31 20:35:28,935 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_1 at position 0
2024-05-31 20:35:28,938 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(121)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299->55857a12-8529-4f00-ab69-b96d955e4226-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-05-31 20:35:28,940 [grpc-default-executor-1] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(217)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299->55857a12-8529-4f00-ab69-b96d955e4226-GrpcLogAppender: Follower failed (request=null, errorCount=1); keep nextIndex (1) unchanged and retry.
2024-05-31 20:35:28,942 [grpc-default-executor-3] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(217)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299->55857a12-8529-4f00-ab69-b96d955e4226-GrpcLogAppender: Follower failed (request=null, errorCount=3); keep nextIndex (2) unchanged and retry.
2024-05-31 20:35:28,944 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-2C253653B299 with new leaderId: 076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:35:28,944 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299: change Leader from null to 076ccc74-63d1-410b-8584-7a1d80cfc8c8 at term 2 for appendEntries, leader elected after 17ms
2024-05-31 20:35:28,944 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299: set configuration 1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null
2024-05-31 20:35:28,944 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299/current/log_inprogress_1
2024-05-31 20:35:28,944 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(435)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2024-05-31 20:35:28,946 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(591)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-SegmentedRaftLogWorker: Rolled log segment from /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299/current/log_inprogress_0 to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299/current/log_0-0
2024-05-31 20:35:28,946 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_1 at position 0
2024-05-31 20:35:28,954 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299/current/log_inprogress_1
2024-05-31 20:35:28,955 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:28,956 [grpc-default-executor-3] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(217)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299->55857a12-8529-4f00-ab69-b96d955e4226-GrpcLogAppender: Follower failed (request=null, errorCount=5); keep nextIndex (3) unchanged and retry.
2024-05-31 20:35:28,957 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 1 >= startIndex == 1
2024-05-31 20:35:29,155 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:29,202 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(682)) - Sending command [closeContainerCommand: containerID: 2, pipelineID: PipelineID=2377c6a9-74bd-4894-88f5-ac6ba249094c, force: false] for container ContainerInfo{id=#2, state=CLOSING, stateEnterTime=2024-05-31T20:35:26.591964773Z, pipelineID=PipelineID=2377c6a9-74bd-4894-88f5-ac6ba249094c, owner=omServiceIdDefault} to 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1) with datanode deadline 1717188299202 and scm deadline 1717188329202
2024-05-31 20:35:29,203 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-05-31 20:35:29,356 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:29,556 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [55857a12-8529-4f00-ab69-b96d955e4226]
2024-05-31 20:35:29,594 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(95)) - A dead datanode is detected. 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1)
2024-05-31 20:35:29,594 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(95)) - A dead datanode is detected. 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1)
2024-05-31 20:35:29,595 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 close command to datanode 076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:35:29,595 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 close command to datanode 390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:35:29,595 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 close command to datanode 55857a12-8529-4f00-ab69-b96d955e4226
2024-05-31 20:35:29,596 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: a8ad8d20-97c9-407a-9fb4-2c253653b299, Nodes: 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:076ccc74-63d1-410b-8584-7a1d80cfc8c8, CreationTimestamp2024-05-31T20:34:52.176Z[Etc/UTC]] removed.
2024-05-31 20:35:29,596 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 2377c6a9-74bd-4894-88f5-ac6ba249094c, Nodes: 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:55857a12-8529-4f00-ab69-b96d955e4226, CreationTimestamp2024-05-31T20:34:09.177Z[Etc/UTC]] removed.
2024-05-31 20:35:29,596 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: a8ad8d20-97c9-407a-9fb4-2c253653b299, Nodes: 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1)55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:076ccc74-63d1-410b-8584-7a1d80cfc8c8, CreationTimestamp2024-05-31T20:34:52.176Z[Etc/UTC]] removed.
2024-05-31 20:35:29,597 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=2377c6a9-74bd-4894-88f5-ac6ba249094c close command to datanode 55857a12-8529-4f00-ab69-b96d955e4226
2024-05-31 20:35:29,597 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 2377c6a9-74bd-4894-88f5-ac6ba249094c, Nodes: 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:55857a12-8529-4f00-ab69-b96d955e4226, CreationTimestamp2024-05-31T20:34:09.177Z[Etc/UTC]] removed.
2024-05-31 20:35:29,597 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(108)) - Clearing command queue of size 6 for DN 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1)
2024-05-31 20:35:29,597 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(212)) - Removed a node: /default-rack/55857a12-8529-4f00-ab69-b96d955e4226
2024-05-31 20:35:29,598 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(108)) - Clearing command queue of size 0 for DN 55857a12-8529-4f00-ab69-b96d955e4226(localhost/127.0.0.1)
2024-05-31 20:35:29,598 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(212)) - Removed a node: /default-rack/55857a12-8529-4f00-ab69-b96d955e4226
2024-05-31 20:35:29,608 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:generateUnhealthyRecords(483)) - Non-empty container 2 is missing. It has 1 keys and 7 bytes used according to SCM metadata. Please visit Recon's missing container page for a list of keys (and their metadata) mapped to this container.
2024-05-31 20:35:29,610 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	TOTAL_KEYS -> 1 , CONTAINER_COUNT -> 1 , TOTAL_USED_BYTES -> 7 , 
2024-05-31 20:35:29,610 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:29,610 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:29,610 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:29,610 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	TOTAL_KEYS -> 1 , CONTAINER_COUNT -> 1 , TOTAL_USED_BYTES -> 7 , 
2024-05-31 20:35:29,610 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:29,610 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:29,613 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 2 pipelines in house.
2024-05-31 20:35:29,651 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:29,651 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:29,652 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:29,652 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:29,652 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:29,652 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:29,652 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:29,710 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:29,711 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:29,711 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-05-31 20:35:29,712 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:29,712 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-05-31 20:35:29,756 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 0 replicas on []
2024-05-31 20:35:30,203 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-05-31 20:35:30,343 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 is not found
2024-05-31 20:35:30,343 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299. Trying to get from SCM.
2024-05-31 20:35:30,346 [IPC Server handler 14 on default port 15000] INFO  ipc.Server (Server.java:logException(3109)) - IPC Server handler 14 on default port 15000, call Call#1016 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from localhost:51548 / 127.0.0.1:51548
org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 not found
	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:158)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManagerImpl.getPipeline(PipelineStateManagerImpl.java:138)
	at jdk.internal.reflect.GeneratedMethodAccessor25.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeLocal(SCMHAInvocationHandler.java:92)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:75)
	at jdk.proxy2/jdk.proxy2.$Proxy42.getPipeline(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.getPipeline(PipelineManagerImpl.java:335)
	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:761)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:960)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:607)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:89)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:232)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-05-31 20:35:30,354 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] ERROR scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(79)) - Could not find pipeline PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 at SCM.
2024-05-31 20:35:30,354 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] ERROR pipeline.PipelineReportHandler (PipelineReportHandler.java:onMessage(98)) - Could not find pipeline id: "a8ad8d20-97c9-407a-9fb4-2c253653b299"
uuid128 {
  mostSigBits: -6292217933241696134
  leastSigBits: -6938872587534224743
}

2024-05-31 20:35:30,657 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:30,657 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:30,657 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:30,657 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:30,657 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:30,657 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:30,657 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:30,714 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:30,714 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:30,714 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-05-31 20:35:30,716 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-05-31 20:35:30,716 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/MISSING ...
2024-05-31 20:35:30,775 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-05-31 20:35:30,775 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-05-31 20:35:30,775 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-05-31 20:35:30,792 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(240)) - HddsDatanodeService host:fv-az1343-628 ip:10.1.0.26
2024-05-31 20:35:30,806 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-05-31 20:35:30,806 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(299)) - Datanode State Machine Task Thread Pool size 2
2024-05-31 20:35:30,807 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(126)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/data-0/hdds of storage type : DISK capacity : 9222449699674390527
2024-05-31 20:35:30,808 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/data-0/hdds to VolumeSet
2024-05-31 20:35:30,808 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis to VolumeSet
2024-05-31 20:35:30,829 [ForkJoinPool.commonPool-worker-2] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-5b762a84-e74e-40ce-be1b-cce11c1437d3/container.db to cache
2024-05-31 20:35:30,829 [ForkJoinPool.commonPool-worker-2] INFO  volume.HddsVolume (HddsVolume.java:loadDbStore(389)) - SchemaV3 db is loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-5b762a84-e74e-40ce-be1b-cce11c1437d3/container.db for volume DS-5b762a84-e74e-40ce-be1b-cce11c1437d3
2024-05-31 20:35:30,829 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 20ms
2024-05-31 20:35:30,832 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-05-31 20:35:30,832 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-05-31 20:35:30,832 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15051 (custom)
2024-05-31 20:35:30,832 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-05-31 20:35:30,832 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15050 (custom)
2024-05-31 20:35:30,833 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-05-31 20:35:30,833 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15052 (custom)
2024-05-31 20:35:30,833 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-05-31 20:35:30,833 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-05-31 20:35:30,833 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-05-31 20:35:30,833 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:35:30,833 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-05-31 20:35:30,833 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-05-31 20:35:30,834 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-05-31 20:35:30,836 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-05-31 20:35:30,836 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-05-31 20:35:30,836 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-05-31 20:35:30,836 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-05-31 20:35:30,836 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-05-31 20:35:30,836 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-05-31 20:35:30,836 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-05-31 20:35:30,837 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-05-31 20:35:30,837 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 55857a12-8529-4f00-ab69-b96d955e4226-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-05-31 20:35:30,837 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-05-31 20:35:30,837 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 55857a12-8529-4f00-ab69-b96d955e4226-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-05-31 20:35:30,837 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-05-31 20:35:30,838 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-05-31 20:35:30,838 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15053 (custom)
2024-05-31 20:35:30,838 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:35:30,838 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-05-31 20:35:30,838 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:35:30,839 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis] (custom)
2024-05-31 20:35:30,839 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-05-31 20:35:30,839 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-05-31 20:35:30,839 [55857a12-8529-4f00-ab69-b96d955e4226-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xf276ba33] REGISTERED
2024-05-31 20:35:30,839 [55857a12-8529-4f00-ab69-b96d955e4226-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - 55857a12-8529-4f00-ab69-b96d955e4226: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299
2024-05-31 20:35:30,839 [55857a12-8529-4f00-ab69-b96d955e4226-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xf276ba33] BIND: 0.0.0.0/0.0.0.0:15053
2024-05-31 20:35:30,840 [55857a12-8529-4f00-ab69-b96d955e4226-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 55857a12-8529-4f00-ab69-b96d955e4226: addNew group-2C253653B299:[] returns group-2C253653B299:java.util.concurrent.CompletableFuture@42467d91[Not completed]
2024-05-31 20:35:30,840 [55857a12-8529-4f00-ab69-b96d955e4226-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - 55857a12-8529-4f00-ab69-b96d955e4226: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/tmp
2024-05-31 20:35:30,840 [55857a12-8529-4f00-ab69-b96d955e4226-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(269)) - 55857a12-8529-4f00-ab69-b96d955e4226: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/tmp is not a group directory; ignoring it. 
2024-05-31 20:35:30,840 [55857a12-8529-4f00-ab69-b96d955e4226-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - 55857a12-8529-4f00-ab69-b96d955e4226: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/ratis/2377c6a9-74bd-4894-88f5-ac6ba249094c
2024-05-31 20:35:30,840 [55857a12-8529-4f00-ab69-b96d955e4226-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 55857a12-8529-4f00-ab69-b96d955e4226: addNew group-AC6BA249094C:[] returns group-AC6BA249094C:java.util.concurrent.CompletableFuture@4679e101[Not completed]
2024-05-31 20:35:30,840 [55857a12-8529-4f00-ab69-b96d955e4226-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xf276ba33, L:/0.0.0.0:15053] ACTIVE
2024-05-31 20:35:30,840 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-05-31 20:35:30,841 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-05-31 20:35:30,843 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(157)) - Initializing replication supervisor with thread count = 10
2024-05-31 20:35:30,843 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-05-31 20:35:30,846 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 55857a12-8529-4f00-ab69-b96d955e4226: new RaftServerImpl for group-2C253653B299:[] with ContainerStateMachine:uninitialized
2024-05-31 20:35:30,846 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:35:30,846 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-05-31 20:35:30,846 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:35:30,846 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-05-31 20:35:30,847 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:35:30,847 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:35:30,847 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:35:30,847 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-2C253653B299: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:35:30,847 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-05-31 20:35:30,847 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:35:30,847 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-05-31 20:35:30,847 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:35:30,847 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:35:30,847 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:35:30,848 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15047
2024-05-31 20:35:30,849 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-05-31 20:35:30,851 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:35:30,851 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:35:30,851 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:35:30,851 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:35:30,851 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:35:30,851 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:35:30,852 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-05-31 20:35:30,852 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 55857a12-8529-4f00-ab69-b96d955e4226: new RaftServerImpl for group-AC6BA249094C:[] with ContainerStateMachine:uninitialized
2024-05-31 20:35:30,852 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-05-31 20:35:30,852 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-05-31 20:35:30,852 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-05-31 20:35:30,852 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-05-31 20:35:30,853 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-05-31 20:35:30,853 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-05-31 20:35:30,853 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-05-31 20:35:30,853 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 55857a12-8529-4f00-ab69-b96d955e4226@group-AC6BA249094C: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-05-31 20:35:30,853 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-05-31 20:35:30,853 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-05-31 20:35:30,853 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-05-31 20:35:30,853 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-05-31 20:35:30,853 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-05-31 20:35:30,853 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-05-31 20:35:30,855 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-05-31 20:35:30,855 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-05-31 20:35:30,855 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-05-31 20:35:30,855 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-05-31 20:35:30,855 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-05-31 20:35:30,855 [55857a12-8529-4f00-ab69-b96d955e4226-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-05-31 20:35:30,856 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-05-31 20:35:30,857 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-05-31 20:35:30,858 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-05-31 20:35:30,858 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-05-31 20:35:30,859 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-05-31 20:35:30,859 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/meta/webserver
2024-05-31 20:35:30,860 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15047
2024-05-31 20:35:30,860 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 17.0.11+9
2024-05-31 20:35:30,864 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-05-31 20:35:30,864 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-05-31 20:35:30,864 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2024-05-31 20:35:30,865 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@5ea231be{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-05-31 20:35:30,865 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2c28e269{static,/static,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/static,AVAILABLE}
2024-05-31 20:35:30,871 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@7fa817ba{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode}
2024-05-31 20:35:30,872 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@7f7de2d4{HTTP/1.1, (http/1.1)}{0.0.0.0:15047}
2024-05-31 20:35:30,872 [main] INFO  server.Server (Server.java:doStart(415)) - Started @107720ms
2024-05-31 20:35:30,873 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-05-31 20:35:30,873 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15047
2024-05-31 20:35:30,874 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-05-31 20:35:30,874 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15048
2024-05-31 20:35:30,875 [Socket Reader #1 for port 15048] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15048
2024-05-31 20:35:30,880 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(327)) - Datanode start with admins: [runner]
2024-05-31 20:35:30,880 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15048
2024-05-31 20:35:30,880 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-05-31 20:35:30,884 [IPC Server listener on 15048] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15048: starting
2024-05-31 20:35:30,885 [55857a12-8529-4f00-ab69-b96d955e4226-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(555)) - Ozone container server started.
2024-05-31 20:35:30,887 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(396)) - Shutting down the Mini Ozone Cluster
2024-05-31 20:35:30,889 [main] INFO  db.CodecTestUtil (CodecTestUtil.java:gc(50)) - gc 0
2024-05-31 20:35:30,973 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 is not found
2024-05-31 20:35:30,973 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299. Trying to get from SCM.
2024-05-31 20:35:30,974 [55857a12-8529-4f00-ab69-b96d955e4226-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-05-31 20:35:30,984 [IPC Server handler 24 on default port 15000] INFO  ipc.Server (Server.java:logException(3109)) - IPC Server handler 24 on default port 15000, call Call#1025 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from localhost:51548 / 127.0.0.1:51548
org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 not found
	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:158)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManagerImpl.getPipeline(PipelineStateManagerImpl.java:138)
	at jdk.internal.reflect.GeneratedMethodAccessor25.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeLocal(SCMHAInvocationHandler.java:92)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:75)
	at jdk.proxy2/jdk.proxy2.$Proxy42.getPipeline(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.getPipeline(PipelineManagerImpl.java:335)
	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:761)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:960)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:607)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:89)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:232)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-05-31 20:35:30,988 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] WARN  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$1(132)) - Failed to remove group group-2C253653B299 of pipeline PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 on peer 55857a12-8529-4f00-ab69-b96d955e4226
java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:99)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:223)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:170)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:98)
	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:145)
	at org.apache.ratis.client.impl.BlockingImpl.sendRequestWithRetry(BlockingImpl.java:109)
	at org.apache.ratis.client.impl.GroupManagementImpl.remove(GroupManagementImpl.java:61)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$1(ClosePipelineCommandHandler.java:124)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:179)
	at java.base/java.util.HashMap$ValueSpliterator.forEachRemaining(HashMap.java:1779)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:121)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:268)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:249)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:167)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:468)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:172)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:221)
	... 20 more
Caused by: org.apache.ratis.thirdparty.io.netty.channel.AbstractChannel$AnnotatedConnectException: finishConnect(..) failed: Connection refused: /127.0.0.1:15051
Caused by: java.net.ConnectException: finishConnect(..) failed: Connection refused
	at org.apache.ratis.thirdparty.io.netty.channel.unix.Errors.newConnectException0(Errors.java:166)
	at org.apache.ratis.thirdparty.io.netty.channel.unix.Errors.handleConnectErrno(Errors.java:131)
	at org.apache.ratis.thirdparty.io.netty.channel.unix.Socket.finishConnect(Socket.java:359)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.doFinishConnect(AbstractEpollChannel.java:710)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.finishConnect(AbstractEpollChannel.java:687)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.AbstractEpollChannel$AbstractEpollUnsafe.epollOutReady(AbstractEpollChannel.java:567)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:499)
	at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:407)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:840)
2024-05-31 20:35:30,986 [55857a12-8529-4f00-ab69-b96d955e4226-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/meta/datanode.id
2024-05-31 20:35:30,993 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] ERROR scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(79)) - Could not find pipeline PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 at SCM.
2024-05-31 20:35:30,998 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] ERROR pipeline.PipelineReportHandler (PipelineReportHandler.java:onMessage(98)) - Could not find pipeline id: "a8ad8d20-97c9-407a-9fb4-2c253653b299"
uuid128 {
  mostSigBits: -6292217933241696134
  leastSigBits: -6938872587534224743
}

2024-05-31 20:35:31,008 [grpc-default-executor-4] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: remove  FOLLOWER 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299:t2, leader=076ccc74-63d1-410b-8584-7a1d80cfc8c8, voted=076ccc74-63d1-410b-8584-7a1d80cfc8c8, raftlog=Memoized:390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-SegmentedRaftLog:OPENED:c1, conf=1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null RUNNING
2024-05-31 20:35:31,008 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299: shutdown
2024-05-31 20:35:31,008 [grpc-default-executor-4] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-2C253653B299,id=390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:35:31,008 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FollowerState
2024-05-31 20:35:31,008 [grpc-default-executor-4] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-StateMachineUpdater: set stopIndex = 1
2024-05-31 20:35:31,008 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-FollowerState was interrupted
2024-05-31 20:35:31,008 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-2C253653B299: Taking a snapshot at:(t:2, i:1) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299/sm/snapshot.2_1
2024-05-31 20:35:31,009 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-2C253653B299: Finished taking a snapshot at:(t:2, i:1) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299/sm/snapshot.2_1 took: 1 ms
2024-05-31 20:35:31,010 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-StateMachineUpdater: Took a snapshot at index 1
2024-05-31 20:35:31,010 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 1
2024-05-31 20:35:31,010 [grpc-default-executor-4] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299: applyIndex: 1
2024-05-31 20:35:31,010 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-05-31 20:35:31,072 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(412)) - Stopping the Mini Ozone Cluster
2024-05-31 20:35:31,072 [main] INFO  om.OzoneManager (OzoneManager.java:stop(2232)) - om1[localhost:15004]: Stopping Ozone Manager
2024-05-31 20:35:31,073 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15004
2024-05-31 20:35:31,074 [IPC Server listener on 15004] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15004
2024-05-31 20:35:31,074 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-05-31 20:35:31,075 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:stop(594)) - Stopping org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer@649e1f4c at port 15007
2024-05-31 20:35:31,075 [main] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(416)) - om1: close
2024-05-31 20:35:31,075 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - om1: shutdown server GrpcServerProtocolService now
2024-05-31 20:35:31,075 [om1-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - om1@group-C5BA1605619E: shutdown
2024-05-31 20:35:31,075 [om1-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2024-05-31 20:35:31,076 [om1-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - om1: shutdown om1@group-C5BA1605619E-LeaderStateImpl
2024-05-31 20:35:31,076 [om1-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - om1@group-C5BA1605619E-PendingRequests: sendNotLeaderResponses
2024-05-31 20:35:31,076 [om1-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - om1@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 12
2024-05-31 20:35:31,076 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshotImpl(481)) -  applied = (t:1, i:12)
2024-05-31 20:35:31,076 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshotImpl(482)) -  skipped = 11
2024-05-31 20:35:31,076 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshotImpl(483)) - notified = (t:1, i:12)
2024-05-31 20:35:31,076 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshotImpl(484)) - snapshot = (t:1, i:12)
2024-05-31 20:35:31,076 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - om1: shutdown server GrpcServerProtocolService successfully
2024-05-31 20:35:31,098 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - om1@group-C5BA1605619E-StateMachineUpdater: Took a snapshot at index 12
2024-05-31 20:35:31,098 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - om1@group-C5BA1605619E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 12
2024-05-31 20:35:31,099 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(527)) - Stopping OzoneManagerStateMachine:om1:group-C5BA1605619E.
2024-05-31 20:35:31,099 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(517)) - Stopping OMDoubleBuffer flush thread
2024-05-31 20:35:31,099 [om1-OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:canFlush(581)) - OMDoubleBuffer flush thread om1-OMDoubleBufferFlushThread is interrupted and will exit.
2024-05-31 20:35:31,100 [om1-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(427)) - om1@group-C5BA1605619E: applyIndex: 12
2024-05-31 20:35:31,100 [om1@group-C5BA1605619E-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - om1@group-C5BA1605619E-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-05-31 20:35:31,172 [UnderReplicatedProcessor] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:chooseNodeInternal(672)) - No available node in (scope="/" excludedScope="[/default-rack/2fad9ecd-4424-4a8b-880f-fd93cda6f409, /default-rack/390bac8a-0dbf-4715-b6fd-0c75abb5c43b, /default-rack/076ccc74-63d1-410b-8584-7a1d80cfc8c8]" excludedNodes="[390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)]"  ancestorGen="1").
2024-05-31 20:35:31,172 [UnderReplicatedProcessor] WARN  algorithms.SCMContainerPlacementRackAware (SCMContainerPlacementRackAware.java:chooseNode(485)) - Failed to find the datanode for container. excludedNodes:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)], affinityNode:
2024-05-31 20:35:31,173 [UnderReplicatedProcessor] INFO  scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:isValidNode(518)) - Datanode b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1) is not chosen. Required metadata size is 0 and required data size is 5368709120 and NodeStatus is OperationalState: DECOMMISSIONED Health: HEALTHY OperationStateExpiry: 0
2024-05-31 20:35:31,173 [UnderReplicatedProcessor] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:chooseNodeInternal(672)) - No available node in (scope="/" excludedScope="[/default-rack/2fad9ecd-4424-4a8b-880f-fd93cda6f409, /default-rack/390bac8a-0dbf-4715-b6fd-0c75abb5c43b, /default-rack/076ccc74-63d1-410b-8584-7a1d80cfc8c8, /default-rack/b079985c-91b9-4d2e-8c89-c2e47b34f7da]" excludedNodes="[390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)]"  ancestorGen="0").
2024-05-31 20:35:31,173 [UnderReplicatedProcessor] WARN  algorithms.SCMContainerPlacementRackAware (SCMContainerPlacementRackAware.java:chooseNode(485)) - Failed to find the datanode for container. excludedNodes:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)], affinityNode:
2024-05-31 20:35:31,173 [UnderReplicatedProcessor] WARN  replication.RatisUnderReplicationHandler (RatisUnderReplicationHandler.java:processAndSendCommands(136)) - Cannot replicate container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-05-31T20:34:23.864421440Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault} because no suitable targets were found.
2024-05-31 20:35:31,173 [UnderReplicatedProcessor] INFO  replication.RatisUnderReplicationHandler (RatisUnderReplicationHandler.java:removeUnhealthyReplicaIfPossible(264)) - Finding an unhealthy replica to delete for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-05-31T20:34:23.864421440Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault} with replicas [ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), placeOfBirth=076ccc74-63d1-410b-8584-7a1d80cfc8c8, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}, ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), placeOfBirth=2fad9ecd-4424-4a8b-880f-fd93cda6f409, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}, ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), placeOfBirth=390bac8a-0dbf-4715-b6fd-0c75abb5c43b, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}] to unblock under replication handling.
2024-05-31 20:35:31,174 [UnderReplicatedProcessor] INFO  replication.RatisUnderReplicationHandler (RatisUnderReplicationHandler.java:removeUnhealthyReplicaIfPossible(292)) - Unable to find a replica to remove for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-05-31T20:34:23.864421440Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault} with replicas [ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), placeOfBirth=076ccc74-63d1-410b-8584-7a1d80cfc8c8, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}, ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), placeOfBirth=2fad9ecd-4424-4a8b-880f-fd93cda6f409, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}, ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), placeOfBirth=390bac8a-0dbf-4715-b6fd-0c75abb5c43b, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}]
2024-05-31 20:35:31,174 [UnderReplicatedProcessor] ERROR replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(127)) - Error processing Health result of class: class org.apache.hadoop.hdds.scm.container.replication.ContainerHealthResult$UnderReplicatedHealthResult for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-05-31T20:34:23.864421440Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault}
org.apache.hadoop.hdds.scm.exceptions.SCMException: Placement Policy: class org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware did not return any nodes. Number of required Nodes 1, Datasize Required: 5368709120
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManagerUtil.getTargetDatanodes(ReplicationManagerUtil.java:101)
	at org.apache.hadoop.hdds.scm.container.replication.RatisUnderReplicationHandler.getTargets(RatisUnderReplicationHandler.java:457)
	at org.apache.hadoop.hdds.scm.container.replication.RatisUnderReplicationHandler.processAndSendCommands(RatisUnderReplicationHandler.java:130)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processUnderReplicatedContainer(ReplicationManager.java:786)
	at org.apache.hadoop.hdds.scm.container.replication.UnderReplicatedProcessor.sendDatanodeCommands(UnderReplicatedProcessor.java:60)
	at org.apache.hadoop.hdds.scm.container.replication.UnderReplicatedProcessor.sendDatanodeCommands(UnderReplicatedProcessor.java:29)
	at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.processContainer(UnhealthyReplicationProcessor.java:156)
	at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.processAll(UnhealthyReplicationProcessor.java:116)
	at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:165)
	at java.base/java.lang.Thread.run(Thread.java:840)
2024-05-31 20:35:31,174 [UnderReplicatedProcessor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(138)) - Processed 0 containers with health state counts {}, failed processing 1, deferred due to load 0
2024-05-31 20:35:31,204 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-05-31 20:35:31,540 [om1-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker close()
2024-05-31 20:35:31,540 [JvmPauseMonitor1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-om1: Stopped
2024-05-31 20:35:31,540 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service KeyDeletingService
2024-05-31 20:35:31,541 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service DirectoryDeletingService
2024-05-31 20:35:31,541 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service OpenKeyCleanupService
2024-05-31 20:35:31,541 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SstFilteringService
2024-05-31 20:35:31,541 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SnapshotDeletingService
2024-05-31 20:35:31,542 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service MultipartUploadCleanupService
2024-05-31 20:35:31,542 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SnapshotDirectoryCleaningService
2024-05-31 20:35:31,543 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@2027e9f9{ozoneManager,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2024-05-31 20:35:31,543 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@462ccaa8{HTTP/1.1, (http/1.1)}{0.0.0.0:15005}
2024-05-31 20:35:31,543 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-05-31 20:35:31,544 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7b6bcbee{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2024-05-31 20:35:31,544 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7c87c960{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-05-31 20:35:31,545 [main] INFO  rocksdiff.RocksDBCheckpointDiffer (RocksDBCheckpointDiffer.java:close(306)) - Shutting down CompactionDagPruningService.
2024-05-31 20:35:31,547 [main] INFO  snapshot.SnapshotDiffManager (SnapshotDiffManager.java:closeExecutorService(1657)) - Shutting down executorService: 'SnapDiffExecutor'
2024-05-31 20:35:31,547 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SnapshotDiffCleanupService
2024-05-31 20:35:31,548 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(471)) - Stopping the HddsDatanodes
2024-05-31 20:35:31,550 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-05-31 20:35:31,550 [ForkJoinPool.commonPool-worker-1] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-8d549ed5-de89-43e1-898f-9aeb04fe8d8b/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-2ee1248f-f02f-4ff8-a917-5c5458f58215/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-cf1e182a-4d8d-4e20-b089-121cd677328f/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-bb861fdb-1577-4261-bac7-37897f3298f1/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-5b762a84-e74e-40ce-be1b-cce11c1437d3/container.db]
2024-05-31 20:35:31,551 [ForkJoinPool.commonPool-worker-3] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-05-31 20:35:31,551 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-05-31 20:35:31,552 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-05-31 20:35:31,552 [ForkJoinPool.commonPool-worker-3] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/data-0/hdds) is shutting down. 
2024-05-31 20:35:31,553 [ForkJoinPool.commonPool-worker-1] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-5b762a84-e74e-40ce-be1b-cce11c1437d3/container.db from cache
2024-05-31 20:35:31,553 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-05-31 20:35:31,553 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/data-0/hdds, DS-bb861fdb-1577-4261-bac7-37897f3298f1) exiting.
2024-05-31 20:35:31,553 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(470)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-5/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-5b762a84-e74e-40ce-be1b-cce11c1437d3/container.db for volume DS-5b762a84-e74e-40ce-be1b-cce11c1437d3
2024-05-31 20:35:31,554 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-05-31 20:35:31,554 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-05-31 20:35:31,554 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(638)) - Ozone container server stopped.
2024-05-31 20:35:31,555 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-05-31 20:35:31,555 [ForkJoinPool.commonPool-worker-3] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(416)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: close
2024-05-31 20:35:31,555 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-05-31 20:35:31,555 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-05-31 20:35:31,555 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@7fa817ba{hddsDatanode,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode}
2024-05-31 20:35:31,555 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-05-31 20:35:31,555 [main] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/data-0/hdds) is shutting down. 
2024-05-31 20:35:31,556 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-05-31 20:35:31,556 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/data-0/hdds, DS-cf1e182a-4d8d-4e20-b089-121cd677328f) exiting.
2024-05-31 20:35:31,556 [main] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(416)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: close
2024-05-31 20:35:31,556 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@7f7de2d4{HTTP/1.1, (http/1.1)}{0.0.0.0:15047}
2024-05-31 20:35:31,556 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-05-31 20:35:31,557 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2c28e269{static,/static,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/static,STOPPED}
2024-05-31 20:35:31,557 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5ea231be{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-05-31 20:35:31,557 [ForkJoinPool.commonPool-worker-1] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-05-31 20:35:31,557 [ForkJoinPool.commonPool-worker-1] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15048
2024-05-31 20:35:31,557 [IPC Server listener on 15048] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15048
2024-05-31 20:35:31,558 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-05-31 20:35:31,558 [Thread-1186] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8 Close channels
2024-05-31 20:35:31,563 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-05-31 20:35:31,563 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-05-31 20:35:31,563 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-05-31 20:35:31,564 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/data-0/hdds) is shutting down. 
2024-05-31 20:35:31,564 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-05-31 20:35:31,564 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/data-0/hdds, DS-8d549ed5-de89-43e1-898f-9aeb04fe8d8b) exiting.
2024-05-31 20:35:31,564 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(416)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: close
2024-05-31 20:35:31,564 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-05-31 20:35:31,566 [Thread-1188] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 55857a12-8529-4f00-ab69-b96d955e4226 Close channels
2024-05-31 20:35:31,566 [Thread-1190] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b Close channels
2024-05-31 20:35:31,567 [Thread-1191] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409 Close channels
2024-05-31 20:35:31,568 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-05-31 20:35:31,568 [Thread-1193] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8 Close channels
2024-05-31 20:35:31,569 [Thread-1194] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 55857a12-8529-4f00-ab69-b96d955e4226 Close channels
2024-05-31 20:35:31,570 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02: shutdown
2024-05-31 20:35:31,570 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1D0408D68C02,id=390bac8a-0dbf-4715-b6fd-0c75abb5c43b
2024-05-31 20:35:31,571 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-LeaderStateImpl
2024-05-31 20:35:31,571 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-PendingRequests: sendNotLeaderResponses
2024-05-31 20:35:31,572 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-StateMachineUpdater: set stopIndex = 0
2024-05-31 20:35:31,572 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-1D0408D68C02: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/3166dcd9-053f-42c3-b8ea-1d0408d68c02/sm/snapshot.1_0
2024-05-31 20:35:31,572 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-1D0408D68C02: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/3166dcd9-053f-42c3-b8ea-1d0408d68c02/sm/snapshot.1_0 took: 1 ms
2024-05-31 20:35:31,573 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-StateMachineUpdater: Took a snapshot at index 0
2024-05-31 20:35:31,573 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-05-31 20:35:31,573 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02: applyIndex: 0
2024-05-31 20:35:31,573 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-05-31 20:35:31,574 [Thread-1196] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409 Close channels
2024-05-31 20:35:31,574 [Thread-1197] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da Close channels
2024-05-31 20:35:31,575 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-05-31 20:35:31,575 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown server GrpcServerProtocolService now
2024-05-31 20:35:31,576 [Thread-1189] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8 Close channels
2024-05-31 20:35:31,578 [Thread-1200] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b Close channels
2024-05-31 20:35:31,579 [Thread-1199] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 55857a12-8529-4f00-ab69-b96d955e4226 Close channels
2024-05-31 20:35:31,580 [Thread-1202] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da Close channels
2024-05-31 20:35:31,581 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(121)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299->390bac8a-0dbf-4715-b6fd-0c75abb5c43b-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2024-05-31 20:35:31,581 [grpc-default-executor-7] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(121)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: APPEND_ENTRIES onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2024-05-31 20:35:31,581 [grpc-default-executor-5] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(217)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299->390bac8a-0dbf-4715-b6fd-0c75abb5c43b-GrpcLogAppender: Follower failed (request=null, errorCount=1); keep nextIndex (3) unchanged and retry.
2024-05-31 20:35:31,581 [grpc-default-executor-6] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(121)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: APPEND_ENTRIES onError, lastRequest: 076ccc74-63d1-410b-8584-7a1d80cfc8c8->390bac8a-0dbf-4715-b6fd-0c75abb5c43b#2-t2,previous=(t:2, i:1),leaderCommit=1,initializing? false,entries: size=1, first=(t:2, i:2), METADATAENTRY(c:1): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2024-05-31 20:35:31,583 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(533)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF->390bac8a-0dbf-4715-b6fd-0c75abb5c43b-GrpcLogAppender is already stopped
2024-05-31 20:35:31,584 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-05-31 20:35:31,584 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: shutdown server GrpcServerProtocolService now
2024-05-31 20:35:31,584 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown server GrpcServerProtocolService successfully
2024-05-31 20:35:31,584 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-05-31 20:35:31,585 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(533)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da@group-9048D00D16EF->2fad9ecd-4424-4a8b-880f-fd93cda6f409-GrpcLogAppender is already stopped
2024-05-31 20:35:31,586 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: shutdown server GrpcServerProtocolService successfully
2024-05-31 20:35:31,586 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-05-31 20:35:31,586 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: shutdown server GrpcServerProtocolService now
2024-05-31 20:35:31,586 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] WARN  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$1(132)) - Failed to remove group group-2C253653B299 of pipeline PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 on peer 390bac8a-0dbf-4715-b6fd-0c75abb5c43b
java.io.IOException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
	at org.apache.ratis.grpc.GrpcUtil.unwrapException(GrpcUtil.java:99)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:223)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.groupAdd(GrpcClientProtocolClient.java:170)
	at org.apache.ratis.grpc.client.GrpcClientRpc.sendRequest(GrpcClientRpc.java:98)
	at org.apache.ratis.client.impl.BlockingImpl.sendRequest(BlockingImpl.java:145)
	at org.apache.ratis.client.impl.BlockingImpl.sendRequestWithRetry(BlockingImpl.java:109)
	at org.apache.ratis.client.impl.GroupManagementImpl.remove(GroupManagementImpl.java:61)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$1(ClosePipelineCommandHandler.java:124)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:179)
	at java.base/java.util.HashMap$ValueSpliterator.forEachRemaining(HashMap.java:1779)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:121)
	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1804)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:268)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:249)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:167)
	at org.apache.ratis.proto.grpc.AdminProtocolServiceGrpc$AdminProtocolServiceBlockingStub.groupManagement(AdminProtocolServiceGrpc.java:468)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.lambda$groupAdd$5(GrpcClientProtocolClient.java:172)
	at org.apache.ratis.grpc.client.GrpcClientProtocolClient.blockingCall(GrpcClientProtocolClient.java:221)
	... 20 more
2024-05-31 20:35:31,586 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-05-31 20:35:31,587 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-05-31 20:35:31,587 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: remove    LEADER 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299:t2, leader=076ccc74-63d1-410b-8584-7a1d80cfc8c8, voted=076ccc74-63d1-410b-8584-7a1d80cfc8c8, raftlog=Memoized:076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-SegmentedRaftLog:OPENED:c2, conf=1: peers:[076ccc74-63d1-410b-8584-7a1d80cfc8c8|127.0.0.1:15025, 55857a12-8529-4f00-ab69-b96d955e4226|127.0.0.1:15052, 390bac8a-0dbf-4715-b6fd-0c75abb5c43b|127.0.0.1:15034]|listeners:[], old=null RUNNING
2024-05-31 20:35:31,587 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299: shutdown
2024-05-31 20:35:31,588 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-2C253653B299,id=076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:35:31,588 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: shutdown 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-LeaderStateImpl
2024-05-31 20:35:31,588 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-PendingRequests: sendNotLeaderResponses
2024-05-31 20:35:31,588 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299->390bac8a-0dbf-4715-b6fd-0c75abb5c43b-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299->390bac8a-0dbf-4715-b6fd-0c75abb5c43b-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-05-31 20:35:31,588 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299->55857a12-8529-4f00-ab69-b96d955e4226-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299->55857a12-8529-4f00-ab69-b96d955e4226-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-05-31 20:35:31,589 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-StateMachineUpdater: set stopIndex = 2
2024-05-31 20:35:31,589 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-2C253653B299: Taking a snapshot at:(t:2, i:2) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299/sm/snapshot.2_2
2024-05-31 20:35:31,589 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-2C253653B299: Finished taking a snapshot at:(t:2, i:2) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299/sm/snapshot.2_2 took: 1 ms
2024-05-31 20:35:31,589 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-StateMachineUpdater: Took a snapshot at index 2
2024-05-31 20:35:31,589 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 2
2024-05-31 20:35:31,590 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-05-31 20:35:31,590 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299: applyIndex: 2
2024-05-31 20:35:31,590 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-05-31 20:35:31,591 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: shutdown server GrpcServerProtocolService successfully
2024-05-31 20:35:31,591 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-05-31 20:35:31,593 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - b079985c-91b9-4d2e-8c89-c2e47b34f7da: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-05-31 20:35:31,603 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x379f52d1, L:/0.0.0.0:15035] CLOSE
2024-05-31 20:35:31,604 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x379f52d1, L:/0.0.0.0:15035] INACTIVE
2024-05-31 20:35:31,604 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x379f52d1, L:/0.0.0.0:15035] UNREGISTERED
2024-05-31 20:35:31,604 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xcecef7ee, L:/0.0.0.0:15017] CLOSE
2024-05-31 20:35:31,605 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xcecef7ee, L:/0.0.0.0:15017] INACTIVE
2024-05-31 20:35:31,605 [2fad9ecd-4424-4a8b-880f-fd93cda6f409-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xcecef7ee, L:/0.0.0.0:15017] UNREGISTERED
2024-05-31 20:35:31,610 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd3564359, L:/0.0.0.0:15044] CLOSE
2024-05-31 20:35:31,610 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd3564359, L:/0.0.0.0:15044] INACTIVE
2024-05-31 20:35:31,610 [b079985c-91b9-4d2e-8c89-c2e47b34f7da-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd3564359, L:/0.0.0.0:15044] UNREGISTERED
2024-05-31 20:35:31,613 [JvmPauseMonitor3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-2fad9ecd-4424-4a8b-880f-fd93cda6f409: Stopped
2024-05-31 20:35:31,615 [JvmPauseMonitor6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-b079985c-91b9-4d2e-8c89-c2e47b34f7da: Stopped
2024-05-31 20:35:31,661 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:31,661 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:31,661 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:31,661 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:31,661 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:31,662 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:31,662 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:31,718 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-05-31 20:35:31,718 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-05-31 20:35:31,718 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-05-31 20:35:31,719 [Recon-SyncOM-2] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(422)) - com.google.protobuf.ServiceException: java.io.EOFException: End of File Exception between local host is: "fv-az1343-628/10.1.0.26"; destination host is: "localhost":15004; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException, while invoking $Proxy85.submitRequest over nodeId=null,nodeAddress=localhost:15004. Trying to failover after sleeping for 2000ms. Current retry count: 0.
2024-05-31 20:35:31,971 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299-SegmentedRaftLogWorker close()
2024-05-31 20:35:31,971 [grpc-default-executor-4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299-SegmentedRaftLogWorker close()
2024-05-31 20:35:31,972 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299
2024-05-31 20:35:31,972 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-PipelineCommandHandlerThread-0] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(140)) - Close Pipeline PipelineID=a8ad8d20-97c9-407a-9fb4-2c253653b299 command on datanode 076ccc74-63d1-410b-8584-7a1d80cfc8c8.
2024-05-31 20:35:31,972 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-2C253653B299: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/ratis/a8ad8d20-97c9-407a-9fb4-2c253653b299
2024-05-31 20:35:31,973 [ForkJoinPool.commonPool-worker-2] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-05-31 20:35:31,973 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-05-31 20:35:31,973 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-05-31 20:35:31,973 [ForkJoinPool.commonPool-worker-2] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/data-0/hdds) is shutting down. 
2024-05-31 20:35:31,973 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-05-31 20:35:31,973 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/data-0/hdds, DS-2ee1248f-f02f-4ff8-a917-5c5458f58215) exiting.
2024-05-31 20:35:31,974 [ForkJoinPool.commonPool-worker-2] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(416)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: close
2024-05-31 20:35:31,974 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-05-31 20:35:31,974 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0: shutdown
2024-05-31 20:35:31,974 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A35EB7B01FA0,id=076ccc74-63d1-410b-8584-7a1d80cfc8c8
2024-05-31 20:35:31,974 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: shutdown 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-LeaderStateImpl
2024-05-31 20:35:31,974 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-PendingRequests: sendNotLeaderResponses
2024-05-31 20:35:31,975 [Thread-1400] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 55857a12-8529-4f00-ab69-b96d955e4226 Close channels
2024-05-31 20:35:31,975 [Thread-1401] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b Close channels
2024-05-31 20:35:31,975 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-StateMachineUpdater: set stopIndex = 0
2024-05-31 20:35:31,975 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-A35EB7B01FA0: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/13364d75-4ec1-47d6-8b5b-a35eb7b01fa0/sm/snapshot.1_0
2024-05-31 20:35:31,976 [Thread-1402] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 2fad9ecd-4424-4a8b-880f-fd93cda6f409 Close channels
2024-05-31 20:35:31,976 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-A35EB7B01FA0: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/ratis/13364d75-4ec1-47d6-8b5b-a35eb7b01fa0/sm/snapshot.1_0 took: 1 ms
2024-05-31 20:35:31,976 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-StateMachineUpdater: Took a snapshot at index 0
2024-05-31 20:35:31,976 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-05-31 20:35:31,976 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0: applyIndex: 0
2024-05-31 20:35:31,976 [076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-05-31 20:35:31,977 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-05-31 20:35:31,977 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: shutdown server GrpcServerProtocolService now
2024-05-31 20:35:31,978 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: shutdown server GrpcServerProtocolService successfully
2024-05-31 20:35:31,978 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-05-31 20:35:31,979 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-05-31 20:35:31,983 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc2f84f11, L:/0.0.0.0:15026] CLOSE
2024-05-31 20:35:31,983 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc2f84f11, L:/0.0.0.0:15026] INACTIVE
2024-05-31 20:35:31,983 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc2f84f11, L:/0.0.0.0:15026] UNREGISTERED
2024-05-31 20:35:32,073 [076ccc74-63d1-410b-8584-7a1d80cfc8c8-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-A35EB7B01FA0-SegmentedRaftLogWorker close()
2024-05-31 20:35:32,073 [JvmPauseMonitor4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-076ccc74-63d1-410b-8584-7a1d80cfc8c8: Stopped
2024-05-31 20:35:32,175 [UnderReplicatedProcessor] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:chooseNodeInternal(672)) - No available node in (scope="/" excludedScope="[/default-rack/2fad9ecd-4424-4a8b-880f-fd93cda6f409, /default-rack/390bac8a-0dbf-4715-b6fd-0c75abb5c43b, /default-rack/076ccc74-63d1-410b-8584-7a1d80cfc8c8]" excludedNodes="[390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)]"  ancestorGen="1").
2024-05-31 20:35:32,175 [UnderReplicatedProcessor] WARN  algorithms.SCMContainerPlacementRackAware (SCMContainerPlacementRackAware.java:chooseNode(485)) - Failed to find the datanode for container. excludedNodes:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)], affinityNode:
2024-05-31 20:35:32,175 [UnderReplicatedProcessor] INFO  scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:isValidNode(518)) - Datanode b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1) is not chosen. Required metadata size is 0 and required data size is 5368709120 and NodeStatus is OperationalState: DECOMMISSIONED Health: HEALTHY OperationStateExpiry: 0
2024-05-31 20:35:32,175 [UnderReplicatedProcessor] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:chooseNodeInternal(672)) - No available node in (scope="/" excludedScope="[/default-rack/2fad9ecd-4424-4a8b-880f-fd93cda6f409, /default-rack/390bac8a-0dbf-4715-b6fd-0c75abb5c43b, /default-rack/076ccc74-63d1-410b-8584-7a1d80cfc8c8, /default-rack/b079985c-91b9-4d2e-8c89-c2e47b34f7da]" excludedNodes="[390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)]"  ancestorGen="0").
2024-05-31 20:35:32,175 [UnderReplicatedProcessor] WARN  algorithms.SCMContainerPlacementRackAware (SCMContainerPlacementRackAware.java:chooseNode(485)) - Failed to find the datanode for container. excludedNodes:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)], affinityNode:
2024-05-31 20:35:32,176 [UnderReplicatedProcessor] WARN  replication.RatisUnderReplicationHandler (RatisUnderReplicationHandler.java:processAndSendCommands(136)) - Cannot replicate container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-05-31T20:34:23.864421440Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault} because no suitable targets were found.
2024-05-31 20:35:32,176 [UnderReplicatedProcessor] INFO  replication.RatisUnderReplicationHandler (RatisUnderReplicationHandler.java:removeUnhealthyReplicaIfPossible(264)) - Finding an unhealthy replica to delete for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-05-31T20:34:23.864421440Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault} with replicas [ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), placeOfBirth=076ccc74-63d1-410b-8584-7a1d80cfc8c8, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}, ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), placeOfBirth=2fad9ecd-4424-4a8b-880f-fd93cda6f409, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}, ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), placeOfBirth=390bac8a-0dbf-4715-b6fd-0c75abb5c43b, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}] to unblock under replication handling.
2024-05-31 20:35:32,176 [UnderReplicatedProcessor] INFO  replication.RatisUnderReplicationHandler (RatisUnderReplicationHandler.java:removeUnhealthyReplicaIfPossible(292)) - Unable to find a replica to remove for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-05-31T20:34:23.864421440Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault} with replicas [ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), placeOfBirth=076ccc74-63d1-410b-8584-7a1d80cfc8c8, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}, ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), placeOfBirth=2fad9ecd-4424-4a8b-880f-fd93cda6f409, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}, ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), placeOfBirth=390bac8a-0dbf-4715-b6fd-0c75abb5c43b, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}]
2024-05-31 20:35:32,176 [UnderReplicatedProcessor] ERROR replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(127)) - Error processing Health result of class: class org.apache.hadoop.hdds.scm.container.replication.ContainerHealthResult$UnderReplicatedHealthResult for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-05-31T20:34:23.864421440Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault}
org.apache.hadoop.hdds.scm.exceptions.SCMException: Placement Policy: class org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware did not return any nodes. Number of required Nodes 1, Datasize Required: 5368709120
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManagerUtil.getTargetDatanodes(ReplicationManagerUtil.java:101)
	at org.apache.hadoop.hdds.scm.container.replication.RatisUnderReplicationHandler.getTargets(RatisUnderReplicationHandler.java:457)
	at org.apache.hadoop.hdds.scm.container.replication.RatisUnderReplicationHandler.processAndSendCommands(RatisUnderReplicationHandler.java:130)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processUnderReplicatedContainer(ReplicationManager.java:786)
	at org.apache.hadoop.hdds.scm.container.replication.UnderReplicatedProcessor.sendDatanodeCommands(UnderReplicatedProcessor.java:60)
	at org.apache.hadoop.hdds.scm.container.replication.UnderReplicatedProcessor.sendDatanodeCommands(UnderReplicatedProcessor.java:29)
	at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.processContainer(UnhealthyReplicationProcessor.java:156)
	at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.processAll(UnhealthyReplicationProcessor.java:116)
	at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:165)
	at java.base/java.lang.Thread.run(Thread.java:840)
2024-05-31 20:35:32,176 [UnderReplicatedProcessor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(138)) - Processed 0 containers with health state counts {}, failed processing 1, deferred due to load 0
2024-05-31 20:35:32,204 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-05-31 20:35:32,227 [390bac8a-0dbf-4715-b6fd-0c75abb5c43b-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 390bac8a-0dbf-4715-b6fd-0c75abb5c43b@group-1D0408D68C02-SegmentedRaftLogWorker close()
2024-05-31 20:35:32,227 [JvmPauseMonitor5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-390bac8a-0dbf-4715-b6fd-0c75abb5c43b: Stopped
2024-05-31 20:35:32,665 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:32,666 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:32,666 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:32,666 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:32,666 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:32,666 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:32,666 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:33,176 [UnderReplicatedProcessor] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:chooseNodeInternal(672)) - No available node in (scope="/" excludedScope="[/default-rack/2fad9ecd-4424-4a8b-880f-fd93cda6f409, /default-rack/390bac8a-0dbf-4715-b6fd-0c75abb5c43b, /default-rack/076ccc74-63d1-410b-8584-7a1d80cfc8c8]" excludedNodes="[390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)]"  ancestorGen="1").
2024-05-31 20:35:33,177 [UnderReplicatedProcessor] WARN  algorithms.SCMContainerPlacementRackAware (SCMContainerPlacementRackAware.java:chooseNode(485)) - Failed to find the datanode for container. excludedNodes:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)], affinityNode:
2024-05-31 20:35:33,177 [UnderReplicatedProcessor] INFO  scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:isValidNode(518)) - Datanode b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1) is not chosen. Required metadata size is 0 and required data size is 5368709120 and NodeStatus is OperationalState: DECOMMISSIONED Health: HEALTHY OperationStateExpiry: 0
2024-05-31 20:35:33,177 [UnderReplicatedProcessor] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:chooseNodeInternal(672)) - No available node in (scope="/" excludedScope="[/default-rack/2fad9ecd-4424-4a8b-880f-fd93cda6f409, /default-rack/390bac8a-0dbf-4715-b6fd-0c75abb5c43b, /default-rack/076ccc74-63d1-410b-8584-7a1d80cfc8c8, /default-rack/b079985c-91b9-4d2e-8c89-c2e47b34f7da]" excludedNodes="[390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)]"  ancestorGen="0").
2024-05-31 20:35:33,177 [UnderReplicatedProcessor] WARN  algorithms.SCMContainerPlacementRackAware (SCMContainerPlacementRackAware.java:chooseNode(485)) - Failed to find the datanode for container. excludedNodes:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)], affinityNode:
2024-05-31 20:35:33,177 [UnderReplicatedProcessor] WARN  replication.RatisUnderReplicationHandler (RatisUnderReplicationHandler.java:processAndSendCommands(136)) - Cannot replicate container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-05-31T20:34:23.864421440Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault} because no suitable targets were found.
2024-05-31 20:35:33,177 [UnderReplicatedProcessor] INFO  replication.RatisUnderReplicationHandler (RatisUnderReplicationHandler.java:removeUnhealthyReplicaIfPossible(264)) - Finding an unhealthy replica to delete for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-05-31T20:34:23.864421440Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault} with replicas [ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), placeOfBirth=076ccc74-63d1-410b-8584-7a1d80cfc8c8, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}, ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), placeOfBirth=2fad9ecd-4424-4a8b-880f-fd93cda6f409, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}, ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), placeOfBirth=390bac8a-0dbf-4715-b6fd-0c75abb5c43b, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}] to unblock under replication handling.
2024-05-31 20:35:33,177 [UnderReplicatedProcessor] INFO  replication.RatisUnderReplicationHandler (RatisUnderReplicationHandler.java:removeUnhealthyReplicaIfPossible(292)) - Unable to find a replica to remove for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-05-31T20:34:23.864421440Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault} with replicas [ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), placeOfBirth=076ccc74-63d1-410b-8584-7a1d80cfc8c8, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}, ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), placeOfBirth=2fad9ecd-4424-4a8b-880f-fd93cda6f409, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}, ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), placeOfBirth=390bac8a-0dbf-4715-b6fd-0c75abb5c43b, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}]
2024-05-31 20:35:33,177 [UnderReplicatedProcessor] ERROR replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(127)) - Error processing Health result of class: class org.apache.hadoop.hdds.scm.container.replication.ContainerHealthResult$UnderReplicatedHealthResult for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-05-31T20:34:23.864421440Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault}
org.apache.hadoop.hdds.scm.exceptions.SCMException: Placement Policy: class org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware did not return any nodes. Number of required Nodes 1, Datasize Required: 5368709120
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManagerUtil.getTargetDatanodes(ReplicationManagerUtil.java:101)
	at org.apache.hadoop.hdds.scm.container.replication.RatisUnderReplicationHandler.getTargets(RatisUnderReplicationHandler.java:457)
	at org.apache.hadoop.hdds.scm.container.replication.RatisUnderReplicationHandler.processAndSendCommands(RatisUnderReplicationHandler.java:130)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processUnderReplicatedContainer(ReplicationManager.java:786)
	at org.apache.hadoop.hdds.scm.container.replication.UnderReplicatedProcessor.sendDatanodeCommands(UnderReplicatedProcessor.java:60)
	at org.apache.hadoop.hdds.scm.container.replication.UnderReplicatedProcessor.sendDatanodeCommands(UnderReplicatedProcessor.java:29)
	at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.processContainer(UnhealthyReplicationProcessor.java:156)
	at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.processAll(UnhealthyReplicationProcessor.java:116)
	at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:165)
	at java.base/java.lang.Thread.run(Thread.java:840)
2024-05-31 20:35:33,178 [UnderReplicatedProcessor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(138)) - Processed 0 containers with health state counts {}, failed processing 1, deferred due to load 0
2024-05-31 20:35:33,205 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-05-31 20:35:33,616 [ForkJoinPool.commonPool-worker-1] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-8d549ed5-de89-43e1-898f-9aeb04fe8d8b/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-2ee1248f-f02f-4ff8-a917-5c5458f58215/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-cf1e182a-4d8d-4e20-b089-121cd677328f/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-bb861fdb-1577-4261-bac7-37897f3298f1/container.db]
2024-05-31 20:35:33,618 [ForkJoinPool.commonPool-worker-1] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-8d549ed5-de89-43e1-898f-9aeb04fe8d8b/container.db from cache
2024-05-31 20:35:33,618 [ForkJoinPool.commonPool-worker-3] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-2ee1248f-f02f-4ff8-a917-5c5458f58215/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-cf1e182a-4d8d-4e20-b089-121cd677328f/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-bb861fdb-1577-4261-bac7-37897f3298f1/container.db]
2024-05-31 20:35:33,618 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(470)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-1/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-8d549ed5-de89-43e1-898f-9aeb04fe8d8b/container.db for volume DS-8d549ed5-de89-43e1-898f-9aeb04fe8d8b
2024-05-31 20:35:33,618 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-05-31 20:35:33,618 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-05-31 20:35:33,619 [ForkJoinPool.commonPool-worker-3] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-bb861fdb-1577-4261-bac7-37897f3298f1/container.db from cache
2024-05-31 20:35:33,619 [ForkJoinPool.commonPool-worker-3] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(470)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-4/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-bb861fdb-1577-4261-bac7-37897f3298f1/container.db for volume DS-bb861fdb-1577-4261-bac7-37897f3298f1
2024-05-31 20:35:33,619 [ForkJoinPool.commonPool-worker-3] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-05-31 20:35:33,619 [ForkJoinPool.commonPool-worker-3] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-05-31 20:35:33,619 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(638)) - Ozone container server stopped.
2024-05-31 20:35:33,620 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@2ffed7fd{hddsDatanode,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode}
2024-05-31 20:35:33,620 [ForkJoinPool.commonPool-worker-3] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(638)) - Ozone container server stopped.
2024-05-31 20:35:33,621 [ForkJoinPool.commonPool-worker-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@7aaa73f6{hddsDatanode,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode}
2024-05-31 20:35:33,621 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@77615884{HTTP/1.1, (http/1.1)}{0.0.0.0:15011}
2024-05-31 20:35:33,621 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-05-31 20:35:33,621 [ForkJoinPool.commonPool-worker-3] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@37988190{HTTP/1.1, (http/1.1)}{0.0.0.0:15038}
2024-05-31 20:35:33,621 [ForkJoinPool.commonPool-worker-3] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-05-31 20:35:33,621 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@3217fef1{static,/static,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/static,STOPPED}
2024-05-31 20:35:33,621 [ForkJoinPool.commonPool-worker-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@39a9ef9a{static,/static,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/static,STOPPED}
2024-05-31 20:35:33,621 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@13e4b8da{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-05-31 20:35:33,622 [ForkJoinPool.commonPool-worker-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@50f5cec3{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-05-31 20:35:33,622 [ForkJoinPool.commonPool-worker-1] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-05-31 20:35:33,622 [ForkJoinPool.commonPool-worker-1] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15012
2024-05-31 20:35:33,622 [IPC Server listener on 15012] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15012
2024-05-31 20:35:33,623 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-05-31 20:35:33,623 [ForkJoinPool.commonPool-worker-3] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-05-31 20:35:33,623 [ForkJoinPool.commonPool-worker-3] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15039
2024-05-31 20:35:33,623 [IPC Server listener on 15039] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15039
2024-05-31 20:35:33,623 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-05-31 20:35:33,669 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-05-31 20:35:33,670 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-05-31 20:35:33,670 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-05-31 20:35:33,670 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:33,670 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:33,670 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-05-31 20:35:33,670 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-05-31 20:35:33,720 [Recon-SyncOM-2] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(422)) - com.google.protobuf.ServiceException: java.net.ConnectException: Call From fv-az1343-628/10.1.0.26 to localhost:15004 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy85.submitRequest over nodeId=null,nodeAddress=localhost:15004 after 1 failover attempts. Trying to failover after sleeping for 4000ms. Current retry count: 1.
2024-05-31 20:35:33,949 [timer1] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(217)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299->55857a12-8529-4f00-ab69-b96d955e4226-GrpcLogAppender: Follower failed (request=null, errorCount=4); keep nextIndex (2) unchanged and retry. (Repeated 2 times in the last 5.000s)
2024-05-31 20:35:33,949 [timer6] WARN  server.GrpcLogAppender (LogUtils.java:warn(121)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299->55857a12-8529-4f00-ab69-b96d955e4226-AppendLogResponseHandler: Failed appendEntries (Repeated 10 times in the last 5.001s): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-05-31 20:35:33,949 [timer0] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(217)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299->55857a12-8529-4f00-ab69-b96d955e4226-GrpcLogAppender: Follower failed (request=null, errorCount=2); keep nextIndex (1) unchanged and retry. (Repeated 2 times in the last 5.001s)
2024-05-31 20:35:33,956 [timer6] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(217)) - 076ccc74-63d1-410b-8584-7a1d80cfc8c8@group-2C253653B299->55857a12-8529-4f00-ab69-b96d955e4226-GrpcLogAppender: Follower failed (request=null, errorCount=10); keep nextIndex (3) unchanged and retry. (Repeated 6 times in the last 5.000s)
2024-05-31 20:35:33,974 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=13364d75-4ec1-47d6-8b5b-a35eb7b01fa0]
2024-05-31 20:35:33,975 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=13364d75-4ec1-47d6-8b5b-a35eb7b01fa0 moved to CLOSED state
2024-05-31 20:35:34,073 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=13364d75-4ec1-47d6-8b5b-a35eb7b01fa0]
2024-05-31 20:35:34,074 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=13364d75-4ec1-47d6-8b5b-a35eb7b01fa0 moved to CLOSED state
2024-05-31 20:35:34,075 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 2 pipelines in house.
2024-05-31 20:35:34,076 [ForkJoinPool.commonPool-worker-2] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-2ee1248f-f02f-4ff8-a917-5c5458f58215/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-cf1e182a-4d8d-4e20-b089-121cd677328f/container.db]
2024-05-31 20:35:34,077 [ForkJoinPool.commonPool-worker-2] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-2ee1248f-f02f-4ff8-a917-5c5458f58215/container.db from cache
2024-05-31 20:35:34,077 [ForkJoinPool.commonPool-worker-2] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(470)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-2/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-2ee1248f-f02f-4ff8-a917-5c5458f58215/container.db for volume DS-2ee1248f-f02f-4ff8-a917-5c5458f58215
2024-05-31 20:35:34,077 [ForkJoinPool.commonPool-worker-2] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-05-31 20:35:34,078 [ForkJoinPool.commonPool-worker-2] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-05-31 20:35:34,078 [ForkJoinPool.commonPool-worker-2] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(638)) - Ozone container server stopped.
2024-05-31 20:35:34,078 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@2563d994{hddsDatanode,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode}
2024-05-31 20:35:34,079 [ForkJoinPool.commonPool-worker-2] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@34ee9000{HTTP/1.1, (http/1.1)}{0.0.0.0:15020}
2024-05-31 20:35:34,079 [ForkJoinPool.commonPool-worker-2] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-05-31 20:35:34,079 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@4f7b4b50{static,/static,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/static,STOPPED}
2024-05-31 20:35:34,079 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2fdbef8d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-05-31 20:35:34,080 [ForkJoinPool.commonPool-worker-2] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-05-31 20:35:34,080 [ForkJoinPool.commonPool-worker-2] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15021
2024-05-31 20:35:34,080 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-05-31 20:35:34,080 [IPC Server listener on 15021] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15021
2024-05-31 20:35:34,178 [UnderReplicatedProcessor] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:chooseNodeInternal(672)) - No available node in (scope="/" excludedScope="[/default-rack/2fad9ecd-4424-4a8b-880f-fd93cda6f409, /default-rack/390bac8a-0dbf-4715-b6fd-0c75abb5c43b, /default-rack/076ccc74-63d1-410b-8584-7a1d80cfc8c8]" excludedNodes="[390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)]"  ancestorGen="1").
2024-05-31 20:35:34,178 [UnderReplicatedProcessor] WARN  algorithms.SCMContainerPlacementRackAware (SCMContainerPlacementRackAware.java:chooseNode(485)) - Failed to find the datanode for container. excludedNodes:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)], affinityNode:
2024-05-31 20:35:34,178 [UnderReplicatedProcessor] INFO  scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:isValidNode(518)) - Datanode b079985c-91b9-4d2e-8c89-c2e47b34f7da(localhost/127.0.0.1) is not chosen. Required metadata size is 0 and required data size is 5368709120 and NodeStatus is OperationalState: DECOMMISSIONED Health: HEALTHY OperationStateExpiry: 0
2024-05-31 20:35:34,179 [UnderReplicatedProcessor] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:chooseNodeInternal(672)) - No available node in (scope="/" excludedScope="[/default-rack/2fad9ecd-4424-4a8b-880f-fd93cda6f409, /default-rack/390bac8a-0dbf-4715-b6fd-0c75abb5c43b, /default-rack/076ccc74-63d1-410b-8584-7a1d80cfc8c8, /default-rack/b079985c-91b9-4d2e-8c89-c2e47b34f7da]" excludedNodes="[390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)]"  ancestorGen="0").
2024-05-31 20:35:34,179 [UnderReplicatedProcessor] WARN  algorithms.SCMContainerPlacementRackAware (SCMContainerPlacementRackAware.java:chooseNode(485)) - Failed to find the datanode for container. excludedNodes:[390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), 076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1)], affinityNode:
2024-05-31 20:35:34,179 [UnderReplicatedProcessor] WARN  replication.RatisUnderReplicationHandler (RatisUnderReplicationHandler.java:processAndSendCommands(136)) - Cannot replicate container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-05-31T20:34:23.864421440Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault} because no suitable targets were found.
2024-05-31 20:35:34,179 [UnderReplicatedProcessor] INFO  replication.RatisUnderReplicationHandler (RatisUnderReplicationHandler.java:removeUnhealthyReplicaIfPossible(264)) - Finding an unhealthy replica to delete for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-05-31T20:34:23.864421440Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault} with replicas [ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), placeOfBirth=076ccc74-63d1-410b-8584-7a1d80cfc8c8, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}, ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), placeOfBirth=2fad9ecd-4424-4a8b-880f-fd93cda6f409, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}, ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), placeOfBirth=390bac8a-0dbf-4715-b6fd-0c75abb5c43b, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}] to unblock under replication handling.
2024-05-31 20:35:34,179 [UnderReplicatedProcessor] INFO  replication.RatisUnderReplicationHandler (RatisUnderReplicationHandler.java:removeUnhealthyReplicaIfPossible(292)) - Unable to find a replica to remove for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-05-31T20:34:23.864421440Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault} with replicas [ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=076ccc74-63d1-410b-8584-7a1d80cfc8c8(localhost/127.0.0.1), placeOfBirth=076ccc74-63d1-410b-8584-7a1d80cfc8c8, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}, ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1), placeOfBirth=2fad9ecd-4424-4a8b-880f-fd93cda6f409, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}, ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1), placeOfBirth=390bac8a-0dbf-4715-b6fd-0c75abb5c43b, sequenceId=2, keyCount=1, bytesUsed=7, isEmpty=false}]
2024-05-31 20:35:34,179 [UnderReplicatedProcessor] ERROR replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(127)) - Error processing Health result of class: class org.apache.hadoop.hdds.scm.container.replication.ContainerHealthResult$UnderReplicatedHealthResult for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-05-31T20:34:23.864421440Z, pipelineID=PipelineID=9a915894-abff-4e14-8344-4a82ed352a01, owner=omServiceIdDefault}
org.apache.hadoop.hdds.scm.exceptions.SCMException: Placement Policy: class org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware did not return any nodes. Number of required Nodes 1, Datasize Required: 5368709120
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManagerUtil.getTargetDatanodes(ReplicationManagerUtil.java:101)
	at org.apache.hadoop.hdds.scm.container.replication.RatisUnderReplicationHandler.getTargets(RatisUnderReplicationHandler.java:457)
	at org.apache.hadoop.hdds.scm.container.replication.RatisUnderReplicationHandler.processAndSendCommands(RatisUnderReplicationHandler.java:130)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processUnderReplicatedContainer(ReplicationManager.java:786)
	at org.apache.hadoop.hdds.scm.container.replication.UnderReplicatedProcessor.sendDatanodeCommands(UnderReplicatedProcessor.java:60)
	at org.apache.hadoop.hdds.scm.container.replication.UnderReplicatedProcessor.sendDatanodeCommands(UnderReplicatedProcessor.java:29)
	at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.processContainer(UnhealthyReplicationProcessor.java:156)
	at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.processAll(UnhealthyReplicationProcessor.java:116)
	at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:165)
	at java.base/java.lang.Thread.run(Thread.java:840)
2024-05-31 20:35:34,179 [UnderReplicatedProcessor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(138)) - Processed 0 containers with health state counts {}, failed processing 1, deferred due to load 0
2024-05-31 20:35:34,205 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(402)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-05-31 20:35:34,230 [main] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-cf1e182a-4d8d-4e20-b089-121cd677328f/container.db]
2024-05-31 20:35:34,231 [main] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-cf1e182a-4d8d-4e20-b089-121cd677328f/container.db from cache
2024-05-31 20:35:34,231 [main] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(470)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-f460b6b2-8064-4396-ade5-fe2bd7cf7699/ozone-meta/datanode-3/data-0/hdds/f460b6b2-8064-4396-ade5-fe2bd7cf7699/DS-cf1e182a-4d8d-4e20-b089-121cd677328f/container.db for volume DS-cf1e182a-4d8d-4e20-b089-121cd677328f
2024-05-31 20:35:34,231 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-05-31 20:35:34,232 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-05-31 20:35:34,232 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(638)) - Ozone container server stopped.
2024-05-31 20:35:34,233 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@77c894d5{hddsDatanode,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode}
2024-05-31 20:35:34,233 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@49b6b53{HTTP/1.1, (http/1.1)}{0.0.0.0:15029}
2024-05-31 20:35:34,233 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-05-31 20:35:34,234 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@67e9ae8c{static,/static,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/static,STOPPED}
2024-05-31 20:35:34,234 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@47e4126a{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-05-31 20:35:34,234 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-05-31 20:35:34,235 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15030
2024-05-31 20:35:34,235 [IPC Server listener on 15030] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15030
2024-05-31 20:35:34,235 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-05-31 20:35:34,236 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(486)) - Stopping the StorageContainerManager
2024-05-31 20:35:34,236 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1653)) - Container Balancer is not running.
2024-05-31 20:35:34,236 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stopReplicationManager(1786)) - Stopping Replication Manager Service.
2024-05-31 20:35:34,236 [main] INFO  replication.ReplicationManager (ReplicationManager.java:stop(329)) - Stopping Replication Monitor Thread.
2024-05-31 20:35:34,236 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1662)) - Stopping the Datanode Admin Monitor.
2024-05-31 20:35:34,236 [OverReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(180)) - OverReplicatedProcessor interrupted. Exiting...
2024-05-31 20:35:34,236 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1669)) - Stopping datanode service RPC server
2024-05-31 20:35:34,236 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(938)) - Replication Monitor Thread is stopped
2024-05-31 20:35:34,236 [UnderReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(180)) - UnderReplicatedProcessor interrupted. Exiting...
2024-05-31 20:35:34,236 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(425)) - Stopping the RPC server for DataNodes
2024-05-31 20:35:34,242 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15002
2024-05-31 20:35:34,252 [IPC Server listener on 15002] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15002
2024-05-31 20:35:34,252 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-05-31 20:35:34,273 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines []
2024-05-31 20:35:34,274 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 2 pipelines in house.
2024-05-31 20:35:34,274 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 2fad9ecd-4424-4a8b-880f-fd93cda6f409(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines []
2024-05-31 20:35:34,274 [SCMHeartbeatProcessor-0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(878)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2024-05-31 20:35:34,275 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1677)) - Stopping block service RPC server
2024-05-31 20:35:34,275 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(171)) - Stopping the RPC server for Block Protocol
2024-05-31 20:35:34,275 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15001
2024-05-31 20:35:34,282 [IPC Server listener on 15001] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15001
2024-05-31 20:35:34,283 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-05-31 20:35:34,283 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1684)) - Stopping the StorageContainerLocationProtocol RPC server
2024-05-31 20:35:34,283 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(213)) - Stopping the RPC server for Client Protocol
2024-05-31 20:35:34,283 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15000
2024-05-31 20:35:34,290 [IPC Server listener on 15000] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15000
2024-05-31 20:35:34,291 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-05-31 20:35:34,291 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1691)) - Stopping Storage Container Manager HTTP server.
2024-05-31 20:35:34,293 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@3faa55{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2024-05-31 20:35:34,294 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@8dbf0f2{HTTP/1.1, (http/1.1)}{0.0.0.0:15003}
2024-05-31 20:35:34,294 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-05-31 20:35:34,295 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@6be80629{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2024-05-31 20:35:34,295 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@383e6734{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-05-31 20:35:34,296 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1699)) - Stopping SCM LayoutVersionManager Service.
2024-05-31 20:35:34,296 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1711)) - Stopping Block Manager Service.
2024-05-31 20:35:34,296 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SCMBlockDeletingService
2024-05-31 20:35:34,296 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SCMBlockDeletingService
2024-05-31 20:35:34,297 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1731)) - Stopping SCM Event Queue.
2024-05-31 20:35:34,299 [JvmPauseMonitor0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-0de31259-7547-4ea4-9e9e-52d889559681: Stopped
2024-05-31 20:35:34,300 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1742)) - Stopping SCM HA services.
2024-05-31 20:35:34,300 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(152)) - Stopping RatisPipelineUtilsThread.
2024-05-31 20:35:34,300 [RatisPipelineUtilsThread-0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(183)) - RatisPipelineUtilsThread is interrupted.
2024-05-31 20:35:34,300 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(128)) - Stopping BackgroundPipelineScrubber Service.
2024-05-31 20:35:34,300 [BackgroundPipelineScrubber] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(112)) - BackgroundPipelineScrubber is interrupted, exit
2024-05-31 20:35:34,301 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2024-05-31 20:35:34,303 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2024-05-31 20:35:34,303 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2024-05-31 20:35:34,304 [main] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(148)) - RatisPipelineUtilsThread is not running, just ignore.
2024-05-31 20:35:34,304 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(123)) - BackgroundPipelineScrubber Service is not running, skip stop.
2024-05-31 20:35:34,304 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(128)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2024-05-31 20:35:34,304 [ExpiredContainerReplicaOpScrubber] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(112)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2024-05-31 20:35:34,304 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SCMBlockDeletingService
2024-05-31 20:35:34,305 [main] INFO  replication.ReplicationManager (ReplicationManager.java:stop(339)) - Replication Monitor Thread is not running.
2024-05-31 20:35:34,305 [main] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(327)) - Cannot stop Container Balancer because it's not running or stopping
2024-05-31 20:35:34,305 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1777)) - Stopping SCM MetadataStore.
2024-05-31 20:35:34,307 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopRecon(501)) - Stopping Recon
2024-05-31 20:35:34,307 [main] INFO  recon.ReconServer (ReconServer.java:stop(235)) - Stopping Recon server
2024-05-31 20:35:34,313 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@48afc94c{recon,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/recon/target/classes/webapps/recon}
2024-05-31 20:35:34,314 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@2280c0f5{HTTP/1.1, (http/1.1)}{0.0.0.0:15008}
2024-05-31 20:35:34,314 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-05-31 20:35:34,315 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@21ec7946{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/recon/target/classes/webapps/static,STOPPED}
2024-05-31 20:35:34,315 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7fab8e9a{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-05-31 20:35:34,316 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(425)) - Stopping the RPC server for DataNodes
2024-05-31 20:35:34,316 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15009
2024-05-31 20:35:34,322 [IPC Server listener on 15009] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15009
2024-05-31 20:35:34,323 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-05-31 20:35:34,373 [SCMHeartbeatProcessor-0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(878)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2024-05-31 20:35:34,373 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 390bac8a-0dbf-4715-b6fd-0c75abb5c43b(localhost/127.0.0.1) moved to stale state. Finalizing its pipelines [PipelineID=3166dcd9-053f-42c3-b8ea-1d0408d68c02]
2024-05-31 20:35:34,374 [main] INFO  scm.ReconScmTask (ReconScmTask.java:stop(72)) - Stopping PipelineSyncTask Thread.
2024-05-31 20:35:34,374 [main] INFO  scm.ReconScmTask (ReconScmTask.java:stop(72)) - Stopping ContainerSizeCountTask Thread.
2024-05-31 20:35:34,374 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=3166dcd9-053f-42c3-b8ea-1d0408d68c02 moved to CLOSED state
2024-05-31 20:35:34,375 [main] INFO  scm.ReconScmTask (ReconScmTask.java:stop(72)) - Stopping ContainerHealthTask Thread.
2024-05-31 20:35:34,375 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:stop(469)) - Stopping SCM Event Queue.
2024-05-31 20:35:34,375 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(422)) - com.google.protobuf.ServiceException: java.io.EOFException: End of File Exception between local host is: "fv-az1343-628/10.1.0.26"; destination host is: "0.0.0.0":15000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException, while invoking $Proxy55.submitRequest over nodeId=scmNodeId,nodeAddress=/0.0.0.0:15000. Trying to failover after sleeping for 2000ms. Current retry count: 0.
2024-05-31 20:35:34,376 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:stop(477)) - Flushing container replica history to DB.
2024-05-31 20:35:34,379 [main] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:stop(303)) - Stopping Ozone Manager Service Provider.
2024-05-31 20:35:34,379 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:stop(230)) - Stopping Recon Task Controller.
2024-05-31 20:35:34,382 [main] INFO  recon.ReconServer (ReconServer.java:stop(260)) - Closing Recon Container Key DB.
2024-05-31 20:35:34,382 [Recon-SyncOM-2] WARN  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(528)) - Unable to get and apply delta updates from OM.
2024-05-31 20:35:34,382 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(537)) - Obtaining full snapshot from Ozone Manager
2024-05-31 20:35:34,383 [Recon-SyncOM-2] ERROR impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getOzoneManagerDBSnapshot(373)) - Unable to obtain Ozone Manager DB Snapshot. 
java.net.ConnectException: Call From fv-az1343-628/10.1.0.26 to localhost:15004 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:480)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:930)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:845)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1571)
	at org.apache.hadoop.ipc.Client.call(Client.java:1513)
	at org.apache.hadoop.ipc.Client.call(Client.java:1410)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:250)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:132)
	at jdk.proxy2/jdk.proxy2.$Proxy85.submitRequest(Unknown Source)
	at jdk.internal.reflect.GeneratedMethodAccessor117.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:433)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:166)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:158)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:96)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:362)
	at jdk.proxy2/jdk.proxy2.$Proxy85.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransport.submitRequest(Hadoop3OmTransport.java:80)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:337)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceList(OzoneManagerProtocolClientSideTranslatorPB.java:1815)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerSnapshotUrl(OzoneManagerServiceProviderImpl.java:322)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:357)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:551)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:531)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:355)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:387)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:539)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$startSyncDataFromOM$0(OzoneManagerServiceProviderImpl.java:267)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:946)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:205)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:600)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:652)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:773)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:347)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1632)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	... 33 more
2024-05-31 20:35:34,384 [Recon-SyncOM-2] ERROR impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:updateReconOmDBWithNewSnapshot(400)) - Null snapshot location got from OM.
2024-05-31 20:35:34,383 [JvmPauseMonitor2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-Recon: Stopped
2024-05-31 20:35:34,566 [shutdown-hook-0] INFO  recon.ReconServer (StringUtils.java:lambda$startupShutdownMessage$0(144)) - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ReconServer at fv-az1343-628/10.1.0.26
************************************************************/
