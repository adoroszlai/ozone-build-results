2024-03-23 11:35:54,502 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(143)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-23 11:35:54,841 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(143)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-23 11:35:54,850 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(207)) - ServiceID for StorageContainerManager is null
2024-03-23 11:35:54,858 [main] WARN  ha.SCMHANodeDetails (SCMHANodeDetails.java:validateSCMHAConfig(180)) - Default/Configured value of config ozone.scm.ratis.enable conflicts with the expected value. Default/Configured: true. Expected: false. Falling back to the expected value. Current State of SCM: SCM is running without Ratis. Ratis SCM -> Non Ratis SCM is not supported.
2024-03-23 11:35:54,859 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(212)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2024-03-23 11:35:55,324 [main] WARN  utils.HAUtils (HAUtils.java:getMetaDir(339)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-23 11:35:55,430 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(171)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-23 11:35:55,439 [main] INFO  utils.LeakDetector (LeakDetector.java:start(73)) - Starting leak detector thread ManagedRocksObject0.
2024-03-23 11:35:55,617 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.5.0-SNAPSHOT/hdds-common-1.5.0-SNAPSHOT.jar!/network-topology-default.xml]
2024-03-23 11:35:55,619 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2024-03-23 11:35:55,652 [main] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.dropwizard3.Dm3MetricRegistriesImpl
2024-03-23 11:35:55,663 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-03-23 11:35:55,799 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(370)) - upgrade localId to 113750153625600000
2024-03-23 11:35:55,800 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(380)) - upgrade delTxnId to 0
2024-03-23 11:35:55,806 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(397)) - upgrade containerId to 0
2024-03-23 11:35:55,809 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToCertificateSequenceId(444)) - upgrade CertificateId to 2
2024-03-23 11:35:55,811 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(241)) - Init the HA SequenceIdGenerator.
2024-03-23 11:35:55,849 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(177)) - Entering startup safe mode.
2024-03-23 11:35:55,860 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2024-03-23 11:35:55,862 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2024-03-23 11:35:55,869 [main] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2024-03-23 11:35:55,879 [main] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2024-03-23 11:35:55,880 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2024-03-23 11:35:55,884 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2024-03-23 11:35:55,884 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(127)) - Starting RatisPipelineUtilsThread.
2024-03-23 11:35:55,887 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(65)) - Starting BackgroundPipelineScrubber Service.
2024-03-23 11:35:55,887 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2024-03-23 11:35:55,892 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(65)) - Starting ExpiredContainerReplicaOpScrubber Service.
2024-03-23 11:35:55,893 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2024-03-23 11:35:55,911 [main] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(80)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-03-23 11:35:55,912 [main] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(80)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-03-23 11:35:55,936 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2024-03-23 11:35:55,986 [main] INFO  replication.ReplicationManager (ReplicationManager.java:start(295)) - Starting Replication Monitor Thread.
2024-03-23 11:35:55,988 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2024-03-23 11:35:55,992 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:35:56,069 [main] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(91)) - containers with one replica threshold count 0
2024-03-23 11:35:56,073 [main] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(176)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-23 11:35:56,075 [main] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(193)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2024-03-23 11:35:56,119 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(440)) - SCM start with adminUsers: [runner]
2024-03-23 11:35:56,338 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for SCMAudit to [].
2024-03-23 11:35:56,368 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-23 11:35:56,400 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15002
2024-03-23 11:35:56,402 [Socket Reader #1 for port 15002] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15002
2024-03-23 11:35:56,443 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for SCMAudit to [].
2024-03-23 11:35:56,448 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-23 11:35:56,448 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15001
2024-03-23 11:35:56,450 [Socket Reader #1 for port 15001] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15001
2024-03-23 11:35:56,478 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for SCMAudit to [].
2024-03-23 11:35:56,491 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-23 11:35:56,491 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15000
2024-03-23 11:35:56,493 [Socket Reader #1 for port 15000] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15000
2024-03-23 11:35:56,540 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2024-03-23 11:35:56,541 [main] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(225)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2024-03-23 11:35:56,544 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1545)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:15000
2024-03-23 11:35:56,608 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(136)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2024-03-23 11:35:56,618 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2024-03-23 11:35:56,618 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2024-03-23 11:35:56,803 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(204)) - RPC server for Client  is listening at /0.0.0.0:15000
2024-03-23 11:35:56,804 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-03-23 11:35:56,805 [IPC Server listener on 15000] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15000: starting
2024-03-23 11:35:56,835 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1558)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:15001
2024-03-23 11:35:56,837 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(162)) - RPC server for Block Protocol is listening at /0.0.0.0:15001
2024-03-23 11:35:56,838 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-03-23 11:35:56,838 [IPC Server listener on 15001] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15001: starting
2024-03-23 11:35:56,848 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(194)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:15002
2024-03-23 11:35:56,849 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-03-23 11:35:56,849 [IPC Server listener on 15002] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15002: starting
2024-03-23 11:35:56,871 [JvmPauseMonitor0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-c49b860f-8bf3-42e8-8266-c06a9572c5ee: Started
2024-03-23 11:35:56,880 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for scm at: http://0.0.0.0:15003
2024-03-23 11:35:56,880 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-23 11:35:56,898 [main] INFO  util.log (Log.java:initialized(170)) - Logging initialized @3773ms to org.eclipse.jetty.util.log.Slf4jLog
2024-03-23 11:35:56,975 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-03-23 11:35:56,980 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.scm is not defined
2024-03-23 11:35:56,986 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-23 11:35:56,988 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2024-03-23 11:35:56,988 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-23 11:35:56,989 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-23 11:35:57,013 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/webserver
2024-03-23 11:35:57,014 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15003
2024-03-23 11:35:57,015 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-03-23 11:35:57,031 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-03-23 11:35:57,032 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-03-23 11:35:57,033 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2024-03-23 11:35:57,040 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@749ebc39{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-03-23 11:35:57,041 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@1f9af742{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2024-03-23 11:35:57,060 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:35:57,068 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@4d484961{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2024-03-23 11:35:57,075 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@bf70ce5{HTTP/1.1, (http/1.1)}{0.0.0.0:15003}
2024-03-23 11:35:57,075 [main] INFO  server.Server (Server.java:doStart(415)) - Started @3950ms
2024-03-23 11:35:57,077 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2024-03-23 11:35:57,077 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2024-03-23 11:35:57,078 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of scm listening at http://0.0.0.0:15003
2024-03-23 11:35:57,080 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-23 11:35:57,139 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for OMAudit to [].
2024-03-23 11:35:57,198 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(115)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2024-03-23 11:35:57,201 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(226)) - Configuration does not have ozone.om.address set. Falling back to the default OM address /127.0.0.1:15004
2024-03-23 11:35:57,201 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(254)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2024-03-23 11:35:57,201 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(261)) - OM Node ID is not set. Setting it to the default ID: om1
2024-03-23 11:35:57,205 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-23 11:35:57,208 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = QUOTA (version = 6), software layout = QUOTA (version = 6)
2024-03-23 11:35:57,274 [main] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(113)) - Skipping Upgrade Action QuotaRepairUpgradeAction since it has been finalized.
2024-03-23 11:35:57,276 [main] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(113)) - Skipping Upgrade Action MockOmUpgradeAction since it has been finalized.
2024-03-23 11:35:57,277 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-23 11:35:57,441 [main] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(115)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:15001]
2024-03-23 11:35:57,470 [main] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(115)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:15001]
2024-03-23 11:35:57,631 [main] INFO  om.OzoneManager (OzoneManager.java:<init>(679)) - OM start with adminUsers: [runner]
2024-03-23 11:35:57,644 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-23 11:35:57,661 [main] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(71)) - OmKeyInfo.getCodec ignorePipeline = true
2024-03-23 11:35:57,877 [main] INFO  om.OzoneManager (OzoneManager.java:instantiateServices(813)) - S3 Multi-Tenancy is disabled
2024-03-23 11:35:57,900 [main] INFO  om.OmSnapshotManager (OmSnapshotManager.java:<init>(177)) - Ozone filesystem snapshot feature is enabled.
2024-03-23 11:35:57,907 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.snapshot.diff.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-23 11:35:57,934 [main] INFO  utils.NativeLibraryLoader (NativeLibraryLoader.java:loadLibrary(108)) - Loading Library: ozone_rocksdb_tools
2024-03-23 11:35:57,936 [main] ERROR snapshot.SnapshotDiffManager (SnapshotDiffManager.java:initNativeLibraryForEfficientDiff(287)) - Native Library for raw sst file reading loading failed.
org.apache.hadoop.hdds.utils.NativeLibraryNotLoadedException: Unable to load library ozone_rocksdb_tools from both java.library.path & resource file libozone_rocksdb_tools.so from jar.
	at org.apache.hadoop.hdds.utils.db.managed.ManagedRawSSTFileReader.loadLibrary(ManagedRawSSTFileReader.java:38)
	at org.apache.hadoop.ozone.om.snapshot.SnapshotDiffManager.initNativeLibraryForEfficientDiff(SnapshotDiffManager.java:285)
	at org.apache.hadoop.ozone.om.snapshot.SnapshotDiffManager.<init>(SnapshotDiffManager.java:259)
	at org.apache.hadoop.ozone.om.OmSnapshotManager.<init>(OmSnapshotManager.java:279)
	at org.apache.hadoop.ozone.om.OzoneManager.instantiateServices(OzoneManager.java:865)
	at org.apache.hadoop.ozone.om.OzoneManager.<init>(OzoneManager.java:689)
	at org.apache.hadoop.ozone.om.OzoneManager.createOm(OzoneManager.java:776)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.createOM(MiniOzoneClusterImpl.java:689)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.createAndStartSingleOM(MiniOzoneClusterImpl.java:673)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.build(MiniOzoneClusterImpl.java:535)
	at org.apache.hadoop.ozone.recon.TestReconAndAdminContainerCLI.init(TestReconAndAdminContainerCLI.java:134)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:728)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:156)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptLifecycleMethod(TimeoutExtension.java:128)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptBeforeAllMethod(TimeoutExtension.java:70)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(InterceptingExecutableInvoker.java:103)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:93)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:92)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:86)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeBeforeAllMethods$13(ClassBasedTestDescriptor.java:412)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeBeforeAllMethods(ClassBasedTestDescriptor.java:410)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:216)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:85)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:148)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:198)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:169)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:93)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:58)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:141)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:57)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:103)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:85)
	at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:63)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2024-03-23 11:35:57,982 [main] INFO  om.OzoneManager (OzoneManager.java:addS3GVolumeToDB(4469)) - Created Volume s3v With Owner runner required for S3Gateway operations.
2024-03-23 11:35:58,026 [main] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(311)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2024-03-23 11:35:58,027 [main] WARN  utils.OzoneManagerRatisUtils (OzoneManagerRatisUtils.java:getOMRatisSnapshotDirectory(476)) - ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
2024-03-23 11:35:58,040 [main] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(311)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2024-03-23 11:35:58,056 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(167)) - Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: localhost:15007
2024-03-23 11:35:58,061 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:35:58,063 [main] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:loadSnapshotInfoFromDB(589)) - TransactionInfo not found in OM DB.
2024-03-23 11:35:58,106 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-03-23 11:35:58,112 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-03-23 11:35:58,112 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.port = 15007 (fallback to raft.grpc.server.port)
2024-03-23 11:35:58,113 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-03-23 11:35:58,113 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.port = 15007 (fallback to raft.grpc.server.port)
2024-03-23 11:35:58,113 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-03-23 11:35:58,114 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15007 (custom)
2024-03-23 11:35:58,195 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 4194304 (custom)
2024-03-23 11:35:58,198 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2024-03-23 11:35:58,198 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2024-03-23 11:35:58,199 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2024-03-23 11:35:58,208 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-23 11:35:58,211 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-03-23 11:35:58,212 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-03-23 11:35:58,353 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2024-03-23 11:35:58,355 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:35:58,355 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-03-23 11:35:58,355 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:35:58,357 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/ratis] (custom)
2024-03-23 11:35:58,358 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-03-23 11:35:58,358 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-03-23 11:35:58,363 [main] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - om1: addNew group-C5BA1605619E:[om1|localhost:15007] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@3ac18a9e[Not completed]
2024-03-23 11:35:58,363 [main] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(2174)) - OzoneManager Ratis server initialized at port 15007
2024-03-23 11:35:58,366 [main] INFO  om.OzoneManager (OzoneManager.java:getRpcServer(1233)) - Creating RPC Server
2024-03-23 11:35:58,378 [om1-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - om1: new RaftServerImpl for group-C5BA1605619E:[om1|localhost:15007] with OzoneManagerStateMachine:uninitialized
2024-03-23 11:35:58,381 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2024-03-23 11:35:58,382 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 1200ms (custom)
2024-03-23 11:35:58,382 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-23 11:35:58,383 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2024-03-23 11:35:58,383 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:35:58,383 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-23 11:35:58,388 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:35:58,394 [om1-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - om1@group-C5BA1605619E: ConfigurationManager, init=-1: peers:[om1|localhost:15007]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-23 11:35:58,407 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 120s (custom)
2024-03-23 11:35:58,410 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-23 11:35:58,414 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 300s (custom)
2024-03-23 11:35:58,414 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-23 11:35:58,418 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-23 11:35:58,419 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-23 11:35:58,490 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2024-03-23 11:35:58,492 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:35:58,493 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-23 11:35:58,493 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-23 11:35:58,494 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-23 11:35:58,494 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-23 11:35:58,937 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-23 11:35:58,938 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 127.0.0.1:15004
2024-03-23 11:35:58,938 [Socket Reader #1 for port 15004] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15004
2024-03-23 11:35:58,963 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2024-03-23 11:35:58,974 [main] INFO  om.OzoneManager (OzoneManager.java:start(1655)) - OzoneManager RPC server is listening at localhost/127.0.0.1:15004
2024-03-23 11:35:58,975 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(588)) - Starting OzoneManagerRatisServer om1 at port 15007
2024-03-23 11:35:58,977 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-23 11:35:58,978 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-23 11:35:58,978 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/ratis] (custom)
2024-03-23 11:35:58,982 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2024-03-23 11:35:58,985 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 18969@fv-az1381-309
2024-03-23 11:35:58,990 [om1-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2024-03-23 11:35:58,991 [om1-impl-thread1] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/raft-meta.conf
2024-03-23 11:35:58,993 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-23 11:35:58,999 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-23 11:35:58,999 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2024-03-23 11:35:59,001 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-23 11:35:59,001 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-23 11:35:59,005 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2024-03-23 11:35:59,009 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-23 11:35:59,010 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-23 11:35:59,010 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2024-03-23 11:35:59,011 [om1-impl-thread1] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[om1@group-C5BA1605619E-cacheEviction-AwaitToRun,5,main] started
2024-03-23 11:35:59,014 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2024-03-23 11:35:59,014 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2024-03-23 11:35:59,015 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2024-03-23 11:35:59,016 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2024-03-23 11:35:59,016 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-23 11:35:59,016 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-23 11:35:59,017 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-23 11:35:59,017 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-23 11:35:59,018 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2024-03-23 11:35:59,019 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 4194312 (custom)
2024-03-23 11:35:59,021 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2024-03-23 11:35:59,021 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-23 11:35:59,021 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-23 11:35:59,022 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2024-03-23 11:35:59,026 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-23 11:35:59,026 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-23 11:35:59,027 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - om1@group-C5BA1605619E: start as a follower, conf=-1: peers:[om1|localhost:15007]|listeners:[], old=null
2024-03-23 11:35:59,027 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-23 11:35:59,029 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-FollowerState
2024-03-23 11:35:59,029 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 1s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:35:59,030 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2024-03-23 11:35:59,031 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 1200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:35:59,032 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-23 11:35:59,033 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-23 11:35:59,033 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2024-03-23 11:35:59,033 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2024-03-23 11:35:59,034 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = true (custom)
2024-03-23 11:35:59,037 [main] INFO  server.RaftServer (RaftServerProxy.java:startImpl(406)) - om1: start RPC server
2024-03-23 11:35:59,061 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:35:59,070 [main] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - om1: GrpcService started, listening on 15007
2024-03-23 11:35:59,070 [JvmPauseMonitor1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-om1: Started
2024-03-23 11:35:59,071 [main] INFO  om.OzoneManager (OzoneManager.java:start(1671)) - Version File has different layout version (6) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
2024-03-23 11:35:59,093 [main] INFO  client.ScmTopologyClient (ScmTopologyClient.java:start(67)) - Initial network topology fetched from SCM: /.
2024-03-23 11:35:59,108 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for ozoneManager at: http://0.0.0.0:15005
2024-03-23 11:35:59,108 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-23 11:35:59,110 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-03-23 11:35:59,110 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.ozoneManager is not defined
2024-03-23 11:35:59,112 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-23 11:35:59,113 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2024-03-23 11:35:59,114 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-23 11:35:59,114 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-23 11:35:59,117 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of ozoneManager uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/webserver
2024-03-23 11:35:59,120 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15005
2024-03-23 11:35:59,120 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-03-23 11:35:59,122 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-03-23 11:35:59,122 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-03-23 11:35:59,123 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2024-03-23 11:35:59,123 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@74300dba{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-03-23 11:35:59,124 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2bb800b5{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2024-03-23 11:35:59,128 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@1eae624e{ozoneManager,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2024-03-23 11:35:59,129 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@5418be12{HTTP/1.1, (http/1.1)}{0.0.0.0:15005}
2024-03-23 11:35:59,129 [main] INFO  server.Server (Server.java:doStart(415)) - Started @6005ms
2024-03-23 11:35:59,130 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-03-23 11:35:59,130 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of ozoneManager listening at http://0.0.0.0:15005
2024-03-23 11:35:59,131 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-03-23 11:35:59,131 [IPC Server listener on 15004] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15004: starting
2024-03-23 11:35:59,145 [main] INFO  om.OzoneManager (OzoneManager.java:startTrashEmptier(2127)) - Trash Interval set to 0. Files deleted won't move to trash
2024-03-23 11:35:59,225 [main] INFO  db.CodecBuffer (CodecBuffer.java:set(63)) - Successfully set constructor to org.apache.hadoop.hdds.utils.db.CodecBuffer$$Lambda$950/1008036274@45d46151
2024-03-23 11:35:59,324 [main] INFO  recon.ReconServer (StringUtils.java:startupShutdownMessage(132)) - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ReconServer
STARTUP_MSG:   host = fv-az1381-309/10.1.0.5
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.5.0-SNAPSHOT
STARTUP_MSG:   classpath = /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/classes:/home/runner/.m2/repository/org/apache/ozone/ozone-common/1.5.0-SNAPSHOT/ozone-common-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/grpc/grpc-netty/1.58.0/grpc-netty-1.58.0.jar:/home/runner/.m2/repository/io/grpc/grpc-core/1.58.0/grpc-core-1.58.0.jar:/home/runner/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/runner/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.23/animal-sniffer-annotations-1.23.jar:/home/runner/.m2/repository/io/grpc/grpc-context/1.58.0/grpc-context-1.58.0.jar:/home/runner/.m2/repository/io/grpc/grpc-util/1.58.0/grpc-util-1.58.0.jar:/home/runner/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/runner/.m2/repository/io/perfmark/perfmark-api/0.26.0/perfmark-api-0.26.0.jar:/home/runner/.m2/repository/io/netty/netty-codec-http2/4.1.100.Final/netty-codec-http2-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-common/4.1.100.Final/netty-common-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-buffer/4.1.100.Final/netty-buffer-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.100.Final/netty-codec-http-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-proxy/4.1.100.Final/netty-handler-proxy-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-socks/4.1.100.Final/netty-codec-socks-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-classes/2.0.61.Final/netty-tcnative-classes-2.0.61.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-linux-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-osx-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-windows-x86_64.jar:/home/runner/.m2/repository/org/apache/commons/commons-compress/1.26.0/commons-compress-1.26.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.5.0-SNAPSHOT/hdds-common-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-client/1.5.0-SNAPSHOT/hdds-client-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-client/1.5.0-SNAPSHOT/ozone-interface-client-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.3.6/hadoop-hdfs-client-3.3.6.jar:/home/runner/.m2/repository/com/squareup/okhttp3/okhttp/4.12.0/okhttp-4.12.0.jar:/home/runner/.m2/repository/com/squareup/okio/okio/3.6.0/okio-3.6.0.jar:/home/runner/.m2/repository/com/squareup/okio/okio-jvm/3.6.0/okio-jvm-3.6.0.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-jdk8/1.9.22/kotlin-stdlib-jdk8-1.9.22.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-jdk7/1.9.22/kotlin-stdlib-jdk7-1.9.22.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.9.22/kotlin-stdlib-common-1.9.22.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-test-utils/1.5.0-SNAPSHOT/hdds-test-utils-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/assertj/assertj-core/3.12.2/assertj-core-3.12.2.jar:/home/runner/.m2/repository/com/google/guava/guava/32.0.0-jre/guava-32.0.0-jre.jar:/home/runner/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/runner/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/runner/.m2/repository/org/checkerframework/checker-qual/3.33.0/checker-qual-3.33.0.jar:/home/runner/.m2/repository/com/google/j2objc/j2objc-annotations/2.8/j2objc-annotations-2.8.jar:/home/runner/.m2/repository/commons-io/commons-io/2.15.1/commons-io-2.15.1.jar:/home/runner/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.10.2/junit-jupiter-api-5.10.2.jar:/home/runner/.m2/repository/org/opentest4j/opentest4j/1.3.0/opentest4j-1.3.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-commons/1.10.2/junit-platform-commons-1.10.2.jar:/home/runner/.m2/repository/ch/qos/reload4j/reload4j/1.2.25/reload4j-1.2.25.jar:/home/runner/.m2/repository/jakarta/annotation/jakarta.annotation-api/2.1.1/jakarta.annotation-api-2.1.1.jar:/home/runner/.m2/repository/org/slf4j/slf4j-api/2.0.12/slf4j-api-2.0.12.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-api/2.17.1/log4j-api-2.17.1.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.5.0-SNAPSHOT/hdds-server-scm-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-server/1.5.0-SNAPSHOT/hdds-hadoop-dependency-server-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.6/hadoop-hdfs-3.3.6.jar:/home/runner/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.10.5/snappy-java-1.1.10.5.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.5.0-SNAPSHOT/hdds-server-framework-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/bouncycastle/bcprov-jdk18on/1.77/bcprov-jdk18on-1.77.jar:/home/runner/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-text/1.11.0/commons-text-1.11.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.5.0-SNAPSHOT/hdds-server-framework-1.5.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-server/1.5.0-SNAPSHOT/hdds-interface-server-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-admin/1.5.0-SNAPSHOT/hdds-interface-admin-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-managed-rocksdb/1.5.0-SNAPSHOT/hdds-managed-rocksdb-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/rocksdb/rocksdbjni/7.7.3/rocksdbjni-7.7.3.jar:/home/runner/.m2/repository/org/slf4j/slf4j-reload4j/2.0.12/slf4j-reload4j-2.0.12.jar:/home/runner/.m2/repository/org/apache/commons/commons-configuration2/2.10.1/commons-configuration2-2.10.1.jar:/home/runner/.m2/repository/commons-fileupload/commons-fileupload/1.5/commons-fileupload-1.5.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-core/2.17.1/log4j-core-2.17.1.jar:/home/runner/.m2/repository/com/lmax/disruptor/3.4.4/disruptor-3.4.4.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util/9.4.53.v20231009/jetty-util-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-server/9.4.53.v20231009/jetty-server-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-http/9.4.53.v20231009/jetty-http-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-io/9.4.53.v20231009/jetty-io-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.53.v20231009/jetty-servlet-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-security/9.4.53.v20231009/jetty-security-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.53.v20231009/jetty-util-ajax-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.53.v20231009/jetty-webapp-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.53.v20231009/jetty-xml-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server/3.0.1/ratis-server-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/1.0.5/ratis-thirdparty-misc-1.0.5.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-proto/3.0.1/ratis-proto-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-common/3.0.1/ratis-common-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-client/3.0.1/ratis-client-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server-api/3.0.1/ratis-server-api-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics-api/3.0.1/ratis-metrics-api-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics-dropwizard3/3.0.1/ratis-metrics-dropwizard3-3.0.1.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_dropwizard/0.16.0/simpleclient_dropwizard-0.16.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient/0.16.0/simpleclient-0.16.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_common/0.16.0/simpleclient_common-0.16.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.16.1/jackson-datatype-jsr310-2.16.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.16.1/jackson-core-2.16.1.jar:/home/runner/.m2/repository/org/apache/ozone/rocksdb-checkpoint-differ/1.5.0-SNAPSHOT/rocksdb-checkpoint-differ-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/jgrapht/jgrapht-core/1.4.0/jgrapht-core-1.4.0.jar:/home/runner/.m2/repository/org/jheaps/jheaps/0.11/jheaps-0.11.jar:/home/runner/.m2/repository/org/jgrapht/jgrapht-ext/1.4.0/jgrapht-ext-1.4.0.jar:/home/runner/.m2/repository/com/github/vlsi/mxgraph/jgraphx/3.9.8.1/jgraphx-3.9.8.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.5.0-SNAPSHOT/ozone-manager-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/aspectj/aspectjrt/1.9.7/aspectjrt-1.9.7.jar:/home/runner/.m2/repository/org/aspectj/aspectjweaver/1.9.7/aspectjweaver-1.9.7.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-client/1.5.0-SNAPSHOT/hdds-interface-client-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-protobuf_3_7/1.1.1/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-storage/1.5.0-SNAPSHOT/ozone-interface-storage-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-client/1.19.4/jersey-client-1.19.4.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-intg/2.3.0/ranger-intg-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-common/2.3.0/ranger-plugins-common-2.3.0.jar:/home/runner/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-cred/2.3.0/ranger-plugins-cred-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-audit/2.3.0/ranger-plugins-audit-2.3.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-client/9.4.53.v20231009/jetty-client-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpmime/4.5.6/httpmime-4.5.6.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore-nio/4.4.16/httpcore-nio-4.4.16.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpasyncclient/4.1.3/httpasyncclient-4.1.3.jar:/home/runner/.m2/repository/com/carrotsearch/hppc/0.8.0/hppc-0.8.0.jar:/home/runner/.m2/repository/org/apache/orc/orc-core/1.5.8/orc-core-1.5.8.jar:/home/runner/.m2/repository/net/java/dev/jna/jna/5.2.0/jna-5.2.0.jar:/home/runner/.m2/repository/net/java/dev/jna/jna-platform/5.2.0/jna-platform-5.2.0.jar:/home/runner/.m2/repository/com/kstruct/gethostname4j/0.0.2/gethostname4j-0.0.2.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugin-classloader/2.3.0/ranger-plugin-classloader-2.3.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-rocks-native/1.5.0-SNAPSHOT/hdds-rocks-native-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.3.6/hadoop-minikdc-3.3.6.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/runner/.m2/repository/junit/junit/4.13.2/junit-4.13.2.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-s3gateway/1.5.0-SNAPSHOT/ozone-s3gateway-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/home/runner/.m2/repository/org/jboss/weld/servlet/weld-servlet-shaded/3.1.9.Final/weld-servlet-shaded-3.1.9.Final.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.42/jersey-container-servlet-core-2.42.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-common/2.42/jersey-common-2.42.jar:/home/runner/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.42/jersey-cdi1x-2.42.jar:/home/runner/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.42/jersey-hk2-2.42.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.42/jersey-media-jaxb-2.42.jar:/home/runner/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-api/2.6.1/hk2-api-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-utils/2.6.1/hk2-utils-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.6.1/aopalliance-repackaged-2.6.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.16.1/jackson-dataformat-xml-2.16.1.jar:/home/runner/.m2/repository/org/codehaus/woodstox/stax2-api/4.2.2/stax2-api-4.2.2.jar:/home/runner/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.4.0/woodstox-core-5.4.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.16.1/jackson-module-jaxb-annotations-2.16.1.jar:/home/runner/.m2/repository/javax/enterprise/cdi-api/2.0/cdi-api-2.0.jar:/home/runner/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/runner/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/runner/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/runner/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.3/jakarta.xml.bind-api-2.3.3.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-runtime/2.3.9/jaxb-runtime-2.3.9.jar:/home/runner/.m2/repository/org/glassfish/jaxb/txw2/2.3.9/txw2-2.3.9.jar:/home/runner/.m2/repository/com/sun/istack/istack-commons-runtime/3.0.12/istack-commons-runtime-3.0.12.jar:/home/runner/.m2/repository/com/sun/activation/jakarta.activation/1.2.2/jakarta.activation-1.2.2.jar:/home/runner/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.2/jakarta.activation-api-1.2.2.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf/1.58.0/grpc-protobuf-1.58.0.jar:/home/runner/.m2/repository/com/google/api/grpc/proto-google-common-protos/2.22.0/proto-google-common-protos-2.22.0.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf-lite/1.58.0/grpc-protobuf-lite-1.58.0.jar:/home/runner/.m2/repository/io/grpc/grpc-stub/1.58.0/grpc-stub-1.58.0.jar:/home/runner/.m2/repository/io/netty/netty-transport/4.1.100.Final/netty-transport-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver/4.1.100.Final/netty-resolver-4.1.100.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-csi/1.5.0-SNAPSHOT/ozone-csi-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java-util/3.19.6/protobuf-java-util-3.19.6.jar:/home/runner/.m2/repository/com/google/code/gson/gson/2.9.0/gson-2.9.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-config/1.5.0-SNAPSHOT/hdds-config-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.100.Final/netty-transport-native-epoll-4.1.100.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.100.Final/netty-transport-classes-epoll-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.100.Final/netty-transport-native-unix-common-4.1.100.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.5.0-SNAPSHOT/ozone-recon-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-reconcodegen/1.5.0-SNAPSHOT/ozone-reconcodegen-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/inject/guice/6.0.0/guice-6.0.0.jar:/home/runner/.m2/repository/jakarta/inject/jakarta.inject-api/2.0.1/jakarta.inject-api-2.0.1.jar:/home/runner/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-assistedinject/6.0.0/guice-assistedinject-6.0.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-servlet/6.0.0/guice-servlet-6.0.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.42/jersey-container-servlet-2.42.jar:/home/runner/.m2/repository/org/glassfish/hk2/guice-bridge/2.6.1/guice-bridge-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-server/2.42/jersey-server-2.42.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-client/2.42/jersey-client-2.42.jar:/home/runner/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.42/jersey-media-json-jackson-2.42.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.42/jersey-entity-filtering-2.42.jar:/home/runner/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/runner/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/runner/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/runner/.m2/repository/org/xerial/sqlite-jdbc/3.44.1.0/sqlite-jdbc-3.44.1.0.jar:/home/runner/.m2/repository/org/springframework/spring-jdbc/5.3.27/spring-jdbc-5.3.27.jar:/home/runner/.m2/repository/org/springframework/spring-beans/5.3.27/spring-beans-5.3.27.jar:/home/runner/.m2/repository/org/springframework/spring-core/5.3.27/spring-core-5.3.27.jar:/home/runner/.m2/repository/org/springframework/spring-tx/5.3.27/spring-tx-5.3.27.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-client/1.5.0-SNAPSHOT/ozone-client-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-erasurecode/1.5.0-SNAPSHOT/hdds-erasurecode-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem/1.5.0-SNAPSHOT/ozone-filesystem-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem-common/1.5.0-SNAPSHOT/ozone-filesystem-common-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-tools/1.5.0-SNAPSHOT/ozone-tools-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-core/1.12.661/aws-java-sdk-core-1.12.661.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpclient/4.5.14/httpclient-4.5.14.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore/4.4.16/httpcore-4.4.16.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.16.1/jackson-dataformat-cbor-2.16.1.jar:/home/runner/.m2/repository/joda-time/joda-time/2.12.7/joda-time-2.12.7.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.12.661/aws-java-sdk-s3-1.12.661.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.12.661/aws-java-sdk-kms-1.12.661.jar:/home/runner/.m2/repository/com/amazonaws/jmespath-java/1.12.661/jmespath-java-1.12.661.jar:/home/runner/.m2/repository/org/kohsuke/metainf-services/metainf-services/1.11/metainf-services-1.11.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-tools/1.5.0-SNAPSHOT/hdds-tools-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-tools/3.0.1/ratis-tools-3.0.1.jar:/home/runner/.m2/repository/commons-cli/commons-cli/1.6.0/commons-cli-1.6.0.jar:/home/runner/.m2/repository/org/apache/commons/commons-lang3/3.14.0/commons-lang3-3.14.0.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.5.0-SNAPSHOT/ozone-manager-1.5.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.5.0-SNAPSHOT/hdds-common-1.5.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-client/1.5.0-SNAPSHOT/hdds-hadoop-dependency-client-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/info/picocli/picocli/4.7.5/picocli-4.7.5.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.16.1/jackson-annotations-2.16.1.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-annotation-processing/1.5.0-SNAPSHOT/hdds-annotation-processing-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-netty/3.0.1/ratis-netty-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-grpc/3.0.1/ratis-grpc-3.0.1.jar:/home/runner/.m2/repository/org/bouncycastle/bcpkix-jdk18on/1.77/bcpkix-jdk18on-1.77.jar:/home/runner/.m2/repository/org/bouncycastle/bcutil-jdk18on/1.77/bcutil-jdk18on-1.77.jar:/home/runner/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/runner/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/runner/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/runner/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-client/1.8.1/jaeger-client-1.8.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-thrift/1.8.1/jaeger-thrift-1.8.1.jar:/home/runner/.m2/repository/org/apache/thrift/libthrift/0.15.0/libthrift-0.15.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-core/1.8.1/jaeger-core-1.8.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.8.1/jaeger-tracerresolver-1.8.1.jar:/home/runner/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.9.22/kotlin-stdlib-1.9.22.jar:/home/runner/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/runner/.m2/repository/org/yaml/snakeyaml/2.0/snakeyaml-2.0.jar:/home/runner/.m2/repository/io/grpc/grpc-api/1.58.0/grpc-api-1.58.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-launcher/1.10.2/junit-platform-launcher-1.10.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-engine/1.10.2/junit-platform-engine-1.10.2.jar:/home/runner/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.6/hadoop-kms-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-auth/3.3.6/hadoop-auth-3.3.6.jar:/home/runner/.m2/repository/com/nimbusds/nimbus-jose-jwt/9.8.1/nimbus-jose-jwt-9.8.1.jar:/home/runner/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper/3.8.4/zookeeper-3.8.4.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.8.4/zookeeper-jute-3.8.4.jar:/home/runner/.m2/repository/org/apache/yetus/audience-annotations/0.12.0/audience-annotations-0.12.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.1.1/hadoop-shaded-guava-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-core/1.19.4/jersey-core-1.19.4.jar:/home/runner/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-server/1.19.4/jersey-server-1.19.4.jar:/home/runner/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.6/hadoop-common-3.3.6.jar:/home/runner/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/runner/.m2/repository/commons-net/commons-net/3.10.0/commons-net-3.10.0.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-servlet/1.19.4/jersey-servlet-1.19.4.jar:/home/runner/.m2/repository/com/github/pjfanning/jersey-json/1.20/jersey-json-1.20.jar:/home/runner/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/runner/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/runner/.m2/repository/com/google/re2j/re2j/1.7/re2j-1.7.jar:/home/runner/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/runner/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-recipes/5.2.0/curator-recipes-5.2.0.jar:/home/runner/.m2/repository/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/runner/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.16.1/jackson-databind-2.16.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.6/hadoop-kms-3.3.6-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.5.0-SNAPSHOT/hdds-server-scm-1.5.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/com/github/luben/zstd-jni/1.5.2-5/zstd-jni-1.5.2-5.jar:/home/runner/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/runner/.m2/repository/io/netty/netty-codec/4.1.100.Final/netty-codec-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler/4.1.100.Final/netty-handler-4.1.100.Final.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-test/1.5.0-SNAPSHOT/hdds-hadoop-dependency-test-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.6/hadoop-common-3.3.6-tests.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.6/hadoop-hdfs-3.3.6-tests.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.10.2/junit-jupiter-engine-5.10.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.10.2/junit-jupiter-params-5.10.2.jar:/home/runner/.m2/repository/org/mockito/mockito-core/4.11.0/mockito-core-4.11.0.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy/1.12.19/byte-buddy-1.12.19.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy-agent/1.12.19/byte-buddy-agent-1.12.19.jar:/home/runner/.m2/repository/org/objenesis/objenesis/3.3/objenesis-3.3.jar:/home/runner/.m2/repository/org/mockito/mockito-junit-jupiter/4.11.0/mockito-junit-jupiter-4.11.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.6/hadoop-distcp-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.3.6/hadoop-mapreduce-client-jobclient-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.3.6/hadoop-mapreduce-client-common-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.3.6/hadoop-yarn-common-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.3.6/hadoop-yarn-api-3.3.6.jar:/home/runner/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/runner/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19.4/jersey-guice-1.19.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.16.1/jackson-jaxrs-json-provider-2.16.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.16.1/jackson-jaxrs-base-2.16.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.3.6/hadoop-yarn-client-3.3.6.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.4.51.v20230217/websocket-client-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.4.51.v20230217/websocket-common-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.4.51.v20230217/websocket-api-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/jline/jline/3.9.0/jline-3.9.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.3.6/hadoop-mapreduce-client-core-3.3.6.jar:/home/runner/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/runner/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-annotations/3.3.6/hadoop-annotations-3.3.6.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/../lib/tools.jar:/home/runner/.m2/repository/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.6/hadoop-distcp-3.3.6-tests.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest/2.2/hamcrest-2.2.jar:/home/runner/.m2/repository/org/slf4j/jul-to-slf4j/2.0.12/jul-to-slf4j-2.0.12.jar:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/gradle-enterprise/test-listeners.jar:
STARTUP_MSG:   build = https://github.com/apache/ozone/44493ef76017b88f2b07ac9f4b5dae3ecb20187b ; compiled by 'runner' on 2024-03-23T11:12Z
STARTUP_MSG:   java = 1.8.0_402
STARTUP_MSG:   conf = {hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=false, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.chunk.write.sync=false, hdds.container.close.threshold=0.9f, hdds.container.ipc.port=9859, hdds.container.ipc.random.port=false, hdds.container.ratis.admin.port=9857, hdds.container.ratis.datastream.enabled=true, hdds.container.ratis.datastream.port=9855, hdds.container.ratis.datastream.random.port=false, hdds.container.ratis.enabled=false, hdds.container.ratis.ipc.port=9858, hdds.container.ratis.ipc.random.port=false, hdds.container.ratis.leader.pending.bytes.limit=1GB, hdds.container.ratis.log.appender.queue.byte-limit=8MB, hdds.container.ratis.log.appender.queue.num-elements=1, hdds.container.ratis.log.purge.gap=1000000, hdds.container.ratis.log.queue.byte-limit=4GB, hdds.container.ratis.log.queue.num-elements=1024, hdds.container.ratis.num.container.op.executors=10, hdds.container.ratis.num.write.chunk.threads.per.volume=4, hdds.container.ratis.replication.level=MAJORITY, hdds.container.ratis.rpc.type=GRPC, hdds.container.ratis.segment.preallocated.size=4MB, hdds.container.ratis.segment.size=64MB, hdds.container.ratis.server.port=9856, hdds.container.ratis.statemachine.max.pending.apply-transactions=10000, hdds.container.ratis.statemachinedata.sync.timeout=10s, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=true, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=false, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.factory.classname=org.apache.hadoop.hdds.fs.MockSpaceUsageCheckFactory$None, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.datanode.http.auth.type=simple, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.replication.zerocopy.enabled=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.slow.op.warning.threshold=500ms, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=5GB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=false, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=1s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.leader.election.minimum.timeout.duration=5s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.ratis.server.retry-cache.timeout.duration=600000ms, hdds.ratis.snapshot.threshold=10000, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.scm.http.auth.type=simple, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/SCM.keytab, hdds.scm.kerberos.principal=SCM/_HOST@REALM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=1, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=10m, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneAccessAuthorizer, ozone.acl.enabled=false, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=4MB, ozone.client.datastream.min.packet.size=256KB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=8MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.reconstruct.stripe.write.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.max.retries=3, ozone.client.read.retry.interval=1, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=1MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=2MB, ozone.client.stream.buffer.size=1MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.csi.default-volume-size=1000000000, ozone.csi.mount.command=goofys --endpoint %s %s %s, ozone.csi.s3g.address=http://localhost:9878, ozone.csi.socket=/var/lib/csi.sock, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.http.policy=HTTP_ONLY, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=0.0.0.0:9862, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.client.rpc.timeout=15m, ozone.om.client.trash.core.pool.size=5, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.group.rights=ALL, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.port=8981, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.ha.raft.server.log.appender.wait-time.min=0ms, ozone.om.ha.raft.server.retrycache.expirytime=300s, ozone.om.handler.count.key=20, ozone.om.http-address=0.0.0.0:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.om.http.auth.type=simple, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.init.default.layout.version=-1, ozone.om.kerberos.keytab.file=/etc/security/keytabs/OM.keytab, ozone.om.kerberos.principal=OM/_HOST@REALM, ozone.om.kerberos.principal.pattern=*, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.network.topology.refresh.duration=1h, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=4MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.s3.grpc.server_enabled=false, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1s, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.finalization.ratis.based.timeout=30s, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.user.rights=ALL, ozone.om.volume.listall.allowed=true, ozone.path.deleting.limit.per.task=6000, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.recon.http.auth.type=simple, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=10m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.sql.db.auto.commit=true, ozone.recon.sql.db.conn.idle.max.age=3600s, ozone.recon.sql.db.conn.idle.test=SELECT 1, ozone.recon.sql.db.conn.idle.test.period=60s, ozone.recon.sql.db.conn.max.active=5, ozone.recon.sql.db.conn.max.age=1800s, ozone.recon.sql.db.conn.timeout=30000ms, ozone.recon.sql.db.driver=org.apache.derby.jdbc.EmbeddedDriver, ozone.recon.sql.db.jdbc.url=jdbc:derby:${ozone.recon.db.dir}/ozone_recon_derby.db, ozone.recon.sql.db.jooq.dialect=DERBY, ozone.recon.task.containercounttask.interval=60s, ozone.recon.task.missingcontainer.interval=300s, ozone.recon.task.pipelinesync.interval=300s, ozone.recon.task.safemode.wait.threshold=300s, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.s3g.http.auth.type=simple, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/_HOST@REALM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.metrics.percentiles.intervals.seconds=60, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=false, ozone.s3g.volume.name=s3v, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.handler.count.key=100, ozone.scm.block.size=4MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=1MB, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.handler.count.key=100, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=1s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=5GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.handler.count.key=100, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=1GB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=4MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=20, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=100ms, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=120s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=3, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=3, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=false, ozone.security.http.kerberos.enabled=false, ozone.security.reconfigure.protocol.acl=*, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.test.test.key=value1, ozone.xceiver.client.metrics.percentiles.intervals.seconds=60, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256, test.scm.client.address=localhost, test.scm.client.bind.host=0.0.0.0, test.scm.client.class=java.lang.Object, test.scm.client.compression.enabled=true, test.scm.client.duration=1h, test.scm.client.enabled=true, test.scm.client.port=9878, test.scm.client.threshold=10, test.scm.client.wait=30m, yarn.app.mapreduce.am.container.log.backups=0, yarn.app.mapreduce.am.container.log.limit.kb=0, yarn.app.mapreduce.task.container.log.backups=0, yarn.nodemanager.container.stderr.pattern={*stderr*,*STDERR*}, yarn.nodemanager.container.stderr.tail.bytes=4096, yarn.nodemanager.windows-container.cpu-limit.enabled=false, yarn.nodemanager.windows-container.memory-limit.enabled=false, yarn.resourcemanager.container.liveness-monitor.interval-ms=600000}
************************************************************/
2024-03-23 11:35:59,336 [main] INFO  recon.ReconServer (SignalLogger.java:register(90)) - registered UNIX signal handlers for [TERM, HUP, INT]
2024-03-23 11:35:59,715 [main] INFO  recon.ReconServer (ReconServer.java:call(116)) - Initializing Recon server...
2024-03-23 11:35:59,757 [main] INFO  persistence.DefaultDataSourceProvider (DefaultDataSourceProvider.java:get(51)) - JDBC Url for Recon : jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/recon/ozone_recon_derby.db 
2024-03-23 11:36:00,061 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:00,132 [om1@group-C5BA1605619E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1103561840ns, electionTimeout:1100ms
2024-03-23 11:36:00,132 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - om1: shutdown om1@group-C5BA1605619E-FollowerState
2024-03-23 11:36:00,133 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-23 11:36:00,136 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-23 11:36:00,136 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderElection1
2024-03-23 11:36:00,141 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - om1@group-C5BA1605619E-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[om1|localhost:15007]|listeners:[], old=null
2024-03-23 11:36:00,142 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - om1@group-C5BA1605619E-LeaderElection1 PRE_VOTE round 0: result PASSED (term=0)
2024-03-23 11:36:00,143 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - om1@group-C5BA1605619E-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[om1|localhost:15007]|listeners:[], old=null
2024-03-23 11:36:00,143 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - om1@group-C5BA1605619E-LeaderElection1 ELECTION round 0: result PASSED (term=1)
2024-03-23 11:36:00,143 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - om1: shutdown om1@group-C5BA1605619E-LeaderElection1
2024-03-23 11:36:00,144 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-23 11:36:00,150 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-03-23 11:36:00,153 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2024-03-23 11:36:00,154 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2024-03-23 11:36:00,158 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2024-03-23 11:36:00,158 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-03-23 11:36:00,158 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-03-23 11:36:00,163 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-03-23 11:36:00,165 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-23 11:36:00,165 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2024-03-23 11:36:00,166 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2024-03-23 11:36:00,166 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-23 11:36:00,167 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderStateImpl
2024-03-23 11:36:00,167 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - om1@group-C5BA1605619E: set firstElectionSinceStartup to false for becomeLeader
2024-03-23 11:36:00,169 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 1760ms
2024-03-23 11:36:00,195 [om1@group-C5BA1605619E-LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-23 11:36:00,216 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - om1@group-C5BA1605619E: set configuration 0: peers:[om1|localhost:15007]|listeners:[], old=null
2024-03-23 11:36:00,223 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-23 11:36:00,233 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2024-03-23 11:36:00,335 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyConfigurationChanged(212)) - Received Configuration change notification from Ratis. New Peer list:
[id: "om1"
address: "localhost:15007"
startupRole: FOLLOWER
]
2024-03-23 11:36:00,337 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-23 11:36:00,352 [main] INFO  codegen.SqlDbUtils (SqlDbUtils.java:createNewDerbyDatabase(67)) - Created derby database at jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/recon/ozone_recon_derby.db.
2024-03-23 11:36:00,541 [main] INFO  impl.ReconContainerMetadataManagerImpl (ReconContainerMetadataManagerImpl.java:initializeTables(141)) - KEY_CONTAINER Table is empty, initializing from CONTAINER_KEY Table ...
2024-03-23 11:36:00,541 [main] INFO  impl.ReconContainerMetadataManagerImpl (ReconContainerMetadataManagerImpl.java:initializeKeyContainerTable(666)) - It took 0.0 seconds to initialized 0 records to KEY_CONTAINER table
2024-03-23 11:36:00,561 [main] INFO  persistence.DefaultDataSourceProvider (DefaultDataSourceProvider.java:get(51)) - JDBC Url for Recon : jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/recon/ozone_recon_derby.db 
2024-03-23 11:36:00,563 [main] INFO  codegen.SqlDbUtils (SqlDbUtils.java:createNewDerbyDatabase(67)) - Created derby database at jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/recon/ozone_recon_derby.db.
2024-03-23 11:36:00,564 [main] INFO  recon.ReconServer (ReconServer.java:call(140)) - Creating Recon Schema.
2024-03-23 11:36:00,905 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for recon at: http://0.0.0.0:15008
2024-03-23 11:36:00,905 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-23 11:36:00,907 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-03-23 11:36:00,908 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.recon is not defined
2024-03-23 11:36:00,910 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-23 11:36:00,911 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recon
2024-03-23 11:36:00,911 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-23 11:36:00,911 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-23 11:36:00,913 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of recon uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/webserver
2024-03-23 11:36:00,919 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(80)) - Registered task ContainerKeyMapperTask with controller.
2024-03-23 11:36:01,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:01,062 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(80)) - Registered task FileSizeCountTask with controller.
2024-03-23 11:36:01,065 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(80)) - Registered task OmTableInsightTask with controller.
2024-03-23 11:36:01,069 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(80)) - Registered task NSSummaryTask with controller.
2024-03-23 11:36:01,072 [main] INFO  ozone.OmUtils (OmUtils.java:getOzoneManagerServiceId(685)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2024-03-23 11:36:01,073 [main] INFO  ozone.OmUtils (OmUtils.java:getOzoneManagerServiceId(704)) - No OzoneManager ServiceID configured.
2024-03-23 11:36:01,074 [main] INFO  protocolPB.OmTransportFactory (OmTransportFactory.java:createFactory(62)) - Loading OM transport implementation org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory as specified by configuration.
2024-03-23 11:36:01,430 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.5.0-SNAPSHOT/hdds-common-1.5.0-SNAPSHOT.jar!/network-topology-default.xml]
2024-03-23 11:36:01,431 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2024-03-23 11:36:01,518 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-03-23 11:36:01,520 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(241)) - Init the HA SequenceIdGenerator.
2024-03-23 11:36:01,523 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(177)) - Entering startup safe mode.
2024-03-23 11:36:01,524 [main] INFO  scm.ReconNodeManager (ReconNodeManager.java:loadExistingNodes(119)) - Loaded 0 nodes from node DB.
2024-03-23 11:36:01,525 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2024-03-23 11:36:01,526 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-23 11:36:01,526 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15009
2024-03-23 11:36:01,527 [Socket Reader #1 for port 15009] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15009
2024-03-23 11:36:01,530 [main] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2024-03-23 11:36:01,551 [main] INFO  recon.ReconServer (ReconServer.java:call(154)) - Initializing support of Recon Features...
2024-03-23 11:36:01,553 [main] INFO  recon.ReconServer (ReconServer.java:call(156)) - Recon server initialized successfully!
2024-03-23 11:36:01,554 [main] INFO  recon.ReconServer (ReconServer.java:start(211)) - Starting Recon server
2024-03-23 11:36:01,554 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Recon metrics system started (again)
2024-03-23 11:36:01,572 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15008
2024-03-23 11:36:01,573 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-03-23 11:36:01,582 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-03-23 11:36:01,583 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-03-23 11:36:01,583 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2024-03-23 11:36:01,584 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@24111a03{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-03-23 11:36:01,584 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@52c1775c{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.5.0-SNAPSHOT/ozone-recon-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-03-23 11:36:02,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:02,901 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@741fada7{recon,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/webserver/jetty-0_0_0_0-15008-ozone-recon-1_5_0-SNAPSHOT_jar-_-any-1034365287305288349/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.5.0-SNAPSHOT/ozone-recon-1.5.0-SNAPSHOT.jar!/webapps/recon}
2024-03-23 11:36:02,903 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@4af133e4{HTTP/1.1, (http/1.1)}{0.0.0.0:15008}
2024-03-23 11:36:02,904 [main] INFO  server.Server (Server.java:doStart(415)) - Started @9779ms
2024-03-23 11:36:02,904 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-03-23 11:36:02,905 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of recon listening at http://0.0.0.0:15008
2024-03-23 11:36:02,905 [main] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:start(239)) - Starting Ozone Manager Service Provider.
2024-03-23 11:36:02,910 [main] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:registerOMDBTasks(217)) - Registered OmDeltaRequest task 
2024-03-23 11:36:02,912 [main] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:registerOMDBTasks(227)) - Registered OmSnapshotRequest task 
2024-03-23 11:36:02,913 [main] INFO  recovery.ReconOmMetadataManagerImpl (ReconOmMetadataManagerImpl.java:start(82)) - Starting ReconOMMetadataManagerImpl
2024-03-23 11:36:02,913 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:start(222)) - Starting Recon Task Controller.
2024-03-23 11:36:02,914 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:start(388)) - Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:15009
2024-03-23 11:36:03,062 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:03,074 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:initializePipelinesFromScm(488)) - Obtained 0 pipelines from SCM.
2024-03-23 11:36:03,074 [main] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 0 pipelines in house.
2024-03-23 11:36:03,074 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:start(401)) - SCM DB initialized
2024-03-23 11:36:03,075 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(194)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:15009
2024-03-23 11:36:03,076 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-03-23 11:36:03,076 [IPC Server listener on 15009] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15009: starting
2024-03-23 11:36:04,066 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:05,066 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:06,067 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:07,067 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:08,067 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:09,068 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:10,068 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:11,068 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:12,069 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:13,069 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:14,069 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:14,096 [main] INFO  scm.ReconScmTask (ReconScmTask.java:register(46)) - Registered PipelineSyncTask task 
2024-03-23 11:36:14,097 [main] INFO  scm.ReconScmTask (ReconScmTask.java:start(56)) - Starting PipelineSyncTask Thread.
2024-03-23 11:36:14,103 [PipelineSyncTask] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 0 pipelines in house.
2024-03-23 11:36:14,104 [PipelineSyncTask] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 7 milliseconds.
2024-03-23 11:36:14,105 [main] INFO  scm.ReconScmTask (ReconScmTask.java:register(46)) - Registered ContainerHealthTask task 
2024-03-23 11:36:14,106 [main] INFO  scm.ReconScmTask (ReconScmTask.java:start(56)) - Starting ContainerHealthTask Thread.
2024-03-23 11:36:14,110 [main] INFO  scm.ReconScmTask (ReconScmTask.java:register(46)) - Registered ContainerSizeCountTask task 
2024-03-23 11:36:14,110 [main] INFO  scm.ReconScmTask (ReconScmTask.java:start(56)) - Starting ContainerSizeCountTask Thread.
2024-03-23 11:36:14,120 [JvmPauseMonitor2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-Recon: Started
2024-03-23 11:36:14,143 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 35 milliseconds to process 0 existing database records.
2024-03-23 11:36:14,144 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:14,178 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-03-23 11:36:14,178 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-03-23 11:36:14,179 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-03-23 11:36:14,192 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(240)) - HddsDatanodeService host:fv-az1381-309 ip:10.1.0.5
2024-03-23 11:36:14,223 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-03-23 11:36:14,226 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(299)) - Datanode State Machine Task Thread Pool size 2
2024-03-23 11:36:14,289 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(125)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/data-0/hdds of storage type : DISK capacity : 9223372036854775807
2024-03-23 11:36:14,292 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/data-0/hdds to VolumeSet
2024-03-23 11:36:14,295 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis to VolumeSet
2024-03-23 11:36:14,300 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 3ms
2024-03-23 11:36:14,356 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for DNAudit to [].
2024-03-23 11:36:14,389 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-03-23 11:36:14,389 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-03-23 11:36:14,390 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15015 (custom)
2024-03-23 11:36:14,390 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-03-23 11:36:14,390 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15014 (custom)
2024-03-23 11:36:14,390 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-03-23 11:36:14,390 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15016 (custom)
2024-03-23 11:36:14,391 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-03-23 11:36:14,391 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:14,391 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-03-23 11:36:14,391 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:14,391 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-23 11:36:14,392 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-03-23 11:36:14,392 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-03-23 11:36:14,394 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-03-23 11:36:14,409 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-03-23 11:36:14,409 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-03-23 11:36:14,410 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-03-23 11:36:14,411 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-03-23 11:36:14,412 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-03-23 11:36:14,414 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-03-23 11:36:14,414 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-03-23 11:36:14,415 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for e3882025-ee77-4273-a30c-caf156427e83-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-03-23 11:36:14,417 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-03-23 11:36:14,417 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for e3882025-ee77-4273-a30c-caf156427e83-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-03-23 11:36:14,418 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-03-23 11:36:14,419 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-03-23 11:36:14,420 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15017 (custom)
2024-03-23 11:36:14,425 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:36:14,426 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-03-23 11:36:14,426 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:36:14,426 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis] (custom)
2024-03-23 11:36:14,426 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-03-23 11:36:14,427 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-03-23 11:36:14,427 [e3882025-ee77-4273-a30c-caf156427e83-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - e3882025-ee77-4273-a30c-caf156427e83: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/tmp
2024-03-23 11:36:14,428 [e3882025-ee77-4273-a30c-caf156427e83-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(269)) - e3882025-ee77-4273-a30c-caf156427e83: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/tmp is not a group directory; ignoring it. 
2024-03-23 11:36:14,431 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-03-23 11:36:14,437 [e3882025-ee77-4273-a30c-caf156427e83-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x60480bcf] REGISTERED
2024-03-23 11:36:14,437 [e3882025-ee77-4273-a30c-caf156427e83-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x60480bcf] BIND: 0.0.0.0/0.0.0.0:15017
2024-03-23 11:36:14,437 [e3882025-ee77-4273-a30c-caf156427e83-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x60480bcf, L:/0.0.0.0:15017] ACTIVE
2024-03-23 11:36:14,456 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-03-23 11:36:14,523 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(163)) - Initializing replication supervisor with thread count = 10
2024-03-23 11:36:14,524 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(317)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-03-23 11:36:14,568 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15011
2024-03-23 11:36:14,569 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-23 11:36:14,570 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-03-23 11:36:14,571 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-03-23 11:36:14,573 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-23 11:36:14,574 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-03-23 11:36:14,574 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-23 11:36:14,574 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-23 11:36:14,576 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/meta/webserver
2024-03-23 11:36:14,576 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15011
2024-03-23 11:36:14,576 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-03-23 11:36:14,579 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-03-23 11:36:14,579 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-03-23 11:36:14,579 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2024-03-23 11:36:14,580 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7319b3ec{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-03-23 11:36:14,580 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@3156d7ed{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-03-23 11:36:14,615 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@67c19ae2{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/meta/webserver/jetty-0_0_0_0-15011-hdds-container-service-1_5_0-SNAPSHOT_jar-_-any-2278209358545649776/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-03-23 11:36:14,617 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@603588c3{HTTP/1.1, (http/1.1)}{0.0.0.0:15011}
2024-03-23 11:36:14,617 [main] INFO  server.Server (Server.java:doStart(415)) - Started @21492ms
2024-03-23 11:36:14,618 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-03-23 11:36:14,618 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15011
2024-03-23 11:36:14,621 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-23 11:36:14,622 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15012
2024-03-23 11:36:14,622 [Socket Reader #1 for port 15012] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15012
2024-03-23 11:36:14,625 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(327)) - Datanode start with admins: [runner]
2024-03-23 11:36:14,625 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15012
2024-03-23 11:36:14,625 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-03-23 11:36:14,632 [IPC Server listener on 15012] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15012: starting
2024-03-23 11:36:14,634 [e3882025-ee77-4273-a30c-caf156427e83-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(555)) - Ozone container server started.
2024-03-23 11:36:14,635 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-03-23 11:36:14,635 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-03-23 11:36:14,635 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-03-23 11:36:14,672 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(240)) - HddsDatanodeService host:fv-az1381-309 ip:10.1.0.5
2024-03-23 11:36:14,689 [e3882025-ee77-4273-a30c-caf156427e83-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-03-23 11:36:14,689 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-03-23 11:36:14,690 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(299)) - Datanode State Machine Task Thread Pool size 2
2024-03-23 11:36:14,694 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(125)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/data-0/hdds of storage type : DISK capacity : 9223372036854775807
2024-03-23 11:36:14,694 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/data-0/hdds to VolumeSet
2024-03-23 11:36:14,696 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis to VolumeSet
2024-03-23 11:36:14,697 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 0ms
2024-03-23 11:36:14,700 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-03-23 11:36:14,701 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-03-23 11:36:14,701 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15024 (custom)
2024-03-23 11:36:14,701 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-03-23 11:36:14,701 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15023 (custom)
2024-03-23 11:36:14,702 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-03-23 11:36:14,702 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15025 (custom)
2024-03-23 11:36:14,702 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-03-23 11:36:14,702 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:14,702 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-03-23 11:36:14,703 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:14,703 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-23 11:36:14,703 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-03-23 11:36:14,704 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-03-23 11:36:14,706 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-03-23 11:36:14,706 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-03-23 11:36:14,707 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-03-23 11:36:14,707 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-03-23 11:36:14,707 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-03-23 11:36:14,708 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-03-23 11:36:14,708 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-03-23 11:36:14,708 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-03-23 11:36:14,708 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 5b4c27d6-a533-4766-a648-a869ad76920c-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-03-23 11:36:14,709 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-03-23 11:36:14,709 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 5b4c27d6-a533-4766-a648-a869ad76920c-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-03-23 11:36:14,710 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-03-23 11:36:14,710 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-03-23 11:36:14,710 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15026 (custom)
2024-03-23 11:36:14,711 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:36:14,714 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-03-23 11:36:14,714 [5b4c27d6-a533-4766-a648-a869ad76920c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xbebc860f] REGISTERED
2024-03-23 11:36:14,714 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:36:14,715 [5b4c27d6-a533-4766-a648-a869ad76920c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xbebc860f] BIND: 0.0.0.0/0.0.0.0:15026
2024-03-23 11:36:14,715 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis] (custom)
2024-03-23 11:36:14,715 [5b4c27d6-a533-4766-a648-a869ad76920c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xbebc860f, L:/0.0.0.0:15026] ACTIVE
2024-03-23 11:36:14,715 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-03-23 11:36:14,716 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-03-23 11:36:14,720 [5b4c27d6-a533-4766-a648-a869ad76920c-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - 5b4c27d6-a533-4766-a648-a869ad76920c: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/tmp
2024-03-23 11:36:14,720 [5b4c27d6-a533-4766-a648-a869ad76920c-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(269)) - 5b4c27d6-a533-4766-a648-a869ad76920c: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/tmp is not a group directory; ignoring it. 
2024-03-23 11:36:14,721 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-03-23 11:36:14,722 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-03-23 11:36:14,729 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(163)) - Initializing replication supervisor with thread count = 10
2024-03-23 11:36:14,729 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(317)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-03-23 11:36:14,735 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15020
2024-03-23 11:36:14,735 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-23 11:36:14,737 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-03-23 11:36:14,738 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-03-23 11:36:14,739 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-23 11:36:14,740 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-03-23 11:36:14,740 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-23 11:36:14,741 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-23 11:36:14,742 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/meta/webserver
2024-03-23 11:36:14,742 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15020
2024-03-23 11:36:14,742 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-03-23 11:36:14,751 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-03-23 11:36:14,751 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-03-23 11:36:14,752 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2024-03-23 11:36:14,753 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@238142bd{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-03-23 11:36:14,753 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@5cc6e13{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-03-23 11:36:14,763 [e3882025-ee77-4273-a30c-caf156427e83-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/meta/datanode.id
2024-03-23 11:36:14,803 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@160cfa74{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/meta/webserver/jetty-0_0_0_0-15020-hdds-container-service-1_5_0-SNAPSHOT_jar-_-any-185510827312314194/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-03-23 11:36:14,805 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@6c40eb48{HTTP/1.1, (http/1.1)}{0.0.0.0:15020}
2024-03-23 11:36:14,806 [main] INFO  server.Server (Server.java:doStart(415)) - Started @21681ms
2024-03-23 11:36:14,806 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-03-23 11:36:14,807 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15020
2024-03-23 11:36:14,808 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-23 11:36:14,808 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15021
2024-03-23 11:36:14,809 [Socket Reader #1 for port 15021] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15021
2024-03-23 11:36:14,814 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(327)) - Datanode start with admins: [runner]
2024-03-23 11:36:14,814 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15021
2024-03-23 11:36:14,815 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-03-23 11:36:14,815 [IPC Server listener on 15021] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15021: starting
2024-03-23 11:36:14,815 [5b4c27d6-a533-4766-a648-a869ad76920c-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(555)) - Ozone container server started.
2024-03-23 11:36:14,816 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-03-23 11:36:14,816 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-03-23 11:36:14,816 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-03-23 11:36:14,826 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(240)) - HddsDatanodeService host:fv-az1381-309 ip:10.1.0.5
2024-03-23 11:36:14,838 [5b4c27d6-a533-4766-a648-a869ad76920c-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-03-23 11:36:14,853 [5b4c27d6-a533-4766-a648-a869ad76920c-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/meta/datanode.id
2024-03-23 11:36:14,855 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-03-23 11:36:14,856 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(299)) - Datanode State Machine Task Thread Pool size 2
2024-03-23 11:36:14,863 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(125)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/data-0/hdds of storage type : DISK capacity : 9223372036854775807
2024-03-23 11:36:14,864 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/data-0/hdds to VolumeSet
2024-03-23 11:36:14,866 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis to VolumeSet
2024-03-23 11:36:14,866 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 0ms
2024-03-23 11:36:14,870 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-03-23 11:36:14,870 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-03-23 11:36:14,871 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15033 (custom)
2024-03-23 11:36:14,871 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-03-23 11:36:14,871 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15032 (custom)
2024-03-23 11:36:14,871 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-03-23 11:36:14,872 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15034 (custom)
2024-03-23 11:36:14,872 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-03-23 11:36:14,872 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:14,872 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-03-23 11:36:14,873 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:14,873 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-23 11:36:14,875 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-03-23 11:36:14,875 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-03-23 11:36:14,880 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-03-23 11:36:14,880 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-03-23 11:36:14,880 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-03-23 11:36:14,881 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-03-23 11:36:14,881 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-03-23 11:36:14,881 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-03-23 11:36:14,881 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-03-23 11:36:14,882 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-03-23 11:36:14,882 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 00b25173-7757-4760-98a7-1e1aa18d5e2d-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-03-23 11:36:14,882 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-03-23 11:36:14,883 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 00b25173-7757-4760-98a7-1e1aa18d5e2d-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-03-23 11:36:14,883 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-03-23 11:36:14,883 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-03-23 11:36:14,884 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15035 (custom)
2024-03-23 11:36:14,884 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:36:14,885 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-03-23 11:36:14,885 [00b25173-7757-4760-98a7-1e1aa18d5e2d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xf876a6fc] REGISTERED
2024-03-23 11:36:14,886 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:36:14,886 [00b25173-7757-4760-98a7-1e1aa18d5e2d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xf876a6fc] BIND: 0.0.0.0/0.0.0.0:15035
2024-03-23 11:36:14,886 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis] (custom)
2024-03-23 11:36:14,886 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-03-23 11:36:14,886 [00b25173-7757-4760-98a7-1e1aa18d5e2d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xf876a6fc, L:/0.0.0.0:15035] ACTIVE
2024-03-23 11:36:14,887 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-03-23 11:36:14,887 [00b25173-7757-4760-98a7-1e1aa18d5e2d-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/tmp
2024-03-23 11:36:14,887 [00b25173-7757-4760-98a7-1e1aa18d5e2d-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(269)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/tmp is not a group directory; ignoring it. 
2024-03-23 11:36:14,888 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-03-23 11:36:14,889 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-03-23 11:36:14,893 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(163)) - Initializing replication supervisor with thread count = 10
2024-03-23 11:36:14,893 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(317)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-03-23 11:36:14,895 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15029
2024-03-23 11:36:14,895 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-23 11:36:14,897 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-03-23 11:36:14,900 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-03-23 11:36:14,902 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-23 11:36:14,903 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-03-23 11:36:14,903 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-23 11:36:14,903 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-23 11:36:14,904 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/meta/webserver
2024-03-23 11:36:14,904 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15029
2024-03-23 11:36:14,904 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-03-23 11:36:14,906 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-03-23 11:36:14,906 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-03-23 11:36:14,906 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2024-03-23 11:36:14,907 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2cedfe5c{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-03-23 11:36:14,907 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7ed49246{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-03-23 11:36:14,942 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@2fa64353{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/meta/webserver/jetty-0_0_0_0-15029-hdds-container-service-1_5_0-SNAPSHOT_jar-_-any-297398572144901109/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-03-23 11:36:14,944 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@714a1a49{HTTP/1.1, (http/1.1)}{0.0.0.0:15029}
2024-03-23 11:36:14,944 [main] INFO  server.Server (Server.java:doStart(415)) - Started @21819ms
2024-03-23 11:36:14,944 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-03-23 11:36:14,945 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15029
2024-03-23 11:36:14,945 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-23 11:36:14,945 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15030
2024-03-23 11:36:14,946 [Socket Reader #1 for port 15030] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15030
2024-03-23 11:36:14,948 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(327)) - Datanode start with admins: [runner]
2024-03-23 11:36:14,948 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15030
2024-03-23 11:36:14,949 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-03-23 11:36:14,949 [IPC Server listener on 15030] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15030: starting
2024-03-23 11:36:14,954 [00b25173-7757-4760-98a7-1e1aa18d5e2d-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(555)) - Ozone container server started.
2024-03-23 11:36:14,954 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-03-23 11:36:14,955 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-03-23 11:36:14,955 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-03-23 11:36:14,957 [00b25173-7757-4760-98a7-1e1aa18d5e2d-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-03-23 11:36:14,960 [00b25173-7757-4760-98a7-1e1aa18d5e2d-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/meta/datanode.id
2024-03-23 11:36:14,967 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(240)) - HddsDatanodeService host:fv-az1381-309 ip:10.1.0.5
2024-03-23 11:36:14,985 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-03-23 11:36:14,985 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(299)) - Datanode State Machine Task Thread Pool size 2
2024-03-23 11:36:14,988 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(125)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/data-0/hdds of storage type : DISK capacity : 9223372036854775807
2024-03-23 11:36:14,988 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/data-0/hdds to VolumeSet
2024-03-23 11:36:14,989 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis to VolumeSet
2024-03-23 11:36:14,989 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 0ms
2024-03-23 11:36:14,992 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-03-23 11:36:14,992 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-03-23 11:36:14,993 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15042 (custom)
2024-03-23 11:36:14,993 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-03-23 11:36:14,993 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15041 (custom)
2024-03-23 11:36:14,993 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-03-23 11:36:14,993 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15043 (custom)
2024-03-23 11:36:14,994 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-03-23 11:36:14,994 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:14,994 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-03-23 11:36:14,994 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:14,995 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-23 11:36:14,995 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-03-23 11:36:14,995 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-03-23 11:36:14,997 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-03-23 11:36:14,997 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-03-23 11:36:14,997 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-03-23 11:36:14,998 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-03-23 11:36:14,998 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-03-23 11:36:14,998 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-03-23 11:36:14,998 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-03-23 11:36:14,998 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-03-23 11:36:14,999 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for bb4f2f6f-344d-4a57-aba3-69abe2cb722c-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-03-23 11:36:14,999 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-03-23 11:36:15,000 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for bb4f2f6f-344d-4a57-aba3-69abe2cb722c-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-03-23 11:36:15,000 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-03-23 11:36:15,000 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-03-23 11:36:15,001 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15044 (custom)
2024-03-23 11:36:15,001 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:36:15,002 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa90e0545] REGISTERED
2024-03-23 11:36:15,003 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-03-23 11:36:15,003 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa90e0545] BIND: 0.0.0.0/0.0.0.0:15044
2024-03-23 11:36:15,003 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:36:15,003 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa90e0545, L:/0.0.0.0:15044] ACTIVE
2024-03-23 11:36:15,003 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis] (custom)
2024-03-23 11:36:15,004 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-03-23 11:36:15,004 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-03-23 11:36:15,004 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis/tmp
2024-03-23 11:36:15,005 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(269)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis/tmp is not a group directory; ignoring it. 
2024-03-23 11:36:15,005 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-03-23 11:36:15,006 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-03-23 11:36:15,008 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(163)) - Initializing replication supervisor with thread count = 10
2024-03-23 11:36:15,009 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(317)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-03-23 11:36:15,011 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15038
2024-03-23 11:36:15,011 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-23 11:36:15,013 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-03-23 11:36:15,015 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-03-23 11:36:15,016 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-23 11:36:15,017 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-03-23 11:36:15,018 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-23 11:36:15,018 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-23 11:36:15,019 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/meta/webserver
2024-03-23 11:36:15,019 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15038
2024-03-23 11:36:15,019 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-03-23 11:36:15,020 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-03-23 11:36:15,021 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-03-23 11:36:15,021 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2024-03-23 11:36:15,022 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@38f4a5f2{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-03-23 11:36:15,022 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@20a05f29{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-03-23 11:36:15,066 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@43fd77e8{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/meta/webserver/jetty-0_0_0_0-15038-hdds-container-service-1_5_0-SNAPSHOT_jar-_-any-8660440081592972633/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-03-23 11:36:15,068 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@5d7ed410{HTTP/1.1, (http/1.1)}{0.0.0.0:15038}
2024-03-23 11:36:15,068 [main] INFO  server.Server (Server.java:doStart(415)) - Started @21943ms
2024-03-23 11:36:15,068 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-03-23 11:36:15,069 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15038
2024-03-23 11:36:15,069 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-23 11:36:15,069 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:15,070 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15039
2024-03-23 11:36:15,070 [Socket Reader #1 for port 15039] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15039
2024-03-23 11:36:15,073 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(327)) - Datanode start with admins: [runner]
2024-03-23 11:36:15,073 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15039
2024-03-23 11:36:15,077 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-03-23 11:36:15,077 [IPC Server listener on 15039] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15039: starting
2024-03-23 11:36:15,082 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-03-23 11:36:15,082 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-03-23 11:36:15,083 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-03-23 11:36:15,085 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(555)) - Ozone container server started.
2024-03-23 11:36:15,095 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-03-23 11:36:15,095 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(240)) - HddsDatanodeService host:fv-az1381-309 ip:10.1.0.5
2024-03-23 11:36:15,098 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/meta/datanode.id
2024-03-23 11:36:15,116 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-03-23 11:36:15,116 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(299)) - Datanode State Machine Task Thread Pool size 2
2024-03-23 11:36:15,118 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(125)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/data-0/hdds of storage type : DISK capacity : 9223372036854775807
2024-03-23 11:36:15,118 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/data-0/hdds to VolumeSet
2024-03-23 11:36:15,119 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis to VolumeSet
2024-03-23 11:36:15,119 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 0ms
2024-03-23 11:36:15,122 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-03-23 11:36:15,122 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-03-23 11:36:15,122 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15051 (custom)
2024-03-23 11:36:15,123 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-03-23 11:36:15,123 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15050 (custom)
2024-03-23 11:36:15,123 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-03-23 11:36:15,123 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15052 (custom)
2024-03-23 11:36:15,123 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-03-23 11:36:15,124 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:15,124 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-03-23 11:36:15,124 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:15,124 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-23 11:36:15,124 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-03-23 11:36:15,125 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-03-23 11:36:15,126 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-03-23 11:36:15,127 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-03-23 11:36:15,127 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-03-23 11:36:15,127 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-03-23 11:36:15,127 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-03-23 11:36:15,128 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-03-23 11:36:15,128 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-03-23 11:36:15,128 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-03-23 11:36:15,128 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-03-23 11:36:15,129 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-03-23 11:36:15,129 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-03-23 11:36:15,130 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-03-23 11:36:15,130 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-03-23 11:36:15,130 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15053 (custom)
2024-03-23 11:36:15,131 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:36:15,131 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-03-23 11:36:15,132 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:36:15,132 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb3d6586f] REGISTERED
2024-03-23 11:36:15,132 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis] (custom)
2024-03-23 11:36:15,133 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-03-23 11:36:15,133 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-03-23 11:36:15,133 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb3d6586f] BIND: 0.0.0.0/0.0.0.0:15053
2024-03-23 11:36:15,133 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb3d6586f, L:/0.0.0.0:15053] ACTIVE
2024-03-23 11:36:15,134 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/tmp
2024-03-23 11:36:15,134 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(269)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/tmp is not a group directory; ignoring it. 
2024-03-23 11:36:15,134 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-03-23 11:36:15,135 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-03-23 11:36:15,137 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(163)) - Initializing replication supervisor with thread count = 10
2024-03-23 11:36:15,138 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(317)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-03-23 11:36:15,140 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15047
2024-03-23 11:36:15,140 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-23 11:36:15,142 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-03-23 11:36:15,142 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-03-23 11:36:15,143 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-23 11:36:15,144 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-03-23 11:36:15,144 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-23 11:36:15,144 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-23 11:36:15,145 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/meta/webserver
2024-03-23 11:36:15,145 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15047
2024-03-23 11:36:15,145 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-03-23 11:36:15,145 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:15,146 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:15,146 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-03-23 11:36:15,147 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-03-23 11:36:15,147 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2024-03-23 11:36:15,148 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@1e144d08{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-03-23 11:36:15,148 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@621bed48{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-03-23 11:36:15,183 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@21a21dfc{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/meta/webserver/jetty-0_0_0_0-15047-hdds-container-service-1_5_0-SNAPSHOT_jar-_-any-4448120365861037815/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-03-23 11:36:15,185 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@3b3374ee{HTTP/1.1, (http/1.1)}{0.0.0.0:15047}
2024-03-23 11:36:15,185 [main] INFO  server.Server (Server.java:doStart(415)) - Started @22061ms
2024-03-23 11:36:15,186 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-03-23 11:36:15,186 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15047
2024-03-23 11:36:15,186 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-23 11:36:15,187 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15048
2024-03-23 11:36:15,187 [Socket Reader #1 for port 15048] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15048
2024-03-23 11:36:15,190 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(327)) - Datanode start with admins: [runner]
2024-03-23 11:36:15,190 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15048
2024-03-23 11:36:15,193 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-03-23 11:36:15,193 [IPC Server listener on 15048] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15048: starting
2024-03-23 11:36:15,195 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(555)) - Ozone container server started.
2024-03-23 11:36:15,197 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 0 of 5 DN Heartbeats.
2024-03-23 11:36:15,197 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-03-23 11:36:15,198 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-23 11:36:15,197 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-03-23 11:36:15,203 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/meta/datanode.id
2024-03-23 11:36:16,070 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:16,147 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:16,147 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:16,198 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 0 of 5 DN Heartbeats.
2024-03-23 11:36:16,198 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-03-23 11:36:16,198 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-23 11:36:16,765 [e3882025-ee77-4273-a30c-caf156427e83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-892f8edf-b04c-4bbd-8c90-36214af705e8/container.db to cache
2024-03-23 11:36:16,766 [e3882025-ee77-4273-a30c-caf156427e83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(420)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-892f8edf-b04c-4bbd-8c90-36214af705e8/container.db for volume DS-892f8edf-b04c-4bbd-8c90-36214af705e8
2024-03-23 11:36:16,774 [e3882025-ee77-4273-a30c-caf156427e83-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/data-0/hdds
2024-03-23 11:36:16,774 [e3882025-ee77-4273-a30c-caf156427e83-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/data-0/hdds
2024-03-23 11:36:16,774 [e3882025-ee77-4273-a30c-caf156427e83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-03-23 11:36:16,776 [e3882025-ee77-4273-a30c-caf156427e83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/data-0/hdds
2024-03-23 11:36:16,788 [e3882025-ee77-4273-a30c-caf156427e83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/data-0/hdds
2024-03-23 11:36:16,790 [e3882025-ee77-4273-a30c-caf156427e83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis
2024-03-23 11:36:16,790 [e3882025-ee77-4273-a30c-caf156427e83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis
2024-03-23 11:36:16,791 [e3882025-ee77-4273-a30c-caf156427e83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-03-23 11:36:16,797 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-03-23 11:36:16,803 [e3882025-ee77-4273-a30c-caf156427e83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15018
2024-03-23 11:36:16,803 [e3882025-ee77-4273-a30c-caf156427e83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(566)) - Starting XceiverServerRatis e3882025-ee77-4273-a30c-caf156427e83
2024-03-23 11:36:16,802 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-03-23 11:36:16,805 [e3882025-ee77-4273-a30c-caf156427e83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(406)) - e3882025-ee77-4273-a30c-caf156427e83: start RPC server
2024-03-23 11:36:16,807 [e3882025-ee77-4273-a30c-caf156427e83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - e3882025-ee77-4273-a30c-caf156427e83: GrpcService started, listening on 15014
2024-03-23 11:36:16,810 [e3882025-ee77-4273-a30c-caf156427e83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - e3882025-ee77-4273-a30c-caf156427e83: GrpcService started, listening on 15016
2024-03-23 11:36:16,811 [e3882025-ee77-4273-a30c-caf156427e83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - e3882025-ee77-4273-a30c-caf156427e83: GrpcService started, listening on 15015
2024-03-23 11:36:16,812 [JvmPauseMonitor3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-e3882025-ee77-4273-a30c-caf156427e83: Started
2024-03-23 11:36:16,812 [e3882025-ee77-4273-a30c-caf156427e83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis e3882025-ee77-4273-a30c-caf156427e83 is started using port 15014 for RATIS
2024-03-23 11:36:16,812 [e3882025-ee77-4273-a30c-caf156427e83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis e3882025-ee77-4273-a30c-caf156427e83 is started using port 15015 for RATIS_ADMIN
2024-03-23 11:36:16,812 [e3882025-ee77-4273-a30c-caf156427e83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis e3882025-ee77-4273-a30c-caf156427e83 is started using port 15016 for RATIS_SERVER
2024-03-23 11:36:16,813 [e3882025-ee77-4273-a30c-caf156427e83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis e3882025-ee77-4273-a30c-caf156427e83 is started using port 15017 for RATIS_DATASTREAM
2024-03-23 11:36:16,817 [e3882025-ee77-4273-a30c-caf156427e83-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-03-23 11:36:16,859 [5b4c27d6-a533-4766-a648-a869ad76920c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-a679f35d-8700-4aa7-8f9c-4f65e6fa09bc/container.db to cache
2024-03-23 11:36:16,859 [5b4c27d6-a533-4766-a648-a869ad76920c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(420)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-a679f35d-8700-4aa7-8f9c-4f65e6fa09bc/container.db for volume DS-a679f35d-8700-4aa7-8f9c-4f65e6fa09bc
2024-03-23 11:36:16,861 [5b4c27d6-a533-4766-a648-a869ad76920c-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/data-0/hdds
2024-03-23 11:36:16,862 [5b4c27d6-a533-4766-a648-a869ad76920c-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/data-0/hdds
2024-03-23 11:36:16,862 [5b4c27d6-a533-4766-a648-a869ad76920c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-03-23 11:36:16,863 [5b4c27d6-a533-4766-a648-a869ad76920c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/data-0/hdds
2024-03-23 11:36:16,863 [5b4c27d6-a533-4766-a648-a869ad76920c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/data-0/hdds
2024-03-23 11:36:16,869 [5b4c27d6-a533-4766-a648-a869ad76920c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis
2024-03-23 11:36:16,869 [5b4c27d6-a533-4766-a648-a869ad76920c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis
2024-03-23 11:36:16,870 [5b4c27d6-a533-4766-a648-a869ad76920c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-03-23 11:36:16,870 [5b4c27d6-a533-4766-a648-a869ad76920c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(75)) - Trying to initialize on demand scanner a second time on a datanode.
2024-03-23 11:36:16,871 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-03-23 11:36:16,871 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-03-23 11:36:16,873 [5b4c27d6-a533-4766-a648-a869ad76920c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15027
2024-03-23 11:36:16,873 [5b4c27d6-a533-4766-a648-a869ad76920c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(566)) - Starting XceiverServerRatis 5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:36:16,875 [5b4c27d6-a533-4766-a648-a869ad76920c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(406)) - 5b4c27d6-a533-4766-a648-a869ad76920c: start RPC server
2024-03-23 11:36:16,877 [5b4c27d6-a533-4766-a648-a869ad76920c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 5b4c27d6-a533-4766-a648-a869ad76920c: GrpcService started, listening on 15023
2024-03-23 11:36:16,878 [5b4c27d6-a533-4766-a648-a869ad76920c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 5b4c27d6-a533-4766-a648-a869ad76920c: GrpcService started, listening on 15025
2024-03-23 11:36:16,881 [5b4c27d6-a533-4766-a648-a869ad76920c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 5b4c27d6-a533-4766-a648-a869ad76920c: GrpcService started, listening on 15024
2024-03-23 11:36:16,881 [5b4c27d6-a533-4766-a648-a869ad76920c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 5b4c27d6-a533-4766-a648-a869ad76920c is started using port 15023 for RATIS
2024-03-23 11:36:16,881 [JvmPauseMonitor4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-5b4c27d6-a533-4766-a648-a869ad76920c: Started
2024-03-23 11:36:16,881 [5b4c27d6-a533-4766-a648-a869ad76920c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 5b4c27d6-a533-4766-a648-a869ad76920c is started using port 15024 for RATIS_ADMIN
2024-03-23 11:36:16,882 [5b4c27d6-a533-4766-a648-a869ad76920c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 5b4c27d6-a533-4766-a648-a869ad76920c is started using port 15025 for RATIS_SERVER
2024-03-23 11:36:16,882 [5b4c27d6-a533-4766-a648-a869ad76920c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 5b4c27d6-a533-4766-a648-a869ad76920c is started using port 15026 for RATIS_DATASTREAM
2024-03-23 11:36:16,887 [5b4c27d6-a533-4766-a648-a869ad76920c-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-03-23 11:36:16,979 [00b25173-7757-4760-98a7-1e1aa18d5e2d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-4620390d-9a40-479a-99aa-5a4e8f975309/container.db to cache
2024-03-23 11:36:16,979 [00b25173-7757-4760-98a7-1e1aa18d5e2d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(420)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-4620390d-9a40-479a-99aa-5a4e8f975309/container.db for volume DS-4620390d-9a40-479a-99aa-5a4e8f975309
2024-03-23 11:36:16,980 [00b25173-7757-4760-98a7-1e1aa18d5e2d-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/data-0/hdds
2024-03-23 11:36:16,981 [00b25173-7757-4760-98a7-1e1aa18d5e2d-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/data-0/hdds
2024-03-23 11:36:16,981 [00b25173-7757-4760-98a7-1e1aa18d5e2d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-03-23 11:36:16,982 [00b25173-7757-4760-98a7-1e1aa18d5e2d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/data-0/hdds
2024-03-23 11:36:16,982 [00b25173-7757-4760-98a7-1e1aa18d5e2d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/data-0/hdds
2024-03-23 11:36:16,984 [00b25173-7757-4760-98a7-1e1aa18d5e2d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis
2024-03-23 11:36:16,984 [00b25173-7757-4760-98a7-1e1aa18d5e2d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis
2024-03-23 11:36:16,985 [00b25173-7757-4760-98a7-1e1aa18d5e2d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-03-23 11:36:16,985 [00b25173-7757-4760-98a7-1e1aa18d5e2d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(75)) - Trying to initialize on demand scanner a second time on a datanode.
2024-03-23 11:36:16,986 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-03-23 11:36:16,988 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-03-23 11:36:16,989 [00b25173-7757-4760-98a7-1e1aa18d5e2d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15036
2024-03-23 11:36:16,989 [00b25173-7757-4760-98a7-1e1aa18d5e2d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(566)) - Starting XceiverServerRatis 00b25173-7757-4760-98a7-1e1aa18d5e2d
2024-03-23 11:36:16,991 [00b25173-7757-4760-98a7-1e1aa18d5e2d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(406)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: start RPC server
2024-03-23 11:36:16,992 [00b25173-7757-4760-98a7-1e1aa18d5e2d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: GrpcService started, listening on 15032
2024-03-23 11:36:16,994 [00b25173-7757-4760-98a7-1e1aa18d5e2d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: GrpcService started, listening on 15034
2024-03-23 11:36:16,995 [00b25173-7757-4760-98a7-1e1aa18d5e2d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: GrpcService started, listening on 15033
2024-03-23 11:36:16,996 [00b25173-7757-4760-98a7-1e1aa18d5e2d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 00b25173-7757-4760-98a7-1e1aa18d5e2d is started using port 15032 for RATIS
2024-03-23 11:36:16,996 [00b25173-7757-4760-98a7-1e1aa18d5e2d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 00b25173-7757-4760-98a7-1e1aa18d5e2d is started using port 15033 for RATIS_ADMIN
2024-03-23 11:36:16,996 [00b25173-7757-4760-98a7-1e1aa18d5e2d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 00b25173-7757-4760-98a7-1e1aa18d5e2d is started using port 15034 for RATIS_SERVER
2024-03-23 11:36:16,996 [00b25173-7757-4760-98a7-1e1aa18d5e2d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 00b25173-7757-4760-98a7-1e1aa18d5e2d is started using port 15035 for RATIS_DATASTREAM
2024-03-23 11:36:16,996 [JvmPauseMonitor5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-00b25173-7757-4760-98a7-1e1aa18d5e2d: Started
2024-03-23 11:36:16,999 [00b25173-7757-4760-98a7-1e1aa18d5e2d-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-03-23 11:36:17,070 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:17,119 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-bff6b704-e145-4390-bc30-ec0553ef30a2/container.db to cache
2024-03-23 11:36:17,119 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(420)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-bff6b704-e145-4390-bc30-ec0553ef30a2/container.db for volume DS-bff6b704-e145-4390-bc30-ec0553ef30a2
2024-03-23 11:36:17,123 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/data-0/hdds
2024-03-23 11:36:17,123 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/data-0/hdds
2024-03-23 11:36:17,123 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-03-23 11:36:17,126 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/data-0/hdds
2024-03-23 11:36:17,126 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/data-0/hdds
2024-03-23 11:36:17,128 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis
2024-03-23 11:36:17,128 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis
2024-03-23 11:36:17,129 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-03-23 11:36:17,129 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(75)) - Trying to initialize on demand scanner a second time on a datanode.
2024-03-23 11:36:17,130 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-03-23 11:36:17,133 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-03-23 11:36:17,135 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15045
2024-03-23 11:36:17,135 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(566)) - Starting XceiverServerRatis bb4f2f6f-344d-4a57-aba3-69abe2cb722c
2024-03-23 11:36:17,136 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(406)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: start RPC server
2024-03-23 11:36:17,137 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: GrpcService started, listening on 15041
2024-03-23 11:36:17,139 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: GrpcService started, listening on 15043
2024-03-23 11:36:17,146 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: GrpcService started, listening on 15042
2024-03-23 11:36:17,146 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis bb4f2f6f-344d-4a57-aba3-69abe2cb722c is started using port 15041 for RATIS
2024-03-23 11:36:17,146 [JvmPauseMonitor6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-bb4f2f6f-344d-4a57-aba3-69abe2cb722c: Started
2024-03-23 11:36:17,146 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis bb4f2f6f-344d-4a57-aba3-69abe2cb722c is started using port 15042 for RATIS_ADMIN
2024-03-23 11:36:17,146 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis bb4f2f6f-344d-4a57-aba3-69abe2cb722c is started using port 15043 for RATIS_SERVER
2024-03-23 11:36:17,147 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis bb4f2f6f-344d-4a57-aba3-69abe2cb722c is started using port 15044 for RATIS_DATASTREAM
2024-03-23 11:36:17,149 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-03-23 11:36:17,150 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 2 milliseconds to process 0 existing database records.
2024-03-23 11:36:17,150 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:17,198 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 0 of 5 DN Heartbeats.
2024-03-23 11:36:17,199 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-03-23 11:36:17,199 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-23 11:36:17,220 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-f5fc6349-2a63-4c91-99e3-3dbec7144f76/container.db to cache
2024-03-23 11:36:17,220 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(420)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-f5fc6349-2a63-4c91-99e3-3dbec7144f76/container.db for volume DS-f5fc6349-2a63-4c91-99e3-3dbec7144f76
2024-03-23 11:36:17,223 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/data-0/hdds
2024-03-23 11:36:17,223 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/data-0/hdds
2024-03-23 11:36:17,224 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-03-23 11:36:17,224 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/data-0/hdds
2024-03-23 11:36:17,225 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/data-0/hdds
2024-03-23 11:36:17,226 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis
2024-03-23 11:36:17,227 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis
2024-03-23 11:36:17,227 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-03-23 11:36:17,228 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(75)) - Trying to initialize on demand scanner a second time on a datanode.
2024-03-23 11:36:17,228 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-03-23 11:36:17,229 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-03-23 11:36:17,230 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15054
2024-03-23 11:36:17,230 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(566)) - Starting XceiverServerRatis 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:17,231 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(406)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: start RPC server
2024-03-23 11:36:17,232 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: GrpcService started, listening on 15050
2024-03-23 11:36:17,233 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: GrpcService started, listening on 15052
2024-03-23 11:36:17,234 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: GrpcService started, listening on 15051
2024-03-23 11:36:17,234 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b is started using port 15050 for RATIS
2024-03-23 11:36:17,234 [JvmPauseMonitor7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: Started
2024-03-23 11:36:17,234 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b is started using port 15051 for RATIS_ADMIN
2024-03-23 11:36:17,235 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b is started using port 15052 for RATIS_SERVER
2024-03-23 11:36:17,235 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b is started using port 15053 for RATIS_DATASTREAM
2024-03-23 11:36:17,238 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-03-23 11:36:18,070 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:18,151 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:18,151 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:18,199 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 0 of 5 DN Heartbeats.
2024-03-23 11:36:18,199 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-03-23 11:36:18,199 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-23 11:36:18,649 [IPC Server handler 3 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/e3882025-ee77-4273-a30c-caf156427e83
2024-03-23 11:36:18,649 [IPC Server handler 4 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/e3882025-ee77-4273-a30c-caf156427e83
2024-03-23 11:36:18,652 [IPC Server handler 3 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: e3882025-ee77-4273-a30c-caf156427e83{ip: 10.1.0.5, host: fv-az1381-309, ports: [HTTP=15011, CLIENT_RPC=15012, REPLICATION=15018, RATIS=15014, RATIS_ADMIN=15015, RATIS_SERVER=15016, RATIS_DATASTREAM=15017, STANDALONE=15013], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-23 11:36:18,652 [IPC Server handler 4 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: e3882025-ee77-4273-a30c-caf156427e83{ip: 10.1.0.5, host: fv-az1381-309, ports: [HTTP=15011, CLIENT_RPC=15012, REPLICATION=15018, RATIS=15014, RATIS_ADMIN=15015, RATIS_SERVER=15016, RATIS_DATASTREAM=15017, STANDALONE=15013], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-23 11:36:18,655 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-23 11:36:18,657 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(138)) - Adding new node e3882025-ee77-4273-a30c-caf156427e83 to Node DB.
2024-03-23 11:36:18,658 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:18,658 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:18,660 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - ContainerSafeModeRule rule is successfully validated
2024-03-23 11:36:18,660 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2024-03-23 11:36:18,661 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-23 11:36:18,661 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 5 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:18,662 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 6 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:18,664 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=07524b35-b4dd-487c-8fd9-3a831e3069be to datanode:e3882025-ee77-4273-a30c-caf156427e83
2024-03-23 11:36:18,673 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 07524b35-b4dd-487c-8fd9-3a831e3069be, Nodes: e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-23T11:36:18.663Z[Etc/UTC]]
2024-03-23 11:36:18,841 [IPC Server handler 4 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:36:18,841 [IPC Server handler 3 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:36:18,841 [IPC Server handler 4 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: 5b4c27d6-a533-4766-a648-a869ad76920c{ip: 10.1.0.5, host: fv-az1381-309, ports: [HTTP=15020, CLIENT_RPC=15021, REPLICATION=15027, RATIS=15023, RATIS_ADMIN=15024, RATIS_SERVER=15025, RATIS_DATASTREAM=15026, STANDALONE=15022], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-23 11:36:18,841 [IPC Server handler 3 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: 5b4c27d6-a533-4766-a648-a869ad76920c{ip: 10.1.0.5, host: fv-az1381-309, ports: [HTTP=15020, CLIENT_RPC=15021, REPLICATION=15027, RATIS=15023, RATIS_ADMIN=15024, RATIS_SERVER=15025, RATIS_DATASTREAM=15026, STANDALONE=15022], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-23 11:36:18,843 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-23 11:36:18,843 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2024-03-23 11:36:18,843 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(138)) - Adding new node 5b4c27d6-a533-4766-a648-a869ad76920c to Node DB.
2024-03-23 11:36:18,844 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=c0ed46c6-9d24-4a92-bbda-2a12cab7754c to datanode:5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:36:18,844 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: c0ed46c6-9d24-4a92-bbda-2a12cab7754c, Nodes: 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-23T11:36:18.844Z[Etc/UTC]]
2024-03-23 11:36:18,962 [IPC Server handler 0 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/00b25173-7757-4760-98a7-1e1aa18d5e2d
2024-03-23 11:36:18,962 [IPC Server handler 5 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/00b25173-7757-4760-98a7-1e1aa18d5e2d
2024-03-23 11:36:18,962 [IPC Server handler 5 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: 00b25173-7757-4760-98a7-1e1aa18d5e2d{ip: 10.1.0.5, host: fv-az1381-309, ports: [HTTP=15029, CLIENT_RPC=15030, REPLICATION=15036, RATIS=15032, RATIS_ADMIN=15033, RATIS_SERVER=15034, RATIS_DATASTREAM=15035, STANDALONE=15031], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-23 11:36:18,962 [IPC Server handler 0 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: 00b25173-7757-4760-98a7-1e1aa18d5e2d{ip: 10.1.0.5, host: fv-az1381-309, ports: [HTTP=15029, CLIENT_RPC=15030, REPLICATION=15036, RATIS=15032, RATIS_ADMIN=15033, RATIS_SERVER=15034, RATIS_DATASTREAM=15035, STANDALONE=15031], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-23 11:36:18,963 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(138)) - Adding new node 00b25173-7757-4760-98a7-1e1aa18d5e2d to Node DB.
2024-03-23 11:36:18,963 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2024-03-23 11:36:18,963 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-23 11:36:18,963 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - DataNodeSafeModeRule rule is successfully validated
2024-03-23 11:36:18,963 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(229)) - All SCM safe mode pre check rules have passed
2024-03-23 11:36:18,963 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(225)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2024-03-23 11:36:18,964 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-23 11:36:18,964 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=8643aede-2156-48e1-8210-1ce430ae568b to datanode:00b25173-7757-4760-98a7-1e1aa18d5e2d
2024-03-23 11:36:18,965 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 8643aede-2156-48e1-8210-1ce430ae568b, Nodes: 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-23T11:36:18.964Z[Etc/UTC]]
2024-03-23 11:36:18,968 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=439e139a-b269-423e-9d21-d246ec176e64 to datanode:5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:36:18,969 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=439e139a-b269-423e-9d21-d246ec176e64 to datanode:00b25173-7757-4760-98a7-1e1aa18d5e2d
2024-03-23 11:36:18,969 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=439e139a-b269-423e-9d21-d246ec176e64 to datanode:e3882025-ee77-4273-a30c-caf156427e83
2024-03-23 11:36:18,970 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 439e139a-b269-423e-9d21-d246ec176e64, Nodes: 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5)00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5)e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-23T11:36:18.968Z[Etc/UTC]]
2024-03-23 11:36:19,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:19,097 [IPC Server handler 2 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/bb4f2f6f-344d-4a57-aba3-69abe2cb722c
2024-03-23 11:36:19,098 [IPC Server handler 0 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/bb4f2f6f-344d-4a57-aba3-69abe2cb722c
2024-03-23 11:36:19,100 [IPC Server handler 2 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: bb4f2f6f-344d-4a57-aba3-69abe2cb722c{ip: 10.1.0.5, host: fv-az1381-309, ports: [HTTP=15038, CLIENT_RPC=15039, REPLICATION=15045, RATIS=15041, RATIS_ADMIN=15042, RATIS_SERVER=15043, RATIS_DATASTREAM=15044, STANDALONE=15040], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-23 11:36:19,101 [IPC Server handler 0 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: bb4f2f6f-344d-4a57-aba3-69abe2cb722c{ip: 10.1.0.5, host: fv-az1381-309, ports: [HTTP=15038, CLIENT_RPC=15039, REPLICATION=15045, RATIS=15041, RATIS_ADMIN=15042, RATIS_SERVER=15043, RATIS_DATASTREAM=15044, STANDALONE=15040], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-23 11:36:19,101 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-23 11:36:19,102 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(138)) - Adding new node bb4f2f6f-344d-4a57-aba3-69abe2cb722c to Node DB.
2024-03-23 11:36:19,102 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:19,102 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:19,103 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72 to datanode:bb4f2f6f-344d-4a57-aba3-69abe2cb722c
2024-03-23 11:36:19,104 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72, Nodes: bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-23T11:36:19.103Z[Etc/UTC]]
2024-03-23 11:36:19,152 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:19,152 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:19,200 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 4 of 5 DN Heartbeats.
2024-03-23 11:36:19,200 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-03-23 11:36:19,200 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-23 11:36:19,200 [IPC Server handler 4 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:19,200 [IPC Server handler 2 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:19,200 [IPC Server handler 4 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b{ip: 10.1.0.5, host: fv-az1381-309, ports: [HTTP=15047, CLIENT_RPC=15048, REPLICATION=15054, RATIS=15050, RATIS_ADMIN=15051, RATIS_SERVER=15052, RATIS_DATASTREAM=15053, STANDALONE=15049], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-23 11:36:19,200 [IPC Server handler 2 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b{ip: 10.1.0.5, host: fv-az1381-309, ports: [HTTP=15047, CLIENT_RPC=15048, REPLICATION=15054, RATIS=15050, RATIS_ADMIN=15051, RATIS_SERVER=15052, RATIS_DATASTREAM=15053, STANDALONE=15049], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-23 11:36:19,201 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-23 11:36:19,201 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(138)) - Adding new node 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b to Node DB.
2024-03-23 11:36:19,202 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=075a3443-897d-4510-a745-e1ae4ba72bfe to datanode:6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:19,202 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:19,203 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:19,203 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 075a3443-897d-4510-a745-e1ae4ba72bfe, Nodes: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-23T11:36:19.202Z[Etc/UTC]]
2024-03-23 11:36:20,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:20,153 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:20,154 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:20,200 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-03-23 11:36:20,200 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-03-23 11:36:20,200 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-23 11:36:20,656 [IPC Server handler 3 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for fv-az1381-309
2024-03-23 11:36:20,840 [IPC Server handler 4 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for fv-az1381-309
2024-03-23 11:36:20,959 [IPC Server handler 5 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for fv-az1381-309
2024-03-23 11:36:21,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:21,098 [IPC Server handler 0 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for fv-az1381-309
2024-03-23 11:36:21,155 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:21,155 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:21,201 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-03-23 11:36:21,201 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-03-23 11:36:21,201 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-23 11:36:21,201 [IPC Server handler 2 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for fv-az1381-309
2024-03-23 11:36:21,203 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:21,203 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:21,663 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - e3882025-ee77-4273-a30c-caf156427e83: addNew group-3A831E3069BE:[e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016] returns group-3A831E3069BE:java.util.concurrent.CompletableFuture@5f7ef6e4[Not completed]
2024-03-23 11:36:21,668 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  lib.Interns (Interns.java:removeEldestEntry(50)) - Metrics intern cache overflow at 2011 for MetricsSystem={MetricsSystem=MetricsInfoImpl{name=MetricsSystem, description=MetricsSystem}, MetricsSystem record=MetricsInfoImpl{name=MetricsSystem, description=MetricsSystem record}}
2024-03-23 11:36:21,670 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - e3882025-ee77-4273-a30c-caf156427e83: new RaftServerImpl for group-3A831E3069BE:[e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016] with ContainerStateMachine:uninitialized
2024-03-23 11:36:21,670 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:21,670 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-23 11:36:21,671 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-23 11:36:21,671 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-23 11:36:21,671 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:36:21,671 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-23 11:36:21,671 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:36:21,671 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE: ConfigurationManager, init=-1: peers:[e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-23 11:36:21,671 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-23 11:36:21,671 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-23 11:36:21,671 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-23 11:36:21,672 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-23 11:36:21,672 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-23 11:36:21,672 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-23 11:36:21,679 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:21,679 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:21,679 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-23 11:36:21,679 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-23 11:36:21,680 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-23 11:36:21,680 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-23 11:36:21,680 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-23 11:36:21,680 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-23 11:36:21,680 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis] (custom)
2024-03-23 11:36:21,680 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/07524b35-b4dd-487c-8fd9-3a831e3069be does not exist. Creating ...
2024-03-23 11:36:21,681 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/07524b35-b4dd-487c-8fd9-3a831e3069be/in_use.lock acquired by nodename 18969@fv-az1381-309
2024-03-23 11:36:21,683 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/07524b35-b4dd-487c-8fd9-3a831e3069be has been successfully formatted.
2024-03-23 11:36:21,683 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/07524b35-b4dd-487c-8fd9-3a831e3069be/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/07524b35-b4dd-487c-8fd9-3a831e3069be/current/raft-meta.conf
2024-03-23 11:36:21,685 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-3A831E3069BE: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-23 11:36:21,685 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-23 11:36:21,685 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-23 11:36:21,685 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:21,685 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-23 11:36:21,687 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-23 11:36:21,689 [IPC Server handler 4 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for fv-az1381-309
2024-03-23 11:36:21,694 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=07524b35-b4dd-487c-8fd9-3a831e3069be. Trying to get from SCM.
2024-03-23 11:36:21,696 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=07524b35-b4dd-487c-8fd9-3a831e3069be
2024-03-23 11:36:21,697 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:21,702 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(86)) - Adding new pipeline Pipeline[ Id: 07524b35-b4dd-487c-8fd9-3a831e3069be, Nodes: e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:e3882025-ee77-4273-a30c-caf156427e83, CreationTimestamp2024-03-23T11:36:18.663Z[Etc/UTC]] to Recon pipeline metadata.
2024-03-23 11:36:21,709 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:21,710 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-23 11:36:21,710 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-23 11:36:21,710 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:21,711 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-cacheEviction-AwaitToRun,5,main] started
2024-03-23 11:36:21,711 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/07524b35-b4dd-487c-8fd9-3a831e3069be
2024-03-23 11:36:21,711 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-23 11:36:21,711 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-23 11:36:21,711 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:21,711 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-23 11:36:21,711 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-23 11:36:21,711 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-23 11:36:21,711 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-23 11:36:21,711 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-23 11:36:21,712 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-23 11:36:21,714 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:21,714 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-23 11:36:21,714 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-23 11:36:21,714 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-23 11:36:21,714 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:21,714 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:21,715 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE: start as a follower, conf=-1: peers:[e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:36:21,715 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-23 11:36:21,715 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e3882025-ee77-4273-a30c-caf156427e83: start e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-FollowerState
2024-03-23 11:36:21,715 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:21,715 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3A831E3069BE,id=e3882025-ee77-4273-a30c-caf156427e83
2024-03-23 11:36:21,715 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-23 11:36:21,715 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-23 11:36:21,716 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-23 11:36:21,716 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-23 11:36:21,716 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-23 11:36:21,715 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:21,722 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=07524b35-b4dd-487c-8fd9-3a831e3069be
2024-03-23 11:36:21,722 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=07524b35-b4dd-487c-8fd9-3a831e3069be.
2024-03-23 11:36:21,723 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - e3882025-ee77-4273-a30c-caf156427e83: addNew group-D246EC176E64:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016] returns group-D246EC176E64:java.util.concurrent.CompletableFuture@792a0a8b[Not completed]
2024-03-23 11:36:21,724 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - e3882025-ee77-4273-a30c-caf156427e83: new RaftServerImpl for group-D246EC176E64:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016] with ContainerStateMachine:uninitialized
2024-03-23 11:36:21,724 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:21,724 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-23 11:36:21,724 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-23 11:36:21,724 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-23 11:36:21,725 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:36:21,725 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-23 11:36:21,725 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:36:21,725 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64: ConfigurationManager, init=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-23 11:36:21,725 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-23 11:36:21,725 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-23 11:36:21,725 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-23 11:36:21,725 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-23 11:36:21,725 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-23 11:36:21,726 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-23 11:36:21,732 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:21,733 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:21,733 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-23 11:36:21,733 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-23 11:36:21,733 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-23 11:36:21,733 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-23 11:36:21,733 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-23 11:36:21,733 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-23 11:36:21,733 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis] (custom)
2024-03-23 11:36:21,734 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/439e139a-b269-423e-9d21-d246ec176e64 does not exist. Creating ...
2024-03-23 11:36:21,735 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/439e139a-b269-423e-9d21-d246ec176e64/in_use.lock acquired by nodename 18969@fv-az1381-309
2024-03-23 11:36:21,736 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/439e139a-b269-423e-9d21-d246ec176e64 has been successfully formatted.
2024-03-23 11:36:21,736 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/439e139a-b269-423e-9d21-d246ec176e64/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/439e139a-b269-423e-9d21-d246ec176e64/current/raft-meta.conf
2024-03-23 11:36:21,737 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-D246EC176E64: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-23 11:36:21,740 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-23 11:36:21,741 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-23 11:36:21,741 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:21,741 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-23 11:36:21,741 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-23 11:36:21,742 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:21,743 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=439e139a-b269-423e-9d21-d246ec176e64. Trying to get from SCM.
2024-03-23 11:36:21,745 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(86)) - Adding new pipeline Pipeline[ Id: 439e139a-b269-423e-9d21-d246ec176e64, Nodes: 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5)00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5)e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-23T11:36:18.968Z[Etc/UTC]] to Recon pipeline metadata.
2024-03-23 11:36:21,745 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:21,746 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-23 11:36:21,746 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-23 11:36:21,746 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:21,746 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=439e139a-b269-423e-9d21-d246ec176e64 reported by e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:21,748 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-cacheEviction-AwaitToRun,5,main] started
2024-03-23 11:36:21,750 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/439e139a-b269-423e-9d21-d246ec176e64
2024-03-23 11:36:21,750 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-23 11:36:21,750 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-23 11:36:21,750 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:21,750 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-23 11:36:21,750 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-23 11:36:21,750 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-23 11:36:21,750 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-23 11:36:21,751 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-23 11:36:21,752 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-23 11:36:21,753 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:21,753 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-23 11:36:21,753 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-23 11:36:21,754 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-23 11:36:21,754 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:21,754 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:21,754 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64: start as a follower, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:36:21,755 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-23 11:36:21,755 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e3882025-ee77-4273-a30c-caf156427e83: start e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-FollowerState
2024-03-23 11:36:21,757 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D246EC176E64,id=e3882025-ee77-4273-a30c-caf156427e83
2024-03-23 11:36:21,757 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-23 11:36:21,757 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-23 11:36:21,757 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-23 11:36:21,757 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-23 11:36:21,757 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-23 11:36:21,760 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=439e139a-b269-423e-9d21-d246ec176e64
2024-03-23 11:36:21,767 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:21,767 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:21,840 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 5b4c27d6-a533-4766-a648-a869ad76920c: addNew group-2A12CAB7754C:[5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025] returns group-2A12CAB7754C:java.util.concurrent.CompletableFuture@677a42c2[Not completed]
2024-03-23 11:36:21,841 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 5b4c27d6-a533-4766-a648-a869ad76920c: new RaftServerImpl for group-2A12CAB7754C:[5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025] with ContainerStateMachine:uninitialized
2024-03-23 11:36:21,841 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:21,841 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-23 11:36:21,841 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-23 11:36:21,842 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-23 11:36:21,842 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:36:21,842 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-23 11:36:21,842 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:36:21,842 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C: ConfigurationManager, init=-1: peers:[5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-23 11:36:21,842 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-23 11:36:21,842 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-23 11:36:21,842 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-23 11:36:21,842 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-23 11:36:21,843 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-23 11:36:21,843 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-23 11:36:21,847 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5) moved to stale state. Finalizing its pipelines [PipelineID=439e139a-b269-423e-9d21-d246ec176e64]
2024-03-23 11:36:21,851 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=439e139a-b269-423e-9d21-d246ec176e64 moved to CLOSED state
2024-03-23 11:36:21,851 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:21,852 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:21,852 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-23 11:36:21,852 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-23 11:36:21,852 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-23 11:36:21,852 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-23 11:36:21,852 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-23 11:36:21,852 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-23 11:36:21,853 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis] (custom)
2024-03-23 11:36:21,853 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/c0ed46c6-9d24-4a92-bbda-2a12cab7754c does not exist. Creating ...
2024-03-23 11:36:21,856 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/c0ed46c6-9d24-4a92-bbda-2a12cab7754c/in_use.lock acquired by nodename 18969@fv-az1381-309
2024-03-23 11:36:21,856 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 2 pipelines in house.
2024-03-23 11:36:21,857 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/c0ed46c6-9d24-4a92-bbda-2a12cab7754c has been successfully formatted.
2024-03-23 11:36:21,858 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/c0ed46c6-9d24-4a92-bbda-2a12cab7754c/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/c0ed46c6-9d24-4a92-bbda-2a12cab7754c/current/raft-meta.conf
2024-03-23 11:36:21,860 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(110)) - Adding new pipeline PipelineID=075a3443-897d-4510-a745-e1ae4ba72bfe from SCM.
2024-03-23 11:36:21,859 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-2A12CAB7754C: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-23 11:36:21,863 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-23 11:36:21,863 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-23 11:36:21,863 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:21,863 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-23 11:36:21,863 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-23 11:36:21,865 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:21,865 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-23 11:36:21,865 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-23 11:36:21,865 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:21,867 [IPC Server handler 8 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for fv-az1381-309
2024-03-23 11:36:21,867 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=c0ed46c6-9d24-4a92-bbda-2a12cab7754c. Trying to get from SCM.
2024-03-23 11:36:21,866 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-cacheEviction-AwaitToRun,5,main] started
2024-03-23 11:36:21,868 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/c0ed46c6-9d24-4a92-bbda-2a12cab7754c
2024-03-23 11:36:21,869 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(110)) - Adding new pipeline PipelineID=eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72 from SCM.
2024-03-23 11:36:21,869 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-23 11:36:21,869 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=c0ed46c6-9d24-4a92-bbda-2a12cab7754c
2024-03-23 11:36:21,870 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:21,868 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(86)) - Adding new pipeline Pipeline[ Id: c0ed46c6-9d24-4a92-bbda-2a12cab7754c, Nodes: 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-23T11:36:18.844Z[Etc/UTC]] to Recon pipeline metadata.
2024-03-23 11:36:21,869 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-23 11:36:21,870 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:21,870 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-23 11:36:21,871 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-23 11:36:21,871 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-23 11:36:21,871 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-23 11:36:21,871 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-23 11:36:21,871 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-23 11:36:21,872 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(110)) - Adding new pipeline PipelineID=8643aede-2156-48e1-8210-1ce430ae568b from SCM.
2024-03-23 11:36:21,873 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(110)) - Adding new pipeline PipelineID=c0ed46c6-9d24-4a92-bbda-2a12cab7754c from SCM.
2024-03-23 11:36:21,874 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:21,874 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-23 11:36:21,874 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-23 11:36:21,875 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-23 11:36:21,875 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:21,875 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:21,874 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] WARN  pipeline.PipelineStateMap (PipelineStateMap.java:addPipeline(84)) - Duplicate pipeline ID detected. PipelineID=c0ed46c6-9d24-4a92-bbda-2a12cab7754c
2024-03-23 11:36:21,875 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C: start as a follower, conf=-1: peers:[5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025]|listeners:[], old=null
2024-03-23 11:36:21,875 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-23 11:36:21,875 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5b4c27d6-a533-4766-a648-a869ad76920c: start 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-FollowerState
2024-03-23 11:36:21,875 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 24 milliseconds.
2024-03-23 11:36:21,881 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:21,876 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2A12CAB7754C,id=5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:36:21,882 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-23 11:36:21,882 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-23 11:36:21,882 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-23 11:36:21,882 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-23 11:36:21,882 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-23 11:36:21,882 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] ERROR pipeline.PipelineReportHandler (PipelineReportHandler.java:onMessage(100)) - Could not process pipeline report=pipelineID {
  id: "c0ed46c6-9d24-4a92-bbda-2a12cab7754c"
  uuid128 {
    mostSigBits: -4544898630093092206
    leastSigBits: -4910566183495305908
  }
}
isLeader: false
bytesWritten: 0
 from dn=5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.StateMachineException: org.apache.hadoop.hdds.scm.pipeline.DuplicatedPipelineIdException from Server peer@group-6685B0AED775: Duplicate pipeline ID PipelineID=c0ed46c6-9d24-4a92-bbda-2a12cab7754c detected.
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy28.addPipeline(Unknown Source)
	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.addPipeline(ReconPipelineManager.java:173)
	at org.apache.hadoop.ozone.recon.scm.ReconPipelineReportHandler.processPipelineReport(ReconPipelineReportHandler.java:88)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:86)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.protocol.exceptions.StateMachineException: org.apache.hadoop.hdds.scm.pipeline.DuplicatedPipelineIdException from Server peer@group-6685B0AED775: Duplicate pipeline ID PipelineID=c0ed46c6-9d24-4a92-bbda-2a12cab7754c detected.
	at org.apache.hadoop.hdds.scm.ha.SCMHAManagerStub$RatisServerStub.submitRequest(SCMHAManagerStub.java:199)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatisServer(SCMHAInvocationHandler.java:123)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:112)
	... 10 more
Caused by: org.apache.hadoop.hdds.scm.pipeline.DuplicatedPipelineIdException: Duplicate pipeline ID PipelineID=c0ed46c6-9d24-4a92-bbda-2a12cab7754c detected.
	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.addPipeline(PipelineStateMap.java:86)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManagerImpl.addPipeline(PipelineStateManagerImpl.java:99)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.scm.ha.SCMHAManagerStub$RatisServerStub.process(SCMHAManagerStub.java:229)
	at org.apache.hadoop.hdds.scm.ha.SCMHAManagerStub$RatisServerStub.submitRequest(SCMHAManagerStub.java:191)
	... 12 more
2024-03-23 11:36:21,884 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:21,885 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=c0ed46c6-9d24-4a92-bbda-2a12cab7754c
2024-03-23 11:36:21,885 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=c0ed46c6-9d24-4a92-bbda-2a12cab7754c.
2024-03-23 11:36:21,886 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 5b4c27d6-a533-4766-a648-a869ad76920c: addNew group-D246EC176E64:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016] returns group-D246EC176E64:java.util.concurrent.CompletableFuture@6345daf5[Not completed]
2024-03-23 11:36:21,887 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 5b4c27d6-a533-4766-a648-a869ad76920c: new RaftServerImpl for group-D246EC176E64:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016] with ContainerStateMachine:uninitialized
2024-03-23 11:36:21,888 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:21,888 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-23 11:36:21,888 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-23 11:36:21,888 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-23 11:36:21,888 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:36:21,888 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-23 11:36:21,888 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:36:21,888 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64: ConfigurationManager, init=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-23 11:36:21,888 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-23 11:36:21,888 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-23 11:36:21,888 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-23 11:36:21,888 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-23 11:36:21,888 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-23 11:36:21,889 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-23 11:36:21,892 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:21,892 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:21,892 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-23 11:36:21,893 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-23 11:36:21,893 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-23 11:36:21,893 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-23 11:36:21,893 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-23 11:36:21,893 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-23 11:36:21,893 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis] (custom)
2024-03-23 11:36:21,893 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/439e139a-b269-423e-9d21-d246ec176e64 does not exist. Creating ...
2024-03-23 11:36:21,894 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/439e139a-b269-423e-9d21-d246ec176e64/in_use.lock acquired by nodename 18969@fv-az1381-309
2024-03-23 11:36:21,896 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/439e139a-b269-423e-9d21-d246ec176e64 has been successfully formatted.
2024-03-23 11:36:21,896 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/439e139a-b269-423e-9d21-d246ec176e64/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/439e139a-b269-423e-9d21-d246ec176e64/current/raft-meta.conf
2024-03-23 11:36:21,897 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-D246EC176E64: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-23 11:36:21,897 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-23 11:36:21,898 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-23 11:36:21,898 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:21,899 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=439e139a-b269-423e-9d21-d246ec176e64 reported by 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:21,900 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/ONE PipelineID=c0ed46c6-9d24-4a92-bbda-2a12cab7754c reported by 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:21,899 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:21,902 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-23 11:36:21,903 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-23 11:36:21,905 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:21,905 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-23 11:36:21,905 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-23 11:36:21,905 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:21,909 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-cacheEviction-AwaitToRun,5,main] started
2024-03-23 11:36:21,909 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/439e139a-b269-423e-9d21-d246ec176e64
2024-03-23 11:36:21,909 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-23 11:36:21,910 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-23 11:36:21,910 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:21,910 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-23 11:36:21,910 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-23 11:36:21,910 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-23 11:36:21,910 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-23 11:36:21,910 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-23 11:36:21,911 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-23 11:36:21,912 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:21,912 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-23 11:36:21,913 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-23 11:36:21,913 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-23 11:36:21,913 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:21,913 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:21,915 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64: start as a follower, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:36:21,915 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-23 11:36:21,915 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5b4c27d6-a533-4766-a648-a869ad76920c: start 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-FollowerState
2024-03-23 11:36:21,915 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D246EC176E64,id=5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:36:21,915 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-23 11:36:21,915 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-23 11:36:21,915 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-23 11:36:21,915 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-23 11:36:21,915 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-23 11:36:21,916 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=439e139a-b269-423e-9d21-d246ec176e64
2024-03-23 11:36:21,927 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:21,927 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:21,958 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: addNew group-1CE430AE568B:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034] returns group-1CE430AE568B:java.util.concurrent.CompletableFuture@6fb88ae6[Not completed]
2024-03-23 11:36:21,960 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: new RaftServerImpl for group-1CE430AE568B:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034] with ContainerStateMachine:uninitialized
2024-03-23 11:36:21,961 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:21,961 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-23 11:36:21,961 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-23 11:36:21,962 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-23 11:36:21,962 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:36:21,963 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-23 11:36:21,963 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:36:21,963 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B: ConfigurationManager, init=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-23 11:36:21,964 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-23 11:36:21,964 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-23 11:36:21,964 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-23 11:36:21,965 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-23 11:36:21,965 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-23 11:36:21,965 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-23 11:36:21,969 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:21,970 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:21,970 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-23 11:36:21,970 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-23 11:36:21,971 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-23 11:36:21,971 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-23 11:36:21,972 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-23 11:36:21,972 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-23 11:36:21,973 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis] (custom)
2024-03-23 11:36:21,973 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/8643aede-2156-48e1-8210-1ce430ae568b does not exist. Creating ...
2024-03-23 11:36:21,974 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/8643aede-2156-48e1-8210-1ce430ae568b/in_use.lock acquired by nodename 18969@fv-az1381-309
2024-03-23 11:36:21,975 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/8643aede-2156-48e1-8210-1ce430ae568b has been successfully formatted.
2024-03-23 11:36:21,975 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/8643aede-2156-48e1-8210-1ce430ae568b/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/8643aede-2156-48e1-8210-1ce430ae568b/current/raft-meta.conf
2024-03-23 11:36:21,976 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-1CE430AE568B: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-23 11:36:21,976 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-23 11:36:21,976 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-23 11:36:21,976 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:21,976 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-23 11:36:21,977 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-23 11:36:21,978 [IPC Server handler 10 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for fv-az1381-309
2024-03-23 11:36:21,979 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=8643aede-2156-48e1-8210-1ce430ae568b
2024-03-23 11:36:21,979 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/ONE PipelineID=8643aede-2156-48e1-8210-1ce430ae568b reported by 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:21,979 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:21,980 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:21,981 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-23 11:36:21,981 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-23 11:36:21,981 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:21,981 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-cacheEviction-AwaitToRun,5,main] started
2024-03-23 11:36:21,981 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/8643aede-2156-48e1-8210-1ce430ae568b
2024-03-23 11:36:21,981 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-23 11:36:21,981 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-23 11:36:21,982 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:21,982 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-23 11:36:21,982 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-23 11:36:21,982 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-23 11:36:21,982 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-23 11:36:21,982 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-23 11:36:21,983 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-23 11:36:21,984 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:21,984 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-23 11:36:21,984 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-23 11:36:21,984 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-23 11:36:21,984 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:21,984 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:21,985 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B: start as a follower, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034]|listeners:[], old=null
2024-03-23 11:36:21,985 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-23 11:36:21,985 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: start 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-FollowerState
2024-03-23 11:36:21,986 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:21,986 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-1CE430AE568B,id=00b25173-7757-4760-98a7-1e1aa18d5e2d
2024-03-23 11:36:21,987 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-23 11:36:21,987 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-23 11:36:21,987 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-23 11:36:21,987 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-23 11:36:21,987 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-23 11:36:21,988 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:21,989 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=8643aede-2156-48e1-8210-1ce430ae568b
2024-03-23 11:36:21,989 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=8643aede-2156-48e1-8210-1ce430ae568b.
2024-03-23 11:36:21,989 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: addNew group-D246EC176E64:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016] returns group-D246EC176E64:java.util.concurrent.CompletableFuture@6b8703c9[Not completed]
2024-03-23 11:36:21,990 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: new RaftServerImpl for group-D246EC176E64:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016] with ContainerStateMachine:uninitialized
2024-03-23 11:36:21,991 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:21,991 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-23 11:36:21,991 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-23 11:36:21,991 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-23 11:36:21,991 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:36:21,991 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-23 11:36:21,991 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:36:21,991 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64: ConfigurationManager, init=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-23 11:36:21,991 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-23 11:36:21,991 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-23 11:36:21,992 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-23 11:36:21,992 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-23 11:36:21,992 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-23 11:36:21,992 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-23 11:36:21,998 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:21,998 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:21,998 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-23 11:36:21,999 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-23 11:36:21,999 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-23 11:36:21,999 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-23 11:36:21,999 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-23 11:36:21,999 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-23 11:36:21,999 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis] (custom)
2024-03-23 11:36:21,999 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/439e139a-b269-423e-9d21-d246ec176e64 does not exist. Creating ...
2024-03-23 11:36:22,000 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/439e139a-b269-423e-9d21-d246ec176e64/in_use.lock acquired by nodename 18969@fv-az1381-309
2024-03-23 11:36:22,002 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/439e139a-b269-423e-9d21-d246ec176e64 has been successfully formatted.
2024-03-23 11:36:22,002 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/439e139a-b269-423e-9d21-d246ec176e64/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/439e139a-b269-423e-9d21-d246ec176e64/current/raft-meta.conf
2024-03-23 11:36:22,002 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-D246EC176E64: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-23 11:36:22,002 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-23 11:36:22,002 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-23 11:36:22,003 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:22,003 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-23 11:36:22,003 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-23 11:36:22,004 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=439e139a-b269-423e-9d21-d246ec176e64 reported by 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:22,005 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:22,009 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 6 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:22,011 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:22,012 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-23 11:36:22,012 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-23 11:36:22,012 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:22,012 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-cacheEviction-AwaitToRun,5,main] started
2024-03-23 11:36:22,012 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/439e139a-b269-423e-9d21-d246ec176e64
2024-03-23 11:36:22,013 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-23 11:36:22,013 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-23 11:36:22,013 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:22,013 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-23 11:36:22,013 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-23 11:36:22,013 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-23 11:36:22,013 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-23 11:36:22,013 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-23 11:36:22,014 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-23 11:36:22,015 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:22,015 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-23 11:36:22,015 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-23 11:36:22,016 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-23 11:36:22,016 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:22,016 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:22,017 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64: start as a follower, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:36:22,017 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-23 11:36:22,017 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: start 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-FollowerState
2024-03-23 11:36:22,017 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:22,017 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D246EC176E64,id=00b25173-7757-4760-98a7-1e1aa18d5e2d
2024-03-23 11:36:22,017 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:22,017 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-23 11:36:22,017 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-23 11:36:22,018 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-23 11:36:22,018 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-23 11:36:22,018 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-23 11:36:22,019 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=439e139a-b269-423e-9d21-d246ec176e64
2024-03-23 11:36:22,071 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:22,104 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: addNew group-9AF5C7649F72:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043] returns group-9AF5C7649F72:java.util.concurrent.CompletableFuture@654ce0b0[Not completed]
2024-03-23 11:36:22,107 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: new RaftServerImpl for group-9AF5C7649F72:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043] with ContainerStateMachine:uninitialized
2024-03-23 11:36:22,107 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:22,107 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-23 11:36:22,107 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-23 11:36:22,107 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-23 11:36:22,107 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:36:22,107 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-23 11:36:22,107 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:36:22,108 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72: ConfigurationManager, init=-1: peers:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-23 11:36:22,108 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-23 11:36:22,108 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-23 11:36:22,108 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-23 11:36:22,108 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-23 11:36:22,108 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-23 11:36:22,108 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-23 11:36:22,112 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:22,112 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:22,113 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-23 11:36:22,113 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-23 11:36:22,113 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-23 11:36:22,113 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-23 11:36:22,113 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-23 11:36:22,113 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-23 11:36:22,114 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis] (custom)
2024-03-23 11:36:22,114 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis/eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72 does not exist. Creating ...
2024-03-23 11:36:22,115 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis/eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72/in_use.lock acquired by nodename 18969@fv-az1381-309
2024-03-23 11:36:22,116 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis/eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72 has been successfully formatted.
2024-03-23 11:36:22,116 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis/eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis/eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72/current/raft-meta.conf
2024-03-23 11:36:22,116 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-9AF5C7649F72: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-23 11:36:22,116 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-23 11:36:22,117 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-23 11:36:22,117 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:22,117 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-23 11:36:22,117 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-23 11:36:22,118 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:22,118 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-23 11:36:22,119 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-23 11:36:22,119 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:22,119 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-cacheEviction-AwaitToRun,5,main] started
2024-03-23 11:36:22,119 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis/eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72
2024-03-23 11:36:22,119 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-23 11:36:22,119 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-23 11:36:22,119 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:22,119 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-23 11:36:22,119 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-23 11:36:22,119 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-23 11:36:22,120 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-23 11:36:22,120 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-23 11:36:22,120 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-23 11:36:22,121 [IPC Server handler 2 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for fv-az1381-309
2024-03-23 11:36:22,122 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:22,123 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-23 11:36:22,123 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/ONE PipelineID=eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72 reported by bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:22,123 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-23 11:36:22,123 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-23 11:36:22,123 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:22,123 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:22,123 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72: start as a follower, conf=-1: peers:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043]|listeners:[], old=null
2024-03-23 11:36:22,124 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-23 11:36:22,124 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: start bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-FollowerState
2024-03-23 11:36:22,124 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9AF5C7649F72,id=bb4f2f6f-344d-4a57-aba3-69abe2cb722c
2024-03-23 11:36:22,124 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:22,124 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-23 11:36:22,124 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-23 11:36:22,125 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-23 11:36:22,125 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-23 11:36:22,125 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-23 11:36:22,128 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72
2024-03-23 11:36:22,128 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72.
2024-03-23 11:36:22,124 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:22,126 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72
2024-03-23 11:36:22,128 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:22,148 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5) moved to stale state. Finalizing its pipelines [PipelineID=eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72]
2024-03-23 11:36:22,148 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72 moved to CLOSED state
2024-03-23 11:36:22,152 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 6 pipelines in house.
2024-03-23 11:36:22,155 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 6 milliseconds.
2024-03-23 11:36:22,156 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:22,156 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:22,201 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-03-23 11:36:22,202 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-03-23 11:36:22,202 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-23 11:36:22,217 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: addNew group-E1AE4BA72BFE:[6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052] returns group-E1AE4BA72BFE:java.util.concurrent.CompletableFuture@27d5235c[Not completed]
2024-03-23 11:36:22,218 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: new RaftServerImpl for group-E1AE4BA72BFE:[6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052] with ContainerStateMachine:uninitialized
2024-03-23 11:36:22,218 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:22,219 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-23 11:36:22,219 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-23 11:36:22,219 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-23 11:36:22,219 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:36:22,219 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-23 11:36:22,219 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:36:22,219 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE: ConfigurationManager, init=-1: peers:[6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-23 11:36:22,219 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-23 11:36:22,219 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-23 11:36:22,220 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-23 11:36:22,220 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-23 11:36:22,220 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-23 11:36:22,220 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-23 11:36:22,242 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:22,242 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:22,242 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-23 11:36:22,242 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-23 11:36:22,242 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-23 11:36:22,242 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-23 11:36:22,242 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-23 11:36:22,243 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-23 11:36:22,243 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis] (custom)
2024-03-23 11:36:22,243 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/075a3443-897d-4510-a745-e1ae4ba72bfe does not exist. Creating ...
2024-03-23 11:36:22,244 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/075a3443-897d-4510-a745-e1ae4ba72bfe/in_use.lock acquired by nodename 18969@fv-az1381-309
2024-03-23 11:36:22,245 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/075a3443-897d-4510-a745-e1ae4ba72bfe has been successfully formatted.
2024-03-23 11:36:22,246 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/075a3443-897d-4510-a745-e1ae4ba72bfe/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/075a3443-897d-4510-a745-e1ae4ba72bfe/current/raft-meta.conf
2024-03-23 11:36:22,248 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5) moved to stale state. Finalizing its pipelines [PipelineID=075a3443-897d-4510-a745-e1ae4ba72bfe]
2024-03-23 11:36:22,249 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=075a3443-897d-4510-a745-e1ae4ba72bfe moved to CLOSED state
2024-03-23 11:36:22,253 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 6 pipelines in house.
2024-03-23 11:36:22,261 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-E1AE4BA72BFE: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-23 11:36:22,263 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-23 11:36:22,263 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-23 11:36:22,264 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:22,264 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-23 11:36:22,264 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-23 11:36:22,268 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=075a3443-897d-4510-a745-e1ae4ba72bfe
2024-03-23 11:36:22,268 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:22,262 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 13 milliseconds.
2024-03-23 11:36:22,271 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:22,273 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-23 11:36:22,273 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-23 11:36:22,273 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:22,264 [IPC Server handler 4 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for fv-az1381-309
2024-03-23 11:36:22,274 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/ONE PipelineID=075a3443-897d-4510-a745-e1ae4ba72bfe reported by 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:22,274 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-cacheEviction-AwaitToRun,5,main] started
2024-03-23 11:36:22,274 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/075a3443-897d-4510-a745-e1ae4ba72bfe
2024-03-23 11:36:22,274 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-23 11:36:22,274 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-23 11:36:22,275 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:22,275 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-23 11:36:22,275 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-23 11:36:22,275 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-23 11:36:22,275 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-23 11:36:22,275 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-23 11:36:22,276 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-23 11:36:22,278 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:22,279 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-23 11:36:22,279 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-23 11:36:22,279 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-23 11:36:22,279 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:22,279 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:22,282 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE: start as a follower, conf=-1: peers:[6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:22,283 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-23 11:36:22,283 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: start 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-FollowerState
2024-03-23 11:36:22,284 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:22,284 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E1AE4BA72BFE,id=6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:22,288 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-23 11:36:22,288 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-23 11:36:22,288 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-23 11:36:22,289 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-23 11:36:22,289 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-23 11:36:22,288 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:22,294 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=075a3443-897d-4510-a745-e1ae4ba72bfe
2024-03-23 11:36:22,294 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=075a3443-897d-4510-a745-e1ae4ba72bfe.
2024-03-23 11:36:22,326 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=439e139a-b269-423e-9d21-d246ec176e64.
2024-03-23 11:36:22,328 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=439e139a-b269-423e-9d21-d246ec176e64.
2024-03-23 11:36:22,331 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=439e139a-b269-423e-9d21-d246ec176e64.
2024-03-23 11:36:22,738 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=439e139a-b269-423e-9d21-d246ec176e64 reported by e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:22,739 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:22,900 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:22,900 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=439e139a-b269-423e-9d21-d246ec176e64 reported by 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:23,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:23,157 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:23,157 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:23,202 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-03-23 11:36:23,202 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-03-23 11:36:23,202 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-23 11:36:23,259 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:23,738 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=439e139a-b269-423e-9d21-d246ec176e64 reported by e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:23,738 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:24,004 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=439e139a-b269-423e-9d21-d246ec176e64 reported by 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:24,005 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:24,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:24,119 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:24,158 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:24,158 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:24,203 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-03-23 11:36:24,203 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-03-23 11:36:24,203 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-23 11:36:24,259 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:24,899 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=439e139a-b269-423e-9d21-d246ec176e64 reported by 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:24,900 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:25,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:25,160 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:25,160 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:25,203 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-03-23 11:36:25,203 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-03-23 11:36:25,204 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-23 11:36:25,261 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:25,261 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:25,738 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=439e139a-b269-423e-9d21-d246ec176e64 reported by e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:25,740 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:25,899 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:25,899 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=439e139a-b269-423e-9d21-d246ec176e64 reported by 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:26,005 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=439e139a-b269-423e-9d21-d246ec176e64 reported by 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:26,005 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:26,072 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:26,119 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:26,161 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:26,161 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:26,204 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-03-23 11:36:26,204 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-03-23 11:36:26,204 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-23 11:36:26,260 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:26,262 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:26,262 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:26,738 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=439e139a-b269-423e-9d21-d246ec176e64 reported by e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:26,739 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:26,740 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:26,740 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:26,899 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:26,899 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5184164291ns, electionTimeout:5182ms
2024-03-23 11:36:26,900 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:26,899 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=439e139a-b269-423e-9d21-d246ec176e64 reported by 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:26,900 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:26,901 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - e3882025-ee77-4273-a30c-caf156427e83: shutdown e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-FollowerState
2024-03-23 11:36:26,901 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-23 11:36:26,901 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-23 11:36:26,901 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e3882025-ee77-4273-a30c-caf156427e83: start e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2
2024-03-23 11:36:26,903 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:36:26,903 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2 PRE_VOTE round 0: result PASSED (term=0)
2024-03-23 11:36:26,904 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: peers:[e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:36:26,904 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2 ELECTION round 0: result PASSED (term=1)
2024-03-23 11:36:26,904 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - e3882025-ee77-4273-a30c-caf156427e83: shutdown e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2
2024-03-23 11:36:26,904 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-23 11:36:26,904 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-03-23 11:36:26,904 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-23 11:36:26,905 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-03-23 11:36:26,905 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-03-23 11:36:26,905 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-03-23 11:36:26,905 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-03-23 11:36:26,905 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-03-23 11:36:26,906 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-23 11:36:26,906 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:26,906 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-23 11:36:26,906 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-23 11:36:26,906 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e3882025-ee77-4273-a30c-caf156427e83: start e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderStateImpl
2024-03-23 11:36:26,906 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE: set firstElectionSinceStartup to false for becomeLeader
2024-03-23 11:36:26,906 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-3A831E3069BE with new leaderId: e3882025-ee77-4273-a30c-caf156427e83
2024-03-23 11:36:26,907 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE: change Leader from null to e3882025-ee77-4273-a30c-caf156427e83 at term 1 for becomeLeader, leader elected after 5234ms
2024-03-23 11:36:26,907 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-23 11:36:26,907 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-23 11:36:26,908 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderElection2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE: set configuration 0: peers:[e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:36:26,910 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:26,908 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5153533820ns, electionTimeout:5141ms
2024-03-23 11:36:26,911 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - e3882025-ee77-4273-a30c-caf156427e83: shutdown e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-FollowerState
2024-03-23 11:36:26,911 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-23 11:36:26,911 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-23 11:36:26,911 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e3882025-ee77-4273-a30c-caf156427e83: start e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-LeaderElection3
2024-03-23 11:36:26,911 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=439e139a-b269-423e-9d21-d246ec176e64 reported by e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:26,913 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-LeaderElection3 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:36:26,917 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/07524b35-b4dd-487c-8fd9-3a831e3069be/current/log_inprogress_0
2024-03-23 11:36:26,919 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:26,919 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:26,922 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-LeaderElection3-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034
2024-03-23 11:36:26,923 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-LeaderElection3-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025
2024-03-23 11:36:26,927 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5012186238ns, electionTimeout:5000ms
2024-03-23 11:36:26,927 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 5b4c27d6-a533-4766-a648-a869ad76920c: shutdown 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-FollowerState
2024-03-23 11:36:26,927 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-23 11:36:26,927 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-23 11:36:26,927 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5b4c27d6-a533-4766-a648-a869ad76920c: start 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4
2024-03-23 11:36:26,930 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:36:26,931 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-23 11:36:26,933 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034
2024-03-23 11:36:26,939 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:26,941 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:26,941 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016
2024-03-23 11:36:26,941 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64: receive requestVote(PRE_VOTE, e3882025-ee77-4273-a30c-caf156427e83, group-D246EC176E64, 0, (t:0, i:0))
2024-03-23 11:36:26,947 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64: receive requestVote(PRE_VOTE, e3882025-ee77-4273-a30c-caf156427e83, group-D246EC176E64, 0, (t:0, i:0))
2024-03-23 11:36:26,948 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-FOLLOWER: accept PRE_VOTE from e3882025-ee77-4273-a30c-caf156427e83: our priority 0 <= candidate's priority 0
2024-03-23 11:36:26,953 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-CANDIDATE: reject PRE_VOTE from e3882025-ee77-4273-a30c-caf156427e83: our priority 1 > candidate's priority 0
2024-03-23 11:36:26,954 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64 replies to PRE_VOTE vote request: e3882025-ee77-4273-a30c-caf156427e83<-5b4c27d6-a533-4766-a648-a869ad76920c#0:FAIL-t0. Peer's state: 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64:t0, leader=null, voted=, raftlog=Memoized:5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:36:26,954 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64 replies to PRE_VOTE vote request: e3882025-ee77-4273-a30c-caf156427e83<-00b25173-7757-4760-98a7-1e1aa18d5e2d#0:OK-t0. Peer's state: 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64:t0, leader=null, voted=, raftlog=Memoized:00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:36:26,967 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-LeaderElection3: PRE_VOTE REJECTED received 2 response(s) and 0 exception(s):
2024-03-23 11:36:26,967 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: e3882025-ee77-4273-a30c-caf156427e83<-00b25173-7757-4760-98a7-1e1aa18d5e2d#0:OK-t0
2024-03-23 11:36:26,967 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 1: e3882025-ee77-4273-a30c-caf156427e83<-5b4c27d6-a533-4766-a648-a869ad76920c#0:FAIL-t0
2024-03-23 11:36:26,969 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-LeaderElection3 PRE_VOTE round 0: result REJECTED
2024-03-23 11:36:26,969 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-LeaderElection3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2024-03-23 11:36:26,969 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - e3882025-ee77-4273-a30c-caf156427e83: shutdown e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-LeaderElection3
2024-03-23 11:36:26,969 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e3882025-ee77-4273-a30c-caf156427e83: start e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-FollowerState
2024-03-23 11:36:26,969 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-LeaderElection3] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64: set firstElectionSinceStartup to false for REJECTED
2024-03-23 11:36:26,971 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64: receive requestVote(PRE_VOTE, 5b4c27d6-a533-4766-a648-a869ad76920c, group-D246EC176E64, 0, (t:0, i:0))
2024-03-23 11:36:26,974 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64: receive requestVote(PRE_VOTE, 5b4c27d6-a533-4766-a648-a869ad76920c, group-D246EC176E64, 0, (t:0, i:0))
2024-03-23 11:36:26,974 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-FOLLOWER: accept PRE_VOTE from 5b4c27d6-a533-4766-a648-a869ad76920c: our priority 0 <= candidate's priority 1
2024-03-23 11:36:26,974 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64 replies to PRE_VOTE vote request: 5b4c27d6-a533-4766-a648-a869ad76920c<-00b25173-7757-4760-98a7-1e1aa18d5e2d#0:OK-t0. Peer's state: 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64:t0, leader=null, voted=, raftlog=Memoized:00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:36:26,974 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(49)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-FOLLOWER: accept PRE_VOTE from 5b4c27d6-a533-4766-a648-a869ad76920c: our priority 0 <= candidate's priority 1
2024-03-23 11:36:26,974 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64 replies to PRE_VOTE vote request: 5b4c27d6-a533-4766-a648-a869ad76920c<-e3882025-ee77-4273-a30c-caf156427e83#0:OK-t0. Peer's state: e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64:t0, leader=null, voted=, raftlog=Memoized:e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:36:26,977 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2024-03-23 11:36:26,978 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 5b4c27d6-a533-4766-a648-a869ad76920c<-00b25173-7757-4760-98a7-1e1aa18d5e2d#0:OK-t0
2024-03-23 11:36:26,978 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4 PRE_VOTE round 0: result PASSED
2024-03-23 11:36:26,979 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4 ELECTION round 0: submit vote requests at term 1 for -1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:36:26,980 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:26,980 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:26,995 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64: receive requestVote(ELECTION, 5b4c27d6-a533-4766-a648-a869ad76920c, group-D246EC176E64, 1, (t:0, i:0))
2024-03-23 11:36:26,996 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64: receive requestVote(ELECTION, 5b4c27d6-a533-4766-a648-a869ad76920c, group-D246EC176E64, 1, (t:0, i:0))
2024-03-23 11:36:26,996 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-FOLLOWER: accept ELECTION from 5b4c27d6-a533-4766-a648-a869ad76920c: our priority 0 <= candidate's priority 1
2024-03-23 11:36:26,996 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:36:26,996 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - e3882025-ee77-4273-a30c-caf156427e83: shutdown e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-FollowerState
2024-03-23 11:36:26,997 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e3882025-ee77-4273-a30c-caf156427e83: start e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-FollowerState
2024-03-23 11:36:26,997 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-FollowerState was interrupted
2024-03-23 11:36:27,002 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64 replies to ELECTION vote request: 5b4c27d6-a533-4766-a648-a869ad76920c<-e3882025-ee77-4273-a30c-caf156427e83#0:OK-t1. Peer's state: e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64:t1, leader=null, voted=5b4c27d6-a533-4766-a648-a869ad76920c, raftlog=Memoized:e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:36:27,004 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4: ELECTION PASSED received 1 response(s) and 0 exception(s):
2024-03-23 11:36:27,004 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 5b4c27d6-a533-4766-a648-a869ad76920c<-e3882025-ee77-4273-a30c-caf156427e83#0:OK-t1
2024-03-23 11:36:27,004 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4 ELECTION round 0: result PASSED
2024-03-23 11:36:27,004 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 5b4c27d6-a533-4766-a648-a869ad76920c: shutdown 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4
2024-03-23 11:36:27,004 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-23 11:36:27,004 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-03-23 11:36:27,005 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-23 11:36:27,005 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-03-23 11:36:27,005 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-03-23 11:36:27,005 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-03-23 11:36:27,005 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-03-23 11:36:27,005 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-03-23 11:36:27,006 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-23 11:36:27,006 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:27,007 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(49)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-FOLLOWER: accept ELECTION from 5b4c27d6-a533-4766-a648-a869ad76920c: our priority 0 <= candidate's priority 1
2024-03-23 11:36:27,008 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:36:27,008 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: shutdown 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-FollowerState
2024-03-23 11:36:27,008 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: start 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-FollowerState
2024-03-23 11:36:27,007 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-23 11:36:27,008 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-FollowerState was interrupted
2024-03-23 11:36:27,008 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-23 11:36:27,009 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64: set firstElectionSinceStartup to false for candidate:5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:36:27,010 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64 replies to ELECTION vote request: 5b4c27d6-a533-4766-a648-a869ad76920c<-00b25173-7757-4760-98a7-1e1aa18d5e2d#0:OK-t1. Peer's state: 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64:t1, leader=null, voted=5b4c27d6-a533-4766-a648-a869ad76920c, raftlog=Memoized:00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:36:27,012 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5026791076ns, electionTimeout:5024ms
2024-03-23 11:36:27,012 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: shutdown 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-FollowerState
2024-03-23 11:36:27,012 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-23 11:36:27,012 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-23 11:36:27,012 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: start 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5
2024-03-23 11:36:27,019 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034]|listeners:[], old=null
2024-03-23 11:36:27,020 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-03-23 11:36:27,020 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:27,020 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2024-03-23 11:36:27,022 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0s (custom)
2024-03-23 11:36:27,025 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-03-23 11:36:27,020 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5 PRE_VOTE round 0: result PASSED (term=0)
2024-03-23 11:36:27,026 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:27,026 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-03-23 11:36:27,026 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5 ELECTION round 0: submit vote requests at term 1 for -1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034]|listeners:[], old=null
2024-03-23 11:36:27,026 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5 ELECTION round 0: result PASSED (term=1)
2024-03-23 11:36:27,027 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: shutdown 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5
2024-03-23 11:36:27,027 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-23 11:36:27,027 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-03-23 11:36:27,027 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-23 11:36:27,027 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-03-23 11:36:27,028 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-03-23 11:36:27,028 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-03-23 11:36:27,028 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-03-23 11:36:27,028 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-03-23 11:36:27,028 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-23 11:36:27,028 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:27,028 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-23 11:36:27,028 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-23 11:36:27,029 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: start 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderStateImpl
2024-03-23 11:36:27,029 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B: set firstElectionSinceStartup to false for becomeLeader
2024-03-23 11:36:27,029 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-1CE430AE568B with new leaderId: 00b25173-7757-4760-98a7-1e1aa18d5e2d
2024-03-23 11:36:27,029 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B: change Leader from null to 00b25173-7757-4760-98a7-1e1aa18d5e2d at term 1 for becomeLeader, leader elected after 5064ms
2024-03-23 11:36:27,029 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-23 11:36:27,030 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-03-23 11:36:27,030 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-03-23 11:36:27,030 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:27,030 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-23 11:36:27,031 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=439e139a-b269-423e-9d21-d246ec176e64 reported by 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:27,030 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-23 11:36:27,033 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderElection5] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B: set configuration 0: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034]|listeners:[], old=null
2024-03-23 11:36:27,036 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-23 11:36:27,040 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/8643aede-2156-48e1-8210-1ce430ae568b/current/log_inprogress_0
2024-03-23 11:36:27,042 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-23 11:36:27,043 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-03-23 11:36:27,044 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:27,044 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2024-03-23 11:36:27,044 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0s (custom)
2024-03-23 11:36:27,045 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-03-23 11:36:27,045 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:27,045 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-03-23 11:36:27,045 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-03-23 11:36:27,045 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-03-23 11:36:27,045 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:27,045 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-23 11:36:27,046 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5b4c27d6-a533-4766-a648-a869ad76920c: start 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderStateImpl
2024-03-23 11:36:27,046 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64: set firstElectionSinceStartup to false for becomeLeader
2024-03-23 11:36:27,046 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-D246EC176E64 with new leaderId: 5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:36:27,047 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64: change Leader from null to 5b4c27d6-a533-4766-a648-a869ad76920c at term 1 for becomeLeader, leader elected after 5158ms
2024-03-23 11:36:27,048 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-23 11:36:27,048 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-23 11:36:27,053 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=439e139a-b269-423e-9d21-d246ec176e64
2024-03-23 11:36:27,053 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=439e139a-b269-423e-9d21-d246ec176e64 reported by 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:27,054 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderElection4] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64: set configuration 0: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:36:27,054 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2024-03-23 11:36:27,055 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - HealthyPipelineSafeModeRule rule is successfully validated
2024-03-23 11:36:27,055 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2024-03-23 11:36:27,055 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2024-03-23 11:36:27,055 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(225)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2024-03-23 11:36:27,055 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(258)) - Service BackgroundPipelineCreator transitions to RUNNING.
2024-03-23 11:36:27,055 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(79)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2024-03-23 11:36:27,055 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(79)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2024-03-23 11:36:27,055 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:notifyStatusChanged(247)) - notifyStatusChanged:RUNNING
2024-03-23 11:36:27,055 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(1403)) - Service ReplicationManager transitions to RUNNING.
2024-03-23 11:36:27,056 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(134)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2024-03-23 11:36:27,057 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/439e139a-b269-423e-9d21-d246ec176e64/current/log_inprogress_0
2024-03-23 11:36:27,068 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5192411453ns, electionTimeout:5184ms
2024-03-23 11:36:27,068 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 5b4c27d6-a533-4766-a648-a869ad76920c: shutdown 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-FollowerState
2024-03-23 11:36:27,068 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-23 11:36:27,068 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-23 11:36:27,068 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5b4c27d6-a533-4766-a648-a869ad76920c: start 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6
2024-03-23 11:36:27,074 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:27,079 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025]|listeners:[], old=null
2024-03-23 11:36:27,079 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6 PRE_VOTE round 0: result PASSED (term=0)
2024-03-23 11:36:27,082 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6 ELECTION round 0: submit vote requests at term 1 for -1: peers:[5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025]|listeners:[], old=null
2024-03-23 11:36:27,082 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6 ELECTION round 0: result PASSED (term=1)
2024-03-23 11:36:27,082 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 5b4c27d6-a533-4766-a648-a869ad76920c: shutdown 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6
2024-03-23 11:36:27,083 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-23 11:36:27,083 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-03-23 11:36:27,090 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-23 11:36:27,098 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-03-23 11:36:27,098 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-03-23 11:36:27,099 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-03-23 11:36:27,099 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-03-23 11:36:27,099 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-03-23 11:36:27,099 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-23 11:36:27,099 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:27,099 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-23 11:36:27,099 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-23 11:36:27,099 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5b4c27d6-a533-4766-a648-a869ad76920c: start 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderStateImpl
2024-03-23 11:36:27,099 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C: set firstElectionSinceStartup to false for becomeLeader
2024-03-23 11:36:27,100 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-2A12CAB7754C with new leaderId: 5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:36:27,110 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C: change Leader from null to 5b4c27d6-a533-4766-a648-a869ad76920c at term 1 for becomeLeader, leader elected after 5257ms
2024-03-23 11:36:27,111 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-23 11:36:27,114 [e3882025-ee77-4273-a30c-caf156427e83-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-D246EC176E64 with new leaderId: 5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:36:27,117 [e3882025-ee77-4273-a30c-caf156427e83-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64: change Leader from null to 5b4c27d6-a533-4766-a648-a869ad76920c at term 1 for appendEntries, leader elected after 5388ms
2024-03-23 11:36:27,117 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-23 11:36:27,124 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:27,127 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 6 millisec, bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:27,124 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderElection6] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C: set configuration 0: peers:[5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025]|listeners:[], old=null
2024-03-23 11:36:27,128 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/c0ed46c6-9d24-4a92-bbda-2a12cab7754c/current/log_inprogress_0
2024-03-23 11:36:27,131 [00b25173-7757-4760-98a7-1e1aa18d5e2d-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-D246EC176E64 with new leaderId: 5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:36:27,131 [00b25173-7757-4760-98a7-1e1aa18d5e2d-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64: change Leader from null to 5b4c27d6-a533-4766-a648-a869ad76920c at term 1 for appendEntries, leader elected after 5139ms
2024-03-23 11:36:27,136 [e3882025-ee77-4273-a30c-caf156427e83-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64: set configuration 0: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:36:27,140 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-23 11:36:27,143 [00b25173-7757-4760-98a7-1e1aa18d5e2d-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64: set configuration 0: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:36:27,144 [00b25173-7757-4760-98a7-1e1aa18d5e2d-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-23 11:36:27,144 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-23 11:36:27,144 [e3882025-ee77-4273-a30c-caf156427e83-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-23 11:36:27,145 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-23 11:36:27,155 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/439e139a-b269-423e-9d21-d246ec176e64/current/log_inprogress_0
2024-03-23 11:36:27,155 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/439e139a-b269-423e-9d21-d246ec176e64/current/log_inprogress_0
2024-03-23 11:36:27,162 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:27,162 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:27,162 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-23 11:36:27,204 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-03-23 11:36:27,205 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Cluster exits safe mode
2024-03-23 11:36:27,205 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-23 11:36:27,205 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(59)) - No unit for hdds.scmclient.rpc.timeout(60000) assuming MILLISECONDS
2024-03-23 11:36:27,205 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(59)) - No unit for hdds.scmclient.max.retry.timeout(6000) assuming MILLISECONDS
2024-03-23 11:36:27,209 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(59)) - No unit for hdds.scmclient.rpc.timeout(60000) assuming MILLISECONDS
2024-03-23 11:36:27,209 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(59)) - No unit for hdds.scmclient.max.retry.timeout(6000) assuming MILLISECONDS
2024-03-23 11:36:27,213 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5089509932ns, electionTimeout:5085ms
2024-03-23 11:36:27,213 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: shutdown bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-FollowerState
2024-03-23 11:36:27,213 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-23 11:36:27,213 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-23 11:36:27,214 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: start bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7
2024-03-23 11:36:27,215 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043]|listeners:[], old=null
2024-03-23 11:36:27,215 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7 PRE_VOTE round 0: result PASSED (term=0)
2024-03-23 11:36:27,216 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7 ELECTION round 0: submit vote requests at term 1 for -1: peers:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043]|listeners:[], old=null
2024-03-23 11:36:27,217 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7 ELECTION round 0: result PASSED (term=1)
2024-03-23 11:36:27,217 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: shutdown bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7
2024-03-23 11:36:27,217 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-23 11:36:27,217 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-03-23 11:36:27,217 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-23 11:36:27,217 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-03-23 11:36:27,218 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-03-23 11:36:27,218 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-03-23 11:36:27,218 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-03-23 11:36:27,218 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-03-23 11:36:27,218 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-23 11:36:27,218 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:27,218 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-23 11:36:27,218 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-23 11:36:27,219 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: start bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderStateImpl
2024-03-23 11:36:27,219 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72: set firstElectionSinceStartup to false for becomeLeader
2024-03-23 11:36:27,219 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-9AF5C7649F72 with new leaderId: bb4f2f6f-344d-4a57-aba3-69abe2cb722c
2024-03-23 11:36:27,219 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72: change Leader from null to bb4f2f6f-344d-4a57-aba3-69abe2cb722c at term 1 for becomeLeader, leader elected after 5110ms
2024-03-23 11:36:27,219 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-23 11:36:27,219 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-23 11:36:27,225 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderElection7] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72: set configuration 0: peers:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043]|listeners:[], old=null
2024-03-23 11:36:27,228 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis/eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72/current/log_inprogress_0
2024-03-23 11:36:27,230 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-23 11:36:27,291 [main] INFO  protocolPB.OmTransportFactory (OmTransportFactory.java:createFactory(62)) - Loading OM transport implementation org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory as specified by configuration.
2024-03-23 11:36:27,331 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5047293808ns, electionTimeout:5041ms
2024-03-23 11:36:27,331 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: shutdown 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-FollowerState
2024-03-23 11:36:27,331 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-23 11:36:27,331 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-23 11:36:27,331 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: start 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8
2024-03-23 11:36:27,335 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:27,335 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8 PRE_VOTE round 0: result PASSED (term=0)
2024-03-23 11:36:27,336 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8 ELECTION round 0: submit vote requests at term 1 for -1: peers:[6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:27,336 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8 ELECTION round 0: result PASSED (term=1)
2024-03-23 11:36:27,336 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: shutdown 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8
2024-03-23 11:36:27,337 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-23 11:36:27,337 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-03-23 11:36:27,337 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-23 11:36:27,337 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-03-23 11:36:27,337 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-03-23 11:36:27,338 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-03-23 11:36:27,338 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-03-23 11:36:27,338 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-03-23 11:36:27,338 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-23 11:36:27,338 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:27,338 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-23 11:36:27,338 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-23 11:36:27,338 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: start 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderStateImpl
2024-03-23 11:36:27,338 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE: set firstElectionSinceStartup to false for becomeLeader
2024-03-23 11:36:27,341 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-E1AE4BA72BFE with new leaderId: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:27,341 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE: change Leader from null to 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b at term 1 for becomeLeader, leader elected after 5118ms
2024-03-23 11:36:27,341 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-23 11:36:27,342 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderElection8] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE: set configuration 0: peers:[6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:27,342 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-23 11:36:27,352 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/075a3443-897d-4510-a745-e1ae4ba72bfe/current/log_inprogress_0
2024-03-23 11:36:27,354 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-23 11:36:27,550 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(464)) - Creating Volume: vol1, with user40799 as owner and space quota set to -1 bytes, counts quota set to -1
2024-03-23 11:36:27,594 [om1-OMStateMachineApplyTransactionThread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(198)) - created volume:vol1 for user:user40799
2024-03-23 11:36:27,601 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(71)) - OmKeyInfo.getCodec ignorePipeline = true
2024-03-23 11:36:27,601 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(71)) - OmKeyInfo.getCodec ignorePipeline = true
2024-03-23 11:36:27,601 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(71)) - OmKeyInfo.getCodec ignorePipeline = true
2024-03-23 11:36:27,601 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(71)) - OmKeyInfo.getCodec ignorePipeline = true
2024-03-23 11:36:27,601 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(71)) - OmKeyInfo.getCodec ignorePipeline = true
2024-03-23 11:36:27,609 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(690)) - Creating Bucket: vol1/bucket1, with bucket layout FILE_SYSTEM_OPTIMIZED, runner as owner, Versioning false, Storage Type set to DISK and Encryption set to false, Replication Type set to server-side default replication type, Namespace Quota set to -1, Space Quota set to -1 
2024-03-23 11:36:27,620 [om1-OMStateMachineApplyTransactionThread - 0] INFO  bucket.OMBucketCreateRequest (OMBucketCreateRequest.java:validateAndUpdateCache(293)) - created bucket: bucket1 of layout FILE_SYSTEM_OPTIMIZED in volume: vol1
2024-03-23 11:36:27,667 [IPC Server handler 4 on default port 15001] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(145)) - Allocate a batch for containerId, change lastId from 0 to 1000.
2024-03-23 11:36:27,675 [IPC Server handler 4 on default port 15001] WARN  ha.SequenceIdGenerator (SequenceIdGenerator.java:allocateBatch(258)) - Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 113750153625600000.
2024-03-23 11:36:27,675 [IPC Server handler 4 on default port 15001] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(145)) - Allocate a batch for localId, change lastId from 113750153625600000 to 113750153625601000.
2024-03-23 11:36:27,744 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - XceiverClientMetrics metrics system started (again)
2024-03-23 11:36:27,914 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 4 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: ICR, size: 1}
2024-03-23 11:36:27,915 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:27,915 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:27,915 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: ICR, size: 1}
2024-03-23 11:36:27,915 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: ICR, size: 1}
2024-03-23 11:36:27,917 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 5 millisec, 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5), {type: ICR, size: 1}
2024-03-23 11:36:27,918 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 6 millisec, 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5), {type: ICR, size: 1}
2024-03-23 11:36:27,922 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:addNewContainer(246)) - Successfully added container #1 to Recon.
2024-03-23 11:36:27,922 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:addNewContainer(246)) - Successfully added container #1 to Recon.
2024-03-23 11:36:27,933 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 22 millisec, 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5), {type: ICR, size: 1}
2024-03-23 11:36:27,933 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 24 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: ICR, size: 1}
2024-03-23 11:36:27,934 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 23 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:27,934 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 23 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:27,934 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 24 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: ICR, size: 1}
2024-03-23 11:36:27,935 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 24 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: ICR, size: 1}
Connecting to Recon: http://0.0.0.0:15008/api/v1/triggerdbsync/om ...
2024-03-23 11:36:28,078 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:28,131 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:28,132 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(537)) - Obtaining full snapshot from Ozone Manager
2024-03-23 11:36:28,151 [qtp1521342613-410] INFO  utils.DBCheckpointServlet (DBCheckpointServlet.java:doGet(301)) - Received GET request to obtain DB checkpoint snapshot
2024-03-23 11:36:28,163 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:28,177 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 14 milliseconds for processing 1 containers.
2024-03-23 11:36:28,178 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:28,178 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:28,178 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:28,178 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:28,178 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:28,178 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:28,179 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:28,912 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:28,913 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:28,913 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:28,912 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:28,913 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:28,914 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:29,013 [qtp1521342613-410] INFO  om.OMDBCheckpointServlet (OMDBCheckpointServlet.java:getCheckpoint(246)) - Compaction pausing 1 started.
2024-03-23 11:36:29,044 [qtp1521342613-410] INFO  db.RDBCheckpointManager (RDBCheckpointManager.java:createCheckpoint(89)) - Created checkpoint in rocksDB at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/db.checkpoints/om.db_checkpoint_1711193789022 in 22 milliseconds
2024-03-23 11:36:29,047 [qtp1521342613-410] INFO  om.OMDBCheckpointServlet (OMDBCheckpointServlet.java:getCheckpoint(258)) - Compaction pausing 1 ended. Elapsed ms: 34
2024-03-23 11:36:29,064 [qtp1521342613-410] INFO  utils.DBCheckpointServlet (DBCheckpointServlet.java:generateSnapshotCheckpoint(225)) - Time taken to write the checkpoint to response output stream: 17 milliseconds
2024-03-23 11:36:29,064 [qtp1521342613-410] INFO  utils.DBCheckpointServlet (DBCheckpointServlet.java:generateSnapshotCheckpoint(228)) - Excluded SST [] from the latest checkpoint.
2024-03-23 11:36:29,076 [qtp1521342613-410] INFO  db.RocksDBCheckpoint (RocksDBCheckpoint.java:cleanupCheckpoint(78)) - Cleaning up RocksDB checkpoint at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/db.checkpoints/om.db_checkpoint_1711193789022
2024-03-23 11:36:29,078 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-23 11:36:29,078 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:updateReconOmDBWithNewSnapshot(390)) - Got new checkpoint from OM : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/recon/om.snapshot.db_1711193788132
2024-03-23 11:36:29,079 [Recon-SyncOM-1] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(71)) - OmKeyInfo.getCodec ignorePipeline = true
2024-03-23 11:36:29,108 [Recon-SyncOM-1] INFO  recovery.ReconOmMetadataManagerImpl (ReconOmMetadataManagerImpl.java:initializeNewRdbStore(107)) - Created OM DB handle from snapshot at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/recon/om.snapshot.db_1711193788132.
2024-03-23 11:36:29,118 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(550)) - Calling reprocess on Recon tasks.
2024-03-23 11:36:29,180 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:29,183 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:29,183 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:29,183 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:29,183 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:29,183 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:29,183 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:29,183 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:29,183 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:29,245 [ReconTaskThread-0] INFO  tasks.OmTableInsightTask (OmTableInsightTask.java:reprocess(137)) - Completed a 'reprocess' run of OmTableInsightTask.
2024-03-23 11:36:29,247 [Recon-NSSummaryTask-1] INFO  tasks.NSSummaryTaskWithLegacy (NSSummaryTaskWithLegacy.java:reprocessWithLegacy(267)) - Completed a reprocess run of NSSummaryTaskWithLegacy
2024-03-23 11:36:29,247 [Recon-NSSummaryTask-1] INFO  tasks.NSSummaryTaskWithOBS (NSSummaryTaskWithOBS.java:reprocessWithOBS(110)) - Completed a reprocess run of NSSummaryTaskWithOBS
2024-03-23 11:36:29,248 [Recon-NSSummaryTask-0] INFO  tasks.NSSummaryTaskWithFSO (NSSummaryTaskWithFSO.java:reprocessWithFSO(213)) - Completed a reprocess run of NSSummaryTaskWithFSO
2024-03-23 11:36:29,249 [ReconTaskThread-0] INFO  tasks.NSSummaryTask (NSSummaryTask.java:reprocess(169)) - Task execution time: 3 milliseconds
2024-03-23 11:36:29,249 [ReconTaskThread-0] INFO  tasks.ContainerKeyMapperTask (ContainerKeyMapperTask.java:reprocess(97)) - Starting a 'reprocess' run of ContainerKeyMapperTask.
2024-03-23 11:36:29,250 [ReconTaskThread-0] INFO  impl.ReconContainerMetadataManagerImpl (ReconContainerMetadataManagerImpl.java:initializeTables(141)) - KEY_CONTAINER Table is empty, initializing from CONTAINER_KEY Table ...
2024-03-23 11:36:29,250 [ReconTaskThread-0] INFO  impl.ReconContainerMetadataManagerImpl (ReconContainerMetadataManagerImpl.java:initializeKeyContainerTable(666)) - It took 0.0 seconds to initialized 0 records to KEY_CONTAINER table
2024-03-23 11:36:29,264 [ReconTaskThread-0] INFO  tasks.ContainerKeyMapperTask (ContainerKeyMapperTask.java:reprocess(140)) - Completed 'reprocess' of ContainerKeyMapperTask.
2024-03-23 11:36:29,264 [ReconTaskThread-0] INFO  tasks.ContainerKeyMapperTask (ContainerKeyMapperTask.java:reprocess(143)) - It took me 0.015 seconds to process 1 keys.
2024-03-23 11:36:29,273 [ReconTaskThread-0] INFO  tasks.FileSizeCountTask (FileSizeCountTask.java:reprocess(84)) - Deleted 0 records from "FILE_COUNT_BY_SIZE"
2024-03-23 11:36:29,281 [ReconTaskThread-0] INFO  tasks.FileSizeCountTask (FileSizeCountTask.java:reprocess(99)) - Completed a 'reprocess' run of FileSizeCountTask.
2024-03-23 11:36:30,080 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:30,185 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:30,187 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 3 milliseconds for processing 1 containers.
2024-03-23 11:36:30,187 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:30,187 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:30,187 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:30,188 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:30,188 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:30,188 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:30,188 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:30,242 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5) moved to HEALTHY state.
2024-03-23 11:36:30,242 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-23 11:36:30,242 [IPC Server handler 8 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startMaintenance(446)) - Starting Maintenance for node 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5)
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
2024-03-23 11:36:30,285 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:30,287 [qtp1609314701-459] INFO  impl.Tools (JooqLogger.java:info(338)) - Kotlin is available, but not kotlin-reflect. Add the kotlin-reflect dependency to better use Kotlin features like data classes
2024-03-23 11:36:30,287 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:30,287 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:30,295 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:30,296 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-03-23 11:36:30,909 [IPC Server handler 0 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-03-23 11:36:30,910 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:30,910 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:31,080 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:36:31,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@f5415ad5. There are 2 pipelines
2024-03-23 11:36:31,083 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(55)) - Admin start on datanode 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5). Finalizing its pipelines [PipelineID=439e139a-b269-423e-9d21-d246ec176e64, PipelineID=c0ed46c6-9d24-4a92-bbda-2a12cab7754c]
2024-03-23 11:36:31,084 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-23 11:36:31,087 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(484)) - Container #1 closed for pipeline=PipelineID=439e139a-b269-423e-9d21-d246ec176e64
2024-03-23 11:36:31,087 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #1, current state: CLOSING
2024-03-23 11:36:31,088 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=439e139a-b269-423e-9d21-d246ec176e64 moved to CLOSED state
2024-03-23 11:36:31,088 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=c0ed46c6-9d24-4a92-bbda-2a12cab7754c moved to CLOSED state
2024-03-23 11:36:31,189 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:31,191 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:31,191 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:31,191 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:31,191 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:31,192 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:31,192 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:31,192 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:31,192 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:31,298 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:31,298 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:31,298 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:31,300 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:31,300 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:31,909 [5b4c27d6-a533-4766-a648-a869ad76920c-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(317)) - Node state updated to ENTERING_MAINTENANCE, scaling executor pool size to 20
2024-03-23 11:36:31,910 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:31,910 [IPC Server handler 11 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-03-23 11:36:31,910 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:31,912 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:31,912 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:31,913 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:31,913 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:31,913 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:31,913 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:32,081 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=439e139a-b269-423e-9d21-d246ec176e64, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-03-23T11:36:31.086Z, pipelineID=PipelineID=439e139a-b269-423e-9d21-d246ec176e64, owner=omServiceIdDefault} to 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5) with datanode deadline 1711194362081 and scm deadline 1711194392081
2024-03-23 11:36:32,081 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=439e139a-b269-423e-9d21-d246ec176e64, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-03-23T11:36:31.086Z, pipelineID=PipelineID=439e139a-b269-423e-9d21-d246ec176e64, owner=omServiceIdDefault} to 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5) with datanode deadline 1711194362081 and scm deadline 1711194392081
2024-03-23 11:36:32,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=439e139a-b269-423e-9d21-d246ec176e64, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-03-23T11:36:31.086Z, pipelineID=PipelineID=439e139a-b269-423e-9d21-d246ec176e64, owner=omServiceIdDefault} to e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5) with datanode deadline 1711194362082 and scm deadline 1711194392082
2024-03-23 11:36:32,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:36:32,082 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@f5415ad5. There are 2 pipelines
2024-03-23 11:36:32,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-23 11:36:32,193 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-23 11:36:32,206 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 13 milliseconds for processing 1 containers.
2024-03-23 11:36:32,206 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:32,206 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:32,206 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:32,206 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:32,207 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:32,207 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:32,207 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:32,302 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:32,302 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:32,302 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:32,304 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:32,304 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:32,912 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:32,912 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:33,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=439e139a-b269-423e-9d21-d246ec176e64, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-03-23T11:36:31.086Z, pipelineID=PipelineID=439e139a-b269-423e-9d21-d246ec176e64, owner=omServiceIdDefault} to 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5) with datanode deadline 1711194363082 and scm deadline 1711194393082
2024-03-23 11:36:33,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=439e139a-b269-423e-9d21-d246ec176e64, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-03-23T11:36:31.086Z, pipelineID=PipelineID=439e139a-b269-423e-9d21-d246ec176e64, owner=omServiceIdDefault} to 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5) with datanode deadline 1711194363082 and scm deadline 1711194393082
2024-03-23 11:36:33,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=439e139a-b269-423e-9d21-d246ec176e64, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-03-23T11:36:31.086Z, pipelineID=PipelineID=439e139a-b269-423e-9d21-d246ec176e64, owner=omServiceIdDefault} to e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5) with datanode deadline 1711194363082 and scm deadline 1711194393082
2024-03-23 11:36:33,082 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:36:33,082 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@f5415ad5. There are 2 pipelines
2024-03-23 11:36:33,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-23 11:36:33,208 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-23 11:36:33,210 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:33,210 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:33,210 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:33,211 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:33,211 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:33,211 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:33,211 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:33,211 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:33,306 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:33,306 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:33,306 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:33,308 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:33,308 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:33,917 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:checkContainerStateAndUpdate(199)) - Container #1 has state OPEN, but given state is CLOSING.
2024-03-23 11:36:33,917 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:checkContainerStateAndUpdate(199)) - Container #1 has state OPEN, but given state is CLOSING.
2024-03-23 11:36:33,918 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5), {type: ICR, size: 1}
2024-03-23 11:36:33,919 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: ICR, size: 1}
2024-03-23 11:36:33,923 [e3882025-ee77-4273-a30c-caf156427e83-CloseContainerThread-0] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-03-23 11:36:33,923 [00b25173-7757-4760-98a7-1e1aa18d5e2d-CloseContainerThread-1] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-03-23 11:36:33,925 [00b25173-7757-4760-98a7-1e1aa18d5e2d-CloseContainerThread-2] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-03-23 11:36:33,929 [00b25173-7757-4760-98a7-1e1aa18d5e2d-CloseContainerThread-0] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-03-23 11:36:33,944 [5b4c27d6-a533-4766-a648-a869ad76920c-ContainerOp-439e139a-b269-423e-9d21-d246ec176e64-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-03-23 11:36:33,944 [5b4c27d6-a533-4766-a648-a869ad76920c-ContainerOp-439e139a-b269-423e-9d21-d246ec176e64-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-03-23 11:36:33,946 [00b25173-7757-4760-98a7-1e1aa18d5e2d-ContainerOp-439e139a-b269-423e-9d21-d246ec176e64-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-03-23 11:36:33,946 [e3882025-ee77-4273-a30c-caf156427e83-ContainerOp-439e139a-b269-423e-9d21-d246ec176e64-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-03-23 11:36:33,951 [00b25173-7757-4760-98a7-1e1aa18d5e2d-ContainerOp-439e139a-b269-423e-9d21-d246ec176e64-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-03-23 11:36:33,952 [e3882025-ee77-4273-a30c-caf156427e83-ContainerOp-439e139a-b269-423e-9d21-d246ec176e64-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-03-23 11:36:33,955 [00b25173-7757-4760-98a7-1e1aa18d5e2d-ContainerOp-439e139a-b269-423e-9d21-d246ec176e64-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(437)) - Container 1 is closed with bcsId 2.
2024-03-23 11:36:33,955 [e3882025-ee77-4273-a30c-caf156427e83-ContainerOp-439e139a-b269-423e-9d21-d246ec176e64-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(437)) - Container 1 is closed with bcsId 2.
2024-03-23 11:36:33,958 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: ICR, size: 1}
2024-03-23 11:36:33,958 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(312)) - Moving container #1 to CLOSED state, datanode 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5) reported CLOSED replica with index 0.
2024-03-23 11:36:33,959 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: ICR, size: 1}
2024-03-23 11:36:33,960 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: ICR, size: 1}
2024-03-23 11:36:33,960 [FixedThreadPoolWithAffinityExecutor-0-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(312)) - Moving container #1 to CLOSED state, datanode 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5) reported CLOSED replica with index 0.
2024-03-23 11:36:33,960 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 4 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: ICR, size: 1}
2024-03-23 11:36:33,964 [5b4c27d6-a533-4766-a648-a869ad76920c-ContainerOp-439e139a-b269-423e-9d21-d246ec176e64-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(437)) - Container 1 is closed with bcsId 2.
2024-03-23 11:36:34,082 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@f5415ad5. There are 2 pipelines
2024-03-23 11:36:34,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-23 11:36:34,085 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:34,212 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-23 11:36:34,214 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:34,214 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:34,214 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:34,214 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:34,214 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:34,214 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:34,214 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:34,214 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:34,310 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:34,310 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:34,310 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:34,312 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:34,312 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:35,082 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@f5415ad5. There are 2 pipelines
2024-03-23 11:36:35,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-23 11:36:35,085 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:36:35,215 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:35,218 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:35,218 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:35,218 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:35,218 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:35,218 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:35,218 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:35,218 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:35,218 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:35,314 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:35,314 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:35,314 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:35,316 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:35,316 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:36,082 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@f5415ad5. There are 2 pipelines
2024-03-23 11:36:36,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-23 11:36:36,086 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:36:36,219 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:36,221 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:36,221 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:36,221 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:36,221 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:36,221 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:36,221 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:36,221 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:36,221 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:36,318 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:36,318 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:36,318 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:36,320 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:36,320 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:37,082 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@f5415ad5. There are 2 pipelines
2024-03-23 11:36:37,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-23 11:36:37,086 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:36:37,222 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:37,224 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:37,225 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:37,225 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:37,225 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:37,225 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:37,225 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:37,225 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:37,225 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:37,322 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:37,322 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:37,322 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:37,324 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:37,324 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:37,891 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=439e139a-b269-423e-9d21-d246ec176e64 since it stays at CLOSED stage.
2024-03-23 11:36:37,892 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=439e139a-b269-423e-9d21-d246ec176e64 close command to datanode 5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:36:37,892 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=439e139a-b269-423e-9d21-d246ec176e64 close command to datanode 00b25173-7757-4760-98a7-1e1aa18d5e2d
2024-03-23 11:36:37,892 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=439e139a-b269-423e-9d21-d246ec176e64 close command to datanode e3882025-ee77-4273-a30c-caf156427e83
2024-03-23 11:36:37,893 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 439e139a-b269-423e-9d21-d246ec176e64, Nodes: 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5)00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5)e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:5b4c27d6-a533-4766-a648-a869ad76920c, CreationTimestamp2024-03-23T11:36:18.968Z[Etc/UTC]] removed.
2024-03-23 11:36:37,893 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=c0ed46c6-9d24-4a92-bbda-2a12cab7754c since it stays at CLOSED stage.
2024-03-23 11:36:37,893 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=c0ed46c6-9d24-4a92-bbda-2a12cab7754c close command to datanode 5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:36:37,893 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: c0ed46c6-9d24-4a92-bbda-2a12cab7754c, Nodes: 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:5b4c27d6-a533-4766-a648-a869ad76920c, CreationTimestamp2024-03-23T11:36:18.844Z[Etc/UTC]] removed.
2024-03-23 11:36:37,958 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=439e139a-b269-423e-9d21-d246ec176e64 is not found
2024-03-23 11:36:37,959 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=439e139a-b269-423e-9d21-d246ec176e64 is not found
2024-03-23 11:36:37,959 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:37,960 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:37,960 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:37,960 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 4 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:37,960 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:37,960 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:37,966 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=439e139a-b269-423e-9d21-d246ec176e64 is not found
2024-03-23 11:36:37,966 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=c0ed46c6-9d24-4a92-bbda-2a12cab7754c is not found
2024-03-23 11:36:38,084 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(472)) - org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@f5415ad5 has 1 sufficientlyReplicated, 0 deleting, 0 underReplicated and 0 unclosed containers
2024-03-23 11:36:38,084 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:putIntoMaintenance(529)) - Datanode 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5) has entered maintenance
2024-03-23 11:36:38,084 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-23 11:36:38,084 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5) moved to HEALTHY state.
2024-03-23 11:36:38,084 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-23 11:36:38,085 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=906eef43-4831-419e-95bd-f5e0ec3bda04 to datanode:00b25173-7757-4760-98a7-1e1aa18d5e2d
2024-03-23 11:36:38,085 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=906eef43-4831-419e-95bd-f5e0ec3bda04 to datanode:e3882025-ee77-4273-a30c-caf156427e83
2024-03-23 11:36:38,086 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=906eef43-4831-419e-95bd-f5e0ec3bda04 to datanode:6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:38,086 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:36:38,086 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 906eef43-4831-419e-95bd-f5e0ec3bda04, Nodes: 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5)e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5)6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-23T11:36:38.085Z[Etc/UTC]]
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-03-23 11:36:38,166 [IPC Server handler 6 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startMaintenance(446)) - Starting Maintenance for node 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:38,166 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5) moved to HEALTHY state.
2024-03-23 11:36:38,166 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-03-23 11:36:38,226 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:38,228 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:38,228 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:38,228 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:38,228 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:38,228 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:38,229 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:38,229 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:38,229 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:38,325 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:38,325 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:38,325 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:38,327 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:38,327 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:38,956 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: remove  FOLLOWER 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64:t1, leader=5b4c27d6-a533-4766-a648-a869ad76920c, voted=5b4c27d6-a533-4766-a648-a869ad76920c, raftlog=Memoized:00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-SegmentedRaftLog:OPENED:c6, conf=0: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null RUNNING
2024-03-23 11:36:38,956 [IPC Server handler 6 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-03-23 11:36:38,957 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - e3882025-ee77-4273-a30c-caf156427e83: remove  FOLLOWER e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64:t1, leader=5b4c27d6-a533-4766-a648-a869ad76920c, voted=5b4c27d6-a533-4766-a648-a869ad76920c, raftlog=Memoized:e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-SegmentedRaftLog:OPENED:c6, conf=0: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null RUNNING
2024-03-23 11:36:38,959 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64: shutdown
2024-03-23 11:36:38,959 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D246EC176E64,id=00b25173-7757-4760-98a7-1e1aa18d5e2d
2024-03-23 11:36:38,959 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: shutdown 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-FollowerState
2024-03-23 11:36:38,959 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-StateMachineUpdater: set stopIndex = 6
2024-03-23 11:36:38,960 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64: shutdown
2024-03-23 11:36:38,962 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-FollowerState was interrupted
2024-03-23 11:36:38,961 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:38,961 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 5 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:38,963 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 6 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:38,963 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 4 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:38,963 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 4 millisec, e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:36:38,962 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-D246EC176E64: Taking a snapshot at:(t:1, i:6) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/439e139a-b269-423e-9d21-d246ec176e64/sm/snapshot.1_6
2024-03-23 11:36:38,962 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D246EC176E64,id=e3882025-ee77-4273-a30c-caf156427e83
2024-03-23 11:36:38,963 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - e3882025-ee77-4273-a30c-caf156427e83: shutdown e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-FollowerState
2024-03-23 11:36:38,963 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-StateMachineUpdater: set stopIndex = 6
2024-03-23 11:36:38,963 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-FollowerState was interrupted
2024-03-23 11:36:38,964 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-D246EC176E64: Taking a snapshot at:(t:1, i:6) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/439e139a-b269-423e-9d21-d246ec176e64/sm/snapshot.1_6
2024-03-23 11:36:38,964 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 5b4c27d6-a533-4766-a648-a869ad76920c: remove    LEADER 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64:t1, leader=5b4c27d6-a533-4766-a648-a869ad76920c, voted=5b4c27d6-a533-4766-a648-a869ad76920c, raftlog=Memoized:5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-SegmentedRaftLog:OPENED:c6, conf=0: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null RUNNING
2024-03-23 11:36:38,964 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64: shutdown
2024-03-23 11:36:38,964 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D246EC176E64,id=5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:36:38,964 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 5b4c27d6-a533-4766-a648-a869ad76920c: shutdown 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-LeaderStateImpl
2024-03-23 11:36:38,965 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-PendingRequests: sendNotLeaderResponses
2024-03-23 11:36:38,965 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64->e3882025-ee77-4273-a30c-caf156427e83-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64->e3882025-ee77-4273-a30c-caf156427e83-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-03-23 11:36:38,965 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64->00b25173-7757-4760-98a7-1e1aa18d5e2d-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64->00b25173-7757-4760-98a7-1e1aa18d5e2d-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-03-23 11:36:38,971 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - e3882025-ee77-4273-a30c-caf156427e83: Completed APPEND_ENTRIES, lastRequest: null
2024-03-23 11:36:38,973 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - e3882025-ee77-4273-a30c-caf156427e83: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "5b4c27d6-a533-4766-a648-a869ad76920c"
  replyId: "e3882025-ee77-4273-a30c-caf156427e83"
  raftGroupId {
    id: "C\236\023\232\262iB>\235!\322F\354\027nd"
  }
  callId: 19
  success: true
}
term: 1
nextIndex: 7
followerCommit: 6
matchIndex: 18446744073709551615
isHearbeat: true

2024-03-23 11:36:38,973 [IPC Server handler 30 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2024-03-23 11:36:38,974 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - e3882025-ee77-4273-a30c-caf156427e83: Completed APPEND_ENTRIES, lastRequest: 5b4c27d6-a533-4766-a648-a869ad76920c->e3882025-ee77-4273-a30c-caf156427e83#14-t1,previous=(t:1, i:5),leaderCommit=5,initializing? false,entries: size=1, first=(t:1, i:6), METADATAENTRY(c:5)
2024-03-23 11:36:38,974 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - e3882025-ee77-4273-a30c-caf156427e83: Completed APPEND_ENTRIES, lastReply: null
2024-03-23 11:36:38,974 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=439e139a-b269-423e-9d21-d246ec176e64 is not found
2024-03-23 11:36:38,974 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=c0ed46c6-9d24-4a92-bbda-2a12cab7754c is not found
2024-03-23 11:36:38,975 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: Completed APPEND_ENTRIES, lastRequest: 5b4c27d6-a533-4766-a648-a869ad76920c->00b25173-7757-4760-98a7-1e1aa18d5e2d#12-t1,previous=(t:1, i:5),leaderCommit=5,initializing? false,entries: size=1, first=(t:1, i:6), METADATAENTRY(c:5)
2024-03-23 11:36:38,976 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-StateMachineUpdater: set stopIndex = 6
2024-03-23 11:36:38,976 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-D246EC176E64: Taking a snapshot at:(t:1, i:6) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/439e139a-b269-423e-9d21-d246ec176e64/sm/snapshot.1_6
2024-03-23 11:36:38,976 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: Completed APPEND_ENTRIES, lastReply: null
2024-03-23 11:36:38,982 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64->00b25173-7757-4760-98a7-1e1aa18d5e2d-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-23 11:36:38,982 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64->e3882025-ee77-4273-a30c-caf156427e83-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-23 11:36:38,983 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64->e3882025-ee77-4273-a30c-caf156427e83-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-23 11:36:38,983 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: Completed APPEND_ENTRIES, lastRequest: null
2024-03-23 11:36:38,983 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "5b4c27d6-a533-4766-a648-a869ad76920c"
  replyId: "00b25173-7757-4760-98a7-1e1aa18d5e2d"
  raftGroupId {
    id: "C\236\023\232\262iB>\235!\322F\354\027nd"
  }
  callId: 19
  success: true
}
term: 1
nextIndex: 7
followerCommit: 6
matchIndex: 18446744073709551615
isHearbeat: true

2024-03-23 11:36:38,985 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64->00b25173-7757-4760-98a7-1e1aa18d5e2d-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-23 11:36:39,009 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-D246EC176E64: Finished taking a snapshot at:(t:1, i:6) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/439e139a-b269-423e-9d21-d246ec176e64/sm/snapshot.1_6 took: 33 ms
2024-03-23 11:36:39,009 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-D246EC176E64: Finished taking a snapshot at:(t:1, i:6) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/439e139a-b269-423e-9d21-d246ec176e64/sm/snapshot.1_6 took: 44 ms
2024-03-23 11:36:39,009 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-D246EC176E64: Finished taking a snapshot at:(t:1, i:6) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/439e139a-b269-423e-9d21-d246ec176e64/sm/snapshot.1_6 took: 49 ms
2024-03-23 11:36:39,010 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-StateMachineUpdater: Took a snapshot at index 6
2024-03-23 11:36:39,010 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 6
2024-03-23 11:36:39,011 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-StateMachineUpdater: Took a snapshot at index 6
2024-03-23 11:36:39,011 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 6
2024-03-23 11:36:39,012 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64: applyIndex: 6
2024-03-23 11:36:39,012 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64: applyIndex: 6
2024-03-23 11:36:39,012 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-StateMachineUpdater: Took a snapshot at index 6
2024-03-23 11:36:39,013 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 6
2024-03-23 11:36:39,013 [5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-23 11:36:39,016 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64: applyIndex: 6
2024-03-23 11:36:39,016 [e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-23 11:36:39,016 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-23 11:36:39,082 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(55)) - Admin start on datanode 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5). Finalizing its pipelines [PipelineID=906eef43-4831-419e-95bd-f5e0ec3bda04, PipelineID=8643aede-2156-48e1-8210-1ce430ae568b]
2024-03-23 11:36:39,082 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@4ecf5624. There are 2 pipelines
2024-03-23 11:36:39,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-23 11:36:39,083 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=906eef43-4831-419e-95bd-f5e0ec3bda04 moved to CLOSED state
2024-03-23 11:36:39,084 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=8643aede-2156-48e1-8210-1ce430ae568b moved to CLOSED state
2024-03-23 11:36:39,087 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:36:39,230 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:39,233 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:39,233 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:39,233 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:39,233 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:39,233 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:39,233 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:39,233 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:39,233 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:39,328 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:39,329 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:39,329 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:39,330 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:39,330 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:39,342 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: addNew group-F5E0EC3BDA04:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052] returns group-F5E0EC3BDA04:java.util.concurrent.CompletableFuture@23eaa37e[Not completed]
2024-03-23 11:36:39,343 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: new RaftServerImpl for group-F5E0EC3BDA04:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052] with ContainerStateMachine:uninitialized
2024-03-23 11:36:39,343 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:39,343 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-23 11:36:39,343 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-23 11:36:39,343 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-23 11:36:39,343 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:36:39,344 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-23 11:36:39,344 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:36:39,344 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04: ConfigurationManager, init=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-23 11:36:39,344 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-23 11:36:39,344 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-23 11:36:39,344 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-23 11:36:39,345 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-23 11:36:39,345 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-23 11:36:39,345 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-23 11:36:39,347 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:39,347 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:39,347 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-23 11:36:39,347 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-23 11:36:39,347 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-23 11:36:39,347 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-23 11:36:39,347 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-23 11:36:39,347 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-23 11:36:39,348 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis] (custom)
2024-03-23 11:36:39,348 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04 does not exist. Creating ...
2024-03-23 11:36:39,349 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04/in_use.lock acquired by nodename 18969@fv-az1381-309
2024-03-23 11:36:39,350 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04 has been successfully formatted.
2024-03-23 11:36:39,350 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04/current/raft-meta.conf
2024-03-23 11:36:39,350 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-F5E0EC3BDA04: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-23 11:36:39,350 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-23 11:36:39,351 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-23 11:36:39,351 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:39,351 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-23 11:36:39,351 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-23 11:36:39,351 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=906eef43-4831-419e-95bd-f5e0ec3bda04. Trying to get from SCM.
2024-03-23 11:36:39,359 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:39,360 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-23 11:36:39,360 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(86)) - Adding new pipeline Pipeline[ Id: 906eef43-4831-419e-95bd-f5e0ec3bda04, Nodes: 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5)e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5)6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:, CreationTimestamp2024-03-23T11:36:38.085Z[Etc/UTC]] to Recon pipeline metadata.
2024-03-23 11:36:39,360 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-23 11:36:39,360 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:39,361 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-cacheEviction-AwaitToRun,5,main] started
2024-03-23 11:36:39,361 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04
2024-03-23 11:36:39,361 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-23 11:36:39,361 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-23 11:36:39,361 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:39,361 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-23 11:36:39,361 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-23 11:36:39,361 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-23 11:36:39,361 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-23 11:36:39,361 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-23 11:36:39,362 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-23 11:36:39,364 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:39,364 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-23 11:36:39,364 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-23 11:36:39,364 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-23 11:36:39,364 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:39,364 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:39,365 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04: start as a follower, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:39,365 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-23 11:36:39,365 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: start 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-FollowerState
2024-03-23 11:36:39,365 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F5E0EC3BDA04,id=6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:39,365 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-23 11:36:39,365 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-23 11:36:39,365 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-23 11:36:39,365 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-23 11:36:39,365 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-23 11:36:39,366 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:39,366 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:39,367 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=906eef43-4831-419e-95bd-f5e0ec3bda04
2024-03-23 11:36:39,377 [grpc-default-executor-4] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: addNew group-F5E0EC3BDA04:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052] returns group-F5E0EC3BDA04:java.util.concurrent.CompletableFuture@1408e766[Not completed]
2024-03-23 11:36:39,378 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: new RaftServerImpl for group-F5E0EC3BDA04:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052] with ContainerStateMachine:uninitialized
2024-03-23 11:36:39,378 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:39,378 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-23 11:36:39,378 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-23 11:36:39,378 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-23 11:36:39,378 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:36:39,378 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-23 11:36:39,379 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:36:39,379 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04: ConfigurationManager, init=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-23 11:36:39,379 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-23 11:36:39,379 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-23 11:36:39,379 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-23 11:36:39,379 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-23 11:36:39,379 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-23 11:36:39,379 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-23 11:36:39,381 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:39,381 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:39,381 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-23 11:36:39,381 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-23 11:36:39,382 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-23 11:36:39,382 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-23 11:36:39,382 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-23 11:36:39,382 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-23 11:36:39,382 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis] (custom)
2024-03-23 11:36:39,382 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04 does not exist. Creating ...
2024-03-23 11:36:39,383 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04/in_use.lock acquired by nodename 18969@fv-az1381-309
2024-03-23 11:36:39,384 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04 has been successfully formatted.
2024-03-23 11:36:39,384 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04/current/raft-meta.conf
2024-03-23 11:36:39,385 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-F5E0EC3BDA04: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-23 11:36:39,385 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-23 11:36:39,385 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-23 11:36:39,385 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:39,385 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-23 11:36:39,385 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-23 11:36:39,386 [IPC Server handler 57 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-03-23 11:36:39,391 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:39,391 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-23 11:36:39,391 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-23 11:36:39,391 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:39,392 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-cacheEviction-AwaitToRun,5,main] started
2024-03-23 11:36:39,392 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04
2024-03-23 11:36:39,392 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-23 11:36:39,392 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-23 11:36:39,392 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:39,392 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-23 11:36:39,392 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-23 11:36:39,393 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-23 11:36:39,393 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-23 11:36:39,393 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-23 11:36:39,393 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-23 11:36:39,395 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:39,395 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-23 11:36:39,395 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-23 11:36:39,395 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-23 11:36:39,395 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:39,395 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:39,396 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04: start as a follower, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:39,396 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-23 11:36:39,396 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: start 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-FollowerState
2024-03-23 11:36:39,397 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F5E0EC3BDA04,id=00b25173-7757-4760-98a7-1e1aa18d5e2d
2024-03-23 11:36:39,397 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-23 11:36:39,397 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-23 11:36:39,397 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-23 11:36:39,397 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-23 11:36:39,398 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-23 11:36:39,402 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:39,403 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:39,428 [grpc-default-executor-4] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - e3882025-ee77-4273-a30c-caf156427e83: addNew group-F5E0EC3BDA04:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052] returns group-F5E0EC3BDA04:java.util.concurrent.CompletableFuture@74271829[Not completed]
2024-03-23 11:36:39,429 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - e3882025-ee77-4273-a30c-caf156427e83: new RaftServerImpl for group-F5E0EC3BDA04:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052] with ContainerStateMachine:uninitialized
2024-03-23 11:36:39,429 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:39,429 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-23 11:36:39,429 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-23 11:36:39,429 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-23 11:36:39,429 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:36:39,429 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-23 11:36:39,430 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:36:39,430 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04: ConfigurationManager, init=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-23 11:36:39,430 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-23 11:36:39,430 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-23 11:36:39,430 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-23 11:36:39,430 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-23 11:36:39,430 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-23 11:36:39,430 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-23 11:36:39,432 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:39,433 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:39,433 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-23 11:36:39,433 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-23 11:36:39,433 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-23 11:36:39,433 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-23 11:36:39,433 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-23 11:36:39,433 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-23 11:36:39,433 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis] (custom)
2024-03-23 11:36:39,433 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04 does not exist. Creating ...
2024-03-23 11:36:39,434 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04/in_use.lock acquired by nodename 18969@fv-az1381-309
2024-03-23 11:36:39,435 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04 has been successfully formatted.
2024-03-23 11:36:39,435 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04/current/raft-meta.conf
2024-03-23 11:36:39,436 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-F5E0EC3BDA04: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-23 11:36:39,436 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-23 11:36:39,436 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-23 11:36:39,436 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:39,436 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-23 11:36:39,436 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-23 11:36:39,439 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:39,439 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-23 11:36:39,439 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-23 11:36:39,439 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:39,439 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-cacheEviction-AwaitToRun,5,main] started
2024-03-23 11:36:39,440 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04
2024-03-23 11:36:39,440 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-23 11:36:39,440 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-23 11:36:39,440 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:39,440 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-23 11:36:39,440 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-23 11:36:39,440 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-23 11:36:39,440 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-23 11:36:39,440 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-23 11:36:39,441 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-23 11:36:39,442 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:39,442 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-23 11:36:39,442 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-23 11:36:39,443 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-23 11:36:39,443 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:39,443 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:39,443 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04: start as a follower, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:39,443 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-23 11:36:39,444 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e3882025-ee77-4273-a30c-caf156427e83: start e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-FollowerState
2024-03-23 11:36:39,444 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F5E0EC3BDA04,id=e3882025-ee77-4273-a30c-caf156427e83
2024-03-23 11:36:39,444 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-23 11:36:39,444 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-23 11:36:39,444 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-23 11:36:39,444 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-23 11:36:39,444 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-23 11:36:39,445 [e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:39,445 [e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:39,463 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=906eef43-4831-419e-95bd-f5e0ec3bda04.
2024-03-23 11:36:39,940 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64-SegmentedRaftLogWorker close()
2024-03-23 11:36:39,940 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64-SegmentedRaftLogWorker close()
2024-03-23 11:36:39,940 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64-SegmentedRaftLogWorker close()
2024-03-23 11:36:39,945 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - e3882025-ee77-4273-a30c-caf156427e83@group-D246EC176E64: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/439e139a-b269-423e-9d21-d246ec176e64
2024-03-23 11:36:39,945 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-D246EC176E64: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/439e139a-b269-423e-9d21-d246ec176e64
2024-03-23 11:36:39,945 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-D246EC176E64: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/439e139a-b269-423e-9d21-d246ec176e64
2024-03-23 11:36:39,946 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=439e139a-b269-423e-9d21-d246ec176e64
org.apache.ratis.protocol.exceptions.GroupMismatchException: e3882025-ee77-4273-a30c-caf156427e83: group-D246EC176E64 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-23 11:36:39,946 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=439e139a-b269-423e-9d21-d246ec176e64
org.apache.ratis.protocol.exceptions.GroupMismatchException: 00b25173-7757-4760-98a7-1e1aa18d5e2d: group-D246EC176E64 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-23 11:36:39,946 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=439e139a-b269-423e-9d21-d246ec176e64
org.apache.ratis.protocol.exceptions.GroupMismatchException: 5b4c27d6-a533-4766-a648-a869ad76920c: group-D246EC176E64 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-23 11:36:39,947 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 5b4c27d6-a533-4766-a648-a869ad76920c: remove    LEADER 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C:t1, leader=5b4c27d6-a533-4766-a648-a869ad76920c, voted=5b4c27d6-a533-4766-a648-a869ad76920c, raftlog=Memoized:5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-SegmentedRaftLog:OPENED:c0, conf=0: peers:[5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025]|listeners:[], old=null RUNNING
2024-03-23 11:36:39,947 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C: shutdown
2024-03-23 11:36:39,947 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-2A12CAB7754C,id=5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:36:39,947 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 5b4c27d6-a533-4766-a648-a869ad76920c: shutdown 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-LeaderStateImpl
2024-03-23 11:36:39,947 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-PendingRequests: sendNotLeaderResponses
2024-03-23 11:36:39,948 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-StateMachineUpdater: set stopIndex = 0
2024-03-23 11:36:39,948 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-2A12CAB7754C: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/c0ed46c6-9d24-4a92-bbda-2a12cab7754c/sm/snapshot.1_0
2024-03-23 11:36:39,949 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-2A12CAB7754C: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/c0ed46c6-9d24-4a92-bbda-2a12cab7754c/sm/snapshot.1_0 took: 1 ms
2024-03-23 11:36:39,949 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-StateMachineUpdater: Took a snapshot at index 0
2024-03-23 11:36:39,949 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-23 11:36:39,949 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C: applyIndex: 0
2024-03-23 11:36:39,950 [5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-23 11:36:39,967 [5b4c27d6-a533-4766-a648-a869ad76920c-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(317)) - Node state updated to IN_MAINTENANCE, scaling executor pool size to 20
2024-03-23 11:36:39,967 [IPC Server handler 20 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5) as the reported value (IN_MAINTENANCE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-03-23 11:36:39,968 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=c0ed46c6-9d24-4a92-bbda-2a12cab7754c is not found
2024-03-23 11:36:40,082 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@4ecf5624. There are 2 pipelines
2024-03-23 11:36:40,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-23 11:36:40,087 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:36:40,131 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C-SegmentedRaftLogWorker close()
2024-03-23 11:36:40,132 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-2A12CAB7754C: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/c0ed46c6-9d24-4a92-bbda-2a12cab7754c
2024-03-23 11:36:40,133 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=c0ed46c6-9d24-4a92-bbda-2a12cab7754c
org.apache.ratis.protocol.exceptions.GroupMismatchException: 5b4c27d6-a533-4766-a648-a869ad76920c: group-2A12CAB7754C not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-23 11:36:40,234 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:40,237 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:40,237 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:40,237 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:40,237 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:40,237 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:40,237 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:40,237 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:40,237 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:40,332 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:40,332 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:40,332 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:40,334 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:40,334 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:40,386 [IPC Server handler 57 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-03-23 11:36:40,956 [00b25173-7757-4760-98a7-1e1aa18d5e2d-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(317)) - Node state updated to ENTERING_MAINTENANCE, scaling executor pool size to 20
2024-03-23 11:36:41,082 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@4ecf5624. There are 2 pipelines
2024-03-23 11:36:41,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-23 11:36:41,088 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:36:41,238 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:41,241 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:41,241 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:41,241 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:41,241 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:41,241 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:41,241 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:41,241 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:41,241 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:41,336 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:41,336 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:41,336 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:41,337 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:41,337 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:41,386 [IPC Server handler 10 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-03-23 11:36:42,082 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@4ecf5624. There are 2 pipelines
2024-03-23 11:36:42,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-23 11:36:42,089 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:36:42,242 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:42,255 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 12 milliseconds for processing 1 containers.
2024-03-23 11:36:42,255 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:42,255 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:42,255 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:42,255 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	TOTAL_KEYS -> 1 , CONTAINER_COUNT -> 1 , TOTAL_USED_BYTES -> 7 , 
2024-03-23 11:36:42,255 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:42,255 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:42,255 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:42,339 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:42,339 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:42,339 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:42,341 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:42,341 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:43,004 [UnderReplicatedProcessor] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:chooseNodeInternal(669)) - No available node in (scope="/" excludedScope="[/default-rack/5b4c27d6-a533-4766-a648-a869ad76920c, /default-rack/e3882025-ee77-4273-a30c-caf156427e83, /default-rack/00b25173-7757-4760-98a7-1e1aa18d5e2d]" excludedNodes="[5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5), e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5)]"  ancestorGen="1").
2024-03-23 11:36:43,004 [UnderReplicatedProcessor] WARN  algorithms.SCMContainerPlacementRackAware (SCMContainerPlacementRackAware.java:chooseNode(485)) - Failed to find the datanode for container. excludedNodes:[5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5), e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5)], affinityNode:
2024-03-23 11:36:43,005 [UnderReplicatedProcessor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [replicateContainerCommand: containerId=1, replicaIndex=0, targetNode=bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5), priority=NORMAL] for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-03-23T11:36:33.960Z, pipelineID=PipelineID=439e139a-b269-423e-9d21-d246ec176e64, owner=omServiceIdDefault} to 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5) with datanode deadline 1711194373005 and scm deadline 1711194403005
2024-03-23 11:36:43,006 [UnderReplicatedProcessor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(138)) - Processed 1 containers with health state counts {UNDER_REPLICATED=1}, failed processing 0, deferred due to load 0
2024-03-23 11:36:43,082 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@4ecf5624. There are 2 pipelines
2024-03-23 11:36:43,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-23 11:36:43,089 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:36:43,258 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 2 milliseconds to process 1 existing database records.
2024-03-23 11:36:43,259 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:36:43,259 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:43,259 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:43,260 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:43,260 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:43,260 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:43,260 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:43,260 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:43,342 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:43,343 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:43,343 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:43,344 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:43,344 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:44,082 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@4ecf5624. There are 2 pipelines
2024-03-23 11:36:44,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-23 11:36:44,089 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:36:44,261 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 1 existing database records.
2024-03-23 11:36:44,263 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:44,263 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:44,263 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:44,263 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:44,263 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:44,263 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:44,263 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:44,263 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:44,346 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:44,346 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:44,346 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:44,348 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:44,348 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:44,488 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5092075435ns, electionTimeout:5085ms
2024-03-23 11:36:44,488 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: shutdown 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-FollowerState
2024-03-23 11:36:44,488 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-23 11:36:44,489 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-23 11:36:44,489 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: start 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-LeaderElection9
2024-03-23 11:36:44,491 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-LeaderElection9 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:44,491 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-LeaderElection9-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016
2024-03-23 11:36:44,491 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-LeaderElection9-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052
2024-03-23 11:36:44,491 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:44,492 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:44,500 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04: receive requestVote(PRE_VOTE, 00b25173-7757-4760-98a7-1e1aa18d5e2d, group-F5E0EC3BDA04, 0, (t:0, i:0))
2024-03-23 11:36:44,500 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-FOLLOWER: accept PRE_VOTE from 00b25173-7757-4760-98a7-1e1aa18d5e2d: our priority 0 <= candidate's priority 0
2024-03-23 11:36:44,500 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04 replies to PRE_VOTE vote request: 00b25173-7757-4760-98a7-1e1aa18d5e2d<-e3882025-ee77-4273-a30c-caf156427e83#0:OK-t0. Peer's state: e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04:t0, leader=null, voted=, raftlog=Memoized:e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:44,501 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04: receive requestVote(PRE_VOTE, 00b25173-7757-4760-98a7-1e1aa18d5e2d, group-F5E0EC3BDA04, 0, (t:0, i:0))
2024-03-23 11:36:44,502 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-FOLLOWER: reject PRE_VOTE from 00b25173-7757-4760-98a7-1e1aa18d5e2d: our priority 1 > candidate's priority 0
2024-03-23 11:36:44,502 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04 replies to PRE_VOTE vote request: 00b25173-7757-4760-98a7-1e1aa18d5e2d<-6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b#0:FAIL-t0. Peer's state: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04:t0, leader=null, voted=, raftlog=Memoized:6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:44,505 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-LeaderElection9: PRE_VOTE REJECTED received 2 response(s) and 0 exception(s):
2024-03-23 11:36:44,505 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 00b25173-7757-4760-98a7-1e1aa18d5e2d<-e3882025-ee77-4273-a30c-caf156427e83#0:OK-t0
2024-03-23 11:36:44,505 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 1: 00b25173-7757-4760-98a7-1e1aa18d5e2d<-6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b#0:FAIL-t0
2024-03-23 11:36:44,505 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-LeaderElection9 PRE_VOTE round 0: result REJECTED
2024-03-23 11:36:44,506 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-LeaderElection9] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2024-03-23 11:36:44,506 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: shutdown 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-LeaderElection9
2024-03-23 11:36:44,506 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: start 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-FollowerState
2024-03-23 11:36:44,506 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-LeaderElection9] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04: set firstElectionSinceStartup to false for REJECTED
2024-03-23 11:36:44,530 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5165113771ns, electionTimeout:5163ms
2024-03-23 11:36:44,530 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: shutdown 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-FollowerState
2024-03-23 11:36:44,530 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-23 11:36:44,531 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-23 11:36:44,531 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: start 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10
2024-03-23 11:36:44,532 [e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:44,532 [e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:44,532 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:44,533 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034
2024-03-23 11:36:44,533 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016
2024-03-23 11:36:44,533 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:44,533 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:44,540 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04: receive requestVote(PRE_VOTE, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, group-F5E0EC3BDA04, 0, (t:0, i:0))
2024-03-23 11:36:44,543 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-FOLLOWER: accept PRE_VOTE from 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: our priority 0 <= candidate's priority 1
2024-03-23 11:36:44,543 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04: receive requestVote(PRE_VOTE, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, group-F5E0EC3BDA04, 0, (t:0, i:0))
2024-03-23 11:36:44,543 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04 replies to PRE_VOTE vote request: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b<-e3882025-ee77-4273-a30c-caf156427e83#0:OK-t0. Peer's state: e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04:t0, leader=null, voted=, raftlog=Memoized:e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:44,543 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-FOLLOWER: accept PRE_VOTE from 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: our priority 0 <= candidate's priority 1
2024-03-23 11:36:44,543 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04 replies to PRE_VOTE vote request: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b<-00b25173-7757-4760-98a7-1e1aa18d5e2d#0:OK-t0. Peer's state: 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04:t0, leader=null, voted=, raftlog=Memoized:00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:44,545 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2024-03-23 11:36:44,545 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b<-00b25173-7757-4760-98a7-1e1aa18d5e2d#0:OK-t0
2024-03-23 11:36:44,545 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10 PRE_VOTE round 0: result PASSED
2024-03-23 11:36:44,548 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10 ELECTION round 0: submit vote requests at term 1 for -1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:44,548 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:44,548 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:44,550 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04: receive requestVote(ELECTION, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, group-F5E0EC3BDA04, 1, (t:0, i:0))
2024-03-23 11:36:44,550 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04: receive requestVote(ELECTION, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, group-F5E0EC3BDA04, 1, (t:0, i:0))
2024-03-23 11:36:44,551 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-FOLLOWER: accept ELECTION from 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: our priority 0 <= candidate's priority 1
2024-03-23 11:36:44,551 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:44,551 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - e3882025-ee77-4273-a30c-caf156427e83: shutdown e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-FollowerState
2024-03-23 11:36:44,550 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-FOLLOWER: accept ELECTION from 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: our priority 0 <= candidate's priority 1
2024-03-23 11:36:44,551 [e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-FollowerState was interrupted
2024-03-23 11:36:44,551 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e3882025-ee77-4273-a30c-caf156427e83: start e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-FollowerState
2024-03-23 11:36:44,552 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:44,552 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: shutdown 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-FollowerState
2024-03-23 11:36:44,553 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04: set firstElectionSinceStartup to false for candidate:6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:44,553 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: start 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-FollowerState
2024-03-23 11:36:44,553 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-FollowerState was interrupted
2024-03-23 11:36:44,554 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04 replies to ELECTION vote request: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b<-e3882025-ee77-4273-a30c-caf156427e83#0:OK-t1. Peer's state: e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04:t1, leader=null, voted=6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, raftlog=Memoized:e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:44,555 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10: ELECTION PASSED received 1 response(s) and 0 exception(s):
2024-03-23 11:36:44,555 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04 replies to ELECTION vote request: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b<-00b25173-7757-4760-98a7-1e1aa18d5e2d#0:OK-t1. Peer's state: 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04:t1, leader=null, voted=6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, raftlog=Memoized:00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:44,555 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b<-e3882025-ee77-4273-a30c-caf156427e83#0:OK-t1
2024-03-23 11:36:44,556 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10 ELECTION round 0: result PASSED
2024-03-23 11:36:44,557 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: shutdown 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10
2024-03-23 11:36:44,557 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-23 11:36:44,558 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-03-23 11:36:44,558 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-23 11:36:44,558 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-03-23 11:36:44,558 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-03-23 11:36:44,558 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-03-23 11:36:44,558 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-03-23 11:36:44,558 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-03-23 11:36:44,559 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-23 11:36:44,559 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:44,559 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-23 11:36:44,559 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-23 11:36:44,559 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-03-23 11:36:44,560 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:44,560 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2024-03-23 11:36:44,560 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0s (custom)
2024-03-23 11:36:44,560 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-03-23 11:36:44,560 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:44,560 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-03-23 11:36:44,560 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-03-23 11:36:44,560 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-03-23 11:36:44,560 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:44,561 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-23 11:36:44,561 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-03-23 11:36:44,561 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:44,561 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2024-03-23 11:36:44,562 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0s (custom)
2024-03-23 11:36:44,562 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-03-23 11:36:44,562 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:44,562 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-03-23 11:36:44,562 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-03-23 11:36:44,562 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-03-23 11:36:44,562 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:44,562 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-23 11:36:44,562 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: start 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderStateImpl
2024-03-23 11:36:44,562 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04: set firstElectionSinceStartup to false for becomeLeader
2024-03-23 11:36:44,562 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-F5E0EC3BDA04 with new leaderId: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:44,563 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04: change Leader from null to 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b at term 1 for becomeLeader, leader elected after 5218ms
2024-03-23 11:36:44,563 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-23 11:36:44,563 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-23 11:36:44,567 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderElection10] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04: set configuration 0: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:44,575 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04/current/log_inprogress_0
2024-03-23 11:36:44,581 [00b25173-7757-4760-98a7-1e1aa18d5e2d-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-F5E0EC3BDA04 with new leaderId: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:44,581 [00b25173-7757-4760-98a7-1e1aa18d5e2d-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04: change Leader from null to 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b at term 1 for appendEntries, leader elected after 5202ms
2024-03-23 11:36:44,583 [e3882025-ee77-4273-a30c-caf156427e83-server-thread2] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-F5E0EC3BDA04 with new leaderId: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:44,583 [e3882025-ee77-4273-a30c-caf156427e83-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04: change Leader from null to 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b at term 1 for appendEntries, leader elected after 5153ms
2024-03-23 11:36:44,594 [e3882025-ee77-4273-a30c-caf156427e83-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04: set configuration 0: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:44,594 [e3882025-ee77-4273-a30c-caf156427e83-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-23 11:36:44,594 [00b25173-7757-4760-98a7-1e1aa18d5e2d-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04: set configuration 0: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:44,595 [00b25173-7757-4760-98a7-1e1aa18d5e2d-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-23 11:36:44,594 [e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-23 11:36:44,596 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-23 11:36:44,607 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04/current/log_inprogress_0
2024-03-23 11:36:44,607 [e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04/current/log_inprogress_0
2024-03-23 11:36:44,610 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-23 11:36:45,082 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@4ecf5624. There are 2 pipelines
2024-03-23 11:36:45,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-23 11:36:45,090 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:36:45,265 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 2 milliseconds to process 1 existing database records.
2024-03-23 11:36:45,267 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:36:45,267 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:45,267 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:45,267 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:45,267 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:45,267 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:45,267 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:45,267 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:45,349 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:45,349 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:45,349 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:45,351 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:45,351 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:45,894 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=906eef43-4831-419e-95bd-f5e0ec3bda04 since it stays at CLOSED stage.
2024-03-23 11:36:45,894 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=906eef43-4831-419e-95bd-f5e0ec3bda04 close command to datanode 00b25173-7757-4760-98a7-1e1aa18d5e2d
2024-03-23 11:36:45,894 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=906eef43-4831-419e-95bd-f5e0ec3bda04 close command to datanode e3882025-ee77-4273-a30c-caf156427e83
2024-03-23 11:36:45,894 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=906eef43-4831-419e-95bd-f5e0ec3bda04 close command to datanode 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:45,894 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 906eef43-4831-419e-95bd-f5e0ec3bda04, Nodes: 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5)e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5)6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, CreationTimestamp2024-03-23T11:36:38.085Z[Etc/UTC]] removed.
2024-03-23 11:36:45,894 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=8643aede-2156-48e1-8210-1ce430ae568b since it stays at CLOSED stage.
2024-03-23 11:36:45,895 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=8643aede-2156-48e1-8210-1ce430ae568b close command to datanode 00b25173-7757-4760-98a7-1e1aa18d5e2d
2024-03-23 11:36:45,895 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 8643aede-2156-48e1-8210-1ce430ae568b, Nodes: 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:00b25173-7757-4760-98a7-1e1aa18d5e2d, CreationTimestamp2024-03-23T11:36:18.964Z[Etc/UTC]] removed.
2024-03-23 11:36:45,971 [nullContainerReplicationThread-0] INFO  replication.PushReplicator (PushReplicator.java:replicate(58)) - Starting replication of container 1 to bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5) using NO_COMPRESSION
2024-03-23 11:36:45,990 [nullContainerReplicationThread-0] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(116)) - Sent 16384 bytes for container 1
2024-03-23 11:36:45,994 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-ReplicationContainerReader-1] INFO  replication.SendContainerRequestHandler (SendContainerRequestHandler.java:onNext(96)) - Accepting container 1
2024-03-23 11:36:45,994 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-ReplicationContainerReader-1] INFO  replication.SendContainerRequestHandler (SendContainerRequestHandler.java:onCompleted(131)) - Container 1 is downloaded with size 16384, starting to import.
2024-03-23 11:36:46,035 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-ReplicationContainerReader-1] INFO  replication.SendContainerRequestHandler (SendContainerRequestHandler.java:onCompleted(137)) - Container 1 is replicated successfully
2024-03-23 11:36:46,041 [grpc-default-executor-2] INFO  replication.GrpcContainerUploader (GrpcContainerUploader.java:onCompleted(132)) - Finished uploading container 1 to bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:46,046 [nullContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(374)) - Successful DONE replicateContainerCommand: containerId=1, replicaIndex=0, targetNode=bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5), priority=NORMAL, transferred 16384 bytes
2024-03-23 11:36:46,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(472)) - org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@4ecf5624 has 1 sufficientlyReplicated, 0 deleting, 0 underReplicated and 0 unclosed containers
2024-03-23 11:36:46,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:putIntoMaintenance(529)) - Datanode 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5) has entered maintenance
2024-03-23 11:36:46,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-23 11:36:46,083 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5) moved to HEALTHY state.
2024-03-23 11:36:46,083 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-23 11:36:46,084 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 to datanode:bb4f2f6f-344d-4a57-aba3-69abe2cb722c
2024-03-23 11:36:46,084 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 to datanode:e3882025-ee77-4273-a30c-caf156427e83
2024-03-23 11:36:46,084 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 to datanode:6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:46,085 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 2d7785c5-43f1-4411-94e4-56171e486153, Nodes: bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5)e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5)6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-23T11:36:46.084Z[Etc/UTC]]
2024-03-23 11:36:46,090 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:36:46,194 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, bb4f2f6f-344d-4a57-aba3-69abe2cb722c, e3882025-ee77-4273-a30c-caf156427e83]
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
2024-03-23 11:36:46,217 [main] INFO  recon.TestReconAndAdminContainerCLI (TestReconAndAdminContainerCLI.java:assertReportsMatch(344)) - Reports do not match (yet): expected: <0> but was: <1>
2024-03-23 11:36:46,268 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:processExistingDBRecords(299)) - DELETED existing unhealthy container record...for Container: 1
2024-03-23 11:36:46,277 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 10 milliseconds to process 1 existing database records.
2024-03-23 11:36:46,279 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:36:46,279 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:46,279 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:46,280 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:46,280 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:46,280 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:46,280 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:46,280 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:46,352 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:46,352 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:46,352 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:46,354 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:46,354 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:46,386 [IPC Server handler 57 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2024-03-23 11:36:46,564 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=906eef43-4831-419e-95bd-f5e0ec3bda04 is not found
2024-03-23 11:36:47,082 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-23 11:36:47,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
2024-03-23 11:36:47,224 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: addNew group-56171E486153:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052] returns group-56171E486153:java.util.concurrent.CompletableFuture@617378c1[Not completed]
2024-03-23 11:36:47,225 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: new RaftServerImpl for group-56171E486153:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052] with ContainerStateMachine:uninitialized
2024-03-23 11:36:47,225 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:47,225 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-23 11:36:47,225 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-23 11:36:47,225 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-23 11:36:47,226 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:36:47,226 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-23 11:36:47,226 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:36:47,226 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153: ConfigurationManager, init=-1: peers:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-23 11:36:47,226 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-23 11:36:47,226 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-23 11:36:47,226 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-23 11:36:47,226 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-23 11:36:47,226 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-23 11:36:47,226 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-03-23 11:36:47,230 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:47,230 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:47,230 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-23 11:36:47,231 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-23 11:36:47,231 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-23 11:36:47,231 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-23 11:36:47,231 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-23 11:36:47,231 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-23 11:36:47,231 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis] (custom)
2024-03-23 11:36:47,232 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis/2d7785c5-43f1-4411-94e4-56171e486153 does not exist. Creating ...
2024-03-23 11:36:47,233 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis/2d7785c5-43f1-4411-94e4-56171e486153/in_use.lock acquired by nodename 18969@fv-az1381-309
2024-03-23 11:36:47,234 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis/2d7785c5-43f1-4411-94e4-56171e486153 has been successfully formatted.
2024-03-23 11:36:47,234 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis/2d7785c5-43f1-4411-94e4-56171e486153/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis/2d7785c5-43f1-4411-94e4-56171e486153/current/raft-meta.conf
2024-03-23 11:36:47,234 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-56171E486153: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-23 11:36:47,235 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-23 11:36:47,235 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-23 11:36:47,235 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:47,235 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-23 11:36:47,235 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-23 11:36:47,237 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:47,237 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-23 11:36:47,237 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-23 11:36:47,237 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:47,238 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-cacheEviction-AwaitToRun,5,main] started
2024-03-23 11:36:47,238 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=2d7785c5-43f1-4411-94e4-56171e486153. Trying to get from SCM.
2024-03-23 11:36:47,238 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis/2d7785c5-43f1-4411-94e4-56171e486153
2024-03-23 11:36:47,238 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-23 11:36:47,238 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-23 11:36:47,238 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:47,239 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-23 11:36:47,239 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-23 11:36:47,239 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-23 11:36:47,239 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-23 11:36:47,239 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-23 11:36:47,239 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-23 11:36:47,241 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:47,243 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(86)) - Adding new pipeline Pipeline[ Id: 2d7785c5-43f1-4411-94e4-56171e486153, Nodes: bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5)e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5)6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-23T11:36:46.084Z[Etc/UTC]] to Recon pipeline metadata.
2024-03-23 11:36:47,244 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 reported by bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:47,245 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-23 11:36:47,245 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-23 11:36:47,245 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-23 11:36:47,245 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:47,246 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:47,246 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153: start as a follower, conf=-1: peers:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:47,246 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-23 11:36:47,246 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: start bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-FollowerState
2024-03-23 11:36:47,249 [IPC Server handler 18 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:recommission(401)) - Queued node 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5) for recommission
2024-03-23 11:36:47,249 [IPC Server handler 18 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:recommission(401)) - Queued node 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5) for recommission
2024-03-23 11:36:47,253 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:47,253 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-56171E486153,id=bb4f2f6f-344d-4a57-aba3-69abe2cb722c
2024-03-23 11:36:47,253 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-23 11:36:47,253 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-23 11:36:47,253 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-23 11:36:47,254 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-23 11:36:47,254 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-23 11:36:47,254 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:47,256 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=2d7785c5-43f1-4411-94e4-56171e486153
2024-03-23 11:36:47,264 [grpc-default-executor-2] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - e3882025-ee77-4273-a30c-caf156427e83: addNew group-56171E486153:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052] returns group-56171E486153:java.util.concurrent.CompletableFuture@75b93449[Not completed]
2024-03-23 11:36:47,265 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - e3882025-ee77-4273-a30c-caf156427e83: new RaftServerImpl for group-56171E486153:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052] with ContainerStateMachine:uninitialized
2024-03-23 11:36:47,265 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:47,265 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-23 11:36:47,265 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-23 11:36:47,265 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-23 11:36:47,265 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:36:47,265 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-23 11:36:47,265 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:36:47,265 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153: ConfigurationManager, init=-1: peers:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-23 11:36:47,265 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-23 11:36:47,266 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-23 11:36:47,266 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-23 11:36:47,266 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-23 11:36:47,266 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-23 11:36:47,266 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-23 11:36:47,268 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:47,268 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:47,268 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-23 11:36:47,268 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-23 11:36:47,268 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-23 11:36:47,268 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-23 11:36:47,268 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-23 11:36:47,269 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-23 11:36:47,269 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis] (custom)
2024-03-23 11:36:47,269 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/2d7785c5-43f1-4411-94e4-56171e486153 does not exist. Creating ...
2024-03-23 11:36:47,270 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/2d7785c5-43f1-4411-94e4-56171e486153/in_use.lock acquired by nodename 18969@fv-az1381-309
2024-03-23 11:36:47,271 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/2d7785c5-43f1-4411-94e4-56171e486153 has been successfully formatted.
2024-03-23 11:36:47,271 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/2d7785c5-43f1-4411-94e4-56171e486153/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/2d7785c5-43f1-4411-94e4-56171e486153/current/raft-meta.conf
2024-03-23 11:36:47,271 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-56171E486153: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-23 11:36:47,271 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-23 11:36:47,272 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-23 11:36:47,272 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:47,272 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-23 11:36:47,273 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-23 11:36:47,273 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 reported by e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:47,273 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=906eef43-4831-419e-95bd-f5e0ec3bda04 is not found
2024-03-23 11:36:47,274 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:47,274 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-23 11:36:47,274 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-23 11:36:47,274 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:47,274 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-cacheEviction-AwaitToRun,5,main] started
2024-03-23 11:36:47,275 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/2d7785c5-43f1-4411-94e4-56171e486153
2024-03-23 11:36:47,275 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-23 11:36:47,275 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-23 11:36:47,275 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:47,275 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-23 11:36:47,275 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-23 11:36:47,275 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-23 11:36:47,275 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-23 11:36:47,275 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-23 11:36:47,276 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-23 11:36:47,277 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:47,277 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-23 11:36:47,277 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-23 11:36:47,278 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-23 11:36:47,278 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:47,278 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:47,281 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-23 11:36:47,282 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153: start as a follower, conf=-1: peers:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:47,282 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-23 11:36:47,282 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e3882025-ee77-4273-a30c-caf156427e83: start e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-FollowerState
2024-03-23 11:36:47,283 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:47,283 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:47,283 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:47,283 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:47,283 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:47,283 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:47,283 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:47,283 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:47,284 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-56171E486153,id=e3882025-ee77-4273-a30c-caf156427e83
2024-03-23 11:36:47,284 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-23 11:36:47,284 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-23 11:36:47,284 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-23 11:36:47,284 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-23 11:36:47,284 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-23 11:36:47,285 [e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:47,285 [e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:47,297 [grpc-default-executor-2] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: addNew group-56171E486153:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052] returns group-56171E486153:java.util.concurrent.CompletableFuture@22ce2672[Not completed]
2024-03-23 11:36:47,298 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: new RaftServerImpl for group-56171E486153:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052] with ContainerStateMachine:uninitialized
2024-03-23 11:36:47,298 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:47,298 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-23 11:36:47,298 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-23 11:36:47,298 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-23 11:36:47,298 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:36:47,298 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-23 11:36:47,298 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:36:47,298 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153: ConfigurationManager, init=-1: peers:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-23 11:36:47,298 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-23 11:36:47,298 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-23 11:36:47,299 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-23 11:36:47,299 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-23 11:36:47,299 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-23 11:36:47,299 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-23 11:36:47,301 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:47,301 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:47,301 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-23 11:36:47,301 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-23 11:36:47,303 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-23 11:36:47,303 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-23 11:36:47,305 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-23 11:36:47,305 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-23 11:36:47,306 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis] (custom)
2024-03-23 11:36:47,307 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/2d7785c5-43f1-4411-94e4-56171e486153 does not exist. Creating ...
2024-03-23 11:36:47,308 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/2d7785c5-43f1-4411-94e4-56171e486153/in_use.lock acquired by nodename 18969@fv-az1381-309
2024-03-23 11:36:47,309 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/2d7785c5-43f1-4411-94e4-56171e486153 has been successfully formatted.
2024-03-23 11:36:47,309 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/2d7785c5-43f1-4411-94e4-56171e486153/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/2d7785c5-43f1-4411-94e4-56171e486153/current/raft-meta.conf
2024-03-23 11:36:47,310 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-56171E486153: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-23 11:36:47,310 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-23 11:36:47,311 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-23 11:36:47,311 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:47,311 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 reported by 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:47,311 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-23 11:36:47,312 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-23 11:36:47,312 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=906eef43-4831-419e-95bd-f5e0ec3bda04 is not found
2024-03-23 11:36:47,314 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:47,315 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-23 11:36:47,315 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-23 11:36:47,315 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:47,315 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-cacheEviction-AwaitToRun,5,main] started
2024-03-23 11:36:47,315 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/2d7785c5-43f1-4411-94e4-56171e486153
2024-03-23 11:36:47,315 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-23 11:36:47,315 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-23 11:36:47,315 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:47,316 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-23 11:36:47,316 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-23 11:36:47,316 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-23 11:36:47,316 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-23 11:36:47,317 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-23 11:36:47,317 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-23 11:36:47,319 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:47,319 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-23 11:36:47,320 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-23 11:36:47,320 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-23 11:36:47,321 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:47,321 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:47,321 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153: start as a follower, conf=-1: peers:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:47,321 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-23 11:36:47,322 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: start 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-FollowerState
2024-03-23 11:36:47,322 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-56171E486153,id=6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:47,322 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:47,322 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:47,322 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-23 11:36:47,323 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-23 11:36:47,323 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-23 11:36:47,323 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-23 11:36:47,323 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-23 11:36:47,328 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=2d7785c5-43f1-4411-94e4-56171e486153.
2024-03-23 11:36:47,356 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:47,356 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:47,356 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:47,357 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:47,358 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:47,386 [IPC Server handler 49 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2024-03-23 11:36:47,387 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=906eef43-4831-419e-95bd-f5e0ec3bda04 is not found
2024-03-23 11:36:47,387 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=8643aede-2156-48e1-8210-1ce430ae568b is not found
2024-03-23 11:36:47,436 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - e3882025-ee77-4273-a30c-caf156427e83: remove  FOLLOWER e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04:t1, leader=6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, voted=6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, raftlog=Memoized:e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-SegmentedRaftLog:OPENED:c0, conf=0: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null RUNNING
2024-03-23 11:36:47,436 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04: shutdown
2024-03-23 11:36:47,436 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F5E0EC3BDA04,id=e3882025-ee77-4273-a30c-caf156427e83
2024-03-23 11:36:47,437 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - e3882025-ee77-4273-a30c-caf156427e83: shutdown e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-FollowerState
2024-03-23 11:36:47,437 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-StateMachineUpdater: set stopIndex = 0
2024-03-23 11:36:47,437 [e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-FollowerState was interrupted
2024-03-23 11:36:47,438 [e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-F5E0EC3BDA04: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04/sm/snapshot.1_0
2024-03-23 11:36:47,439 [e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-F5E0EC3BDA04: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04/sm/snapshot.1_0 took: 1 ms
2024-03-23 11:36:47,440 [e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-StateMachineUpdater: Took a snapshot at index 0
2024-03-23 11:36:47,440 [e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-23 11:36:47,440 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04: applyIndex: 0
2024-03-23 11:36:47,440 [e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-23 11:36:47,562 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: remove    LEADER 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04:t1, leader=6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, voted=6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, raftlog=Memoized:6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-SegmentedRaftLog:OPENED:c0, conf=0: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null RUNNING
2024-03-23 11:36:47,562 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04: shutdown
2024-03-23 11:36:47,563 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F5E0EC3BDA04,id=6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:47,563 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: shutdown 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-LeaderStateImpl
2024-03-23 11:36:47,563 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04->00b25173-7757-4760-98a7-1e1aa18d5e2d-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04->00b25173-7757-4760-98a7-1e1aa18d5e2d-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-03-23 11:36:47,563 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-PendingRequests: sendNotLeaderResponses
2024-03-23 11:36:47,565 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: Completed APPEND_ENTRIES, lastRequest: null
2024-03-23 11:36:47,565 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b"
  replyId: "00b25173-7757-4760-98a7-1e1aa18d5e2d"
  raftGroupId {
    id: "\220n\357CH1A\236\225\275\365\340\354;\332\004"
  }
  callId: 3
  success: true
}
term: 1
nextIndex: 1
matchIndex: 18446744073709551615
isHearbeat: true

2024-03-23 11:36:47,564 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04->e3882025-ee77-4273-a30c-caf156427e83-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04->e3882025-ee77-4273-a30c-caf156427e83-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-03-23 11:36:47,566 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-StateMachineUpdater: set stopIndex = 0
2024-03-23 11:36:47,566 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-F5E0EC3BDA04: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04/sm/snapshot.1_0
2024-03-23 11:36:47,566 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04->00b25173-7757-4760-98a7-1e1aa18d5e2d-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-23 11:36:47,566 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: Completed APPEND_ENTRIES, lastRequest: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b->00b25173-7757-4760-98a7-1e1aa18d5e2d#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "00b25173-7757-4760-98a7-1e1aa18d5e2d"
address: "10.1.0.5:15034"
dataStreamAddress: "10.1.0.5:15035"
clientAddress: "10.1.0.5:15032"
adminAddress: "10.1.0.5:15033"
startupRole: FOLLOWER
,id: "e3882025-ee77-4273-a30c-caf156427e83"
address: "10.1.0.5:15016"
dataStreamAddress: "10.1.0.5:15017"
clientAddress: "10.1.0.5:15014"
adminAddress: "10.1.0.5:15015"
startupRole: FOLLOWER
,id: "6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b"
address: "10.1.0.5:15052"
priority: 1
dataStreamAddress: "10.1.0.5:15053"
clientAddress: "10.1.0.5:15050"
adminAddress: "10.1.0.5:15051"
startupRole: FOLLOWER
, old:)
2024-03-23 11:36:47,567 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: Completed APPEND_ENTRIES, lastReply: null
2024-03-23 11:36:47,567 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - e3882025-ee77-4273-a30c-caf156427e83: Completed APPEND_ENTRIES, lastRequest: null
2024-03-23 11:36:47,568 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - e3882025-ee77-4273-a30c-caf156427e83: Completed APPEND_ENTRIES, lastRequest: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b->e3882025-ee77-4273-a30c-caf156427e83#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "00b25173-7757-4760-98a7-1e1aa18d5e2d"
address: "10.1.0.5:15034"
dataStreamAddress: "10.1.0.5:15035"
clientAddress: "10.1.0.5:15032"
adminAddress: "10.1.0.5:15033"
startupRole: FOLLOWER
,id: "e3882025-ee77-4273-a30c-caf156427e83"
address: "10.1.0.5:15016"
dataStreamAddress: "10.1.0.5:15017"
clientAddress: "10.1.0.5:15014"
adminAddress: "10.1.0.5:15015"
startupRole: FOLLOWER
,id: "6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b"
address: "10.1.0.5:15052"
priority: 1
dataStreamAddress: "10.1.0.5:15053"
clientAddress: "10.1.0.5:15050"
adminAddress: "10.1.0.5:15051"
startupRole: FOLLOWER
, old:)
2024-03-23 11:36:47,568 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - e3882025-ee77-4273-a30c-caf156427e83: Completed APPEND_ENTRIES, lastReply: null
2024-03-23 11:36:47,568 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - e3882025-ee77-4273-a30c-caf156427e83: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b"
  replyId: "e3882025-ee77-4273-a30c-caf156427e83"
  raftGroupId {
    id: "\220n\357CH1A\236\225\275\365\340\354;\332\004"
  }
  callId: 3
  success: true
}
term: 1
nextIndex: 1
matchIndex: 18446744073709551615
isHearbeat: true

2024-03-23 11:36:47,567 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-F5E0EC3BDA04: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04/sm/snapshot.1_0 took: 1 ms
2024-03-23 11:36:47,568 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04->00b25173-7757-4760-98a7-1e1aa18d5e2d-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-23 11:36:47,568 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-StateMachineUpdater: Took a snapshot at index 0
2024-03-23 11:36:47,569 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-23 11:36:47,569 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04->e3882025-ee77-4273-a30c-caf156427e83-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-23 11:36:47,570 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04->e3882025-ee77-4273-a30c-caf156427e83-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-23 11:36:47,570 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04: applyIndex: 0
2024-03-23 11:36:47,570 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-23 11:36:47,577 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04-SegmentedRaftLogWorker close()
2024-03-23 11:36:47,579 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-F5E0EC3BDA04: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04
2024-03-23 11:36:47,579 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=906eef43-4831-419e-95bd-f5e0ec3bda04
org.apache.ratis.protocol.exceptions.GroupMismatchException: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: group-F5E0EC3BDA04 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-23 11:36:47,609 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04-SegmentedRaftLogWorker close()
2024-03-23 11:36:47,611 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - e3882025-ee77-4273-a30c-caf156427e83@group-F5E0EC3BDA04: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04
2024-03-23 11:36:47,611 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=906eef43-4831-419e-95bd-f5e0ec3bda04
org.apache.ratis.protocol.exceptions.GroupMismatchException: e3882025-ee77-4273-a30c-caf156427e83: group-F5E0EC3BDA04 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-23 11:36:48,082 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:processCancelledNodes(292)) - Recommissioned node org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@f5415ad5
2024-03-23 11:36:48,082 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5) moved to HEALTHY state.
2024-03-23 11:36:48,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:processCancelledNodes(292)) - Recommissioned node org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@4ecf5624
2024-03-23 11:36:48,083 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-23 11:36:48,083 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5) moved to HEALTHY state.
2024-03-23 11:36:48,083 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-23 11:36:48,084 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=4ebe2e72-678e-491b-9c18-95313ce3adab to datanode:5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:36:48,085 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 4ebe2e72-678e-491b-9c18-95313ce3adab, Nodes: 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-23T11:36:48.084Z[Etc/UTC]]
2024-03-23 11:36:48,086 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=1448d56d-848d-4e5a-9e97-9b901d931523 to datanode:00b25173-7757-4760-98a7-1e1aa18d5e2d
2024-03-23 11:36:48,087 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 1448d56d-848d-4e5a-9e97-9b901d931523, Nodes: 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-23T11:36:48.086Z[Etc/UTC]]
2024-03-23 11:36:48,091 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-03-23 11:36:48,284 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:48,291 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 7 milliseconds for processing 1 containers.
2024-03-23 11:36:48,291 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:48,291 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:48,291 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:48,291 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:48,291 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:48,292 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:48,292 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:48,296 [IPC Server handler 15 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startDecommission(357)) - Starting Decommission for node bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:48,297 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5) moved to HEALTHY state.
2024-03-23 11:36:48,297 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-03-23 11:36:48,360 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:48,360 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:48,360 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:48,362 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:48,362 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:48,385 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: remove  FOLLOWER 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04:t1, leader=6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, voted=6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, raftlog=Memoized:00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-SegmentedRaftLog:OPENED:c0, conf=0: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null RUNNING
2024-03-23 11:36:48,385 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04: shutdown
2024-03-23 11:36:48,385 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F5E0EC3BDA04,id=00b25173-7757-4760-98a7-1e1aa18d5e2d
2024-03-23 11:36:48,385 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: shutdown 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-FollowerState
2024-03-23 11:36:48,386 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-StateMachineUpdater: set stopIndex = 0
2024-03-23 11:36:48,386 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-FollowerState was interrupted
2024-03-23 11:36:48,389 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-F5E0EC3BDA04: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04/sm/snapshot.1_0
2024-03-23 11:36:48,389 [IPC Server handler 59 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5) as the reported value (IN_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-03-23 11:36:48,390 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-F5E0EC3BDA04: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04/sm/snapshot.1_0 took: 0 ms
2024-03-23 11:36:48,390 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-StateMachineUpdater: Took a snapshot at index 0
2024-03-23 11:36:48,390 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-23 11:36:48,390 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04: applyIndex: 0
2024-03-23 11:36:48,391 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-23 11:36:48,391 [IPC Server handler 14 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5) as the reported value (IN_MAINTENANCE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-03-23 11:36:48,392 [00b25173-7757-4760-98a7-1e1aa18d5e2d-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(317)) - Node state updated to IN_MAINTENANCE, scaling executor pool size to 20
2024-03-23 11:36:48,395 [00b25173-7757-4760-98a7-1e1aa18d5e2d-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(317)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-03-23 11:36:48,609 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04-SegmentedRaftLogWorker close()
2024-03-23 11:36:48,611 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-F5E0EC3BDA04: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/906eef43-4831-419e-95bd-f5e0ec3bda04
2024-03-23 11:36:48,612 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=906eef43-4831-419e-95bd-f5e0ec3bda04
org.apache.ratis.protocol.exceptions.GroupMismatchException: 00b25173-7757-4760-98a7-1e1aa18d5e2d: group-F5E0EC3BDA04 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-23 11:36:48,612 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: remove    LEADER 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B:t1, leader=00b25173-7757-4760-98a7-1e1aa18d5e2d, voted=00b25173-7757-4760-98a7-1e1aa18d5e2d, raftlog=Memoized:00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-SegmentedRaftLog:OPENED:c0, conf=0: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034]|listeners:[], old=null RUNNING
2024-03-23 11:36:48,612 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B: shutdown
2024-03-23 11:36:48,612 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-1CE430AE568B,id=00b25173-7757-4760-98a7-1e1aa18d5e2d
2024-03-23 11:36:48,612 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: shutdown 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-LeaderStateImpl
2024-03-23 11:36:48,612 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-PendingRequests: sendNotLeaderResponses
2024-03-23 11:36:48,613 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-StateMachineUpdater: set stopIndex = 0
2024-03-23 11:36:48,613 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-1CE430AE568B: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/8643aede-2156-48e1-8210-1ce430ae568b/sm/snapshot.1_0
2024-03-23 11:36:48,613 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-1CE430AE568B: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/8643aede-2156-48e1-8210-1ce430ae568b/sm/snapshot.1_0 took: 1 ms
2024-03-23 11:36:48,614 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-StateMachineUpdater: Took a snapshot at index 0
2024-03-23 11:36:48,614 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-23 11:36:48,614 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B: applyIndex: 0
2024-03-23 11:36:48,614 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-23 11:36:48,968 [IPC Server handler 31 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5) as the reported value (IN_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-03-23 11:36:49,044 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B-SegmentedRaftLogWorker close()
2024-03-23 11:36:49,046 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-1CE430AE568B: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/8643aede-2156-48e1-8210-1ce430ae568b
2024-03-23 11:36:49,046 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=8643aede-2156-48e1-8210-1ce430ae568b
org.apache.ratis.protocol.exceptions.GroupMismatchException: 00b25173-7757-4760-98a7-1e1aa18d5e2d: group-1CE430AE568B not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-23 11:36:49,047 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: addNew group-9B901D931523:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034] returns group-9B901D931523:java.util.concurrent.CompletableFuture@46093b96[Not completed]
2024-03-23 11:36:49,048 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: new RaftServerImpl for group-9B901D931523:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034] with ContainerStateMachine:uninitialized
2024-03-23 11:36:49,048 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:49,048 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-23 11:36:49,048 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-23 11:36:49,048 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-23 11:36:49,048 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:36:49,048 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-23 11:36:49,048 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:36:49,048 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523: ConfigurationManager, init=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-23 11:36:49,048 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-23 11:36:49,048 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-23 11:36:49,048 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-23 11:36:49,048 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-23 11:36:49,049 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-23 11:36:49,049 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-23 11:36:49,050 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:49,050 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:49,050 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-23 11:36:49,050 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-23 11:36:49,051 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-23 11:36:49,051 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-23 11:36:49,051 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-23 11:36:49,051 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-23 11:36:49,051 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis] (custom)
2024-03-23 11:36:49,051 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/1448d56d-848d-4e5a-9e97-9b901d931523 does not exist. Creating ...
2024-03-23 11:36:49,052 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/1448d56d-848d-4e5a-9e97-9b901d931523/in_use.lock acquired by nodename 18969@fv-az1381-309
2024-03-23 11:36:49,054 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/1448d56d-848d-4e5a-9e97-9b901d931523 has been successfully formatted.
2024-03-23 11:36:49,054 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/1448d56d-848d-4e5a-9e97-9b901d931523/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/1448d56d-848d-4e5a-9e97-9b901d931523/current/raft-meta.conf
2024-03-23 11:36:49,054 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-9B901D931523: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-23 11:36:49,054 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-23 11:36:49,054 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-23 11:36:49,055 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:49,055 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-23 11:36:49,055 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-23 11:36:49,055 [IPC Server handler 41 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2024-03-23 11:36:49,056 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=1448d56d-848d-4e5a-9e97-9b901d931523. Trying to get from SCM.
2024-03-23 11:36:49,056 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:49,056 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=1448d56d-848d-4e5a-9e97-9b901d931523
2024-03-23 11:36:49,057 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-23 11:36:49,057 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-23 11:36:49,057 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:49,057 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(86)) - Adding new pipeline Pipeline[ Id: 1448d56d-848d-4e5a-9e97-9b901d931523, Nodes: 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:00b25173-7757-4760-98a7-1e1aa18d5e2d, CreationTimestamp2024-03-23T11:36:48.086Z[Etc/UTC]] to Recon pipeline metadata.
2024-03-23 11:36:49,057 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-cacheEviction-AwaitToRun,5,main] started
2024-03-23 11:36:49,057 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/1448d56d-848d-4e5a-9e97-9b901d931523
2024-03-23 11:36:49,057 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-23 11:36:49,057 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-23 11:36:49,057 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:49,058 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-23 11:36:49,058 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-23 11:36:49,058 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-23 11:36:49,058 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-23 11:36:49,058 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-23 11:36:49,058 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-23 11:36:49,059 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:49,059 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-23 11:36:49,059 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-23 11:36:49,060 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-23 11:36:49,060 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:49,060 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:49,060 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523: start as a follower, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034]|listeners:[], old=null
2024-03-23 11:36:49,060 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-23 11:36:49,060 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: start 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-FollowerState
2024-03-23 11:36:49,069 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:49,069 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9B901D931523,id=00b25173-7757-4760-98a7-1e1aa18d5e2d
2024-03-23 11:36:49,069 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-23 11:36:49,069 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-23 11:36:49,069 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-23 11:36:49,070 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-23 11:36:49,070 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-23 11:36:49,069 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:49,070 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=1448d56d-848d-4e5a-9e97-9b901d931523
2024-03-23 11:36:49,070 [00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=1448d56d-848d-4e5a-9e97-9b901d931523.
2024-03-23 11:36:49,082 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@c66a7ebf. There are 2 pipelines
2024-03-23 11:36:49,082 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(55)) - Admin start on datanode bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5). Finalizing its pipelines [PipelineID=eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72, PipelineID=2d7785c5-43f1-4411-94e4-56171e486153]
2024-03-23 11:36:49,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-23 11:36:49,083 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72 moved to CLOSED state
2024-03-23 11:36:49,084 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 moved to CLOSED state
2024-03-23 11:36:49,092 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:36:49,235 [IPC Server handler 57 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (DECOMMISSIONING, 0)
2024-03-23 11:36:49,235 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 reported by bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:49,272 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 reported by e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:49,293 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:49,295 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:49,295 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:49,295 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:49,295 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:49,295 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:49,295 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:49,295 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:49,295 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:49,311 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 reported by 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:49,363 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:49,363 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:49,364 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:49,365 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:49,365 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:49,967 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 5b4c27d6-a533-4766-a648-a869ad76920c: addNew group-95313CE3ADAB:[5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025] returns group-95313CE3ADAB:java.util.concurrent.CompletableFuture@523478dc[Not completed]
2024-03-23 11:36:49,968 [5b4c27d6-a533-4766-a648-a869ad76920c-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(317)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-03-23 11:36:49,968 [IPC Server handler 20 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2024-03-23 11:36:49,969 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 5b4c27d6-a533-4766-a648-a869ad76920c: new RaftServerImpl for group-95313CE3ADAB:[5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025] with ContainerStateMachine:uninitialized
2024-03-23 11:36:49,969 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:49,969 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-23 11:36:49,969 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-23 11:36:49,970 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-23 11:36:49,970 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:36:49,970 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-23 11:36:49,970 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:36:49,970 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB: ConfigurationManager, init=-1: peers:[5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-23 11:36:49,970 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-23 11:36:49,970 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-23 11:36:49,970 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-23 11:36:49,970 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-23 11:36:49,970 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-23 11:36:49,970 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-23 11:36:49,972 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:49,972 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:49,972 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-23 11:36:49,972 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-23 11:36:49,973 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-23 11:36:49,973 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-23 11:36:49,973 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-23 11:36:49,973 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-23 11:36:49,973 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis] (custom)
2024-03-23 11:36:49,973 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/4ebe2e72-678e-491b-9c18-95313ce3adab does not exist. Creating ...
2024-03-23 11:36:49,975 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/4ebe2e72-678e-491b-9c18-95313ce3adab/in_use.lock acquired by nodename 18969@fv-az1381-309
2024-03-23 11:36:49,976 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/4ebe2e72-678e-491b-9c18-95313ce3adab has been successfully formatted.
2024-03-23 11:36:49,976 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/4ebe2e72-678e-491b-9c18-95313ce3adab/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/4ebe2e72-678e-491b-9c18-95313ce3adab/current/raft-meta.conf
2024-03-23 11:36:49,977 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-95313CE3ADAB: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-23 11:36:49,977 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-23 11:36:49,977 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-23 11:36:49,977 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:49,977 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=4ebe2e72-678e-491b-9c18-95313ce3adab. Trying to get from SCM.
2024-03-23 11:36:49,978 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=4ebe2e72-678e-491b-9c18-95313ce3adab
2024-03-23 11:36:49,977 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-23 11:36:49,978 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-23 11:36:49,978 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(86)) - Adding new pipeline Pipeline[ Id: 4ebe2e72-678e-491b-9c18-95313ce3adab, Nodes: 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:5b4c27d6-a533-4766-a648-a869ad76920c, CreationTimestamp2024-03-23T11:36:48.084Z[Etc/UTC]] to Recon pipeline metadata.
2024-03-23 11:36:49,979 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:49,980 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-23 11:36:49,980 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-23 11:36:49,980 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:49,980 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-cacheEviction-AwaitToRun,5,main] started
2024-03-23 11:36:49,980 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/4ebe2e72-678e-491b-9c18-95313ce3adab
2024-03-23 11:36:49,980 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-23 11:36:49,980 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-23 11:36:49,981 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:49,981 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-23 11:36:49,981 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-23 11:36:49,981 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-23 11:36:49,981 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-23 11:36:49,981 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-23 11:36:49,981 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-23 11:36:49,983 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:49,983 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-23 11:36:49,983 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-23 11:36:49,983 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-23 11:36:49,983 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:49,984 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:49,984 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB: start as a follower, conf=-1: peers:[5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025]|listeners:[], old=null
2024-03-23 11:36:49,984 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-23 11:36:49,984 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5b4c27d6-a533-4766-a648-a869ad76920c: start 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-FollowerState
2024-03-23 11:36:49,987 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-95313CE3ADAB,id=5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:36:49,987 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-23 11:36:49,987 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-23 11:36:49,987 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-23 11:36:49,987 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-23 11:36:49,987 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-23 11:36:49,987 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:49,988 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:49,988 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=4ebe2e72-678e-491b-9c18-95313ce3adab
2024-03-23 11:36:49,988 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=4ebe2e72-678e-491b-9c18-95313ce3adab.
2024-03-23 11:36:50,082 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@c66a7ebf. There are 2 pipelines
2024-03-23 11:36:50,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-23 11:36:50,092 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:36:50,235 [IPC Server handler 57 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (DECOMMISSIONING, 0)
2024-03-23 11:36:50,236 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(317)) - Node state updated to DECOMMISSIONING, scaling executor pool size to 20
2024-03-23 11:36:50,273 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 reported by e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:50,296 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:50,302 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 6 milliseconds for processing 1 containers.
2024-03-23 11:36:50,302 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:50,302 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:50,302 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	TOTAL_KEYS -> 1 , CONTAINER_COUNT -> 1 , TOTAL_USED_BYTES -> 7 , 
2024-03-23 11:36:50,302 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:50,302 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:50,302 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:50,302 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:50,312 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 reported by 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:50,367 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:50,367 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:50,367 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:50,368 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:50,368 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:50,999 [OverReplicatedProcessor] INFO  replication.RatisOverReplicationHandler (RatisOverReplicationHandler.java:processAndSendCommands(115)) - Container #1 is over replicated. Actual replica count is 4, with 0 pending delete(s). Expected replica count is 3.
2024-03-23 11:36:51,000 [OverReplicatedProcessor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [deleteContainerCommand: containerID: 1, replicaIndex: 0, force: true] for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-03-23T11:36:33.960Z, pipelineID=PipelineID=439e139a-b269-423e-9d21-d246ec176e64, owner=omServiceIdDefault} to bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5) with datanode deadline 1711194381000 and scm deadline 1711194411000
2024-03-23 11:36:51,000 [OverReplicatedProcessor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(138)) - Processed 1 containers with health state counts {OVER_REPLICATED=1}, failed processing 0, deferred due to load 0
2024-03-23 11:36:51,082 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@c66a7ebf. There are 2 pipelines
2024-03-23 11:36:51,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-23 11:36:51,092 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:36:51,235 [IPC Server handler 9 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5) as the reported value (DECOMMISSIONING, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-03-23 11:36:51,236 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 reported by bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:51,304 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:processExistingDBRecords(299)) - DELETED existing unhealthy container record...for Container: 1
2024-03-23 11:36:51,305 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 2 milliseconds to process 1 existing database records.
2024-03-23 11:36:51,306 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:51,306 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:51,306 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:51,306 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:51,306 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:51,306 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:51,306 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:51,306 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:51,370 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:51,370 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:51,370 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:51,371 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:51,371 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:52,082 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@c66a7ebf. There are 2 pipelines
2024-03-23 11:36:52,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-23 11:36:52,093 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:36:52,240 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-DeleteContainerThread-0] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:markContainerForDelete(424)) - Moving container /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/current/containerDir0/1 to state DELETED from state:CLOSED
2024-03-23 11:36:52,272 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 reported by e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:52,307 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:52,309 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:52,309 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:52,309 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:52,309 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:52,309 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:52,309 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:52,310 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:52,310 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:52,312 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 reported by 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:52,349 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5027164577ns, electionTimeout:5026ms
2024-03-23 11:36:52,349 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: shutdown 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-FollowerState
2024-03-23 11:36:52,349 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-23 11:36:52,350 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-23 11:36:52,350 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: start 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11
2024-03-23 11:36:52,352 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:52,352 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043
2024-03-23 11:36:52,352 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:52,352 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:52,354 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153: receive requestVote(PRE_VOTE, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, group-56171E486153, 0, (t:0, i:0))
2024-03-23 11:36:52,355 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-FOLLOWER: accept PRE_VOTE from 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: our priority 0 <= candidate's priority 1
2024-03-23 11:36:52,355 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153 replies to PRE_VOTE vote request: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b<-e3882025-ee77-4273-a30c-caf156427e83#0:OK-t0. Peer's state: e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153:t0, leader=null, voted=, raftlog=Memoized:e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:52,356 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2024-03-23 11:36:52,356 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b<-e3882025-ee77-4273-a30c-caf156427e83#0:OK-t0
2024-03-23 11:36:52,357 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11 PRE_VOTE round 0: result PASSED
2024-03-23 11:36:52,358 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11 ELECTION round 0: submit vote requests at term 1 for -1: peers:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:52,362 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:52,362 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:52,362 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153: receive requestVote(PRE_VOTE, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, group-56171E486153, 0, (t:0, i:0))
2024-03-23 11:36:52,362 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-FOLLOWER: accept PRE_VOTE from 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: our priority 0 <= candidate's priority 1
2024-03-23 11:36:52,362 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153 replies to PRE_VOTE vote request: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b<-bb4f2f6f-344d-4a57-aba3-69abe2cb722c#0:OK-t0. Peer's state: bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153:t0, leader=null, voted=, raftlog=Memoized:bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:52,366 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153: receive requestVote(ELECTION, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, group-56171E486153, 1, (t:0, i:0))
2024-03-23 11:36:52,366 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153: receive requestVote(ELECTION, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, group-56171E486153, 1, (t:0, i:0))
2024-03-23 11:36:52,366 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-FOLLOWER: accept ELECTION from 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: our priority 0 <= candidate's priority 1
2024-03-23 11:36:52,366 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-FOLLOWER: accept ELECTION from 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: our priority 0 <= candidate's priority 1
2024-03-23 11:36:52,366 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:52,366 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:52,366 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: shutdown bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-FollowerState
2024-03-23 11:36:52,366 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - e3882025-ee77-4273-a30c-caf156427e83: shutdown e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-FollowerState
2024-03-23 11:36:52,367 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-FollowerState was interrupted
2024-03-23 11:36:52,367 [e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-FollowerState was interrupted
2024-03-23 11:36:52,367 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: start bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-FollowerState
2024-03-23 11:36:52,370 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153: set firstElectionSinceStartup to false for candidate:6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:52,370 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e3882025-ee77-4273-a30c-caf156427e83: start e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-FollowerState
2024-03-23 11:36:52,371 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153: set firstElectionSinceStartup to false for candidate:6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:52,372 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153 replies to ELECTION vote request: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b<-bb4f2f6f-344d-4a57-aba3-69abe2cb722c#0:OK-t1. Peer's state: bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153:t1, leader=null, voted=6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, raftlog=Memoized:bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:52,372 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153 replies to ELECTION vote request: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b<-e3882025-ee77-4273-a30c-caf156427e83#0:OK-t1. Peer's state: e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153:t1, leader=null, voted=6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, raftlog=Memoized:e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:52,373 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11: ELECTION PASSED received 1 response(s) and 0 exception(s):
2024-03-23 11:36:52,373 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:52,373 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:52,373 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:52,373 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b<-e3882025-ee77-4273-a30c-caf156427e83#0:OK-t1
2024-03-23 11:36:52,374 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11 ELECTION round 0: result PASSED
2024-03-23 11:36:52,374 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: shutdown 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11
2024-03-23 11:36:52,374 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-23 11:36:52,374 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-03-23 11:36:52,374 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-23 11:36:52,375 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-03-23 11:36:52,375 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-03-23 11:36:52,375 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:52,375 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-03-23 11:36:52,375 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-03-23 11:36:52,375 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-03-23 11:36:52,376 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-23 11:36:52,376 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:52,376 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-23 11:36:52,376 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-23 11:36:52,375 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:52,376 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-03-23 11:36:52,376 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:52,376 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2024-03-23 11:36:52,377 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0s (custom)
2024-03-23 11:36:52,377 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-03-23 11:36:52,377 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:52,377 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-03-23 11:36:52,377 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-03-23 11:36:52,377 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-03-23 11:36:52,377 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:52,377 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-23 11:36:52,378 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-03-23 11:36:52,378 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:52,378 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2024-03-23 11:36:52,378 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0s (custom)
2024-03-23 11:36:52,378 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-03-23 11:36:52,379 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:52,379 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-03-23 11:36:52,379 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-03-23 11:36:52,379 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-03-23 11:36:52,379 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:52,379 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-23 11:36:52,379 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: start 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderStateImpl
2024-03-23 11:36:52,379 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153: set firstElectionSinceStartup to false for becomeLeader
2024-03-23 11:36:52,381 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-56171E486153 with new leaderId: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:52,381 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153: change Leader from null to 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b at term 1 for becomeLeader, leader elected after 5080ms
2024-03-23 11:36:52,381 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-23 11:36:52,383 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-23 11:36:52,383 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 reported by 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:52,387 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderElection11] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153: set configuration 0: peers:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:52,394 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/2d7785c5-43f1-4411-94e4-56171e486153/current/log_inprogress_0
2024-03-23 11:36:52,397 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-56171E486153 with new leaderId: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:52,399 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153: change Leader from null to 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b at term 1 for appendEntries, leader elected after 5171ms
2024-03-23 11:36:52,402 [e3882025-ee77-4273-a30c-caf156427e83-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-56171E486153 with new leaderId: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:52,402 [e3882025-ee77-4273-a30c-caf156427e83-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153: change Leader from null to 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b at term 1 for appendEntries, leader elected after 5136ms
2024-03-23 11:36:52,405 [e3882025-ee77-4273-a30c-caf156427e83-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153: set configuration 0: peers:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:52,405 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153: set configuration 0: peers:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null
2024-03-23 11:36:52,405 [e3882025-ee77-4273-a30c-caf156427e83-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-23 11:36:52,405 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-23 11:36:52,405 [e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-23 11:36:52,405 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-23 11:36:52,416 [e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/2d7785c5-43f1-4411-94e4-56171e486153/current/log_inprogress_0
2024-03-23 11:36:52,417 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis/2d7785c5-43f1-4411-94e4-56171e486153/current/log_inprogress_0
2024-03-23 11:36:52,419 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-23 11:36:53,009 [UnderReplicatedProcessor] INFO  replication.RatisUnderReplicationHandler (RatisUnderReplicationHandler.java:verifyUnderReplication(314)) - The container #1 state changed and it's not under replicated any more.
2024-03-23 11:36:53,009 [UnderReplicatedProcessor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(138)) - Processed 1 containers with health state counts {UNDER_REPLICATED=1}, failed processing 0, deferred due to load 0
2024-03-23 11:36:53,082 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@c66a7ebf. There are 2 pipelines
2024-03-23 11:36:53,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-23 11:36:53,093 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:36:53,310 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:53,312 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:53,312 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:53,312 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:53,313 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:53,313 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:53,313 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:53,313 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:53,313 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:53,378 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:53,378 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:53,378 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:53,379 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:53,380 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:54,082 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@c66a7ebf. There are 2 pipelines
2024-03-23 11:36:54,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-23 11:36:54,092 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5031630587ns, electionTimeout:5022ms
2024-03-23 11:36:54,092 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: shutdown 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-FollowerState
2024-03-23 11:36:54,092 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-23 11:36:54,093 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-23 11:36:54,093 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: start 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12
2024-03-23 11:36:54,094 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:36:54,094 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034]|listeners:[], old=null
2024-03-23 11:36:54,094 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12 PRE_VOTE round 0: result PASSED (term=0)
2024-03-23 11:36:54,096 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12 ELECTION round 0: submit vote requests at term 1 for -1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034]|listeners:[], old=null
2024-03-23 11:36:54,096 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12 ELECTION round 0: result PASSED (term=1)
2024-03-23 11:36:54,096 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: shutdown 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12
2024-03-23 11:36:54,096 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-23 11:36:54,096 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-03-23 11:36:54,096 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-23 11:36:54,096 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-03-23 11:36:54,097 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-03-23 11:36:54,097 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-03-23 11:36:54,097 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-03-23 11:36:54,097 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-03-23 11:36:54,097 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-23 11:36:54,097 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:54,097 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-23 11:36:54,097 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-23 11:36:54,097 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: start 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderStateImpl
2024-03-23 11:36:54,098 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523: set firstElectionSinceStartup to false for becomeLeader
2024-03-23 11:36:54,098 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-9B901D931523 with new leaderId: 00b25173-7757-4760-98a7-1e1aa18d5e2d
2024-03-23 11:36:54,098 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523: change Leader from null to 00b25173-7757-4760-98a7-1e1aa18d5e2d at term 1 for becomeLeader, leader elected after 5049ms
2024-03-23 11:36:54,098 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-23 11:36:54,099 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-23 11:36:54,102 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderElection12] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523: set configuration 0: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034]|listeners:[], old=null
2024-03-23 11:36:54,107 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/1448d56d-848d-4e5a-9e97-9b901d931523/current/log_inprogress_0
2024-03-23 11:36:54,109 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-23 11:36:54,313 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-23 11:36:54,316 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:54,316 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:54,316 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:54,316 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:54,316 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:54,316 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:54,316 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:54,316 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:54,381 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:54,381 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:54,381 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:54,383 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:54,383 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:55,082 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@c66a7ebf. There are 2 pipelines
2024-03-23 11:36:55,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-23 11:36:55,095 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:36:55,158 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5173930310ns, electionTimeout:5170ms
2024-03-23 11:36:55,158 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 5b4c27d6-a533-4766-a648-a869ad76920c: shutdown 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-FollowerState
2024-03-23 11:36:55,158 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-23 11:36:55,159 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-23 11:36:55,159 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5b4c27d6-a533-4766-a648-a869ad76920c: start 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13
2024-03-23 11:36:55,160 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025]|listeners:[], old=null
2024-03-23 11:36:55,160 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13 PRE_VOTE round 0: result PASSED (term=0)
2024-03-23 11:36:55,161 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13 ELECTION round 0: submit vote requests at term 1 for -1: peers:[5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025]|listeners:[], old=null
2024-03-23 11:36:55,162 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13 ELECTION round 0: result PASSED (term=1)
2024-03-23 11:36:55,162 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 5b4c27d6-a533-4766-a648-a869ad76920c: shutdown 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13
2024-03-23 11:36:55,162 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-23 11:36:55,162 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-03-23 11:36:55,162 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-23 11:36:55,162 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-03-23 11:36:55,162 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-03-23 11:36:55,162 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-03-23 11:36:55,163 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-03-23 11:36:55,163 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-03-23 11:36:55,163 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-23 11:36:55,163 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:55,163 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-23 11:36:55,163 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-23 11:36:55,163 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5b4c27d6-a533-4766-a648-a869ad76920c: start 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderStateImpl
2024-03-23 11:36:55,163 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB: set firstElectionSinceStartup to false for becomeLeader
2024-03-23 11:36:55,163 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-95313CE3ADAB with new leaderId: 5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:36:55,163 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB: change Leader from null to 5b4c27d6-a533-4766-a648-a869ad76920c at term 1 for becomeLeader, leader elected after 5193ms
2024-03-23 11:36:55,164 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-23 11:36:55,165 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderElection13] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB: set configuration 0: peers:[5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025]|listeners:[], old=null
2024-03-23 11:36:55,165 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-23 11:36:55,174 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/4ebe2e72-678e-491b-9c18-95313ce3adab/current/log_inprogress_0
2024-03-23 11:36:55,175 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-23 11:36:55,317 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:55,319 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:55,319 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:55,319 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:55,319 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:55,319 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:55,319 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:55,319 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:55,319 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:55,385 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:55,385 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:55,385 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:55,386 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:55,386 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:55,896 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72 since it stays at CLOSED stage.
2024-03-23 11:36:55,896 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72 close command to datanode bb4f2f6f-344d-4a57-aba3-69abe2cb722c
2024-03-23 11:36:55,896 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72, Nodes: bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:bb4f2f6f-344d-4a57-aba3-69abe2cb722c, CreationTimestamp2024-03-23T11:36:19.103Z[Etc/UTC]] removed.
2024-03-23 11:36:55,896 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 since it stays at CLOSED stage.
2024-03-23 11:36:55,896 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 close command to datanode bb4f2f6f-344d-4a57-aba3-69abe2cb722c
2024-03-23 11:36:55,896 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 close command to datanode e3882025-ee77-4273-a30c-caf156427e83
2024-03-23 11:36:55,896 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 close command to datanode 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:55,897 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 2d7785c5-43f1-4411-94e4-56171e486153, Nodes: bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5)e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5)6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, CreationTimestamp2024-03-23T11:36:46.084Z[Etc/UTC]] removed.
2024-03-23 11:36:56,082 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(472)) - org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@c66a7ebf has 0 sufficientlyReplicated, 0 deleting, 0 underReplicated and 0 unclosed containers
2024-03-23 11:36:56,083 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:completeDecommission(522)) - Datanode bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5) has completed the admin workflow. The operational state has been set to DECOMMISSIONED
2024-03-23 11:36:56,083 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5) moved to HEALTHY state.
2024-03-23 11:36:56,083 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-23 11:36:56,084 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc to datanode:e3882025-ee77-4273-a30c-caf156427e83
2024-03-23 11:36:56,084 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc to datanode:5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:36:56,084 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc to datanode:00b25173-7757-4760-98a7-1e1aa18d5e2d
2024-03-23 11:36:56,085 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 2d76b7c9-57b7-4fbf-bb1d-adc18a360adc, Nodes: e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5)5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5)00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-23T11:36:56.084Z[Etc/UTC]]
2024-03-23 11:36:56,095 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:36:56,119 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:36:56,243 [IPC Server handler 62 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5) as the reported value (DECOMMISSIONING, 0) does not match the value stored in SCM (DECOMMISSIONED, 0)
2024-03-23 11:36:56,244 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72 is not found
2024-03-23 11:36:56,244 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 is not found
2024-03-23 11:36:56,273 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 is not found
2024-03-23 11:36:56,320 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:56,322 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:56,322 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:56,323 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:56,323 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:56,323 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:56,323 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:56,323 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:56,323 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:56,383 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 is not found
2024-03-23 11:36:56,388 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:56,388 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:56,388 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:56,389 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:56,390 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:56,978 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 5b4c27d6-a533-4766-a648-a869ad76920c: addNew group-ADC18A360ADC:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016] returns group-ADC18A360ADC:java.util.concurrent.CompletableFuture@565ebcdb[Not completed]
2024-03-23 11:36:56,979 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 5b4c27d6-a533-4766-a648-a869ad76920c: new RaftServerImpl for group-ADC18A360ADC:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016] with ContainerStateMachine:uninitialized
2024-03-23 11:36:56,979 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:56,979 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-23 11:36:56,979 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-23 11:36:56,980 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-23 11:36:56,980 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:36:56,980 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-23 11:36:56,980 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:36:56,980 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC: ConfigurationManager, init=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-23 11:36:56,980 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-23 11:36:56,980 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-23 11:36:56,980 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-23 11:36:56,980 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-23 11:36:56,980 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-23 11:36:56,980 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-23 11:36:56,982 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:56,982 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:56,982 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-23 11:36:56,982 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-23 11:36:56,982 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-23 11:36:56,982 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-23 11:36:56,982 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-23 11:36:56,983 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-23 11:36:56,983 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis] (custom)
2024-03-23 11:36:56,983 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc does not exist. Creating ...
2024-03-23 11:36:56,984 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc/in_use.lock acquired by nodename 18969@fv-az1381-309
2024-03-23 11:36:56,985 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc has been successfully formatted.
2024-03-23 11:36:56,985 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc/current/raft-meta.conf
2024-03-23 11:36:56,986 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-ADC18A360ADC: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-23 11:36:56,986 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-23 11:36:56,986 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-23 11:36:56,986 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:56,986 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-23 11:36:56,986 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-23 11:36:56,987 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc. Trying to get from SCM.
2024-03-23 11:36:56,987 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:56,988 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-23 11:36:56,988 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(86)) - Adding new pipeline Pipeline[ Id: 2d76b7c9-57b7-4fbf-bb1d-adc18a360adc, Nodes: e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5)5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5)00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-23T11:36:56.084Z[Etc/UTC]] to Recon pipeline metadata.
2024-03-23 11:36:56,988 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-23 11:36:56,988 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:56,988 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-cacheEviction-AwaitToRun,5,main] started
2024-03-23 11:36:56,988 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc
2024-03-23 11:36:56,988 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-23 11:36:56,989 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-23 11:36:56,989 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:56,989 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc reported by 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:56,989 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-23 11:36:56,989 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-23 11:36:56,989 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-23 11:36:56,989 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-23 11:36:56,989 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-23 11:36:56,990 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-23 11:36:56,991 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:56,991 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-23 11:36:56,992 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-23 11:36:56,992 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-23 11:36:56,992 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:56,992 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:56,992 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC: start as a follower, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:36:56,992 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-23 11:36:56,992 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5b4c27d6-a533-4766-a648-a869ad76920c: start 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-FollowerState
2024-03-23 11:36:56,993 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-ADC18A360ADC,id=5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:36:56,993 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-23 11:36:56,993 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-23 11:36:56,993 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-23 11:36:56,993 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-23 11:36:56,993 [5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-23 11:36:56,994 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:56,994 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc
2024-03-23 11:36:56,994 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:57,002 [grpc-default-executor-4] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - e3882025-ee77-4273-a30c-caf156427e83: addNew group-ADC18A360ADC:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016] returns group-ADC18A360ADC:java.util.concurrent.CompletableFuture@1d3da76a[Not completed]
2024-03-23 11:36:57,003 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - e3882025-ee77-4273-a30c-caf156427e83: new RaftServerImpl for group-ADC18A360ADC:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016] with ContainerStateMachine:uninitialized
2024-03-23 11:36:57,004 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:57,004 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-23 11:36:57,004 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-23 11:36:57,004 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-23 11:36:57,004 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:36:57,004 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-23 11:36:57,004 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:36:57,004 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC: ConfigurationManager, init=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-23 11:36:57,004 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-23 11:36:57,005 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-23 11:36:57,005 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-23 11:36:57,005 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-23 11:36:57,005 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-23 11:36:57,005 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-23 11:36:57,007 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:57,007 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:57,007 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-23 11:36:57,007 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-23 11:36:57,007 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-23 11:36:57,007 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-23 11:36:57,007 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-23 11:36:57,007 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-23 11:36:57,007 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis] (custom)
2024-03-23 11:36:57,008 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc does not exist. Creating ...
2024-03-23 11:36:57,008 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc/in_use.lock acquired by nodename 18969@fv-az1381-309
2024-03-23 11:36:57,010 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc has been successfully formatted.
2024-03-23 11:36:57,010 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc/current/raft-meta.conf
2024-03-23 11:36:57,011 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-ADC18A360ADC: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-23 11:36:57,011 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-23 11:36:57,011 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-23 11:36:57,011 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:57,011 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-23 11:36:57,011 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-23 11:36:57,013 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 is not found
2024-03-23 11:36:57,013 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc reported by e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:57,014 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:57,015 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-23 11:36:57,015 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-23 11:36:57,015 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:57,015 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-cacheEviction-AwaitToRun,5,main] started
2024-03-23 11:36:57,015 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc
2024-03-23 11:36:57,015 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-23 11:36:57,016 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-23 11:36:57,016 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:57,016 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-23 11:36:57,016 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-23 11:36:57,016 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-23 11:36:57,016 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-23 11:36:57,016 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-23 11:36:57,016 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-23 11:36:57,018 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:57,018 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-23 11:36:57,018 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-23 11:36:57,021 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-23 11:36:57,021 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:57,021 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:57,021 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC: start as a follower, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:36:57,021 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-23 11:36:57,021 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e3882025-ee77-4273-a30c-caf156427e83: start e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-FollowerState
2024-03-23 11:36:57,022 [e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:57,022 [e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:57,022 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-ADC18A360ADC,id=e3882025-ee77-4273-a30c-caf156427e83
2024-03-23 11:36:57,022 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-23 11:36:57,022 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-23 11:36:57,022 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-23 11:36:57,022 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-23 11:36:57,022 [e3882025-ee77-4273-a30c-caf156427e83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-23 11:36:57,035 [grpc-default-executor-4] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: addNew group-ADC18A360ADC:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016] returns group-ADC18A360ADC:java.util.concurrent.CompletableFuture@39b22187[Not completed]
2024-03-23 11:36:57,035 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: new RaftServerImpl for group-ADC18A360ADC:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016] with ContainerStateMachine:uninitialized
2024-03-23 11:36:57,036 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:36:57,036 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-23 11:36:57,036 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-23 11:36:57,036 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-23 11:36:57,036 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:36:57,036 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-23 11:36:57,036 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:36:57,036 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC: ConfigurationManager, init=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-23 11:36:57,036 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-23 11:36:57,036 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-23 11:36:57,036 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-23 11:36:57,036 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-23 11:36:57,036 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-23 11:36:57,036 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-23 11:36:57,038 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:36:57,038 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:36:57,038 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-23 11:36:57,038 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-23 11:36:57,038 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-23 11:36:57,039 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-23 11:36:57,039 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-23 11:36:57,039 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-23 11:36:57,039 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis] (custom)
2024-03-23 11:36:57,039 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc does not exist. Creating ...
2024-03-23 11:36:57,040 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc/in_use.lock acquired by nodename 18969@fv-az1381-309
2024-03-23 11:36:57,041 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc has been successfully formatted.
2024-03-23 11:36:57,041 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc/current/raft-meta.conf
2024-03-23 11:36:57,041 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-ADC18A360ADC: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-23 11:36:57,042 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-23 11:36:57,042 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-23 11:36:57,042 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:57,042 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-23 11:36:57,042 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-23 11:36:57,043 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:57,043 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc reported by 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:57,043 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-23 11:36:57,043 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-23 11:36:57,044 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:57,044 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-cacheEviction-AwaitToRun,5,main] started
2024-03-23 11:36:57,044 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc
2024-03-23 11:36:57,044 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-23 11:36:57,044 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-23 11:36:57,044 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-23 11:36:57,044 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-23 11:36:57,044 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-23 11:36:57,044 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-23 11:36:57,044 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-23 11:36:57,044 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-23 11:36:57,045 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-23 11:36:57,046 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:36:57,046 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-23 11:36:57,046 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-23 11:36:57,047 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-23 11:36:57,047 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:57,047 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-23 11:36:57,047 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC: start as a follower, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:36:57,047 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-23 11:36:57,047 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: start 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-FollowerState
2024-03-23 11:36:57,048 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:36:57,048 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:36:57,052 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-ADC18A360ADC,id=00b25173-7757-4760-98a7-1e1aa18d5e2d
2024-03-23 11:36:57,052 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-23 11:36:57,052 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-23 11:36:57,052 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-23 11:36:57,052 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-23 11:36:57,052 [00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-23 11:36:57,057 [5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc.
2024-03-23 11:36:57,095 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:36:57,120 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:36:57,243 [IPC Server handler 62 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5) as the reported value (DECOMMISSIONING, 0) does not match the value stored in SCM (DECOMMISSIONED, 0)
2024-03-23 11:36:57,244 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(317)) - Node state updated to DECOMMISSIONED, scaling executor pool size to 20
2024-03-23 11:36:57,245 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: remove    LEADER bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72:t1, leader=bb4f2f6f-344d-4a57-aba3-69abe2cb722c, voted=bb4f2f6f-344d-4a57-aba3-69abe2cb722c, raftlog=Memoized:bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-SegmentedRaftLog:OPENED:c0, conf=0: peers:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043]|listeners:[], old=null RUNNING
2024-03-23 11:36:57,245 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72: shutdown
2024-03-23 11:36:57,245 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-9AF5C7649F72,id=bb4f2f6f-344d-4a57-aba3-69abe2cb722c
2024-03-23 11:36:57,245 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: shutdown bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-LeaderStateImpl
2024-03-23 11:36:57,245 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-PendingRequests: sendNotLeaderResponses
2024-03-23 11:36:57,246 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-StateMachineUpdater: set stopIndex = 0
2024-03-23 11:36:57,246 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-9AF5C7649F72: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis/eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72/sm/snapshot.1_0
2024-03-23 11:36:57,246 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-9AF5C7649F72: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis/eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72/sm/snapshot.1_0 took: 1 ms
2024-03-23 11:36:57,246 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-StateMachineUpdater: Took a snapshot at index 0
2024-03-23 11:36:57,246 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-23 11:36:57,247 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72: applyIndex: 0
2024-03-23 11:36:57,247 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-23 11:36:57,271 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - e3882025-ee77-4273-a30c-caf156427e83: remove  FOLLOWER e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153:t1, leader=6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, voted=6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, raftlog=Memoized:e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-SegmentedRaftLog:OPENED:c0, conf=0: peers:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null RUNNING
2024-03-23 11:36:57,271 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153: shutdown
2024-03-23 11:36:57,271 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-56171E486153,id=e3882025-ee77-4273-a30c-caf156427e83
2024-03-23 11:36:57,271 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - e3882025-ee77-4273-a30c-caf156427e83: shutdown e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-FollowerState
2024-03-23 11:36:57,271 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-StateMachineUpdater: set stopIndex = 0
2024-03-23 11:36:57,271 [e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-FollowerState was interrupted
2024-03-23 11:36:57,271 [e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-56171E486153: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/2d7785c5-43f1-4411-94e4-56171e486153/sm/snapshot.1_0
2024-03-23 11:36:57,273 [e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-56171E486153: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/2d7785c5-43f1-4411-94e4-56171e486153/sm/snapshot.1_0 took: 2 ms
2024-03-23 11:36:57,273 [e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-StateMachineUpdater: Took a snapshot at index 0
2024-03-23 11:36:57,273 [e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-23 11:36:57,274 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153: applyIndex: 0
2024-03-23 11:36:57,274 [e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-23 11:36:57,324 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-23 11:36:57,326 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:57,326 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:57,326 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:57,326 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:57,326 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:57,326 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:57,326 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:57,326 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:57,383 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 is not found
2024-03-23 11:36:57,391 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:57,391 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:57,391 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:57,393 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:57,393 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:57,421 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153-SegmentedRaftLogWorker close()
2024-03-23 11:36:57,422 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - e3882025-ee77-4273-a30c-caf156427e83@group-56171E486153: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/2d7785c5-43f1-4411-94e4-56171e486153
2024-03-23 11:36:57,423 [e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=2d7785c5-43f1-4411-94e4-56171e486153
org.apache.ratis.protocol.exceptions.GroupMismatchException: e3882025-ee77-4273-a30c-caf156427e83: group-56171E486153 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-23 11:36:58,012 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc reported by e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:58,042 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc reported by 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:58,096 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:36:58,120 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:36:58,232 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72-SegmentedRaftLogWorker close()
2024-03-23 11:36:58,234 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-9AF5C7649F72: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis/eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72
2024-03-23 11:36:58,234 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72
org.apache.ratis.protocol.exceptions.GroupMismatchException: bb4f2f6f-344d-4a57-aba3-69abe2cb722c: group-9AF5C7649F72 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-23 11:36:58,234 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: remove  FOLLOWER bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153:t1, leader=6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, voted=6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, raftlog=Memoized:bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-SegmentedRaftLog:OPENED:c0, conf=0: peers:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null RUNNING
2024-03-23 11:36:58,234 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153: shutdown
2024-03-23 11:36:58,234 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-56171E486153,id=bb4f2f6f-344d-4a57-aba3-69abe2cb722c
2024-03-23 11:36:58,234 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: shutdown bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-FollowerState
2024-03-23 11:36:58,234 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-StateMachineUpdater: set stopIndex = 0
2024-03-23 11:36:58,235 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-FollowerState was interrupted
2024-03-23 11:36:58,235 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-56171E486153: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis/2d7785c5-43f1-4411-94e4-56171e486153/sm/snapshot.1_0
2024-03-23 11:36:58,236 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-56171E486153: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis/2d7785c5-43f1-4411-94e4-56171e486153/sm/snapshot.1_0 took: 1 ms
2024-03-23 11:36:58,237 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-StateMachineUpdater: Took a snapshot at index 0
2024-03-23 11:36:58,237 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-23 11:36:58,237 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153: applyIndex: 0
2024-03-23 11:36:58,237 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-23 11:36:58,243 [IPC Server handler 13 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5) as the reported value (DECOMMISSIONED, 0) does not match the value stored in SCM (DECOMMISSIONING, 0)
2024-03-23 11:36:58,243 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 is not found
2024-03-23 11:36:58,245 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:58,245 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:36:58,327 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-23 11:36:58,329 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:58,329 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:58,329 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:58,329 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:58,329 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:58,329 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:58,329 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:58,329 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:58,382 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: remove    LEADER 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153:t1, leader=6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, voted=6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, raftlog=Memoized:6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-SegmentedRaftLog:OPENED:c0, conf=0: peers:[bb4f2f6f-344d-4a57-aba3-69abe2cb722c|10.1.0.5:15043, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b|10.1.0.5:15052]|listeners:[], old=null RUNNING
2024-03-23 11:36:58,382 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153: shutdown
2024-03-23 11:36:58,382 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-56171E486153,id=6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:36:58,382 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: shutdown 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-LeaderStateImpl
2024-03-23 11:36:58,382 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-PendingRequests: sendNotLeaderResponses
2024-03-23 11:36:58,383 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153->bb4f2f6f-344d-4a57-aba3-69abe2cb722c-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153->bb4f2f6f-344d-4a57-aba3-69abe2cb722c-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-03-23 11:36:58,384 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: Completed APPEND_ENTRIES, lastRequest: null
2024-03-23 11:36:58,384 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153->e3882025-ee77-4273-a30c-caf156427e83-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153->e3882025-ee77-4273-a30c-caf156427e83-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-03-23 11:36:58,384 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b"
  replyId: "bb4f2f6f-344d-4a57-aba3-69abe2cb722c"
  raftGroupId {
    id: "-w\205\305C\361D\021\224\344V\027\036HaS"
  }
  callId: 5
  success: true
}
term: 1
nextIndex: 1
matchIndex: 18446744073709551615
isHearbeat: true

2024-03-23 11:36:58,384 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - e3882025-ee77-4273-a30c-caf156427e83: Completed APPEND_ENTRIES, lastRequest: null
2024-03-23 11:36:58,386 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-StateMachineUpdater: set stopIndex = 0
2024-03-23 11:36:58,387 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-56171E486153: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/2d7785c5-43f1-4411-94e4-56171e486153/sm/snapshot.1_0
2024-03-23 11:36:58,387 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - e3882025-ee77-4273-a30c-caf156427e83: Completed APPEND_ENTRIES, lastRequest: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b->e3882025-ee77-4273-a30c-caf156427e83#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "bb4f2f6f-344d-4a57-aba3-69abe2cb722c"
address: "10.1.0.5:15043"
dataStreamAddress: "10.1.0.5:15044"
clientAddress: "10.1.0.5:15041"
adminAddress: "10.1.0.5:15042"
startupRole: FOLLOWER
,id: "e3882025-ee77-4273-a30c-caf156427e83"
address: "10.1.0.5:15016"
dataStreamAddress: "10.1.0.5:15017"
clientAddress: "10.1.0.5:15014"
adminAddress: "10.1.0.5:15015"
startupRole: FOLLOWER
,id: "6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b"
address: "10.1.0.5:15052"
priority: 1
dataStreamAddress: "10.1.0.5:15053"
clientAddress: "10.1.0.5:15050"
adminAddress: "10.1.0.5:15051"
startupRole: FOLLOWER
, old:)
2024-03-23 11:36:58,387 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - e3882025-ee77-4273-a30c-caf156427e83: Completed APPEND_ENTRIES, lastReply: null
2024-03-23 11:36:58,387 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-56171E486153: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/2d7785c5-43f1-4411-94e4-56171e486153/sm/snapshot.1_0 took: 1 ms
2024-03-23 11:36:58,387 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-StateMachineUpdater: Took a snapshot at index 0
2024-03-23 11:36:58,388 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-23 11:36:58,388 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153->e3882025-ee77-4273-a30c-caf156427e83-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-23 11:36:58,389 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: Completed APPEND_ENTRIES, lastRequest: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b->bb4f2f6f-344d-4a57-aba3-69abe2cb722c#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "bb4f2f6f-344d-4a57-aba3-69abe2cb722c"
address: "10.1.0.5:15043"
dataStreamAddress: "10.1.0.5:15044"
clientAddress: "10.1.0.5:15041"
adminAddress: "10.1.0.5:15042"
startupRole: FOLLOWER
,id: "e3882025-ee77-4273-a30c-caf156427e83"
address: "10.1.0.5:15016"
dataStreamAddress: "10.1.0.5:15017"
clientAddress: "10.1.0.5:15014"
adminAddress: "10.1.0.5:15015"
startupRole: FOLLOWER
,id: "6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b"
address: "10.1.0.5:15052"
priority: 1
dataStreamAddress: "10.1.0.5:15053"
clientAddress: "10.1.0.5:15050"
adminAddress: "10.1.0.5:15051"
startupRole: FOLLOWER
, old:)
2024-03-23 11:36:58,388 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153->bb4f2f6f-344d-4a57-aba3-69abe2cb722c-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-23 11:36:58,389 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153: applyIndex: 0
2024-03-23 11:36:58,389 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: Completed APPEND_ENTRIES, lastReply: null
2024-03-23 11:36:58,389 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-23 11:36:58,390 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153->bb4f2f6f-344d-4a57-aba3-69abe2cb722c-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-23 11:36:58,394 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:58,394 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:58,394 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:58,396 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:58,396 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:58,396 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153-SegmentedRaftLogWorker close()
2024-03-23 11:36:58,397 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/2d7785c5-43f1-4411-94e4-56171e486153
2024-03-23 11:36:58,398 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=2d7785c5-43f1-4411-94e4-56171e486153
org.apache.ratis.protocol.exceptions.GroupMismatchException: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: group-56171E486153 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-23 11:36:58,421 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153-SegmentedRaftLogWorker close()
2024-03-23 11:36:58,422 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c@group-56171E486153: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/ratis/2d7785c5-43f1-4411-94e4-56171e486153
2024-03-23 11:36:58,422 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=2d7785c5-43f1-4411-94e4-56171e486153
org.apache.ratis.protocol.exceptions.GroupMismatchException: bb4f2f6f-344d-4a57-aba3-69abe2cb722c: group-56171E486153 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-23 11:36:58,987 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc reported by 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:59,042 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc reported by 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5)
2024-03-23 11:36:59,096 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:36:59,120 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:36:59,330 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:36:59,333 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:36:59,333 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:36:59,333 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:36:59,333 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:59,333 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:59,333 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:36:59,333 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:36:59,333 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:36:59,398 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:36:59,398 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:36:59,398 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:36:59,400 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:36:59,400 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:36:59,988 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc reported by 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5)
2024-03-23 11:37:00,013 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc reported by e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5)
2024-03-23 11:37:00,097 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:37:00,121 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:00,334 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-23 11:37:00,336 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:37:00,336 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:00,336 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:00,336 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:00,336 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:00,336 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:00,336 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:00,336 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:00,401 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:00,402 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:00,402 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:00,403 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:00,403 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:00,988 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc reported by 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5)
2024-03-23 11:37:01,012 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc reported by e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5)
2024-03-23 11:37:01,042 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc reported by 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5)
2024-03-23 11:37:01,097 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:37:01,121 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:01,337 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-23 11:37:01,339 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:37:01,339 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:01,339 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:01,339 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:01,339 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:01,339 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:01,339 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:01,339 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:01,405 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:01,405 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:01,405 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:01,406 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:01,407 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:01,987 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc reported by 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5)
2024-03-23 11:37:02,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:37:02,107 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5114596530ns, electionTimeout:5113ms
2024-03-23 11:37:02,107 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 5b4c27d6-a533-4766-a648-a869ad76920c: shutdown 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-FollowerState
2024-03-23 11:37:02,107 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-23 11:37:02,108 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-23 11:37:02,108 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5b4c27d6-a533-4766-a648-a869ad76920c: start 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14
2024-03-23 11:37:02,109 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:37:02,110 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:37:02,110 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:37:02,114 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC: receive requestVote(PRE_VOTE, 5b4c27d6-a533-4766-a648-a869ad76920c, group-ADC18A360ADC, 0, (t:0, i:0))
2024-03-23 11:37:02,114 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-FOLLOWER: accept PRE_VOTE from 5b4c27d6-a533-4766-a648-a869ad76920c: our priority 0 <= candidate's priority 1
2024-03-23 11:37:02,114 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC: receive requestVote(PRE_VOTE, 5b4c27d6-a533-4766-a648-a869ad76920c, group-ADC18A360ADC, 0, (t:0, i:0))
2024-03-23 11:37:02,114 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC replies to PRE_VOTE vote request: 5b4c27d6-a533-4766-a648-a869ad76920c<-e3882025-ee77-4273-a30c-caf156427e83#0:OK-t0. Peer's state: e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC:t0, leader=null, voted=, raftlog=Memoized:e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:37:02,114 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-FOLLOWER: accept PRE_VOTE from 5b4c27d6-a533-4766-a648-a869ad76920c: our priority 0 <= candidate's priority 1
2024-03-23 11:37:02,114 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC replies to PRE_VOTE vote request: 5b4c27d6-a533-4766-a648-a869ad76920c<-00b25173-7757-4760-98a7-1e1aa18d5e2d#0:OK-t0. Peer's state: 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC:t0, leader=null, voted=, raftlog=Memoized:00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:37:02,115 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2024-03-23 11:37:02,115 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 5b4c27d6-a533-4766-a648-a869ad76920c<-00b25173-7757-4760-98a7-1e1aa18d5e2d#0:OK-t0
2024-03-23 11:37:02,115 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14 PRE_VOTE round 0: result PASSED
2024-03-23 11:37:02,117 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14 ELECTION round 0: submit vote requests at term 1 for -1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:37:02,117 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-23 11:37:02,117 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-23 11:37:02,118 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC: receive requestVote(ELECTION, 5b4c27d6-a533-4766-a648-a869ad76920c, group-ADC18A360ADC, 1, (t:0, i:0))
2024-03-23 11:37:02,119 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-FOLLOWER: accept ELECTION from 5b4c27d6-a533-4766-a648-a869ad76920c: our priority 0 <= candidate's priority 1
2024-03-23 11:37:02,119 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:37:02,119 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - e3882025-ee77-4273-a30c-caf156427e83: shutdown e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-FollowerState
2024-03-23 11:37:02,119 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC: receive requestVote(ELECTION, 5b4c27d6-a533-4766-a648-a869ad76920c, group-ADC18A360ADC, 1, (t:0, i:0))
2024-03-23 11:37:02,120 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - e3882025-ee77-4273-a30c-caf156427e83: start e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-FollowerState
2024-03-23 11:37:02,120 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-FOLLOWER: accept ELECTION from 5b4c27d6-a533-4766-a648-a869ad76920c: our priority 0 <= candidate's priority 1
2024-03-23 11:37:02,120 [e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-FollowerState was interrupted
2024-03-23 11:37:02,120 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC: set firstElectionSinceStartup to false for candidate:5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:37:02,120 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:37:02,121 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: shutdown 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-FollowerState
2024-03-23 11:37:02,121 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: start 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-FollowerState
2024-03-23 11:37:02,121 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:02,122 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-FollowerState was interrupted
2024-03-23 11:37:02,122 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC: set firstElectionSinceStartup to false for candidate:5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:37:02,123 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC replies to ELECTION vote request: 5b4c27d6-a533-4766-a648-a869ad76920c<-e3882025-ee77-4273-a30c-caf156427e83#0:OK-t1. Peer's state: e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC:t1, leader=null, voted=5b4c27d6-a533-4766-a648-a869ad76920c, raftlog=Memoized:e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:37:02,123 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC replies to ELECTION vote request: 5b4c27d6-a533-4766-a648-a869ad76920c<-00b25173-7757-4760-98a7-1e1aa18d5e2d#0:OK-t1. Peer's state: 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC:t1, leader=null, voted=5b4c27d6-a533-4766-a648-a869ad76920c, raftlog=Memoized:00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:37:02,124 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14: ELECTION PASSED received 1 response(s) and 0 exception(s):
2024-03-23 11:37:02,124 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 5b4c27d6-a533-4766-a648-a869ad76920c<-e3882025-ee77-4273-a30c-caf156427e83#0:OK-t1
2024-03-23 11:37:02,124 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14 ELECTION round 0: result PASSED
2024-03-23 11:37:02,124 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 5b4c27d6-a533-4766-a648-a869ad76920c: shutdown 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14
2024-03-23 11:37:02,124 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-23 11:37:02,124 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-03-23 11:37:02,124 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-23 11:37:02,124 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-03-23 11:37:02,124 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-03-23 11:37:02,124 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-03-23 11:37:02,124 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-03-23 11:37:02,124 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-03-23 11:37:02,125 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-23 11:37:02,125 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:37:02,125 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-23 11:37:02,125 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-23 11:37:02,125 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-03-23 11:37:02,125 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:37:02,126 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2024-03-23 11:37:02,126 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0s (custom)
2024-03-23 11:37:02,126 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-03-23 11:37:02,126 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:37:02,126 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-03-23 11:37:02,126 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-03-23 11:37:02,126 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-03-23 11:37:02,126 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:37:02,126 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-23 11:37:02,127 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-03-23 11:37:02,127 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:37:02,127 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2024-03-23 11:37:02,127 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0s (custom)
2024-03-23 11:37:02,128 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-03-23 11:37:02,128 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:37:02,128 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-03-23 11:37:02,128 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-03-23 11:37:02,128 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-03-23 11:37:02,128 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:37:02,128 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-23 11:37:02,128 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 5b4c27d6-a533-4766-a648-a869ad76920c: start 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderStateImpl
2024-03-23 11:37:02,128 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC: set firstElectionSinceStartup to false for becomeLeader
2024-03-23 11:37:02,128 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-ADC18A360ADC with new leaderId: 5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:37:02,129 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC: change Leader from null to 5b4c27d6-a533-4766-a648-a869ad76920c at term 1 for becomeLeader, leader elected after 5148ms
2024-03-23 11:37:02,129 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-23 11:37:02,129 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-23 11:37:02,130 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc reported by 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5)
2024-03-23 11:37:02,131 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc
2024-03-23 11:37:02,138 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderElection14] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC: set configuration 0: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:37:02,138 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc/current/log_inprogress_0
2024-03-23 11:37:02,145 [e3882025-ee77-4273-a30c-caf156427e83-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-ADC18A360ADC with new leaderId: 5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:37:02,145 [e3882025-ee77-4273-a30c-caf156427e83-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC: change Leader from null to 5b4c27d6-a533-4766-a648-a869ad76920c at term 1 for appendEntries, leader elected after 5140ms
2024-03-23 11:37:02,149 [00b25173-7757-4760-98a7-1e1aa18d5e2d-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-ADC18A360ADC with new leaderId: 5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:37:02,149 [00b25173-7757-4760-98a7-1e1aa18d5e2d-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC: change Leader from null to 5b4c27d6-a533-4766-a648-a869ad76920c at term 1 for appendEntries, leader elected after 5112ms
2024-03-23 11:37:02,153 [e3882025-ee77-4273-a30c-caf156427e83-server-thread3] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC: set configuration 0: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:37:02,153 [e3882025-ee77-4273-a30c-caf156427e83-server-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-23 11:37:02,159 [00b25173-7757-4760-98a7-1e1aa18d5e2d-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC: set configuration 0: peers:[00b25173-7757-4760-98a7-1e1aa18d5e2d|10.1.0.5:15034, 5b4c27d6-a533-4766-a648-a869ad76920c|10.1.0.5:15025, e3882025-ee77-4273-a30c-caf156427e83|10.1.0.5:15016]|listeners:[], old=null
2024-03-23 11:37:02,159 [e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-23 11:37:02,159 [00b25173-7757-4760-98a7-1e1aa18d5e2d-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-23 11:37:02,160 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-23 11:37:02,171 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc/current/log_inprogress_0
2024-03-23 11:37:02,171 [e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc/current/log_inprogress_0
2024-03-23 11:37:02,173 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-23 11:37:02,340 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:37:02,342 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:37:02,342 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:02,342 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:02,342 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:02,342 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:02,342 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:02,342 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:02,342 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:02,408 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:02,408 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:02,408 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:02,410 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:02,410 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:03,083 [Recon-SyncSCMContainerInfo-0] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:syncWithSCMContainerInfo(557)) - Got list of containers from SCM : 1
2024-03-23 11:37:03,098 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:37:03,122 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:03,343 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:37:03,345 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:37:03,345 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:03,345 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:03,345 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:03,345 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:03,345 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:03,345 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:03,346 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:03,411 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:03,411 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:03,411 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:03,413 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:03,413 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:04,099 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:37:04,122 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:04,132 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:37:04,132 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:37:04,346 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:37:04,348 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:37:04,348 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:04,349 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:04,349 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:04,349 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:04,349 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:04,349 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:04,349 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:04,414 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:04,414 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:04,415 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:04,416 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:04,416 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:05,099 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:37:05,123 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:05,350 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-23 11:37:05,351 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:37:05,352 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:05,352 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:05,352 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:05,352 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:05,352 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:05,352 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:05,352 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:05,417 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:05,417 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:05,417 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:05,419 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:05,419 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:06,099 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:37:06,123 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:06,353 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-23 11:37:06,355 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:37:06,355 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:06,355 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:06,355 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:06,355 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:06,355 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:06,355 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:06,355 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:06,420 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:06,421 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:06,421 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:06,422 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:06,422 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:07,100 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:37:07,123 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:07,356 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-23 11:37:07,358 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:37:07,358 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:07,358 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:07,358 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:07,358 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:07,358 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:07,358 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:07,358 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:07,424 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:07,424 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:07,424 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:07,425 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:07,426 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:08,100 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:37:08,124 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:08,359 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:37:08,361 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:37:08,361 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:08,361 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:08,361 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:08,361 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:08,361 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:08,361 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:08,361 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:08,427 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:08,427 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:08,427 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:08,429 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:08,429 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:09,101 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:37:09,124 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:09,362 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:37:09,364 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:37:09,364 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:09,364 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:09,364 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:09,364 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:09,364 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:09,364 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:09,364 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:09,431 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:09,431 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:09,431 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:09,432 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:09,432 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:10,102 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:37:10,124 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:10,365 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:37:10,367 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:37:10,367 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:10,367 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:10,367 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:10,367 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:10,367 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:10,367 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:10,367 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:10,433 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:10,434 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:10,434 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:10,435 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:10,435 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:11,043 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:37:11,044 [FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:37:11,102 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:37:11,125 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:11,368 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:37:11,370 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:37:11,371 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:11,371 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:11,371 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:11,371 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:11,371 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:11,371 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:11,371 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:11,437 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:11,437 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:11,437 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:11,438 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:11,438 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:12,103 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:37:12,125 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:12,372 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:37:12,374 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:37:12,374 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:12,374 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:12,374 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:12,374 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:12,374 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:12,374 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:12,375 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:12,439 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:12,440 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:12,440 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:12,441 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:12,441 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:13,103 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:37:13,125 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:13,375 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-23 11:37:13,377 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:37:13,378 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:13,378 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:13,378 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:13,378 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:13,378 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:13,378 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:13,378 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:13,443 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:13,443 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:13,443 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:13,444 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:13,444 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:14,103 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:37:14,128 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:14,135 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:37:14,136 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:37:14,152 [ContainerSizeCountTask] INFO  tasks.ContainerSizeCountTask (ContainerSizeCountTask.java:run(101)) - Deleted 0 records from "CONTAINER_COUNT_BY_SIZE"
2024-03-23 11:37:14,162 [ContainerSizeCountTask] INFO  tasks.ContainerSizeCountTask (ContainerSizeCountTask.java:process(200)) - Completed a 'process' run of ContainerSizeCountTask.
2024-03-23 11:37:14,162 [ContainerSizeCountTask] INFO  tasks.ContainerSizeCountTask (ContainerSizeCountTask.java:run(114)) - Elapsed Time in milliseconds for Process() execution: 10
2024-03-23 11:37:14,379 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-23 11:37:14,381 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:37:14,381 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:14,381 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:14,381 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:14,381 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:14,381 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:14,382 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:14,382 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:14,446 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:14,446 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:14,446 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:14,447 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:14,447 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:15,104 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:37:15,129 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:15,382 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:37:15,385 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:37:15,385 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:15,385 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:15,385 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:15,385 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:15,385 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:15,385 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:15,385 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:15,450 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:15,450 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:15,450 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:15,452 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:15,452 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:16,104 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:37:16,129 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:16,386 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:37:16,388 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:37:16,388 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:16,388 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:16,388 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:16,388 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:16,388 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:16,388 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:16,388 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:16,453 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:16,453 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:16,453 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:16,455 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:16,455 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:16,817 [e3882025-ee77-4273-a30c-caf156427e83-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-03-23 11:37:16,888 [5b4c27d6-a533-4766-a648-a869ad76920c-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-03-23 11:37:17,000 [00b25173-7757-4760-98a7-1e1aa18d5e2d-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-03-23 11:37:17,105 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:37:17,130 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:17,150 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-03-23 11:37:17,238 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-03-23 11:37:17,389 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-23 11:37:17,390 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:37:17,391 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:17,391 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:17,391 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:17,391 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:17,391 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:17,391 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:17,391 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:17,456 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:17,456 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:17,456 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:17,458 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:17,458 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:18,105 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:37:18,130 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:18,392 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-23 11:37:18,394 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:37:18,394 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:18,394 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:18,394 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:18,394 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:18,394 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:18,394 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:18,394 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:18,459 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:18,459 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:18,459 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:18,460 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:18,460 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:19,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:37:19,130 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:19,395 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-23 11:37:19,397 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:37:19,397 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:19,397 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:19,397 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:19,397 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:19,397 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:19,397 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:19,397 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:19,462 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:19,462 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:19,462 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:19,463 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:19,463 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:20,106 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:37:20,131 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:20,398 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:37:20,400 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:37:20,400 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:20,400 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:20,400 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:20,400 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:20,400 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:20,401 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:20,401 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:20,464 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:20,464 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:20,464 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:20,466 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:20,466 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:21,107 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:37:21,131 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:21,401 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:37:21,403 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:37:21,403 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:21,403 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:21,403 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:21,403 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:21,404 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:21,404 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:21,404 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:21,467 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:21,467 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:21,467 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:21,469 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:21,469 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:22,107 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:37:22,131 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:22,404 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:37:22,406 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:37:22,406 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:22,406 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:22,406 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:22,407 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:22,407 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:22,407 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:22,407 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:22,470 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:22,470 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:22,470 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:22,472 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:22,472 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:23,108 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:37:23,132 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:23,407 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:37:23,410 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:37:23,410 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:23,410 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:23,410 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:23,410 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:23,410 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:23,410 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:23,410 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:23,473 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:23,473 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:23,473 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:23,475 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:23,475 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:24,108 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:37:24,132 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:24,411 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:37:24,413 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:37:24,413 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:24,413 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:24,413 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:24,413 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:24,413 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:24,413 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:24,413 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:24,476 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:24,476 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:24,476 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:24,478 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:24,478 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:25,109 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-23 11:37:25,133 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
2024-03-23 11:37:25,414 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:37:25,417 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-23 11:37:25,417 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:25,417 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:25,417 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:25,417 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:25,417 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:25,417 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:25,418 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:25,479 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:25,480 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:25,480 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:25,481 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:25,481 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:26,109 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-23 11:37:26,133 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [00b25173-7757-4760-98a7-1e1aa18d5e2d, 5b4c27d6-a533-4766-a648-a869ad76920c, e3882025-ee77-4273-a30c-caf156427e83]
====> [2] DECOMMISSIONING, DECOMMISSIONED, false TIMED OUT. PRINTING THREAD DUMP. <====

Timestamp: 2024-03-23 11:37:26,211

"IPC Server handler 78 on default port 15009" daemon prio=5 tid=549 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SCMHeartbeatProcessor-0" daemon prio=5 tid=442 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5b4c27d6-a533-4766-a648-a869ad76920c-BlockDeletingService#2" daemon prio=5 tid=1218 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 47 on default port 15009" daemon prio=5 tid=518 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 60 on default port 15000" daemon prio=5 tid=113 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=652 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 23 on default port 15009" daemon prio=5 tid=494 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 9 on default port 15002" daemon prio=5 tid=262 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 47 on default port 15002" daemon prio=5 tid=300 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1521342613-409" daemon prio=5 tid=409 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"5b4c27d6-a533-4766-a648-a869ad76920c-BlockDeletingService#1" daemon prio=5 tid=759 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=623 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"IPC Server handler 85 on default port 15002" daemon prio=5 tid=338 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=680 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 15000" daemon prio=5 tid=60 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 31 on default port 15000" daemon prio=5 tid=84 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=651 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"IPC Server handler 28 on default port 15000" daemon prio=5 tid=81 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 52 on default port 15009" daemon prio=5 tid=523 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 99 on default port 15000" daemon prio=5 tid=152 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-ChunkWriter-2-0" daemon prio=5 tid=810 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 24 on default port 15000" daemon prio=5 tid=77 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server idle connection scanner for port 15000" daemon prio=5 tid=39 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Socket Reader #1 for port 15002"  prio=5 tid=28 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 1 on default port 15000" daemon prio=5 tid=54 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-worker-ELG-3-1" daemon prio=5 tid=851 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:312)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:376)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"e3882025-ee77-4273-a30c-caf156427e83-server-thread2" daemon prio=5 tid=1213 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp941659818-617" daemon prio=5 tid=617 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 84 on default port 15002" daemon prio=5 tid=337 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler" daemon prio=5 tid=1053 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-BlockDeletingService#0" daemon prio=5 tid=776 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 15002" daemon prio=5 tid=264 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=624 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1521342613-405" daemon prio=5 tid=405 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 15001" daemon prio=5 tid=167 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 62 on default port 15002" daemon prio=5 tid=315 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 5 on default port 15001" daemon prio=5 tid=158 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 56 on default port 15009" daemon prio=5 tid=527 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"timer6" daemon prio=5 tid=949 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 48 on default port 15000" daemon prio=5 tid=101 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Reference Handler" daemon prio=10 tid=2 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
        at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
"IPC Server handler 88 on default port 15002" daemon prio=5 tid=341 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-BlockDeletingService#2" daemon prio=5 tid=1222 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"client-write-TID-0"  prio=5 tid=958 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5b4c27d6-a533-4766-a648-a869ad76920c-DatanodeReportManager-4" daemon prio=5 tid=631 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-ChunkWriter-2-0" daemon prio=5 tid=791 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-SegmentedRaftLogWorker"  prio=5 tid=388 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$917/424912382.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 33 on default port 15002" daemon prio=5 tid=286 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PeriodicHDDSVolumeChecker" daemon prio=5 tid=784 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 70 on default port 15009" daemon prio=5 tid=541 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=708 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 90 on default port 15002" daemon prio=5 tid=343 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"e3882025-ee77-4273-a30c-caf156427e83-DatanodeStateMachineDaemonThread" daemon prio=5 tid=598 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:369)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:556)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1386/959870495.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 15009" daemon prio=5 tid=488 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 43 on default port 15002" daemon prio=5 tid=296 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 28 on default port 15002" daemon prio=5 tid=281 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 79 on default port 15000" daemon prio=5 tid=132 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"JvmPauseMonitor7" daemon prio=5 tid=812 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$554/718511919.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 59 on default port 15001" daemon prio=5 tid=212 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 35 on default port 15009" daemon prio=5 tid=506 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1609314701-464" daemon prio=5 tid=464 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.reservedWait(ReservedThreadExecutor.java:324)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:399)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"e3882025-ee77-4273-a30c-caf156427e83-ChunkReader-ELG-0" daemon prio=5 tid=736 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 29 on default port 15000" daemon prio=5 tid=82 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 81 on default port 15001" daemon prio=5 tid=234 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 22 on default port 15001" daemon prio=5 tid=175 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 11 on default port 15009" daemon prio=5 tid=482 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server listener on 15021" daemon prio=5 tid=620 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 92 on default port 15009" daemon prio=5 tid=563 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/data-0/hdds)" daemon prio=5 tid=807 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server handler 54 on default port 15001" daemon prio=5 tid=207 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp670342028-646" daemon prio=5 tid=646 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 15009" daemon prio=5 tid=489 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"e3882025-ee77-4273-a30c-caf156427e83-CloseContainerThread-1"  prio=5 tid=1068 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Timer-0"  prio=5 tid=393 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 12 on default port 15004" daemon prio=5 tid=426 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 43 on default port 15001" daemon prio=5 tid=196 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 27 on default port 15009" daemon prio=5 tid=498 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=47 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Signal Dispatcher" daemon prio=9 tid=4 runnable
java.lang.Thread.State: RUNNABLE
"IPC Server handler 94 on default port 15001" daemon prio=5 tid=247 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=454 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5b4c27d6-a533-4766-a648-a869ad76920c-CommandProcessorThread" daemon prio=5 tid=632 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:684)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1388/1074834806.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 70 on default port 15000" daemon prio=5 tid=123 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp941659818-616" daemon prio=5 tid=616 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderStateImpl" daemon prio=5 tid=1178 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:762)
"IPC Server handler 70 on default port 15002" daemon prio=5 tid=323 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 10 on default port 15002" daemon prio=5 tid=263 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server listener on 15004" daemon prio=5 tid=381 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 87 on default port 15002" daemon prio=5 tid=340 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 32 on default port 15000" daemon prio=5 tid=85 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=30 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"5b4c27d6-a533-4766-a648-a869ad76920c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=742 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 81 on default port 15002" daemon prio=5 tid=334 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1609314701-459" daemon prio=5 tid=459 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"5b4c27d6-a533-4766-a648-a869ad76920c-PeriodicHDDSVolumeChecker" daemon prio=5 tid=745 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 34 on default port 15002" daemon prio=5 tid=287 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 97 on default port 15009" daemon prio=5 tid=568 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 61 on default port 15009" daemon prio=5 tid=532 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Timer-1" daemon prio=5 tid=435 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 46 on default port 15009" daemon prio=5 tid=517 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=738 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 46 on default port 15002" daemon prio=5 tid=299 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 96 on default port 15000" daemon prio=5 tid=149 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 2 on default port 15000" daemon prio=5 tid=55 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-34-thread-1"  prio=5 tid=356 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-StateMachineUpdater" daemon prio=5 tid=1184 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 15048"  prio=5 tid=705 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 21 on default port 15001" daemon prio=5 tid=174 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-DatanodeStateMachineTaskThread-1"  prio=5 tid=780 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 66 on default port 15001" daemon prio=5 tid=219 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 51 on default port 15009" daemon prio=5 tid=522 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 36 on default port 15002" daemon prio=5 tid=289 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1727814855-673" daemon prio=5 tid=673 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=385 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 15002" daemon prio=5 tid=255 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerMetadataScanner" daemon prio=5 tid=806 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server handler 14 on default port 15004" daemon prio=5 tid=428 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 90 on default port 15009" daemon prio=5 tid=561 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 16 on default port 15009" daemon prio=5 tid=487 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"process reaper" daemon prio=10 tid=13 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-BlockDeletingService#0" daemon prio=5 tid=814 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 63 on default port 15002" daemon prio=5 tid=316 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-EventQueue-StaleNodeForReconStaleNodeHandler" daemon prio=5 tid=844 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 74 on default port 15009" daemon prio=5 tid=545 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 29 on default port 15001" daemon prio=5 tid=182 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-cacheEviction-AwaitToRun" daemon prio=5 tid=1181 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 31 on default port 15002" daemon prio=5 tid=284 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp670342028-641-acceptor-0@335f365b-ServerConnector@714a1a49{HTTP/1.1, (http/1.1)}{0.0.0.0:15029}" daemon prio=3 tid=641 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-ChunkWriter-0-0" daemon prio=5 tid=770 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 79 on default port 15009" daemon prio=5 tid=550 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-ChunkWriter-0-0" daemon prio=5 tid=808 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 53 on default port 15000" daemon prio=5 tid=106 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 66 on default port 15000" daemon prio=5 tid=119 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 21 on default port 15009" daemon prio=5 tid=492 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-DatanodeReportManager-0" daemon prio=5 tid=683 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"e3882025-ee77-4273-a30c-caf156427e83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=719 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 80 on default port 15000" daemon prio=5 tid=133 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 12 on default port 15009" daemon prio=5 tid=483 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-PeriodicHDDSVolumeChecker" daemon prio=5 tid=764 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 15001" daemon prio=5 tid=169 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server listener on 15030" daemon prio=5 tid=648 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 30 on default port 15000" daemon prio=5 tid=83 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Parameter Sending Thread for localhost/127.0.0.1:15004" daemon prio=5 tid=967 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferQueue.awaitFulfill(SynchronousQueue.java:764)
        at java.util.concurrent.SynchronousQueue$TransferQueue.transfer(SynchronousQueue.java:695)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1105)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 62 on default port 15009" daemon prio=5 tid=533 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1521342613-408" daemon prio=5 tid=408 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 15001" daemon prio=5 tid=160 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 40 on default port 15001" daemon prio=5 tid=193 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 17 on default port 15004" daemon prio=5 tid=431 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 80 on default port 15009" daemon prio=5 tid=551 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-SegmentedRaftLogWorker"  prio=5 tid=1193 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$917/424912382.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"e3882025-ee77-4273-a30c-caf156427e83-BlockDeletingService#1" daemon prio=5 tid=740 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 45 on default port 15000" daemon prio=5 tid=98 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"BackgroundPipelineScrubber" daemon prio=5 tid=20 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:107)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$489/464583224.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-PipelineCommandHandlerThread-0"  prio=5 tid=859 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 83 on default port 15000" daemon prio=5 tid=136 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SSL Certificates Store Monitor" daemon prio=5 tid=441 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 80 on default port 15001" daemon prio=5 tid=233 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 14 on default port 15000" daemon prio=5 tid=67 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 84 on default port 15009" daemon prio=5 tid=555 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-DatanodeStateMachineTaskThread-0"  prio=5 tid=661 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"e3882025-ee77-4273-a30c-caf156427e83-DatanodeStateMachineTaskThread-0"  prio=5 tid=605 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ReconTaskThread-0"  prio=5 tid=1042 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 15048" daemon prio=5 tid=704 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"qtp1727814855-668" daemon prio=5 tid=668 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp149384698-588" daemon prio=5 tid=588 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-0" daemon prio=5 tid=855 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 15000" daemon prio=5 tid=66 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-ChunkReader-ELG-0" daemon prio=5 tid=813 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 15002" daemon prio=5 tid=270 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 5 on default port 15000" daemon prio=5 tid=58 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 90 on default port 15001" daemon prio=5 tid=243 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-StateMachineUpdater" daemon prio=5 tid=1154 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 49 on default port 15001" daemon prio=5 tid=202 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 40 on default port 15009" daemon prio=5 tid=511 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 67 on default port 15000" daemon prio=5 tid=120 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"junit-jupiter-timeout-watcher"  prio=10 tid=1045 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 15009" daemon prio=5 tid=473 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-cacheEviction-AwaitToRun" daemon prio=5 tid=887 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.lang.Thread.run(Thread.java:750)
"surefire-forkedjvm-ping-30s" daemon prio=5 tid=11 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 44 on default port 15000" daemon prio=5 tid=97 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server listener on 15000" daemon prio=5 tid=37 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"pool-33-thread-1"  prio=5 tid=1055 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"CompactionDagPruningService" daemon prio=5 tid=371 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"e3882025-ee77-4273-a30c-caf156427e83-BlockDeletingService#0" daemon prio=5 tid=737 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SCMBlockDeletingService#0" daemon prio=5 tid=353 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 71 on default port 15002" daemon prio=5 tid=324 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 11 on default port 15001" daemon prio=5 tid=164 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 98 on default port 15002" daemon prio=5 tid=351 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1609314701-462" daemon prio=5 tid=462 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler" daemon prio=5 tid=1048 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-SnapshotDirectoryCleaningService#0" daemon prio=5 tid=402 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 52 on default port 15002" daemon prio=5 tid=305 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderStateImpl" daemon prio=5 tid=1176 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:762)
"Recon-FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=450 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 15002" daemon prio=5 tid=265 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp910839493-699" daemon prio=5 tid=699 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-DatanodeStateMachineDaemonThread" daemon prio=5 tid=654 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:369)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:556)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1386/959870495.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"DatanodeAdminManager-0" daemon prio=5 tid=25 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp149384698-583" daemon prio=5 tid=583 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 50 on default port 15002" daemon prio=5 tid=303 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-executor-3" daemon prio=5 tid=924 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 33 on default port 15000" daemon prio=5 tid=86 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 44 on default port 15009" daemon prio=5 tid=515 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 18 on default port 15000" daemon prio=5 tid=71 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-groupManagement"  prio=5 tid=871 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 60 on default port 15001" daemon prio=5 tid=213 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 54 on default port 15009" daemon prio=5 tid=525 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"e3882025-ee77-4273-a30c-caf156427e83-DatanodeReportManager-4" daemon prio=5 tid=603 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-MultipartUploadCleanupService#0" daemon prio=5 tid=403 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-ChunkReader-ELG-0" daemon prio=5 tid=775 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 15001" daemon prio=5 tid=163 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp910839493-700" daemon prio=5 tid=700 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 57 on default port 15002" daemon prio=5 tid=310 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 62 on default port 15000" daemon prio=5 tid=115 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server listener on 15039" daemon prio=5 tid=676 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 38 on default port 15001" daemon prio=5 tid=191 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 91 on default port 15001" daemon prio=5 tid=244 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 34 on default port 15000" daemon prio=5 tid=87 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-SegmentedRaftLogWorker"  prio=5 tid=1156 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$917/424912382.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-SegmentedRaftLogWorker"  prio=5 tid=1152 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$917/424912382.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-DatanodeReportManager-1" daemon prio=5 tid=656 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 69 on default port 15000" daemon prio=5 tid=122 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-FollowerState" daemon prio=5 tid=1204 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"IPC Server handler 88 on default port 15009" daemon prio=5 tid=559 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 55 on default port 15000" daemon prio=5 tid=108 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-EventQueue-PipelineReportForReconPipelineReportHandler" daemon prio=5 tid=820 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 22 on default port 15002" daemon prio=5 tid=275 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 77 on default port 15009" daemon prio=5 tid=548 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 83 on default port 15001" daemon prio=5 tid=236 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 57 on default port 15009" daemon prio=5 tid=528 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 26 on default port 15000" daemon prio=5 tid=79 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-DatanodeReportManager-3" daemon prio=5 tid=686 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-177-thread-1" daemon prio=5 tid=786 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 15009" daemon prio=5 tid=472 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"e3882025-ee77-4273-a30c-caf156427e83-CloseContainerThread-2"  prio=5 tid=1069 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 98 on default port 15001" daemon prio=5 tid=251 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 2 on default port 15001" daemon prio=5 tid=155 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SSL Certificates Store Monitor" daemon prio=5 tid=440 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1223 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Connector-Scheduler-5418be12-1"  prio=5 tid=968 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Recon-FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=452 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 15001" daemon prio=5 tid=154 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"main"  prio=5 tid=1 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.Thread.dumpThreads(Native Method)
        at java.lang.Thread.getAllStackTraces(Thread.java:1615)
        at org.apache.ozone.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:83)
        at org.apache.ozone.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:69)
        at org.apache.ozone.test.TimedOutTestsListener.lambda$executionFinished$0(TimedOutTestsListener.java:55)
        at org.apache.ozone.test.TimedOutTestsListener$$Lambda$2396/2033072788.accept(Unknown Source)
        at java.util.Optional.ifPresent(Optional.java:159)
        at org.apache.ozone.test.TimedOutTestsListener.executionFinished(TimedOutTestsListener.java:51)
        at org.junit.platform.launcher.core.CompositeTestExecutionListener.lambda$executionFinished$10(CompositeTestExecutionListener.java:73)
        at org.junit.platform.launcher.core.CompositeTestExecutionListener$$Lambda$2363/187911388.accept(Unknown Source)
        at org.junit.platform.launcher.core.CompositeTestExecutionListener.lambda$notifyEach$19(CompositeTestExecutionListener.java:102)
        at org.junit.platform.launcher.core.CompositeTestExecutionListener$$Lambda$247/1687087217.accept(Unknown Source)
        at org.junit.platform.commons.util.CollectionUtils.forEachInReverseOrder(CollectionUtils.java:221)
        at org.junit.platform.launcher.core.IterationOrder$2.forEach(IterationOrder.java:30)
        at org.junit.platform.launcher.core.CompositeTestExecutionListener.notifyEach(CompositeTestExecutionListener.java:100)
        at org.junit.platform.launcher.core.CompositeTestExecutionListener.executionFinished(CompositeTestExecutionListener.java:72)
        at org.junit.platform.launcher.core.ExecutionListenerAdapter.executionFinished(ExecutionListenerAdapter.java:56)
        at org.junit.platform.launcher.core.CompositeEngineExecutionListener.lambda$executionFinished$6(CompositeEngineExecutionListener.java:59)
        at org.junit.platform.launcher.core.CompositeEngineExecutionListener$$Lambda$2354/21266003.accept(Unknown Source)
        at org.junit.platform.launcher.core.CompositeEngineExecutionListener.lambda$notifyEach$11(CompositeEngineExecutionListener.java:74)
        at org.junit.platform.launcher.core.CompositeEngineExecutionListener$$Lambda$296/61814127.accept(Unknown Source)
        at org.junit.platform.commons.util.CollectionUtils.forEachInReverseOrder(CollectionUtils.java:221)
        at org.junit.platform.launcher.core.IterationOrder$2.forEach(IterationOrder.java:30)
        at org.junit.platform.launcher.core.CompositeEngineExecutionListener.notifyEach(CompositeEngineExecutionListener.java:72)
        at org.junit.platform.launcher.core.CompositeEngineExecutionListener.executionFinished(CompositeEngineExecutionListener.java:58)
        at org.junit.platform.launcher.core.DelegatingEngineExecutionListener.executionFinished(DelegatingEngineExecutionListener.java:46)
        at org.junit.platform.launcher.core.StackTracePruningEngineExecutionListener.executionFinished(StackTracePruningEngineExecutionListener.java:46)
        at org.junit.platform.launcher.core.DelegatingEngineExecutionListener.executionFinished(DelegatingEngineExecutionListener.java:46)
        at org.junit.platform.launcher.core.OutcomeDelayingEngineExecutionListener.executionFinished(OutcomeDelayingEngineExecutionListener.java:63)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.reportCompletion(NodeTestTask.java:195)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:226)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:204)
        at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:142)
        at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.lambda$execute$2(TestTemplateTestDescriptor.java:110)
        at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor$$Lambda$2083/567691585.accept(Unknown Source)
        at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)
        at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:647)
        at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:272)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)
        at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
        at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
        at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
        at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
        at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
        at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
        at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:272)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384)
        at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
        at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
        at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
        at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
        at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
        at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
        at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:272)
        at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384)
        at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
        at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
        at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
        at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
        at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
        at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
        at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:110)
        at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:44)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$317/2054077982.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$316/1098737173.invoke(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$315/1476061571.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService$$Lambda$321/1220813917.accept(Unknown Source)
        at java.util.ArrayList.forEach(ArrayList.java:1259)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$317/2054077982.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$316/1098737173.invoke(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$315/1476061571.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService$$Lambda$321/1220813917.accept(Unknown Source)
        at java.util.ArrayList.forEach(ArrayList.java:1259)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$317/2054077982.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$316/1098737173.invoke(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$315/1476061571.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
        at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
        at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:198)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:169)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:93)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:58)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator$$Lambda$235/1720746883.accept(Unknown Source)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:141)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:57)
        at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:103)
        at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:85)
        at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
        at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:63)
        at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
        at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
        at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
        at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
"IPC Server handler 3 on default port 15004" daemon prio=5 tid=417 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-StateMachineUpdater" daemon prio=5 tid=1188 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 64 on default port 15001" daemon prio=5 tid=217 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp439694398-360" daemon prio=5 tid=360 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 59 on default port 15002" daemon prio=5 tid=312 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-BlockDeletingService#1" daemon prio=5 tid=798 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 15000" daemon prio=5 tid=57 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 75 on default port 15002" daemon prio=5 tid=328 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 51 on default port 15001" daemon prio=5 tid=204 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-BlockDeletingService#1" daemon prio=5 tid=817 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 96 on default port 15001" daemon prio=5 tid=249 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 24 on default port 15001" daemon prio=5 tid=177 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=762 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 52 on default port 15001" daemon prio=5 tid=205 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 20 on default port 15001" daemon prio=5 tid=173 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"derby.rawStoreDaemon" daemon prio=5 tid=436 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.derby.impl.services.daemon.BasicDaemon.rest(Unknown Source)
        at org.apache.derby.impl.services.daemon.BasicDaemon.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 55 on default port 15001" daemon prio=5 tid=208 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 79 on default port 15001" daemon prio=5 tid=232 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 23 on default port 15001" daemon prio=5 tid=176 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 80 on default port 15002" daemon prio=5 tid=333 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 29 on default port 15009" daemon prio=5 tid=500 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 49 on default port 15009" daemon prio=5 tid=520 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Finalizer" daemon prio=8 tid=3 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:188)
"00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-cacheEviction-AwaitToRun" daemon prio=5 tid=1192 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=51 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"e3882025-ee77-4273-a30c-caf156427e83-CloseContainerThread-0"  prio=5 tid=1056 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 15000" daemon prio=5 tid=68 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"timer5" daemon prio=5 tid=946 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 70 on default port 15001" daemon prio=5 tid=223 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 50 on default port 15001" daemon prio=5 tid=203 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 45 on default port 15001" daemon prio=5 tid=198 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 69 on default port 15002" daemon prio=5 tid=322 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 13 on default port 15004" daemon prio=5 tid=427 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=44 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Recon-SyncSCMContainerInfo-0"  prio=5 tid=470 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 15001" daemon prio=5 tid=156 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15012" daemon prio=5 tid=597 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp149384698-584" daemon prio=5 tid=584 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 73 on default port 15001" daemon prio=5 tid=226 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 8 on default port 15004" daemon prio=5 tid=422 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1-groupManagement"  prio=5 tid=376 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Recon-SyncOM-1"  prio=5 tid=965 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 15009" daemon prio=5 tid=474 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 1 on default port 15004" daemon prio=5 tid=415 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15012"  prio=5 tid=593 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"qtp439694398-358" daemon prio=5 tid=358 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-worker-ELG-3-3" daemon prio=5 tid=857 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:312)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:376)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"qtp1521342613-407-acceptor-0@16c9e501-ServerConnector@5418be12{HTTP/1.1, (http/1.1)}{0.0.0.0:15005}" daemon prio=3 tid=407 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1219 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 15002" daemon prio=5 tid=253 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-DatanodeReportManager-0" daemon prio=5 tid=655 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 86 on default port 15001" daemon prio=5 tid=239 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"5b4c27d6-a533-4766-a648-a869ad76920c-DatanodeStateMachineTaskThread-1"  prio=5 tid=741 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5b4c27d6-a533-4766-a648-a869ad76920c-ChunkWriter-1-0" daemon prio=5 tid=751 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 24 on default port 15002" daemon prio=5 tid=277 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 39 on default port 15009" daemon prio=5 tid=510 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 76 on default port 15000" daemon prio=5 tid=129 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 13 on default port 15002" daemon prio=5 tid=266 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"JvmPauseMonitor6" daemon prio=5 tid=793 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$554/718511919.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 93 on default port 15001" daemon prio=5 tid=246 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 26 on default port 15009" daemon prio=5 tid=497 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 99 on default port 15009" daemon prio=5 tid=570 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 25 on default port 15009" daemon prio=5 tid=496 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerSizeCountTask" daemon prio=5 tid=575 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ozone.recon.tasks.ContainerSizeCountTask.run(ContainerSizeCountTask.java:94)
        at org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda$1299/1791718028.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp149384698-587" daemon prio=5 tid=587 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForPipelineReportHandler" daemon prio=5 tid=824 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"e3882025-ee77-4273-a30c-caf156427e83-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=720 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-StateMachineUpdater" daemon prio=5 tid=1158 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.lang.Thread.run(Thread.java:750)
"pool-116-thread-1"  prio=5 tid=582 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=800 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 15002" daemon prio=5 tid=27 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 5 on default port 15009" daemon prio=5 tid=476 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"e3882025-ee77-4273-a30c-caf156427e83-CommandProcessorThread" daemon prio=5 tid=604 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:684)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1388/1074834806.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 25 on default port 15001" daemon prio=5 tid=178 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"timer3" daemon prio=5 tid=925 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 75 on default port 15001" daemon prio=5 tid=228 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 38 on default port 15009" daemon prio=5 tid=509 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-executor-5" daemon prio=5 tid=1080 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5b4c27d6-a533-4766-a648-a869ad76920c-DatanodeReportManager-0" daemon prio=5 tid=627 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 52 on default port 15000" daemon prio=5 tid=105 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"e3882025-ee77-4273-a30c-caf156427e83-server-thread3" daemon prio=5 tid=1211 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer1" daemon prio=5 tid=920 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=781 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 36 on default port 15000" daemon prio=5 tid=89 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 38 on default port 15002" daemon prio=5 tid=291 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1@group-C5BA1605619E-StateMachineUpdater" daemon prio=5 tid=390 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 30 on default port 15002" daemon prio=5 tid=283 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-CommandProcessorThread" daemon prio=5 tid=660 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:684)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1388/1074834806.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1727814855-672" daemon prio=5 tid=672 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 41 on default port 15001" daemon prio=5 tid=194 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-142-thread-1"  prio=5 tid=610 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 98 on default port 15009" daemon prio=5 tid=569 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 25 on default port 15002" daemon prio=5 tid=278 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 93 on default port 15002" daemon prio=5 tid=346 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"timer0" daemon prio=5 tid=951 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"pool-203-thread-1" daemon prio=5 tid=805 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 15000" daemon prio=5 tid=63 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-SegmentedRaftLogWorker"  prio=5 tid=1182 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$917/424912382.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-SnapshotDeletingService#0" daemon prio=5 tid=401 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule" daemon prio=5 tid=822 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 84 on default port 15001" daemon prio=5 tid=237 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 56 on default port 15000" daemon prio=5 tid=109 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 46 on default port 15000" daemon prio=5 tid=99 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15004"  prio=5 tid=382 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderStateImpl" daemon prio=5 tid=1206 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:762)
"IPC Server handler 27 on default port 15000" daemon prio=5 tid=80 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement"  prio=5 tid=877 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=596 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5b4c27d6-a533-4766-a648-a869ad76920c-DatanodeReportManager-1" daemon prio=5 tid=628 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1216 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-BlockDeletingService#0" daemon prio=5 tid=795 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-OMDoubleBufferFlushThread" daemon prio=5 tid=374 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.canFlush(OzoneManagerDoubleBuffer.java:570)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.flushTransactions(OzoneManagerDoubleBuffer.java:294)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer$$Lambda$707/1523123921.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 71 on default port 15001" daemon prio=5 tid=224 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"LeakDetector-ManagedRocksObject0" daemon prio=5 tid=17 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at org.apache.hadoop.hdds.utils.LeakDetector.run(LeakDetector.java:80)
        at org.apache.hadoop.hdds.utils.LeakDetector$$Lambda$436/731584462.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 15009" daemon prio=5 tid=481 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 93 on default port 15009" daemon prio=5 tid=564 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 32 on default port 15002" daemon prio=5 tid=285 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 54 on default port 15002" daemon prio=5 tid=307 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-ReplicationContainerReader-1" daemon prio=5 tid=1122 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 53 on default port 15001" daemon prio=5 tid=206 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"PartialTableCache-Cleanup-0" daemon prio=5 tid=960 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor5" daemon prio=5 tid=774 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$554/718511919.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 39 on default port 15000" daemon prio=5 tid=92 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=451 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 68 on default port 15001" daemon prio=5 tid=221 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"e3882025-ee77-4273-a30c-caf156427e83-DatanodeReportManager-0" daemon prio=5 tid=599 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 95 on default port 15009" daemon prio=5 tid=566 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 16 on default port 15002" daemon prio=5 tid=269 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=635 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-72f689bc-1"  prio=5 tid=466 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-220-thread-1"  prio=5 tid=694 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 39 on default port 15002" daemon prio=5 tid=292 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 26 on default port 15001" daemon prio=5 tid=179 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server listener on 15012" daemon prio=5 tid=592 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 20 on default port 15002" daemon prio=5 tid=273 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 78 on default port 15002" daemon prio=5 tid=331 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Timer for 'StorageContainerManager' metrics system" daemon prio=5 tid=52 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 28 on default port 15009" daemon prio=5 tid=499 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=761 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 20 on default port 15009" daemon prio=5 tid=491 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp439694398-361" daemon prio=5 tid=361 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"5b4c27d6-a533-4766-a648-a869ad76920c-ChunkReader-ELG-0" daemon prio=5 tid=755 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 51 on default port 15000" daemon prio=5 tid=104 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FullTableCache-Cleanup-0" daemon prio=5 tid=939 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 42 on default port 15000" daemon prio=5 tid=95 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"JvmPauseMonitor2" daemon prio=5 tid=576 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$554/718511919.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor3" daemon prio=5 tid=735 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$554/718511919.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@28b39bfc" daemon prio=5 tid=581 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.lang.Thread.run(Thread.java:750)
"e3882025-ee77-4273-a30c-caf156427e83-ChunkWriter-1-0" daemon prio=5 tid=732 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 86 on default port 15009" daemon prio=5 tid=557 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15039" daemon prio=5 tid=681 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@4ff2ad84" daemon prio=5 tid=637 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 15009" daemon prio=5 tid=443 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=797 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@dbc09f0" daemon prio=5 tid=665 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-CloseContainerForCloseContainerEventHandler" daemon prio=5 tid=1054 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 96 on default port 15002" daemon prio=5 tid=349 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Session-HouseKeeper-4d1c3ed5-1"  prio=5 tid=675 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 15048" daemon prio=5 tid=709 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 95 on default port 15002" daemon prio=5 tid=348 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp670342028-642" daemon prio=5 tid=642 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 55 on default port 15009" daemon prio=5 tid=526 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 95 on default port 15001" daemon prio=5 tid=248 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-DatanodeReportManager-4" daemon prio=5 tid=715 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 72 on default port 15002" daemon prio=5 tid=325 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 62 on default port 15001" daemon prio=5 tid=215 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"5b4c27d6-a533-4766-a648-a869ad76920c-ChunkWriter-0-0" daemon prio=5 tid=750 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 15009" daemon prio=5 tid=484 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 56 on default port 15002" daemon prio=5 tid=309 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/data-0/hdds)" daemon prio=5 tid=730 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"NetworkTopologyPoller" daemon prio=5 tid=396 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-DeleteContainerThread-0"  prio=5 tid=1159 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1609314701-461" daemon prio=5 tid=461 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-LeaderStateImpl" daemon prio=5 tid=438 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:762)
"IPC Server handler 41 on default port 15002" daemon prio=5 tid=294 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 58 on default port 15001" daemon prio=5 tid=211 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-executor-4" daemon prio=5 tid=1079 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 15004" daemon prio=5 tid=420 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 9 on default port 15001" daemon prio=5 tid=162 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 92 on default port 15000" daemon prio=5 tid=145 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=384 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"qtp910839493-697-acceptor-0@10535271-ServerConnector@3b3374ee{HTTP/1.1, (http/1.1)}{0.0.0.0:15047}" daemon prio=3 tid=697 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp1521342613-411" daemon prio=5 tid=411 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.reservedWait(ReservedThreadExecutor.java:324)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:399)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-DatanodeReportManager-2" daemon prio=5 tid=685 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-OMStateMachineApplyTransactionThread - 0" daemon prio=5 tid=938 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1609314701-465" daemon prio=5 tid=465 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 15030"  prio=5 tid=649 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"grpc-default-worker-ELG-3-2" daemon prio=5 tid=854 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:312)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:376)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 58 on default port 15002" daemon prio=5 tid=311 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 44 on default port 15002" daemon prio=5 tid=297 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 66 on default port 15002" daemon prio=5 tid=319 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 67 on default port 15002" daemon prio=5 tid=320 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-CommandProcessorThread" daemon prio=5 tid=716 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:684)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1388/1074834806.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 98 on default port 15000" daemon prio=5 tid=151 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15039"  prio=5 tid=677 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderStateImpl" daemon prio=5 tid=935 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:762)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-DatanodeReportManager-2" daemon prio=5 tid=713 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5b4c27d6-a533-4766-a648-a869ad76920c-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=743 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 15004" daemon prio=5 tid=421 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=758 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp910839493-702" daemon prio=5 tid=702 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 49 on default port 15000" daemon prio=5 tid=102 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-StateMachineUpdater" daemon prio=5 tid=890 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 74 on default port 15002" daemon prio=5 tid=327 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp439694398-363" daemon prio=5 tid=363 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 15001" daemon prio=5 tid=171 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15030" daemon prio=5 tid=653 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15009"  prio=5 tid=444 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 89 on default port 15001" daemon prio=5 tid=242 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/data-0/hdds)" daemon prio=5 tid=788 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=816 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-DatanodeReportManager-3" daemon prio=5 tid=714 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-DatanodeStateMachineTaskThread-1"  prio=5 tid=799 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 15001" daemon prio=5 tid=161 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 66 on default port 15009" daemon prio=5 tid=537 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 7 on default port 15009" daemon prio=5 tid=478 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 64 on default port 15002" daemon prio=5 tid=317 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-99-thread-1" daemon prio=5 tid=728 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Parameter Sending Thread for 0.0.0.0/0.0.0.0:15002" daemon prio=5 tid=722 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferQueue.awaitFulfill(SynchronousQueue.java:764)
        at java.util.concurrent.SynchronousQueue$TransferQueue.transfer(SynchronousQueue.java:695)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1105)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 82 on default port 15002" daemon prio=5 tid=335 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server idle connection scanner for port 15009" daemon prio=5 tid=445 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 61 on default port 15002" daemon prio=5 tid=314 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=35 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"qtp910839493-695" daemon prio=5 tid=695 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp1727814855-674" daemon prio=5 tid=674 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Recon-FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=457 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"e3882025-ee77-4273-a30c-caf156427e83-DatanodeReportManager-2" daemon prio=5 tid=601 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-worker-ELG-3-4" daemon prio=5 tid=858 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:312)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:376)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PipelineCommandHandlerThread-0"  prio=5 tid=876 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 39 on default port 15001" daemon prio=5 tid=192 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 59 on default port 15009" daemon prio=5 tid=530 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=782 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp941659818-612" daemon prio=5 tid=612 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-2b614ab0-1"  prio=5 tid=703 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor0" daemon prio=5 tid=355 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$554/718511919.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-PipelineCommandHandlerThread-0"  prio=5 tid=870 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 73 on default port 15000" daemon prio=5 tid=126 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp941659818-614" daemon prio=5 tid=614 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"e3882025-ee77-4273-a30c-caf156427e83-DatanodeReportManager-1" daemon prio=5 tid=600 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp439694398-359-acceptor-0@58d9a9c9-ServerConnector@bf70ce5{HTTP/1.1, (http/1.1)}{0.0.0.0:15003}" daemon prio=3 tid=359 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderStateImpl" daemon prio=5 tid=901 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:762)
"ContainerMetadataScanner" daemon prio=5 tid=729 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"5b4c27d6-a533-4766-a648-a869ad76920c-BlockDeletingService#0" daemon prio=5 tid=756 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 41 on default port 15009" daemon prio=5 tid=512 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-ChunkWriter-2-0" daemon prio=5 tid=772 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-2" daemon prio=5 tid=869 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 75 on default port 15000" daemon prio=5 tid=128 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-PeriodicHDDSVolumeChecker" daemon prio=5 tid=803 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 68 on default port 15000" daemon prio=5 tid=121 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 25 on default port 15000" daemon prio=5 tid=78 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 97 on default port 15001" daemon prio=5 tid=250 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15000" daemon prio=5 tid=53 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Client (1615502727) connection to 0.0.0.0/0.0.0.0:15009 from runner" daemon prio=5 tid=723 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1026)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1077)
"IPC Server handler 4 on default port 15009" daemon prio=5 tid=475 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"LeaseManager#LeaseMonitor" daemon prio=5 tid=354 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1037)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1328)
        at java.util.concurrent.Semaphore.tryAcquire(Semaphore.java:409)
        at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:285)
        at java.lang.Thread.run(Thread.java:750)
"5b4c27d6-a533-4766-a648-a869ad76920c-ChunkWriter-2-0" daemon prio=5 tid=752 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerHealthTask" daemon prio=5 tid=574 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.recon.fsck.ContainerHealthTask.run(ContainerHealthTask.java:111)
        at org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda$1299/1791718028.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Recon-EventQueue-NewNodeForReconNewNodeHandler" daemon prio=5 tid=819 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp941659818-611" daemon prio=5 tid=611 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"timer2" daemon prio=5 tid=922 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-groupManagement"  prio=5 tid=860 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 37 on default port 15000" daemon prio=5 tid=90 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp439694398-364" daemon prio=5 tid=364 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=595 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"JvmPauseMonitor4" daemon prio=5 tid=754 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$554/718511919.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 48 on default port 15001" daemon prio=5 tid=201 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp941659818-615" daemon prio=5 tid=615 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 92 on default port 15002" daemon prio=5 tid=345 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-server-thread1" daemon prio=5 tid=1210 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 97 on default port 15000" daemon prio=5 tid=150 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 46 on default port 15001" daemon prio=5 tid=199 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=796 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-194-thread-1"  prio=5 tid=666 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 36 on default port 15009" daemon prio=5 tid=507 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 71 on default port 15009" daemon prio=5 tid=542 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 67 on default port 15001" daemon prio=5 tid=220 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 4 on default port 15002" daemon prio=5 tid=257 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=42 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 34 on default port 15001" daemon prio=5 tid=187 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-cacheEviction-AwaitToRun" daemon prio=5 tid=1155 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.lang.Thread.run(Thread.java:750)
"e3882025-ee77-4273-a30c-caf156427e83-groupManagement"  prio=5 tid=832 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 15009" daemon prio=5 tid=471 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-DatanodeStateMachineTaskThread-0"  prio=5 tid=717 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 15009" daemon prio=5 tid=480 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server idle connection scanner for port 15048" daemon prio=5 tid=706 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=830 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 87 on default port 15001" daemon prio=5 tid=240 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 38 on default port 15000" daemon prio=5 tid=91 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-BlockDeletingService#1" daemon prio=5 tid=779 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 15000" daemon prio=5 tid=61 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 53 on default port 15002" daemon prio=5 tid=306 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 65 on default port 15000" daemon prio=5 tid=118 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-DatanodeStateMachineDaemonThread" daemon prio=5 tid=682 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:369)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:556)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1386/959870495.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 49 on default port 15002" daemon prio=5 tid=302 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=801 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 15001"  prio=5 tid=33 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"ContainerMetadataScanner" daemon prio=5 tid=748 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server Responder" daemon prio=5 tid=679 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@3ea0a810" daemon prio=5 tid=693 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.lang.Thread.run(Thread.java:750)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-DatanodeReportManager-3" daemon prio=5 tid=658 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 73 on default port 15009" daemon prio=5 tid=544 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 8 on default port 15009" daemon prio=5 tid=479 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp670342028-644" daemon prio=5 tid=644 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 76 on default port 15002" daemon prio=5 tid=329 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=49 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 78 on default port 15001" daemon prio=5 tid=231 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"prometheus" daemon prio=5 tid=366 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.hadoop.metrics2.impl.SinkQueue.waitForData(SinkQueue.java:114)
        at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:83)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:135)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:89)
"IPC Server handler 65 on default port 15009" daemon prio=5 tid=536 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/data-0/hdds)" daemon prio=5 tid=749 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server handler 35 on default port 15000" daemon prio=5 tid=88 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 60 on default port 15009" daemon prio=5 tid=531 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 50 on default port 15000" daemon prio=5 tid=103 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SCMHeartbeatProcessor-0" daemon prio=5 tid=18 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-2344c39b-1"  prio=5 tid=591 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/data-0/hdds)" daemon prio=5 tid=769 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"5b4c27d6-a533-4766-a648-a869ad76920c-CloseContainerThread-1"  prio=5 tid=1070 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 15004" daemon prio=5 tid=414 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 31 on default port 15009" daemon prio=5 tid=502 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 87 on default port 15000" daemon prio=5 tid=140 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"e3882025-ee77-4273-a30c-caf156427e83-DatanodeStateMachineTaskThread-1"  prio=5 tid=718 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-DatanodeStateMachineDaemonThread" daemon prio=5 tid=710 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:369)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:556)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1386/959870495.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 30 on default port 15009" daemon prio=5 tid=501 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15021" daemon prio=5 tid=625 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=446 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=818 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 42 on default port 15001" daemon prio=5 tid=195 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 65 on default port 15002" daemon prio=5 tid=318 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 45 on default port 15002" daemon prio=5 tid=298 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15000"  prio=5 tid=38 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 4 on default port 15004" daemon prio=5 tid=418 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-FollowerState" daemon prio=5 tid=1205 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"Socket Reader #1 for port 15021"  prio=5 tid=621 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 19 on default port 15002" daemon prio=5 tid=272 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp439694398-362" daemon prio=5 tid=362 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 85 on default port 15009" daemon prio=5 tid=556 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 96 on default port 15009" daemon prio=5 tid=567 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=777 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC->e3882025-ee77-4273-a30c-caf156427e83-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=1208 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:286)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:254)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:80)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1622/1199789025.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=707 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"IPC Server handler 93 on default port 15000" daemon prio=5 tid=146 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Client (1615502727) connection to 0.0.0.0/0.0.0.0:15002 from runner" daemon prio=5 tid=721 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1026)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1077)
"pool-73-thread-1"  prio=5 tid=439 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 15002" daemon prio=5 tid=261 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp670342028-643" daemon prio=5 tid=643 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Recon-FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=456 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-168-thread-1"  prio=5 tid=638 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-50fc74a8-1"  prio=5 tid=619 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 15009" daemon prio=5 tid=486 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-DatanodeReportManager-0" daemon prio=5 tid=711 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp149384698-590" daemon prio=5 tid=590 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 83 on default port 15009" daemon prio=5 tid=554 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 43 on default port 15000" daemon prio=5 tid=96 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 21 on default port 15002" daemon prio=5 tid=274 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-cacheEviction-AwaitToRun" daemon prio=5 tid=1151 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 15002" daemon prio=5 tid=254 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 59 on default port 15000" daemon prio=5 tid=112 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 17 on default port 15001" daemon prio=5 tid=170 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-DatanodeCommandQueueUpdatedForDatanodeCommandCountUpdatedHandler" daemon prio=5 tid=829 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 54 on default port 15000" daemon prio=5 tid=107 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1609314701-460-acceptor-0@1a9b635e-ServerConnector@4af133e4{HTTP/1.1, (http/1.1)}{0.0.0.0:15008}" daemon prio=3 tid=460 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Recon-FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=453 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 15001" daemon prio=5 tid=172 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=449 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 85 on default port 15000" daemon prio=5 tid=138 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=45 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"e3882025-ee77-4273-a30c-caf156427e83-server-thread1" daemon prio=5 tid=1209 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 15002" daemon prio=5 tid=267 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 76 on default port 15001" daemon prio=5 tid=229 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 10 on default port 15004" daemon prio=5 tid=424 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"e3882025-ee77-4273-a30c-caf156427e83-ChunkWriter-0-0" daemon prio=5 tid=731 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-SstFilteringService#0" daemon prio=5 tid=400 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 30 on default port 15001" daemon prio=5 tid=183 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 90 on default port 15000" daemon prio=5 tid=143 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"PartialTableCache-Cleanup-0" daemon prio=5 tid=959 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 99 on default port 15001" daemon prio=5 tid=252 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 3 on default port 15000" daemon prio=5 tid=56 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-StateMachineUpdater" daemon prio=5 tid=837 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.lang.Thread.run(Thread.java:750)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-DatanodeReportManager-2" daemon prio=5 tid=657 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-151-thread-1" daemon prio=5 tid=766 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 22 on default port 15000" daemon prio=5 tid=75 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=778 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp670342028-640" daemon prio=5 tid=640 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"e3882025-ee77-4273-a30c-caf156427e83-PipelineCommandHandlerThread-0"  prio=5 tid=831 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 57 on default port 15000" daemon prio=5 tid=110 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-CloseContainerThread-1"  prio=5 tid=1059 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 15002" daemon prio=5 tid=259 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-DatanodeReportManager-1" daemon prio=5 tid=712 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 71 on default port 15000" daemon prio=5 tid=124 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 19 on default port 15004" daemon prio=5 tid=433 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 23 on default port 15000" daemon prio=5 tid=76 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"5b4c27d6-a533-4766-a648-a869ad76920c-ChunkWriter-3-0" daemon prio=5 tid=753 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"e3882025-ee77-4273-a30c-caf156427e83-BlockDeletingService#2" daemon prio=5 tid=1215 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PipelineSyncTask" daemon prio=5 tid=571 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.recon.scm.PipelineSyncTask.run(PipelineSyncTask.java:76)
        at org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda$1299/1791718028.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp149384698-589" daemon prio=5 tid=589 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"UnderReplicatedProcessor" daemon prio=5 tid=23 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:174)
        at java.lang.Thread.run(Thread.java:750)
"5b4c27d6-a533-4766-a648-a869ad76920c-DatanodeStateMachineDaemonThread" daemon prio=5 tid=626 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:369)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:556)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1386/959870495.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 15001" daemon prio=5 tid=166 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 69 on default port 15001" daemon prio=5 tid=222 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=739 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 89 on default port 15002" daemon prio=5 tid=342 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15001" daemon prio=5 tid=153 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 55 on default port 15002" daemon prio=5 tid=308 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=828 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-66-thread-1"  prio=5 tid=404 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 15039" daemon prio=5 tid=678 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 77 on default port 15000" daemon prio=5 tid=130 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 79 on default port 15002" daemon prio=5 tid=332 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 83 on default port 15002" daemon prio=5 tid=336 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"e3882025-ee77-4273-a30c-caf156427e83-ChunkWriter-2-0" daemon prio=5 tid=733 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=43 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 15002" daemon prio=5 tid=258 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 64 on default port 15009" daemon prio=5 tid=535 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 42 on default port 15009" daemon prio=5 tid=513 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1727814855-671" daemon prio=5 tid=671 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp670342028-645" daemon prio=5 tid=645 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 56 on default port 15001" daemon prio=5 tid=209 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=757 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1727814855-669-acceptor-0@2c43825e-ServerConnector@5d7ed410{HTTP/1.1, (http/1.1)}{0.0.0.0:15038}" daemon prio=3 tid=669 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 29 on default port 15002" daemon prio=5 tid=282 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerMetadataScanner" daemon prio=5 tid=787 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server handler 94 on default port 15002" daemon prio=5 tid=347 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server idle connection scanner for port 15004" daemon prio=5 tid=383 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 53 on default port 15009" daemon prio=5 tid=524 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 77 on default port 15001" daemon prio=5 tid=230 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 58 on default port 15009" daemon prio=5 tid=529 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 77 on default port 15002" daemon prio=5 tid=330 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"gradle-enterprise-test-client-gradle-enterprise-test-listener"  prio=5 tid=14 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.io.ObjectOutputStream$BlockDataOutputStream.getUTFLength(ObjectOutputStream.java:2152)
        at java.io.ObjectOutputStream.writeString(ObjectOutputStream.java:1303)
        at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1172)
        at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)
        at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)
        at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)
        at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
        at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)
        at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)
        at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)
        at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
        at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)
        at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)
        at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)
        at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
        at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
        at com.gradle.maven.scan.extension.test.listener.obfuscated.k.a.a(SourceFile:141)
        at com.gradle.maven.scan.extension.test.listener.obfuscated.k.a.b(SourceFile:93)
        at com.gradle.maven.scan.extension.test.listener.obfuscated.k.a$$Lambda$256/215614514.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=40 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"IPC Server handler 94 on default port 15009" daemon prio=5 tid=565 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 91 on default port 15009" daemon prio=5 tid=562 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1609314701-458" daemon prio=5 tid=458 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 37 on default port 15001" daemon prio=5 tid=190 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 22 on default port 15009" daemon prio=5 tid=493 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server listener on 15001" daemon prio=5 tid=32 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-SegmentedRaftLogWorker"  prio=5 tid=888 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$917/424912382.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 72 on default port 15001" daemon prio=5 tid=225 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 42 on default port 15002" daemon prio=5 tid=295 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 75 on default port 15009" daemon prio=5 tid=546 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-OpenPipelineForHealthyPipelineSafeModeRule" daemon prio=5 tid=833 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 68 on default port 15009" daemon prio=5 tid=539 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 18 on default port 15002" daemon prio=5 tid=271 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 72 on default port 15009" daemon prio=5 tid=543 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-CloseContainerThread-2"  prio=5 tid=1060 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-client-thread1" daemon prio=5 tid=937 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5b4c27d6-a533-4766-a648-a869ad76920c-DatanodeStateMachineTaskThread-0"  prio=5 tid=633 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 15004" daemon prio=5 tid=416 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-CloseContainerThread-0"  prio=5 tid=1058 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 15002" daemon prio=5 tid=256 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 15 on default port 15004" daemon prio=5 tid=429 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 68 on default port 15002" daemon prio=5 tid=321 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 27 on default port 15002" daemon prio=5 tid=280 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 88 on default port 15001" daemon prio=5 tid=241 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 19 on default port 15000" daemon prio=5 tid=72 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerMetadataScanner" daemon prio=5 tid=768 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server handler 37 on default port 15009" daemon prio=5 tid=508 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Parameter Sending Thread for 0.0.0.0/0.0.0.0:15009" daemon prio=5 tid=724 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferQueue.awaitFulfill(SynchronousQueue.java:764)
        at java.util.concurrent.SynchronousQueue$TransferQueue.transfer(SynchronousQueue.java:695)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1105)
        at java.lang.Thread.run(Thread.java:750)
"qtp670342028-639" daemon prio=5 tid=639 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 32 on default port 15009" daemon prio=5 tid=503 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 82 on default port 15001" daemon prio=5 tid=235 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-StateMachineUpdater" daemon prio=5 tid=1195 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 35 on default port 15002" daemon prio=5 tid=288 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 6 on default port 15000" daemon prio=5 tid=59 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 85 on default port 15001" daemon prio=5 tid=238 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 57 on default port 15001" daemon prio=5 tid=210 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 63 on default port 15000" daemon prio=5 tid=116 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-ReplicationContainerReader-0" daemon prio=5 tid=1121 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 15001" daemon prio=5 tid=159 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp941659818-613-acceptor-0@7114b827-ServerConnector@6c40eb48{HTTP/1.1, (http/1.1)}{0.0.0.0:15020}" daemon prio=3 tid=613 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 91 on default port 15000" daemon prio=5 tid=144 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-DatanodeReportManager-4" daemon prio=5 tid=659 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 15001" daemon prio=5 tid=157 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=448 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 89 on default port 15000" daemon prio=5 tid=142 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule" daemon prio=5 tid=823 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5b4c27d6-a533-4766-a648-a869ad76920c-CloseContainerThread-2"  prio=5 tid=1071 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 47 on default port 15001" daemon prio=5 tid=200 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 7 on default port 15002" daemon prio=5 tid=260 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 89 on default port 15009" daemon prio=5 tid=560 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 20 on default port 15000" daemon prio=5 tid=73 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Session-HouseKeeper-1c3b4cb-1"  prio=5 tid=647 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 74 on default port 15001" daemon prio=5 tid=227 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 84 on default port 15000" daemon prio=5 tid=137 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 81 on default port 15000" daemon prio=5 tid=134 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 24 on default port 15009" daemon prio=5 tid=495 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1727814855-670" daemon prio=5 tid=670 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 36 on default port 15001" daemon prio=5 tid=189 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 97 on default port 15002" daemon prio=5 tid=350 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 74 on default port 15000" daemon prio=5 tid=127 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@527bdc42" daemon prio=5 tid=609 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.lang.Thread.run(Thread.java:750)
"qtp1521342613-410" daemon prio=5 tid=410 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 92 on default port 15001" daemon prio=5 tid=245 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp910839493-698" daemon prio=5 tid=698 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-BlockDeletingService#2" daemon prio=5 tid=1224 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-CommandProcessorThread" daemon prio=5 tid=688 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:684)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1388/1074834806.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-ChunkWriter-1-0" daemon prio=5 tid=790 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"nullContainerReplicationThread-0" daemon prio=5 tid=1120 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.PriorityBlockingQueue.take(PriorityBlockingQueue.java:549)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 15021" daemon prio=5 tid=622 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=36 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-ChunkWriter-0-0" daemon prio=5 tid=789 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1217 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-5d8be063-1"  prio=5 tid=413 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 26 on default port 15002" daemon prio=5 tid=279 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 16 on default port 15000" daemon prio=5 tid=69 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 87 on default port 15009" daemon prio=5 tid=558 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-ChunkReader-ELG-0" daemon prio=5 tid=794 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 95 on default port 15000" daemon prio=5 tid=148 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 99 on default port 15002" daemon prio=5 tid=352 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server idle connection scanner for port 15012" daemon prio=5 tid=594 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 50 on default port 15009" daemon prio=5 tid=521 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC->00b25173-7757-4760-98a7-1e1aa18d5e2d-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=1207 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:286)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:254)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:80)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1622/1199789025.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 82 on default port 15000" daemon prio=5 tid=135 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 37 on default port 15002" daemon prio=5 tid=290 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"5b4c27d6-a533-4766-a648-a869ad76920c-CloseContainerThread-0"  prio=5 tid=1057 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=447 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-DirectoryDeletingService#0" daemon prio=5 tid=398 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"MutableQuantiles-0" daemon prio=5 tid=945 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-server-thread2" daemon prio=5 tid=1212 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer4" daemon prio=5 tid=927 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 12 on default port 15001" daemon prio=5 tid=165 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"null-request--thread1" daemon prio=5 tid=948 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"e3882025-ee77-4273-a30c-caf156427e83-ChunkWriter-3-0" daemon prio=5 tid=734 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 15009" daemon prio=5 tid=490 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 32 on default port 15001" daemon prio=5 tid=185 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-DatanodeStateMachineTaskThread-0"  prio=5 tid=689 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 15030" daemon prio=5 tid=650 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=50 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"e3882025-ee77-4273-a30c-caf156427e83-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=579 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 65 on default port 15001" daemon prio=5 tid=218 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 28 on default port 15001" daemon prio=5 tid=181 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 73 on default port 15002" daemon prio=5 tid=326 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp910839493-701" daemon prio=5 tid=701 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 21 on default port 15000" daemon prio=5 tid=74 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 61 on default port 15001" daemon prio=5 tid=214 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 91 on default port 15002" daemon prio=5 tid=344 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 41 on default port 15000" daemon prio=5 tid=94 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-server-thread3" daemon prio=5 tid=1214 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 69 on default port 15009" daemon prio=5 tid=540 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-boss-ELG-1-1" daemon prio=5 tid=391 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-DatanodeCommandForSCMNodeManager"  prio=5 tid=825 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=691 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 76 on default port 15009" daemon prio=5 tid=547 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-DatanodeStateMachineTaskThread-1"  prio=5 tid=760 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 63 on default port 15009" daemon prio=5 tid=534 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 61 on default port 15000" daemon prio=5 tid=114 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-ChunkWriter-3-0" daemon prio=5 tid=773 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 67 on default port 15009" daemon prio=5 tid=538 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 33 on default port 15001" daemon prio=5 tid=186 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Connector-Scheduler-4af133e4-1"  prio=5 tid=964 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 15000" daemon prio=5 tid=65 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-SegmentedRaftLogWorker"  prio=5 tid=1186 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$917/424912382.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-ChunkWriter-1-0" daemon prio=5 tid=809 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ExpiredContainerReplicaOpScrubber" daemon prio=5 tid=21 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:107)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$489/464583224.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-cacheEviction-AwaitToRun" daemon prio=5 tid=1185 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.lang.Thread.run(Thread.java:750)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-DatanodeReportManager-1" daemon prio=5 tid=684 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1521342613-406" daemon prio=5 tid=406 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=815 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 15009" daemon prio=5 tid=485 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"PartialTableCache-Cleanup-0" daemon prio=5 tid=944 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5b4c27d6-a533-4766-a648-a869ad76920c-groupManagement"  prio=5 tid=843 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-1" daemon prio=5 tid=856 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 51 on default port 15002" daemon prio=5 tid=304 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-ReplicationContainerReader-2" daemon prio=5 tid=1123 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 33 on default port 15009" daemon prio=5 tid=504 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-125-thread-1" daemon prio=5 tid=747 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=46 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=41 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 44 on default port 15001" daemon prio=5 tid=197 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"5b4c27d6-a533-4766-a648-a869ad76920c-DatanodeReportManager-2" daemon prio=5 tid=629 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-cacheEviction-AwaitToRun" daemon prio=5 tid=387 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 72 on default port 15000" daemon prio=5 tid=125 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 9 on default port 15000" daemon prio=5 tid=62 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp941659818-618" daemon prio=5 tid=618 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 58 on default port 15000" daemon prio=5 tid=111 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 64 on default port 15000" daemon prio=5 tid=117 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=455 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache-Cleanup-0" daemon prio=5 tid=943 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1727814855-667" daemon prio=5 tid=667 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 88 on default port 15000" daemon prio=5 tid=141 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 17 on default port 15000" daemon prio=5 tid=70 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 6 on default port 15009" daemon prio=5 tid=477 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 5 on default port 15004" daemon prio=5 tid=419 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"5b4c27d6-a533-4766-a648-a869ad76920c-DatanodeReportManager-3" daemon prio=5 tid=630 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor1" daemon prio=5 tid=392 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$554/718511919.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-6e18bc2f-1"  prio=5 tid=365 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 15001" daemon prio=5 tid=34 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=663 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"OverReplicatedProcessor" daemon prio=5 tid=24 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:174)
        at java.lang.Thread.run(Thread.java:750)
"surefire-forkedjvm-command-thread" daemon prio=5 tid=10 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.FileInputStream.readBytes(Native Method)
        at java.io.FileInputStream.read(FileInputStream.java:255)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
        at java.io.DataInputStream.readInt(DataInputStream.java:387)
        at org.apache.maven.surefire.booter.MasterProcessCommand.decode(MasterProcessCommand.java:113)
        at org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:383)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 60 on default port 15002" daemon prio=5 tid=313 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 11 on default port 15000" daemon prio=5 tid=64 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 34 on default port 15009" daemon prio=5 tid=505 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 31 on default port 15001" daemon prio=5 tid=184 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1-SnapshotDiffCleanupService#0" daemon prio=5 tid=372 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 78 on default port 15000" daemon prio=5 tid=131 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Client (1615502727) connection to localhost/127.0.0.1:15004 from runner" daemon prio=5 tid=966 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1026)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1077)
"IPC Server handler 48 on default port 15009" daemon prio=5 tid=519 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server idle connection scanner for port 15002" daemon prio=5 tid=29 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-BlockDeletingService#2" daemon prio=5 tid=1220 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-ChunkWriter-3-0" daemon prio=5 tid=792 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1609314701-463" daemon prio=5 tid=463 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.reservedWait(ReservedThreadExecutor.java:324)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:399)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 27 on default port 15001" daemon prio=5 tid=180 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"RatisPipelineUtilsThread-0"  prio=5 tid=19 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.run(BackgroundPipelineCreator.java:179)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator$$Lambda$487/1424392446.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 94 on default port 15000" daemon prio=5 tid=147 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"bb4f2f6f-344d-4a57-aba3-69abe2cb722c-DatanodeReportManager-4" daemon prio=5 tid=687 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 45 on default port 15009" daemon prio=5 tid=516 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 18 on default port 15004" daemon prio=5 tid=432 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1-OpenKeyCleanupService#0" daemon prio=5 tid=399 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp149384698-586" daemon prio=5 tid=586 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 86 on default port 15002" daemon prio=5 tid=339 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 40 on default port 15000" daemon prio=5 tid=93 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FullTableCache-Cleanup-0" daemon prio=5 tid=940 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 15004" daemon prio=5 tid=423 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp439694398-357" daemon prio=5 tid=357 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 43 on default port 15009" daemon prio=5 tid=514 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 82 on default port 15009" daemon prio=5 tid=553 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 15 on default port 15002" daemon prio=5 tid=268 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 40 on default port 15002" daemon prio=5 tid=293 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-ChunkWriter-3-0" daemon prio=5 tid=811 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"00b25173-7757-4760-98a7-1e1aa18d5e2d-ChunkWriter-1-0" daemon prio=5 tid=771 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule" daemon prio=5 tid=821 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5b4c27d6-a533-4766-a648-a869ad76920c-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=607 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"qtp149384698-585-acceptor-0@c40e3ee-ServerConnector@603588c3{HTTP/1.1, (http/1.1)}{0.0.0.0:15011}" daemon prio=3 tid=585 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 81 on default port 15009" daemon prio=5 tid=552 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"e3882025-ee77-4273-a30c-caf156427e83-DatanodeReportManager-3" daemon prio=5 tid=602 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1221 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 15004" daemon prio=5 tid=430 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp910839493-696" daemon prio=5 tid=696 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 35 on default port 15001" daemon prio=5 tid=188 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-cacheEviction-AwaitToRun" daemon prio=5 tid=834 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 86 on default port 15000" daemon prio=5 tid=139 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-SegmentedRaftLogWorker"  prio=5 tid=835 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$917/424912382.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1521342613-412" daemon prio=5 tid=412 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 23 on default port 15002" daemon prio=5 tid=276 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"e3882025-ee77-4273-a30c-caf156427e83-PeriodicHDDSVolumeChecker" daemon prio=5 tid=726 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ReplicationMonitor" daemon prio=5 tid=22 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:931)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager$$Lambda$503/26462224.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=31 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-KeyDeletingService#0" daemon prio=5 tid=397 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 15004" daemon prio=5 tid=425 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"5b4c27d6-a533-4766-a648-a869ad76920c-PipelineCommandHandlerThread-0"  prio=5 tid=842 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 63 on default port 15001" daemon prio=5 tid=216 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=48 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 48 on default port 15002" daemon prio=5 tid=301 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 47 on default port 15000" daemon prio=5 tid=100 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"timer7" daemon prio=5 tid=950 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 15 on default port 15001" daemon prio=5 tid=168 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)

2024-03-23 11:37:26,340 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:addNewContainer(246)) - Successfully added container #2 to Recon.
2024-03-23 11:37:26,340 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 40 millisec, 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5), {type: ICR, size: 1}
Connecting to Recon: http://0.0.0.0:15008/api/v1/triggerdbsync/om ...
2024-03-23 11:37:26,373 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:26,373 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:26,373 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-23 11:37:26,385 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 2, SequenceNumber diff: 7, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:26,385 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 7 records
2024-03-23 11:37:26,418 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:37:26,422 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 4 milliseconds for processing 2 containers.
2024-03-23 11:37:26,422 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:26,422 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:26,422 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:26,422 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:26,422 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:26,422 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:26,422 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:26,465 [ReconTaskThread-0] INFO  tasks.OmTableInsightTask (OmTableInsightTask.java:process(211)) - Completed a 'process' run of OmTableInsightTask.
2024-03-23 11:37:26,466 [ReconTaskThread-0] INFO  tasks.NSSummaryTaskWithFSO (NSSummaryTaskWithFSO.java:processWithFSO(165)) - Completed a process run of NSSummaryTaskWithFSO
2024-03-23 11:37:26,467 [ReconTaskThread-0] INFO  tasks.NSSummaryTaskWithLegacy (NSSummaryTaskWithLegacy.java:processWithLegacy(205)) - Completed a process run of NSSummaryTaskWithLegacy
2024-03-23 11:37:26,467 [ReconTaskThread-0] INFO  tasks.NSSummaryTaskWithOBS (NSSummaryTaskWithOBS.java:processWithOBS(206)) - Completed a process run of NSSummaryTaskWithOBS
2024-03-23 11:37:26,471 [ReconTaskThread-0] INFO  tasks.ContainerKeyMapperTask (ContainerKeyMapperTask.java:process(261)) - ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
2024-03-23 11:37:26,489 [ReconTaskThread-0] INFO  tasks.FileSizeCountTask (FileSizeCountTask.java:process(201)) - Completed a 'process' run of FileSizeCountTask.
2024-03-23 11:37:27,110 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-03-23 11:37:27,389 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-03-23 11:37:27,391 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-03-23 11:37:27,391 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-03-23 11:37:27,392 [main] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/data-0/hdds) is shutting down. 
2024-03-23 11:37:27,393 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-03-23 11:37:27,393 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/data-0/hdds, DS-f5fc6349-2a63-4c91-99e3-3dbec7144f76) exiting.
2024-03-23 11:37:27,395 [main] INFO  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:shutdownScanner(206)) - On-demand container scanner is shutting down.
2024-03-23 11:37:27,399 [main] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(416)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: close
2024-03-23 11:37:27,400 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE: shutdown
2024-03-23 11:37:27,400 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-03-23 11:37:27,400 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-E1AE4BA72BFE,id=6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:37:27,401 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: shutdown 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-LeaderStateImpl
2024-03-23 11:37:27,401 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-PendingRequests: sendNotLeaderResponses
2024-03-23 11:37:27,409 [Thread-965] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d Close channels
2024-03-23 11:37:27,413 [Thread-967] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c Close channels
2024-03-23 11:37:27,413 [Thread-966] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - e3882025-ee77-4273-a30c-caf156427e83 Close channels
2024-03-23 11:37:27,415 [grpc-default-executor-2] WARN  server.GrpcClientProtocolService (LogUtils.java:warn(121)) - 0-OrderedRequestStreamObserver0: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2024-03-23 11:37:27,415 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-StateMachineUpdater: set stopIndex = 3
2024-03-23 11:37:27,416 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-E1AE4BA72BFE: Taking a snapshot at:(t:1, i:3) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/075a3443-897d-4510-a745-e1ae4ba72bfe/sm/snapshot.1_3
2024-03-23 11:37:27,418 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-E1AE4BA72BFE: Finished taking a snapshot at:(t:1, i:3) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/075a3443-897d-4510-a745-e1ae4ba72bfe/sm/snapshot.1_3 took: 2 ms
2024-03-23 11:37:27,419 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-StateMachineUpdater: Took a snapshot at index 3
2024-03-23 11:37:27,419 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 3
2024-03-23 11:37:27,421 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE: applyIndex: 3
2024-03-23 11:37:27,421 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-23 11:37:27,423 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:37:27,426 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 2 containers.
2024-03-23 11:37:27,426 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:27,426 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:27,426 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:27,426 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:27,426 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:27,426 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:27,427 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:27,494 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:27,494 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:27,494 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-03-23 11:37:27,496 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:27,496 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:28,111 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-03-23 11:37:28,303 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE-SegmentedRaftLogWorker close()
2024-03-23 11:37:28,427 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:37:28,429 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 2 containers.
2024-03-23 11:37:28,429 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:28,429 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:28,429 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:28,430 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:28,430 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:28,430 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:28,430 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:28,497 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:28,497 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:28,497 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-03-23 11:37:28,499 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:28,499 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:29,111 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-03-23 11:37:29,430 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:37:29,433 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 2 containers.
2024-03-23 11:37:29,433 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:29,433 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:29,433 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:29,433 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:29,433 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:29,433 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:29,433 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:29,501 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:29,501 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:29,501 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-03-23 11:37:29,502 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:29,502 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:30,044 [Recon-FixedThreadPoolWithAffinityExecutor-0-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), {type: FCR, size: 1}
2024-03-23 11:37:30,112 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-03-23 11:37:30,324 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5) moved to stale state. Finalizing its pipelines [PipelineID=075a3443-897d-4510-a745-e1ae4ba72bfe]
2024-03-23 11:37:30,324 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5) moved to stale state. Finalizing its pipelines [PipelineID=906eef43-4831-419e-95bd-f5e0ec3bda04, PipelineID=075a3443-897d-4510-a745-e1ae4ba72bfe, PipelineID=2d7785c5-43f1-4411-94e4-56171e486153]
2024-03-23 11:37:30,325 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(484)) - Container #2 closed for pipeline=PipelineID=075a3443-897d-4510-a745-e1ae4ba72bfe
2024-03-23 11:37:30,325 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #2, current state: CLOSING
2024-03-23 11:37:30,325 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=075a3443-897d-4510-a745-e1ae4ba72bfe moved to CLOSED state
2024-03-23 11:37:30,326 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(484)) - Container #2 closed for pipeline=PipelineID=075a3443-897d-4510-a745-e1ae4ba72bfe
2024-03-23 11:37:30,326 [Recon-EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #2, current state: CLOSING
2024-03-23 11:37:30,326 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=075a3443-897d-4510-a745-e1ae4ba72bfe moved to CLOSED state
2024-03-23 11:37:30,326 [Recon-EventQueue-DatanodeCommandForReconNodeManager] DEBUG scm.ReconNodeManager (ReconNodeManager.java:onMessage(213)) - Ignoring unsupported command closeContainerCommand for Datanode 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b.
2024-03-23 11:37:30,327 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 moved to CLOSED state
2024-03-23 11:37:30,328 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 11 pipelines in house.
2024-03-23 11:37:30,329 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(152)) - Removing invalid pipeline PipelineID=906eef43-4831-419e-95bd-f5e0ec3bda04 from Recon.
2024-03-23 11:37:30,329 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 906eef43-4831-419e-95bd-f5e0ec3bda04, Nodes: 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5)e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5)6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, CreationTimestamp2024-03-23T11:36:38.085Z[Etc/UTC]] removed.
2024-03-23 11:37:30,330 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(152)) - Removing invalid pipeline PipelineID=439e139a-b269-423e-9d21-d246ec176e64 from Recon.
2024-03-23 11:37:30,330 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 439e139a-b269-423e-9d21-d246ec176e64, Nodes: 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5)00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5)e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:5b4c27d6-a533-4766-a648-a869ad76920c, CreationTimestamp2024-03-23T11:36:18.968Z[Etc/UTC]] removed.
2024-03-23 11:37:30,331 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(152)) - Removing invalid pipeline PipelineID=eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72 from Recon.
2024-03-23 11:37:30,331 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: eb3e8d6e-30ef-4dcc-a8c7-9af5c7649f72, Nodes: bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:bb4f2f6f-344d-4a57-aba3-69abe2cb722c, CreationTimestamp2024-03-23T11:36:19.103Z[Etc/UTC]] removed.
2024-03-23 11:37:30,331 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(152)) - Removing invalid pipeline PipelineID=2d7785c5-43f1-4411-94e4-56171e486153 from Recon.
2024-03-23 11:37:30,331 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 2d7785c5-43f1-4411-94e4-56171e486153, Nodes: bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5)e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5)6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, CreationTimestamp2024-03-23T11:36:46.084Z[Etc/UTC]] removed.
2024-03-23 11:37:30,332 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(152)) - Removing invalid pipeline PipelineID=8643aede-2156-48e1-8210-1ce430ae568b from Recon.
2024-03-23 11:37:30,333 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 8643aede-2156-48e1-8210-1ce430ae568b, Nodes: 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:00b25173-7757-4760-98a7-1e1aa18d5e2d, CreationTimestamp2024-03-23T11:36:18.964Z[Etc/UTC]] removed.
2024-03-23 11:37:30,333 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(152)) - Removing invalid pipeline PipelineID=c0ed46c6-9d24-4a92-bbda-2a12cab7754c from Recon.
2024-03-23 11:37:30,333 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: c0ed46c6-9d24-4a92-bbda-2a12cab7754c, Nodes: 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:5b4c27d6-a533-4766-a648-a869ad76920c, CreationTimestamp2024-03-23T11:36:18.844Z[Etc/UTC]] removed.
2024-03-23 11:37:30,335 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 8 milliseconds.
2024-03-23 11:37:30,414 [Thread-966] WARN  grpc.GrpcUtil (GrpcUtil.java:shutdownManagedChannel(233)) - Timed out gracefully shutting down connection: ManagedChannelOrphanWrapper{delegate=ManagedChannelImpl{logId=196, target=10.1.0.5:15016}}. 
2024-03-23 11:37:30,416 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(533)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-56171E486153->e3882025-ee77-4273-a30c-caf156427e83-GrpcLogAppender is already stopped
2024-03-23 11:37:30,418 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-03-23 11:37:30,419 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: shutdown server GrpcServerProtocolService now
2024-03-23 11:37:30,425 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: shutdown server GrpcServerProtocolService successfully
2024-03-23 11:37:30,426 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-03-23 11:37:30,427 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-03-23 11:37:30,431 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb3d6586f, L:/0.0.0.0:15053] CLOSE
2024-03-23 11:37:30,431 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb3d6586f, L:/0.0.0.0:15053] INACTIVE
2024-03-23 11:37:30,431 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb3d6586f, L:/0.0.0.0:15053] UNREGISTERED
2024-03-23 11:37:30,434 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-23 11:37:30,436 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 2 containers.
2024-03-23 11:37:30,436 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:30,437 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:30,437 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:30,437 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:30,437 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:30,437 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:30,437 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:30,451 [JvmPauseMonitor7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: Stopped
2024-03-23 11:37:30,503 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:30,503 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:30,504 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-03-23 11:37:30,505 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:30,505 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:31,113 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 2, pipelineID: PipelineID=075a3443-897d-4510-a745-e1ae4ba72bfe, force: false] for container ContainerInfo{id=#2, state=CLOSING, stateEnterTime=2024-03-23T11:37:30.324Z, pipelineID=PipelineID=075a3443-897d-4510-a745-e1ae4ba72bfe, owner=omServiceIdDefault} to 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5) with datanode deadline 1711194421112 and scm deadline 1711194451112
2024-03-23 11:37:31,113 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-03-23 11:37:31,437 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:37:31,440 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 2 containers.
2024-03-23 11:37:31,440 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:31,440 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:31,440 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:31,440 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:31,440 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:31,440 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:31,440 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:31,506 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:31,507 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:31,507 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-03-23 11:37:31,508 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:31,508 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:32,113 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 2, pipelineID: PipelineID=075a3443-897d-4510-a745-e1ae4ba72bfe, force: false] for container ContainerInfo{id=#2, state=CLOSING, stateEnterTime=2024-03-23T11:37:30.324Z, pipelineID=PipelineID=075a3443-897d-4510-a745-e1ae4ba72bfe, owner=omServiceIdDefault} to 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5) with datanode deadline 1711194422113 and scm deadline 1711194452113
2024-03-23 11:37:32,113 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-03-23 11:37:32,441 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-23 11:37:32,443 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 2 containers.
2024-03-23 11:37:32,443 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:32,443 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:32,443 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:32,443 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:32,443 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:32,443 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:32,443 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:32,463 [main] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-892f8edf-b04c-4bbd-8c90-36214af705e8/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-a679f35d-8700-4aa7-8f9c-4f65e6fa09bc/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-4620390d-9a40-479a-99aa-5a4e8f975309/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-bff6b704-e145-4390-bc30-ec0553ef30a2/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-f5fc6349-2a63-4c91-99e3-3dbec7144f76/container.db]
2024-03-23 11:37:32,467 [main] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-f5fc6349-2a63-4c91-99e3-3dbec7144f76/container.db from cache
2024-03-23 11:37:32,467 [main] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(451)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-f5fc6349-2a63-4c91-99e3-3dbec7144f76/container.db for volume DS-f5fc6349-2a63-4c91-99e3-3dbec7144f76
2024-03-23 11:37:32,467 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-03-23 11:37:32,468 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-03-23 11:37:32,468 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(638)) - Ozone container server stopped.
2024-03-23 11:37:32,470 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@21a21dfc{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-03-23 11:37:32,472 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@3b3374ee{HTTP/1.1, (http/1.1)}{0.0.0.0:15047}
2024-03-23 11:37:32,472 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-03-23 11:37:32,472 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@621bed48{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2024-03-23 11:37:32,473 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@1e144d08{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-03-23 11:37:32,474 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-03-23 11:37:32,474 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15048
2024-03-23 11:37:32,475 [IPC Server listener on 15048] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15048
2024-03-23 11:37:32,475 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-03-23 11:37:32,476 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b]
2024-03-23 11:37:32,510 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:32,510 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:32,510 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-03-23 11:37:32,511 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:32,511 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:33,114 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 2, pipelineID: PipelineID=075a3443-897d-4510-a745-e1ae4ba72bfe, force: false] for container ContainerInfo{id=#2, state=CLOSING, stateEnterTime=2024-03-23T11:37:30.324Z, pipelineID=PipelineID=075a3443-897d-4510-a745-e1ae4ba72bfe, owner=omServiceIdDefault} to 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5) with datanode deadline 1711194423114 and scm deadline 1711194453114
2024-03-23 11:37:33,114 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-03-23 11:37:33,247 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5), {type: FCR, size: 0}
2024-03-23 11:37:33,326 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(95)) - A dead datanode is detected. 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5)
2024-03-23 11:37:33,327 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(95)) - A dead datanode is detected. 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5)
2024-03-23 11:37:33,328 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=075a3443-897d-4510-a745-e1ae4ba72bfe close command to datanode 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:37:33,328 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 075a3443-897d-4510-a745-e1ae4ba72bfe, Nodes: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, CreationTimestamp2024-03-23T11:36:19.202Z[Etc/UTC]] removed.
2024-03-23 11:37:33,328 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 075a3443-897d-4510-a745-e1ae4ba72bfe, Nodes: 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b, CreationTimestamp2024-03-23T11:36:19.202Z[Etc/UTC]] removed.
2024-03-23 11:37:33,329 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(108)) - Clearing command queue of size 5 for DN 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5)
2024-03-23 11:37:33,330 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(211)) - Removed a node: /default-rack/6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:37:33,330 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(108)) - Clearing command queue of size 0 for DN 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b(fv-az1381-309/10.1.0.5)
2024-03-23 11:37:33,330 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(211)) - Removed a node: /default-rack/6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b
2024-03-23 11:37:33,339 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-23 11:37:33,341 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:generateUnhealthyRecords(483)) - Non-empty container 2 is missing. It has 1 keys and 0 bytes used according to SCM metadata. Please visit Recon's missing container page for a list of keys (and their metadata) mapped to this container.
2024-03-23 11:37:33,346 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 6 milliseconds for processing 2 containers.
2024-03-23 11:37:33,346 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:33,346 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	TOTAL_KEYS -> 1 , CONTAINER_COUNT -> 1 , TOTAL_USED_BYTES -> 0 , 
2024-03-23 11:37:33,346 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:33,346 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:33,346 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:33,346 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:33,346 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:33,347 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 4 pipelines in house.
2024-03-23 11:37:33,350 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 3 milliseconds.
2024-03-23 11:37:33,362 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  tasks.ContainerSizeCountTask (ContainerSizeCountTask.java:process(200)) - Completed a 'process' run of ContainerSizeCountTask.
2024-03-23 11:37:33,445 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 2 milliseconds to process 1 existing database records.
2024-03-23 11:37:33,447 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 2 containers.
2024-03-23 11:37:33,447 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:33,447 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:33,447 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:33,447 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:33,447 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:33,447 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:33,447 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:33,477 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 0 replicas on []
2024-03-23 11:37:33,513 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:33,513 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:33,513 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-03-23 11:37:33,515 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:33,515 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:34,115 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-03-23 11:37:34,450 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 3 milliseconds to process 1 existing database records.
2024-03-23 11:37:34,452 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 2 containers.
2024-03-23 11:37:34,452 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:34,452 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:34,452 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:34,452 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:34,452 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:34,452 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:34,452 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/MISSING ...
2024-03-23 11:37:34,499 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-03-23 11:37:34,516 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(240)) - HddsDatanodeService host:fv-az1381-309 ip:10.1.0.5
2024-03-23 11:37:34,516 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:34,517 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:34,517 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-03-23 11:37:34,518 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-23 11:37:34,518 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-23 11:37:34,527 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-03-23 11:37:34,528 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(299)) - Datanode State Machine Task Thread Pool size 2
2024-03-23 11:37:34,529 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(125)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/data-0/hdds of storage type : DISK capacity : 9223372036854775807
2024-03-23 11:37:34,530 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/data-0/hdds to VolumeSet
2024-03-23 11:37:34,531 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis to VolumeSet
2024-03-23 11:37:34,541 [ForkJoinPool.commonPool-worker-0] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-f5fc6349-2a63-4c91-99e3-3dbec7144f76/container.db to cache
2024-03-23 11:37:34,541 [ForkJoinPool.commonPool-worker-0] INFO  volume.HddsVolume (HddsVolume.java:loadDbStore(373)) - SchemaV3 db is loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-f5fc6349-2a63-4c91-99e3-3dbec7144f76/container.db for volume DS-f5fc6349-2a63-4c91-99e3-3dbec7144f76
2024-03-23 11:37:34,541 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 10ms
2024-03-23 11:37:34,544 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-03-23 11:37:34,544 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-03-23 11:37:34,544 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15051 (custom)
2024-03-23 11:37:34,544 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-03-23 11:37:34,544 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15050 (custom)
2024-03-23 11:37:34,545 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-03-23 11:37:34,545 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15052 (custom)
2024-03-23 11:37:34,545 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-03-23 11:37:34,545 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-23 11:37:34,545 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-03-23 11:37:34,546 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:37:34,546 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-23 11:37:34,546 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-03-23 11:37:34,546 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-03-23 11:37:34,548 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-03-23 11:37:34,548 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-03-23 11:37:34,548 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-03-23 11:37:34,549 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-03-23 11:37:34,549 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-03-23 11:37:34,549 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-03-23 11:37:34,549 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-03-23 11:37:34,549 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-03-23 11:37:34,549 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-03-23 11:37:34,550 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-03-23 11:37:34,550 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-03-23 11:37:34,550 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-03-23 11:37:34,550 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-03-23 11:37:34,551 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15053 (custom)
2024-03-23 11:37:34,551 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:37:34,551 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-03-23 11:37:34,551 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:37:34,552 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis] (custom)
2024-03-23 11:37:34,552 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-03-23 11:37:34,552 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-03-23 11:37:34,552 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x265a2564] REGISTERED
2024-03-23 11:37:34,553 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x265a2564] BIND: 0.0.0.0/0.0.0.0:15053
2024-03-23 11:37:34,553 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x265a2564, L:/0.0.0.0:15053] ACTIVE
2024-03-23 11:37:34,553 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/075a3443-897d-4510-a745-e1ae4ba72bfe
2024-03-23 11:37:34,553 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: addNew group-E1AE4BA72BFE:[] returns group-E1AE4BA72BFE:java.util.concurrent.CompletableFuture@69cafb6e[Not completed]
2024-03-23 11:37:34,553 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/tmp
2024-03-23 11:37:34,554 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(269)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/ratis/tmp is not a group directory; ignoring it. 
2024-03-23 11:37:34,554 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-03-23 11:37:34,554 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b: new RaftServerImpl for group-E1AE4BA72BFE:[] with ContainerStateMachine:uninitialized
2024-03-23 11:37:34,554 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-23 11:37:34,554 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-23 11:37:34,554 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-23 11:37:34,555 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-23 11:37:34,555 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-23 11:37:34,555 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-23 11:37:34,555 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-23 11:37:34,555 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-03-23 11:37:34,555 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b@group-E1AE4BA72BFE: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-23 11:37:34,555 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-23 11:37:34,555 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-23 11:37:34,556 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-23 11:37:34,556 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-23 11:37:34,556 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-23 11:37:34,556 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-23 11:37:34,557 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(163)) - Initializing replication supervisor with thread count = 10
2024-03-23 11:37:34,557 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(317)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-03-23 11:37:34,558 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-23 11:37:34,558 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-23 11:37:34,558 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-23 11:37:34,558 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-23 11:37:34,558 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-23 11:37:34,559 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-23 11:37:34,559 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15047
2024-03-23 11:37:34,559 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-23 11:37:34,560 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-03-23 11:37:34,561 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-03-23 11:37:34,562 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-23 11:37:34,562 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-03-23 11:37:34,562 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-23 11:37:34,563 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-23 11:37:34,563 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/meta/webserver
2024-03-23 11:37:34,563 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15047
2024-03-23 11:37:34,563 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-03-23 11:37:34,565 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-03-23 11:37:34,565 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-03-23 11:37:34,565 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2024-03-23 11:37:34,566 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6d8ee197{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-03-23 11:37:34,566 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@57cc9d6f{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-03-23 11:37:34,600 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@13eb3b5c{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/meta/webserver/jetty-0_0_0_0-15047-hdds-container-service-1_5_0-SNAPSHOT_jar-_-any-1740495814562822977/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-03-23 11:37:34,602 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@3da18ccf{HTTP/1.1, (http/1.1)}{0.0.0.0:15047}
2024-03-23 11:37:34,602 [main] INFO  server.Server (Server.java:doStart(415)) - Started @101478ms
2024-03-23 11:37:34,603 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-03-23 11:37:34,603 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15047
2024-03-23 11:37:34,604 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-23 11:37:34,604 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15048
2024-03-23 11:37:34,604 [Socket Reader #1 for port 15048] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15048
2024-03-23 11:37:34,611 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(327)) - Datanode start with admins: [runner]
2024-03-23 11:37:34,611 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15048
2024-03-23 11:37:34,611 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-03-23 11:37:34,611 [IPC Server listener on 15048] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15048: starting
2024-03-23 11:37:34,613 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(555)) - Ozone container server started.
2024-03-23 11:37:34,615 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-03-23 11:37:34,615 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(396)) - Shutting down the Mini Ozone Cluster
2024-03-23 11:37:34,617 [6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/meta/datanode.id
2024-03-23 11:37:34,618 [main] INFO  db.CodecTestUtil (CodecTestUtil.java:gc(50)) - gc 0
2024-03-23 11:37:34,959 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(412)) - Stopping the Mini Ozone Cluster
2024-03-23 11:37:34,959 [main] INFO  om.OzoneManager (OzoneManager.java:stop(2238)) - om1[localhost:15004]: Stopping Ozone Manager
2024-03-23 11:37:34,959 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15004
2024-03-23 11:37:34,960 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-03-23 11:37:34,960 [IPC Server listener on 15004] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15004
2024-03-23 11:37:34,961 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:stop(594)) - Stopping org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer@56930e8b at port 15007
2024-03-23 11:37:34,961 [main] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(416)) - om1: close
2024-03-23 11:37:34,961 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - om1: shutdown server GrpcServerProtocolService now
2024-03-23 11:37:34,961 [om1-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - om1@group-C5BA1605619E: shutdown
2024-03-23 11:37:34,962 [om1-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2024-03-23 11:37:34,962 [om1-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - om1: shutdown om1@group-C5BA1605619E-LeaderStateImpl
2024-03-23 11:37:34,962 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - om1: shutdown server GrpcServerProtocolService successfully
2024-03-23 11:37:34,962 [om1-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - om1@group-C5BA1605619E-PendingRequests: sendNotLeaderResponses
2024-03-23 11:37:34,965 [om1-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - om1@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 12
2024-03-23 11:37:34,965 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshotImpl(481)) -  applied = (t:1, i:11)
2024-03-23 11:37:34,966 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshotImpl(482)) -  skipped = 11
2024-03-23 11:37:34,966 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshotImpl(483)) - notified = (t:1, i:12)
2024-03-23 11:37:34,966 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshotImpl(484)) - snapshot = (t:1, i:12)
2024-03-23 11:37:34,975 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - om1@group-C5BA1605619E-StateMachineUpdater: Took a snapshot at index 12
2024-03-23 11:37:34,976 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - om1@group-C5BA1605619E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 12
2024-03-23 11:37:34,976 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(527)) - Stopping OzoneManagerStateMachine:om1:group-C5BA1605619E.
2024-03-23 11:37:34,976 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(517)) - Stopping OMDoubleBuffer flush thread
2024-03-23 11:37:34,976 [om1-OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:canFlush(581)) - OMDoubleBuffer flush thread om1-OMDoubleBufferFlushThread is interrupted and will exit.
2024-03-23 11:37:34,977 [om1-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(427)) - om1@group-C5BA1605619E: applyIndex: 11
2024-03-23 11:37:34,978 [om1@group-C5BA1605619E-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - om1@group-C5BA1605619E-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-23 11:37:35,116 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-03-23 11:37:35,346 [om1-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker close()
2024-03-23 11:37:35,346 [JvmPauseMonitor1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-om1: Stopped
2024-03-23 11:37:35,347 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service KeyDeletingService
2024-03-23 11:37:35,347 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service DirectoryDeletingService
2024-03-23 11:37:35,347 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service OpenKeyCleanupService
2024-03-23 11:37:35,348 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SstFilteringService
2024-03-23 11:37:35,348 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SnapshotDeletingService
2024-03-23 11:37:35,348 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service MultipartUploadCleanupService
2024-03-23 11:37:35,348 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SnapshotDirectoryCleaningService
2024-03-23 11:37:35,349 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@1eae624e{ozoneManager,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2024-03-23 11:37:35,350 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@5418be12{HTTP/1.1, (http/1.1)}{0.0.0.0:15005}
2024-03-23 11:37:35,350 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-03-23 11:37:35,350 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2bb800b5{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2024-03-23 11:37:35,351 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@74300dba{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-03-23 11:37:35,352 [main] INFO  rocksdiff.RocksDBCheckpointDiffer (RocksDBCheckpointDiffer.java:close(310)) - Shutting down CompactionDagPruningService.
2024-03-23 11:37:35,354 [main] INFO  snapshot.SnapshotDiffManager (SnapshotDiffManager.java:closeExecutorService(1657)) - Shutting down executorService: 'SnapDiffExecutor'
2024-03-23 11:37:35,354 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SnapshotDiffCleanupService
2024-03-23 11:37:35,355 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(471)) - Stopping the HddsDatanodes
2024-03-23 11:37:35,360 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-03-23 11:37:35,361 [ForkJoinPool.commonPool-worker-1] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-892f8edf-b04c-4bbd-8c90-36214af705e8/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-a679f35d-8700-4aa7-8f9c-4f65e6fa09bc/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-4620390d-9a40-479a-99aa-5a4e8f975309/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-bff6b704-e145-4390-bc30-ec0553ef30a2/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-f5fc6349-2a63-4c91-99e3-3dbec7144f76/container.db]
2024-03-23 11:37:35,362 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-03-23 11:37:35,364 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-03-23 11:37:35,364 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-03-23 11:37:35,364 [main] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/data-0/hdds) is shutting down. 
2024-03-23 11:37:35,365 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-03-23 11:37:35,365 [ForkJoinPool.commonPool-worker-2] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-03-23 11:37:35,366 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-03-23 11:37:35,366 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-03-23 11:37:35,366 [ForkJoinPool.commonPool-worker-2] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/data-0/hdds) is shutting down. 
2024-03-23 11:37:35,366 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-03-23 11:37:35,367 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-03-23 11:37:35,367 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-03-23 11:37:35,367 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/data-0/hdds) is shutting down. 
2024-03-23 11:37:35,366 [ForkJoinPool.commonPool-worker-1] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-f5fc6349-2a63-4c91-99e3-3dbec7144f76/container.db from cache
2024-03-23 11:37:35,365 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/data-0/hdds, DS-4620390d-9a40-479a-99aa-5a4e8f975309) exiting.
2024-03-23 11:37:35,367 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-03-23 11:37:35,370 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-03-23 11:37:35,370 [main] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(416)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: close
2024-03-23 11:37:35,370 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(451)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-5/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-f5fc6349-2a63-4c91-99e3-3dbec7144f76/container.db for volume DS-f5fc6349-2a63-4c91-99e3-3dbec7144f76
2024-03-23 11:37:35,370 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/data-0/hdds, DS-a679f35d-8700-4aa7-8f9c-4f65e6fa09bc) exiting.
2024-03-23 11:37:35,370 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/data-0/hdds, DS-892f8edf-b04c-4bbd-8c90-36214af705e8) exiting.
2024-03-23 11:37:35,370 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-03-23 11:37:35,370 [00b25173-7757-4760-98a7-1e1aa18d5e2d-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC: shutdown
2024-03-23 11:37:35,371 [00b25173-7757-4760-98a7-1e1aa18d5e2d-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523: shutdown
2024-03-23 11:37:35,371 [00b25173-7757-4760-98a7-1e1aa18d5e2d-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-9B901D931523,id=00b25173-7757-4760-98a7-1e1aa18d5e2d
2024-03-23 11:37:35,371 [00b25173-7757-4760-98a7-1e1aa18d5e2d-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-ADC18A360ADC,id=00b25173-7757-4760-98a7-1e1aa18d5e2d
2024-03-23 11:37:35,371 [00b25173-7757-4760-98a7-1e1aa18d5e2d-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: shutdown 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-FollowerState
2024-03-23 11:37:35,371 [00b25173-7757-4760-98a7-1e1aa18d5e2d-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: shutdown 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-LeaderStateImpl
2024-03-23 11:37:35,371 [00b25173-7757-4760-98a7-1e1aa18d5e2d-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-PendingRequests: sendNotLeaderResponses
2024-03-23 11:37:35,372 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-ADC18A360ADC: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc/sm/snapshot.1_0
2024-03-23 11:37:35,372 [00b25173-7757-4760-98a7-1e1aa18d5e2d-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-StateMachineUpdater: set stopIndex = 0
2024-03-23 11:37:35,371 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-FollowerState was interrupted
2024-03-23 11:37:35,377 [ForkJoinPool.commonPool-worker-2] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(416)) - e3882025-ee77-4273-a30c-caf156427e83: close
2024-03-23 11:37:35,377 [00b25173-7757-4760-98a7-1e1aa18d5e2d-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-StateMachineUpdater: set stopIndex = 0
2024-03-23 11:37:35,377 [e3882025-ee77-4273-a30c-caf156427e83-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC: shutdown
2024-03-23 11:37:35,377 [e3882025-ee77-4273-a30c-caf156427e83-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-ADC18A360ADC,id=e3882025-ee77-4273-a30c-caf156427e83
2024-03-23 11:37:35,377 [e3882025-ee77-4273-a30c-caf156427e83-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - e3882025-ee77-4273-a30c-caf156427e83: shutdown e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-FollowerState
2024-03-23 11:37:35,377 [e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-FollowerState was interrupted
2024-03-23 11:37:35,378 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-ADC18A360ADC: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc/sm/snapshot.1_0 took: 7 ms
2024-03-23 11:37:35,378 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-StateMachineUpdater: Took a snapshot at index 0
2024-03-23 11:37:35,378 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-23 11:37:35,378 [00b25173-7757-4760-98a7-1e1aa18d5e2d-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC: applyIndex: 0
2024-03-23 11:37:35,374 [Thread-1104] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 6dd6d2ae-0ce2-42d8-b4ff-b62997ce329b Close channels
2024-03-23 11:37:35,374 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(416)) - 5b4c27d6-a533-4766-a648-a869ad76920c: close
2024-03-23 11:37:35,374 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-03-23 11:37:35,374 [Thread-1103] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - e3882025-ee77-4273-a30c-caf156427e83 Close channels
2024-03-23 11:37:35,379 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-03-23 11:37:35,379 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-23 11:37:35,378 [e3882025-ee77-4273-a30c-caf156427e83-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-StateMachineUpdater: set stopIndex = 0
2024-03-23 11:37:35,377 [e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-ADC18A360ADC: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc/sm/snapshot.1_0
2024-03-23 11:37:35,377 [e3882025-ee77-4273-a30c-caf156427e83-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE: shutdown
2024-03-23 11:37:35,377 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - e3882025-ee77-4273-a30c-caf156427e83: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-03-23 11:37:35,382 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-03-23 11:37:35,382 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: shutdown server GrpcServerProtocolService now
2024-03-23 11:37:35,377 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-9B901D931523: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/1448d56d-848d-4e5a-9e97-9b901d931523/sm/snapshot.1_0
2024-03-23 11:37:35,383 [5b4c27d6-a533-4766-a648-a869ad76920c-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC: shutdown
2024-03-23 11:37:35,382 [Thread-1109] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d Close channels
2024-03-23 11:37:35,382 [e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-ADC18A360ADC: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc/sm/snapshot.1_0 took: 5 ms
2024-03-23 11:37:35,382 [e3882025-ee77-4273-a30c-caf156427e83-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-3A831E3069BE,id=e3882025-ee77-4273-a30c-caf156427e83
2024-03-23 11:37:35,383 [e3882025-ee77-4273-a30c-caf156427e83-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - e3882025-ee77-4273-a30c-caf156427e83: shutdown e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-LeaderStateImpl
2024-03-23 11:37:35,383 [e3882025-ee77-4273-a30c-caf156427e83-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-PendingRequests: sendNotLeaderResponses
2024-03-23 11:37:35,383 [e3882025-ee77-4273-a30c-caf156427e83-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-StateMachineUpdater: set stopIndex = 0
2024-03-23 11:37:35,382 [5b4c27d6-a533-4766-a648-a869ad76920c-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB: shutdown
2024-03-23 11:37:35,383 [5b4c27d6-a533-4766-a648-a869ad76920c-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-95313CE3ADAB,id=5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:37:35,384 [5b4c27d6-a533-4766-a648-a869ad76920c-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 5b4c27d6-a533-4766-a648-a869ad76920c: shutdown 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-LeaderStateImpl
2024-03-23 11:37:35,384 [5b4c27d6-a533-4766-a648-a869ad76920c-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-PendingRequests: sendNotLeaderResponses
2024-03-23 11:37:35,384 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-95313CE3ADAB: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/4ebe2e72-678e-491b-9c18-95313ce3adab/sm/snapshot.1_0
2024-03-23 11:37:35,384 [5b4c27d6-a533-4766-a648-a869ad76920c-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-StateMachineUpdater: set stopIndex = 0
2024-03-23 11:37:35,381 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(638)) - Ozone container server stopped.
2024-03-23 11:37:35,384 [grpc-default-executor-5] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(121)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: APPEND_ENTRIES onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2024-03-23 11:37:35,379 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 5b4c27d6-a533-4766-a648-a869ad76920c: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-03-23 11:37:35,384 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-95313CE3ADAB: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/4ebe2e72-678e-491b-9c18-95313ce3adab/sm/snapshot.1_0 took: 0 ms
2024-03-23 11:37:35,385 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-StateMachineUpdater: Took a snapshot at index 0
2024-03-23 11:37:35,385 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-23 11:37:35,383 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-3A831E3069BE: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/07524b35-b4dd-487c-8fd9-3a831e3069be/sm/snapshot.1_0
2024-03-23 11:37:35,383 [e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-StateMachineUpdater: Took a snapshot at index 0
2024-03-23 11:37:35,385 [e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-23 11:37:35,385 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-3A831E3069BE: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/ratis/07524b35-b4dd-487c-8fd9-3a831e3069be/sm/snapshot.1_0 took: 2 ms
2024-03-23 11:37:35,386 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-StateMachineUpdater: Took a snapshot at index 0
2024-03-23 11:37:35,386 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-23 11:37:35,386 [grpc-default-executor-3] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(121)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: APPEND_ENTRIES onError, lastRequest: 5b4c27d6-a533-4766-a648-a869ad76920c->00b25173-7757-4760-98a7-1e1aa18d5e2d#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "00b25173-7757-4760-98a7-1e1aa18d5e2d"
address: "10.1.0.5:15034"
dataStreamAddress: "10.1.0.5:15035"
clientAddress: "10.1.0.5:15032"
adminAddress: "10.1.0.5:15033"
startupRole: FOLLOWER
,id: "5b4c27d6-a533-4766-a648-a869ad76920c"
address: "10.1.0.5:15025"
priority: 1
dataStreamAddress: "10.1.0.5:15026"
clientAddress: "10.1.0.5:15023"
adminAddress: "10.1.0.5:15024"
startupRole: FOLLOWER
,id: "e3882025-ee77-4273-a30c-caf156427e83"
address: "10.1.0.5:15016"
dataStreamAddress: "10.1.0.5:15017"
clientAddress: "10.1.0.5:15014"
adminAddress: "10.1.0.5:15015"
startupRole: FOLLOWER
, old:): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2024-03-23 11:37:35,386 [e3882025-ee77-4273-a30c-caf156427e83-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(427)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE: applyIndex: 0
2024-03-23 11:37:35,383 [5b4c27d6-a533-4766-a648-a869ad76920c-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-ADC18A360ADC,id=5b4c27d6-a533-4766-a648-a869ad76920c
2024-03-23 11:37:35,386 [5b4c27d6-a533-4766-a648-a869ad76920c-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 5b4c27d6-a533-4766-a648-a869ad76920c: shutdown 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-LeaderStateImpl
2024-03-23 11:37:35,386 [5b4c27d6-a533-4766-a648-a869ad76920c-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB: applyIndex: 0
2024-03-23 11:37:35,386 [Thread-1110] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 5b4c27d6-a533-4766-a648-a869ad76920c Close channels
2024-03-23 11:37:35,385 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-9B901D931523: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/ratis/1448d56d-848d-4e5a-9e97-9b901d931523/sm/snapshot.1_0 took: 8 ms
2024-03-23 11:37:35,388 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-StateMachineUpdater: Took a snapshot at index 0
2024-03-23 11:37:35,388 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-23 11:37:35,388 [00b25173-7757-4760-98a7-1e1aa18d5e2d-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523: applyIndex: 0
2024-03-23 11:37:35,388 [grpc-default-executor-4] WARN  server.GrpcLogAppender (LogUtils.java:warn(121)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC->00b25173-7757-4760-98a7-1e1aa18d5e2d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2024-03-23 11:37:35,389 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(533)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC->00b25173-7757-4760-98a7-1e1aa18d5e2d-GrpcLogAppender is already stopped
2024-03-23 11:37:35,389 [00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-23 11:37:35,393 [e3882025-ee77-4273-a30c-caf156427e83-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(427)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC: applyIndex: 0
2024-03-23 11:37:35,400 [5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-23 11:37:35,401 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC->00b25173-7757-4760-98a7-1e1aa18d5e2d-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC->00b25173-7757-4760-98a7-1e1aa18d5e2d-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-03-23 11:37:35,401 [e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-23 11:37:35,401 [5b4c27d6-a533-4766-a648-a869ad76920c-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-PendingRequests: sendNotLeaderResponses
2024-03-23 11:37:35,401 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC->e3882025-ee77-4273-a30c-caf156427e83-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC->e3882025-ee77-4273-a30c-caf156427e83-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-03-23 11:37:35,405 [5b4c27d6-a533-4766-a648-a869ad76920c-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-StateMachineUpdater: set stopIndex = 0
2024-03-23 11:37:35,405 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-ADC18A360ADC: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc/sm/snapshot.1_0
2024-03-23 11:37:35,405 [Thread-1112] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d Close channels
2024-03-23 11:37:35,405 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-ADC18A360ADC: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/ratis/2d76b7c9-57b7-4fbf-bb1d-adc18a360adc/sm/snapshot.1_0 took: 1 ms
2024-03-23 11:37:35,406 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-StateMachineUpdater: Took a snapshot at index 0
2024-03-23 11:37:35,406 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-23 11:37:35,410 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - e3882025-ee77-4273-a30c-caf156427e83: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-03-23 11:37:35,410 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - e3882025-ee77-4273-a30c-caf156427e83: shutdown server GrpcServerProtocolService now
2024-03-23 11:37:35,410 [grpc-default-executor-4] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(217)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC->00b25173-7757-4760-98a7-1e1aa18d5e2d-GrpcLogAppender: Follower failed (request=null, errorCount=1); keep nextIndex (1) unchanged and retry.
2024-03-23 11:37:35,411 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - e3882025-ee77-4273-a30c-caf156427e83: Completed APPEND_ENTRIES, lastRequest: 5b4c27d6-a533-4766-a648-a869ad76920c->e3882025-ee77-4273-a30c-caf156427e83#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "00b25173-7757-4760-98a7-1e1aa18d5e2d"
address: "10.1.0.5:15034"
dataStreamAddress: "10.1.0.5:15035"
clientAddress: "10.1.0.5:15032"
adminAddress: "10.1.0.5:15033"
startupRole: FOLLOWER
,id: "5b4c27d6-a533-4766-a648-a869ad76920c"
address: "10.1.0.5:15025"
priority: 1
dataStreamAddress: "10.1.0.5:15026"
clientAddress: "10.1.0.5:15023"
adminAddress: "10.1.0.5:15024"
startupRole: FOLLOWER
,id: "e3882025-ee77-4273-a30c-caf156427e83"
address: "10.1.0.5:15016"
dataStreamAddress: "10.1.0.5:15017"
clientAddress: "10.1.0.5:15014"
adminAddress: "10.1.0.5:15015"
startupRole: FOLLOWER
, old:)
2024-03-23 11:37:35,411 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - e3882025-ee77-4273-a30c-caf156427e83: Completed APPEND_ENTRIES, lastReply: null
2024-03-23 11:37:35,410 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - e3882025-ee77-4273-a30c-caf156427e83: Completed APPEND_ENTRIES, lastRequest: null
2024-03-23 11:37:35,411 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - e3882025-ee77-4273-a30c-caf156427e83: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "5b4c27d6-a533-4766-a648-a869ad76920c"
  replyId: "e3882025-ee77-4273-a30c-caf156427e83"
  raftGroupId {
    id: "-v\267\311W\267O\277\273\035\255\301\2126\n\334"
  }
  callId: 16
  success: true
}
term: 1
nextIndex: 1
matchIndex: 18446744073709551615
isHearbeat: true

2024-03-23 11:37:35,411 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(533)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC->e3882025-ee77-4273-a30c-caf156427e83-GrpcLogAppender is already stopped
2024-03-23 11:37:35,412 [5b4c27d6-a533-4766-a648-a869ad76920c-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC: applyIndex: 0
2024-03-23 11:37:35,412 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC->e3882025-ee77-4273-a30c-caf156427e83-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-23 11:37:35,412 [5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-23 11:37:35,415 [Thread-1117] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - e3882025-ee77-4273-a30c-caf156427e83 Close channels
2024-03-23 11:37:35,415 [e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-23 11:37:35,416 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: shutdown server GrpcServerProtocolService successfully
2024-03-23 11:37:35,416 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-03-23 11:37:35,417 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 5b4c27d6-a533-4766-a648-a869ad76920c: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-03-23 11:37:35,418 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 5b4c27d6-a533-4766-a648-a869ad76920c: shutdown server GrpcServerProtocolService now
2024-03-23 11:37:35,420 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@13eb3b5c{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-03-23 11:37:35,420 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - e3882025-ee77-4273-a30c-caf156427e83: shutdown server GrpcServerProtocolService successfully
2024-03-23 11:37:35,421 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - e3882025-ee77-4273-a30c-caf156427e83: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-03-23 11:37:35,420 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 5b4c27d6-a533-4766-a648-a869ad76920c: shutdown server GrpcServerProtocolService successfully
2024-03-23 11:37:35,421 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 5b4c27d6-a533-4766-a648-a869ad76920c: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-03-23 11:37:35,421 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@3da18ccf{HTTP/1.1, (http/1.1)}{0.0.0.0:15047}
2024-03-23 11:37:35,421 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-03-23 11:37:35,426 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-03-23 11:37:35,427 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@57cc9d6f{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2024-03-23 11:37:35,428 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@6d8ee197{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-03-23 11:37:35,428 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - e3882025-ee77-4273-a30c-caf156427e83: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-03-23 11:37:35,429 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 5b4c27d6-a533-4766-a648-a869ad76920c: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-03-23 11:37:35,429 [ForkJoinPool.commonPool-worker-1] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-03-23 11:37:35,431 [ForkJoinPool.commonPool-worker-1] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15048
2024-03-23 11:37:35,432 [IPC Server listener on 15048] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15048
2024-03-23 11:37:35,433 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-03-23 11:37:35,440 [00b25173-7757-4760-98a7-1e1aa18d5e2d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xf876a6fc, L:/0.0.0.0:15035] CLOSE
2024-03-23 11:37:35,441 [00b25173-7757-4760-98a7-1e1aa18d5e2d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xf876a6fc, L:/0.0.0.0:15035] INACTIVE
2024-03-23 11:37:35,441 [00b25173-7757-4760-98a7-1e1aa18d5e2d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xf876a6fc, L:/0.0.0.0:15035] UNREGISTERED
2024-03-23 11:37:35,455 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 2 milliseconds to process 1 existing database records.
2024-03-23 11:37:35,457 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 2 containers.
2024-03-23 11:37:35,457 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:35,457 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:35,457 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:35,457 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:35,457 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:35,457 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:35,457 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:35,463 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-03-23 11:37:35,463 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-03-23 11:37:35,463 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-03-23 11:37:35,464 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/data-0/hdds) is shutting down. 
2024-03-23 11:37:35,464 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-03-23 11:37:35,464 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/data-0/hdds, DS-bff6b704-e145-4390-bc30-ec0553ef30a2) exiting.
2024-03-23 11:37:35,464 [5b4c27d6-a533-4766-a648-a869ad76920c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xbebc860f, L:/0.0.0.0:15026] CLOSE
2024-03-23 11:37:35,464 [5b4c27d6-a533-4766-a648-a869ad76920c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xbebc860f, L:/0.0.0.0:15026] INACTIVE
2024-03-23 11:37:35,465 [5b4c27d6-a533-4766-a648-a869ad76920c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xbebc860f, L:/0.0.0.0:15026] UNREGISTERED
2024-03-23 11:37:35,470 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(416)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: close
2024-03-23 11:37:35,470 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-03-23 11:37:35,478 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-03-23 11:37:35,478 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: shutdown server GrpcServerProtocolService now
2024-03-23 11:37:35,479 [e3882025-ee77-4273-a30c-caf156427e83-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x60480bcf, L:/0.0.0.0:15017] CLOSE
2024-03-23 11:37:35,479 [e3882025-ee77-4273-a30c-caf156427e83-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x60480bcf, L:/0.0.0.0:15017] INACTIVE
2024-03-23 11:37:35,479 [e3882025-ee77-4273-a30c-caf156427e83-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x60480bcf, L:/0.0.0.0:15017] UNREGISTERED
2024-03-23 11:37:35,487 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: shutdown server GrpcServerProtocolService successfully
2024-03-23 11:37:35,487 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-03-23 11:37:35,491 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - bb4f2f6f-344d-4a57-aba3-69abe2cb722c: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-03-23 11:37:35,497 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa90e0545, L:/0.0.0.0:15044] CLOSE
2024-03-23 11:37:35,497 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa90e0545, L:/0.0.0.0:15044] INACTIVE
2024-03-23 11:37:35,497 [bb4f2f6f-344d-4a57-aba3-69abe2cb722c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa90e0545, L:/0.0.0.0:15044] UNREGISTERED
2024-03-23 11:37:35,506 [JvmPauseMonitor6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-bb4f2f6f-344d-4a57-aba3-69abe2cb722c: Stopped
2024-03-23 11:37:35,520 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-23 11:37:35,520 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-23 11:37:35,520 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-03-23 11:37:35,525 [Recon-SyncOM-2] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(422)) - com.google.protobuf.ServiceException: java.io.EOFException: End of File Exception between local host is: "fv-az1381-309/10.1.0.5"; destination host is: "localhost":15004; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException, while invoking $Proxy77.submitRequest over nodeId=null,nodeAddress=localhost:15004. Trying to failover after sleeping for 2000ms. Current retry count: 0.
2024-03-23 11:37:35,929 [e3882025-ee77-4273-a30c-caf156427e83-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - e3882025-ee77-4273-a30c-caf156427e83@group-3A831E3069BE-SegmentedRaftLogWorker close()
2024-03-23 11:37:36,111 [00b25173-7757-4760-98a7-1e1aa18d5e2d-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-9B901D931523-SegmentedRaftLogWorker close()
2024-03-23 11:37:36,117 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-03-23 11:37:36,142 [5b4c27d6-a533-4766-a648-a869ad76920c-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-ADC18A360ADC-SegmentedRaftLogWorker close()
2024-03-23 11:37:36,175 [e3882025-ee77-4273-a30c-caf156427e83-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - e3882025-ee77-4273-a30c-caf156427e83@group-ADC18A360ADC-SegmentedRaftLogWorker close()
2024-03-23 11:37:36,175 [JvmPauseMonitor3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-e3882025-ee77-4273-a30c-caf156427e83: Stopped
2024-03-23 11:37:36,175 [00b25173-7757-4760-98a7-1e1aa18d5e2d-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 00b25173-7757-4760-98a7-1e1aa18d5e2d@group-ADC18A360ADC-SegmentedRaftLogWorker close()
2024-03-23 11:37:36,176 [JvmPauseMonitor5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-00b25173-7757-4760-98a7-1e1aa18d5e2d: Stopped
2024-03-23 11:37:36,177 [5b4c27d6-a533-4766-a648-a869ad76920c-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 5b4c27d6-a533-4766-a648-a869ad76920c@group-95313CE3ADAB-SegmentedRaftLogWorker close()
2024-03-23 11:37:36,178 [JvmPauseMonitor4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-5b4c27d6-a533-4766-a648-a869ad76920c: Stopped
2024-03-23 11:37:36,460 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 2 milliseconds to process 1 existing database records.
2024-03-23 11:37:36,461 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 2 containers.
2024-03-23 11:37:36,461 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:36,461 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:36,461 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:36,461 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:36,461 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:36,461 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:36,462 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:37,117 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-03-23 11:37:37,464 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 2 milliseconds to process 1 existing database records.
2024-03-23 11:37:37,467 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 3 milliseconds for processing 2 containers.
2024-03-23 11:37:37,467 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-23 11:37:37,467 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-23 11:37:37,467 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:37,467 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:37,467 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-23 11:37:37,467 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-23 11:37:37,467 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-23 11:37:37,509 [ForkJoinPool.commonPool-worker-1] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-892f8edf-b04c-4bbd-8c90-36214af705e8/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-a679f35d-8700-4aa7-8f9c-4f65e6fa09bc/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-4620390d-9a40-479a-99aa-5a4e8f975309/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-bff6b704-e145-4390-bc30-ec0553ef30a2/container.db]
2024-03-23 11:37:37,511 [ForkJoinPool.commonPool-worker-1] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-bff6b704-e145-4390-bc30-ec0553ef30a2/container.db from cache
2024-03-23 11:37:37,511 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(451)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-4/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-bff6b704-e145-4390-bc30-ec0553ef30a2/container.db for volume DS-bff6b704-e145-4390-bc30-ec0553ef30a2
2024-03-23 11:37:37,512 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-03-23 11:37:37,512 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-03-23 11:37:37,513 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(638)) - Ozone container server stopped.
2024-03-23 11:37:37,515 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@43fd77e8{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-03-23 11:37:37,515 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@5d7ed410{HTTP/1.1, (http/1.1)}{0.0.0.0:15038}
2024-03-23 11:37:37,516 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-03-23 11:37:37,516 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@20a05f29{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2024-03-23 11:37:37,518 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@38f4a5f2{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-03-23 11:37:37,519 [ForkJoinPool.commonPool-worker-1] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-03-23 11:37:37,519 [ForkJoinPool.commonPool-worker-1] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15039
2024-03-23 11:37:37,520 [IPC Server listener on 15039] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15039
2024-03-23 11:37:37,520 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-03-23 11:37:37,526 [Recon-SyncOM-2] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(422)) - com.google.protobuf.ServiceException: java.net.ConnectException: Call From fv-az1381-309/10.1.0.5 to localhost:15004 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy77.submitRequest over nodeId=null,nodeAddress=localhost:15004 after 1 failover attempts. Trying to failover after sleeping for 4000ms. Current retry count: 1.
2024-03-23 11:37:38,064 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5) moved to stale state. Finalizing its pipelines [PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc, PipelineID=07524b35-b4dd-487c-8fd9-3a831e3069be]
2024-03-23 11:37:38,064 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode e3882025-ee77-4273-a30c-caf156427e83(fv-az1381-309/10.1.0.5) moved to stale state. Finalizing its pipelines [PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc, PipelineID=07524b35-b4dd-487c-8fd9-3a831e3069be]
2024-03-23 11:37:38,065 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc moved to CLOSED state
2024-03-23 11:37:38,065 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc moved to CLOSED state
2024-03-23 11:37:38,065 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=07524b35-b4dd-487c-8fd9-3a831e3069be moved to CLOSED state
2024-03-23 11:37:38,065 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5) moved to stale state. Finalizing its pipelines [PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc, PipelineID=1448d56d-848d-4e5a-9e97-9b901d931523]
2024-03-23 11:37:38,065 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=07524b35-b4dd-487c-8fd9-3a831e3069be moved to CLOSED state
2024-03-23 11:37:38,066 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=1448d56d-848d-4e5a-9e97-9b901d931523 moved to CLOSED state
2024-03-23 11:37:38,067 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 4 pipelines in house.
2024-03-23 11:37:38,069 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 4 milliseconds.
2024-03-23 11:37:38,071 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 00b25173-7757-4760-98a7-1e1aa18d5e2d(fv-az1381-309/10.1.0.5) moved to stale state. Finalizing its pipelines [PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc, PipelineID=1448d56d-848d-4e5a-9e97-9b901d931523]
2024-03-23 11:37:38,072 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 4 pipelines in house.
2024-03-23 11:37:38,075 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 4 milliseconds.
2024-03-23 11:37:38,118 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-03-23 11:37:38,164 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5) moved to stale state. Finalizing its pipelines [PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc, PipelineID=4ebe2e72-678e-491b-9c18-95313ce3adab]
2024-03-23 11:37:38,164 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 5b4c27d6-a533-4766-a648-a869ad76920c(fv-az1381-309/10.1.0.5) moved to stale state. Finalizing its pipelines [PipelineID=2d76b7c9-57b7-4fbf-bb1d-adc18a360adc, PipelineID=4ebe2e72-678e-491b-9c18-95313ce3adab]
2024-03-23 11:37:38,165 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=4ebe2e72-678e-491b-9c18-95313ce3adab moved to CLOSED state
2024-03-23 11:37:38,165 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=4ebe2e72-678e-491b-9c18-95313ce3adab moved to CLOSED state
2024-03-23 11:37:38,166 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 4 pipelines in house.
2024-03-23 11:37:38,168 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 4 milliseconds.
2024-03-23 11:37:38,178 [ForkJoinPool.commonPool-worker-2] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-892f8edf-b04c-4bbd-8c90-36214af705e8/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-a679f35d-8700-4aa7-8f9c-4f65e6fa09bc/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-4620390d-9a40-479a-99aa-5a4e8f975309/container.db]
2024-03-23 11:37:38,180 [ForkJoinPool.commonPool-worker-2] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-892f8edf-b04c-4bbd-8c90-36214af705e8/container.db from cache
2024-03-23 11:37:38,180 [ForkJoinPool.commonPool-worker-2] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(451)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-1/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-892f8edf-b04c-4bbd-8c90-36214af705e8/container.db for volume DS-892f8edf-b04c-4bbd-8c90-36214af705e8
2024-03-23 11:37:38,181 [main] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-a679f35d-8700-4aa7-8f9c-4f65e6fa09bc/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-4620390d-9a40-479a-99aa-5a4e8f975309/container.db]
2024-03-23 11:37:38,181 [ForkJoinPool.commonPool-worker-0] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-a679f35d-8700-4aa7-8f9c-4f65e6fa09bc/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-4620390d-9a40-479a-99aa-5a4e8f975309/container.db]
2024-03-23 11:37:38,181 [ForkJoinPool.commonPool-worker-2] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-03-23 11:37:38,182 [main] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-4620390d-9a40-479a-99aa-5a4e8f975309/container.db from cache
2024-03-23 11:37:38,182 [main] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(451)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-3/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-4620390d-9a40-479a-99aa-5a4e8f975309/container.db for volume DS-4620390d-9a40-479a-99aa-5a4e8f975309
2024-03-23 11:37:38,182 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-03-23 11:37:38,183 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-03-23 11:37:38,186 [ForkJoinPool.commonPool-worker-0] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-a679f35d-8700-4aa7-8f9c-4f65e6fa09bc/container.db from cache
2024-03-23 11:37:38,186 [ForkJoinPool.commonPool-worker-0] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(451)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3471a041-186a-46a4-b264-8f64b32f15a1/ozone-meta/datanode-2/data-0/hdds/3471a041-186a-46a4-b264-8f64b32f15a1/DS-a679f35d-8700-4aa7-8f9c-4f65e6fa09bc/container.db for volume DS-a679f35d-8700-4aa7-8f9c-4f65e6fa09bc
2024-03-23 11:37:38,187 [ForkJoinPool.commonPool-worker-2] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-03-23 11:37:38,187 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-03-23 11:37:38,187 [ForkJoinPool.commonPool-worker-2] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(638)) - Ozone container server stopped.
2024-03-23 11:37:38,189 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@67c19ae2{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-03-23 11:37:38,189 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-03-23 11:37:38,190 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(638)) - Ozone container server stopped.
2024-03-23 11:37:38,190 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@2fa64353{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-03-23 11:37:38,191 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(638)) - Ozone container server stopped.
2024-03-23 11:37:38,191 [ForkJoinPool.commonPool-worker-2] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@603588c3{HTTP/1.1, (http/1.1)}{0.0.0.0:15011}
2024-03-23 11:37:38,192 [ForkJoinPool.commonPool-worker-2] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-03-23 11:37:38,192 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@714a1a49{HTTP/1.1, (http/1.1)}{0.0.0.0:15029}
2024-03-23 11:37:38,193 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-03-23 11:37:38,193 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7ed49246{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2024-03-23 11:37:38,194 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2cedfe5c{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-03-23 11:37:38,193 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@3156d7ed{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2024-03-23 11:37:38,193 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@160cfa74{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-03-23 11:37:38,195 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7319b3ec{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-03-23 11:37:38,195 [ForkJoinPool.commonPool-worker-2] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-03-23 11:37:38,195 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-03-23 11:37:38,196 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15030
2024-03-23 11:37:38,195 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@6c40eb48{HTTP/1.1, (http/1.1)}{0.0.0.0:15020}
2024-03-23 11:37:38,197 [ForkJoinPool.commonPool-worker-0] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-03-23 11:37:38,196 [ForkJoinPool.commonPool-worker-2] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15012
2024-03-23 11:37:38,198 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5cc6e13{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2024-03-23 11:37:38,198 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-03-23 11:37:38,197 [IPC Server listener on 15030] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15030
2024-03-23 11:37:38,199 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@238142bd{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-03-23 11:37:38,199 [IPC Server listener on 15012] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15012
2024-03-23 11:37:38,200 [ForkJoinPool.commonPool-worker-0] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-03-23 11:37:38,200 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-03-23 11:37:38,201 [ForkJoinPool.commonPool-worker-0] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15021
2024-03-23 11:37:38,202 [IPC Server listener on 15021] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15021
2024-03-23 11:37:38,202 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-03-23 11:37:38,202 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(486)) - Stopping the StorageContainerManager
2024-03-23 11:37:38,202 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1653)) - Container Balancer is not running.
2024-03-23 11:37:38,203 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stopReplicationManager(1786)) - Stopping Replication Manager Service.
2024-03-23 11:37:38,203 [main] INFO  replication.ReplicationManager (ReplicationManager.java:stop(328)) - Stopping Replication Monitor Thread.
2024-03-23 11:37:38,203 [UnderReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(180)) - UnderReplicatedProcessor interrupted. Exiting...
2024-03-23 11:37:38,203 [OverReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(180)) - OverReplicatedProcessor interrupted. Exiting...
2024-03-23 11:37:38,204 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(935)) - Replication Monitor Thread is stopped
2024-03-23 11:37:38,204 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1662)) - Stopping the Datanode Admin Monitor.
2024-03-23 11:37:38,204 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1669)) - Stopping datanode service RPC server
2024-03-23 11:37:38,204 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(425)) - Stopping the RPC server for DataNodes
2024-03-23 11:37:38,204 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15002
2024-03-23 11:37:38,211 [IPC Server listener on 15002] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15002
2024-03-23 11:37:38,212 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-03-23 11:37:38,264 [SCMHeartbeatProcessor-0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(878)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2024-03-23 11:37:38,264 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5) moved to stale state. Finalizing its pipelines []
2024-03-23 11:37:38,264 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode bb4f2f6f-344d-4a57-aba3-69abe2cb722c(fv-az1381-309/10.1.0.5) moved to stale state. Finalizing its pipelines []
2024-03-23 11:37:38,264 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1677)) - Stopping block service RPC server
2024-03-23 11:37:38,265 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(171)) - Stopping the RPC server for Block Protocol
2024-03-23 11:37:38,265 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15001
2024-03-23 11:37:38,266 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 4 pipelines in house.
2024-03-23 11:37:38,269 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 5 milliseconds.
2024-03-23 11:37:38,272 [IPC Server listener on 15001] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15001
2024-03-23 11:37:38,272 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-03-23 11:37:38,273 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1684)) - Stopping the StorageContainerLocationProtocol RPC server
2024-03-23 11:37:38,273 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(213)) - Stopping the RPC server for Client Protocol
2024-03-23 11:37:38,273 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15000
2024-03-23 11:37:38,277 [IPC Server listener on 15000] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15000
2024-03-23 11:37:38,278 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1691)) - Stopping Storage Container Manager HTTP server.
2024-03-23 11:37:38,278 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-03-23 11:37:38,279 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@4d484961{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2024-03-23 11:37:38,279 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@bf70ce5{HTTP/1.1, (http/1.1)}{0.0.0.0:15003}
2024-03-23 11:37:38,280 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-03-23 11:37:38,280 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@1f9af742{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2024-03-23 11:37:38,280 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@749ebc39{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-03-23 11:37:38,281 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1699)) - Stopping SCM LayoutVersionManager Service.
2024-03-23 11:37:38,281 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1711)) - Stopping Block Manager Service.
2024-03-23 11:37:38,281 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SCMBlockDeletingService
2024-03-23 11:37:38,282 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SCMBlockDeletingService
2024-03-23 11:37:38,282 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1731)) - Stopping SCM Event Queue.
2024-03-23 11:37:38,284 [JvmPauseMonitor0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-c49b860f-8bf3-42e8-8266-c06a9572c5ee: Stopped
2024-03-23 11:37:38,284 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1742)) - Stopping SCM HA services.
2024-03-23 11:37:38,284 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(152)) - Stopping RatisPipelineUtilsThread.
2024-03-23 11:37:38,284 [RatisPipelineUtilsThread-0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(183)) - RatisPipelineUtilsThread is interrupted.
2024-03-23 11:37:38,285 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(128)) - Stopping BackgroundPipelineScrubber Service.
2024-03-23 11:37:38,285 [BackgroundPipelineScrubber] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(112)) - BackgroundPipelineScrubber is interrupted, exit
2024-03-23 11:37:38,285 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2024-03-23 11:37:38,287 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2024-03-23 11:37:38,287 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2024-03-23 11:37:38,287 [main] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(148)) - RatisPipelineUtilsThread is not running, just ignore.
2024-03-23 11:37:38,287 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(123)) - BackgroundPipelineScrubber Service is not running, skip stop.
2024-03-23 11:37:38,288 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(128)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2024-03-23 11:37:38,288 [ExpiredContainerReplicaOpScrubber] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(112)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2024-03-23 11:37:38,288 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SCMBlockDeletingService
2024-03-23 11:37:38,288 [main] INFO  replication.ReplicationManager (ReplicationManager.java:stop(338)) - Replication Monitor Thread is not running.
2024-03-23 11:37:38,288 [main] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(327)) - Cannot stop Container Balancer because it's not running or stopping
2024-03-23 11:37:38,288 [LeaseManager#LeaseMonitor] WARN  lease.LeaseManager (LeaseManager.java:run(287)) - Lease manager is interrupted. Shutting down...
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1039)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1328)
	at java.util.concurrent.Semaphore.tryAcquire(Semaphore.java:409)
	at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:285)
	at java.lang.Thread.run(Thread.java:750)
2024-03-23 11:37:38,289 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1777)) - Stopping SCM MetadataStore.
2024-03-23 11:37:38,290 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopRecon(501)) - Stopping Recon
2024-03-23 11:37:38,290 [main] INFO  recon.ReconServer (ReconServer.java:stop(235)) - Stopping Recon server
2024-03-23 11:37:38,300 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@741fada7{recon,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.5.0-SNAPSHOT/ozone-recon-1.5.0-SNAPSHOT.jar!/webapps/recon}
2024-03-23 11:37:38,300 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@4af133e4{HTTP/1.1, (http/1.1)}{0.0.0.0:15008}
2024-03-23 11:37:38,300 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-03-23 11:37:38,301 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@52c1775c{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.5.0-SNAPSHOT/ozone-recon-1.5.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2024-03-23 11:37:38,301 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@24111a03{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-03-23 11:37:38,302 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(425)) - Stopping the RPC server for DataNodes
2024-03-23 11:37:38,302 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15009
2024-03-23 11:37:38,304 [IPC Server listener on 15009] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15009
2024-03-23 11:37:38,306 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-03-23 11:37:38,364 [SCMHeartbeatProcessor-0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(878)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2024-03-23 11:37:38,365 [main] INFO  scm.ReconScmTask (ReconScmTask.java:stop(72)) - Stopping PipelineSyncTask Thread.
2024-03-23 11:37:38,365 [main] INFO  scm.ReconScmTask (ReconScmTask.java:stop(72)) - Stopping ContainerHealthTask Thread.
2024-03-23 11:37:38,365 [main] INFO  scm.ReconScmTask (ReconScmTask.java:stop(72)) - Stopping ContainerSizeCountTask Thread.
2024-03-23 11:37:38,365 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:stop(462)) - Stopping SCM Event Queue.
2024-03-23 11:37:38,365 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:stop(470)) - Flushing container replica history to DB.
2024-03-23 11:37:38,369 [main] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:stop(303)) - Stopping Ozone Manager Service Provider.
2024-03-23 11:37:38,369 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:stop(230)) - Stopping Recon Task Controller.
2024-03-23 11:37:38,369 [ContainerSizeCountTask] INFO  tasks.ContainerSizeCountTask (ContainerSizeCountTask.java:process(200)) - Completed a 'process' run of ContainerSizeCountTask.
2024-03-23 11:37:38,369 [ContainerSizeCountTask] INFO  tasks.ContainerSizeCountTask (ContainerSizeCountTask.java:run(114)) - Elapsed Time in milliseconds for Process() execution: 4
2024-03-23 11:37:38,371 [main] INFO  recon.ReconServer (ReconServer.java:stop(260)) - Closing Recon Container Key DB.
2024-03-23 11:37:38,371 [Recon-SyncOM-2] WARN  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(528)) - Unable to get and apply delta updates from OM.
2024-03-23 11:37:38,372 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(537)) - Obtaining full snapshot from Ozone Manager
2024-03-23 11:37:38,373 [JvmPauseMonitor2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-Recon: Stopped
2024-03-23 11:37:38,374 [Recon-SyncOM-2] ERROR impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getOzoneManagerDBSnapshot(373)) - Unable to obtain Ozone Manager DB Snapshot. 
java.nio.channels.ClosedByInterruptException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:658)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:191)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:600)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:652)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:773)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:347)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1632)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1410)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:250)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:132)
	at com.sun.proxy.$Proxy77.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor106.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:433)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:166)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:158)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:96)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:362)
	at com.sun.proxy.$Proxy77.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransport.submitRequest(Hadoop3OmTransport.java:80)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:345)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceList(OzoneManagerProtocolClientSideTranslatorPB.java:1801)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerSnapshotUrl(OzoneManagerServiceProviderImpl.java:322)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:357)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:551)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:531)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:355)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:387)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:539)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$startSyncDataFromOM$0(OzoneManagerServiceProviderImpl.java:267)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-23 11:37:38,374 [Recon-SyncOM-2] ERROR impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:updateReconOmDBWithNewSnapshot(400)) - Null snapshot location got from OM.
2024-03-23 11:37:38,572 [shutdown-hook-0] INFO  recon.ReconServer (StringUtils.java:lambda$startupShutdownMessage$0(144)) - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ReconServer at fv-az1381-309/10.1.0.5
************************************************************/
