2024-03-25 19:42:01,896 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(143)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-25 19:42:02,225 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(143)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-25 19:42:02,229 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(207)) - ServiceID for StorageContainerManager is null
2024-03-25 19:42:02,237 [main] WARN  ha.SCMHANodeDetails (SCMHANodeDetails.java:validateSCMHAConfig(180)) - Default/Configured value of config ozone.scm.ratis.enable conflicts with the expected value. Default/Configured: true. Expected: false. Falling back to the expected value. Current State of SCM: SCM is running without Ratis. Ratis SCM -> Non Ratis SCM is not supported.
2024-03-25 19:42:02,238 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(212)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2024-03-25 19:42:02,680 [main] WARN  utils.HAUtils (HAUtils.java:getMetaDir(339)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-25 19:42:02,784 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(171)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-25 19:42:02,792 [main] INFO  utils.LeakDetector (LeakDetector.java:start(73)) - Starting leak detector thread ManagedRocksObject0.
2024-03-25 19:42:02,966 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.5.0-SNAPSHOT/hdds-common-1.5.0-SNAPSHOT.jar!/network-topology-default.xml]
2024-03-25 19:42:02,968 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2024-03-25 19:42:03,007 [main] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.dropwizard3.Dm3MetricRegistriesImpl
2024-03-25 19:42:03,020 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-03-25 19:42:03,180 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(370)) - upgrade localId to 113750153625600000
2024-03-25 19:42:03,181 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(380)) - upgrade delTxnId to 0
2024-03-25 19:42:03,186 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(397)) - upgrade containerId to 0
2024-03-25 19:42:03,190 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToCertificateSequenceId(444)) - upgrade CertificateId to 2
2024-03-25 19:42:03,192 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(241)) - Init the HA SequenceIdGenerator.
2024-03-25 19:42:03,229 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(177)) - Entering startup safe mode.
2024-03-25 19:42:03,240 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2024-03-25 19:42:03,242 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2024-03-25 19:42:03,248 [main] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2024-03-25 19:42:03,258 [main] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2024-03-25 19:42:03,258 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2024-03-25 19:42:03,263 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2024-03-25 19:42:03,264 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(127)) - Starting RatisPipelineUtilsThread.
2024-03-25 19:42:03,267 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(65)) - Starting BackgroundPipelineScrubber Service.
2024-03-25 19:42:03,268 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2024-03-25 19:42:03,272 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(65)) - Starting ExpiredContainerReplicaOpScrubber Service.
2024-03-25 19:42:03,273 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2024-03-25 19:42:03,291 [main] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(80)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-03-25 19:42:03,291 [main] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(80)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-03-25 19:42:03,312 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2024-03-25 19:42:03,362 [main] INFO  replication.ReplicationManager (ReplicationManager.java:start(295)) - Starting Replication Monitor Thread.
2024-03-25 19:42:03,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:03,366 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2024-03-25 19:42:03,427 [main] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(91)) - containers with one replica threshold count 0
2024-03-25 19:42:03,432 [main] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(176)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-25 19:42:03,434 [main] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(193)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2024-03-25 19:42:03,476 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(440)) - SCM start with adminUsers: [runner]
2024-03-25 19:42:03,682 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for SCMAudit to [].
2024-03-25 19:42:03,704 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-25 19:42:03,729 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15002
2024-03-25 19:42:03,731 [Socket Reader #1 for port 15002] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15002
2024-03-25 19:42:03,771 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for SCMAudit to [].
2024-03-25 19:42:03,775 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-25 19:42:03,775 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15001
2024-03-25 19:42:03,776 [Socket Reader #1 for port 15001] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15001
2024-03-25 19:42:03,799 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for SCMAudit to [].
2024-03-25 19:42:03,808 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-25 19:42:03,809 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15000
2024-03-25 19:42:03,809 [Socket Reader #1 for port 15000] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15000
2024-03-25 19:42:03,845 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2024-03-25 19:42:03,845 [main] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(225)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2024-03-25 19:42:03,848 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1545)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:15000
2024-03-25 19:42:03,896 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(136)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2024-03-25 19:42:03,906 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2024-03-25 19:42:03,906 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2024-03-25 19:42:04,105 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(204)) - RPC server for Client  is listening at /0.0.0.0:15000
2024-03-25 19:42:04,106 [IPC Server listener on 15000] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15000: starting
2024-03-25 19:42:04,107 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-03-25 19:42:04,127 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1558)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:15001
2024-03-25 19:42:04,128 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(162)) - RPC server for Block Protocol is listening at /0.0.0.0:15001
2024-03-25 19:42:04,129 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-03-25 19:42:04,129 [IPC Server listener on 15001] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15001: starting
2024-03-25 19:42:04,138 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(194)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:15002
2024-03-25 19:42:04,139 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-03-25 19:42:04,139 [IPC Server listener on 15002] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15002: starting
2024-03-25 19:42:04,166 [JvmPauseMonitor0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-9c2d3f76-8b57-48c2-b1f2-06f080cfbafd: Started
2024-03-25 19:42:04,176 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for scm at: http://0.0.0.0:15003
2024-03-25 19:42:04,176 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-25 19:42:04,200 [main] INFO  util.log (Log.java:initialized(170)) - Logging initialized @3717ms to org.eclipse.jetty.util.log.Slf4jLog
2024-03-25 19:42:04,282 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-03-25 19:42:04,286 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.scm is not defined
2024-03-25 19:42:04,291 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-25 19:42:04,293 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2024-03-25 19:42:04,293 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-25 19:42:04,293 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-25 19:42:04,318 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/webserver
2024-03-25 19:42:04,319 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15003
2024-03-25 19:42:04,320 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-03-25 19:42:04,338 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-03-25 19:42:04,339 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-03-25 19:42:04,340 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2024-03-25 19:42:04,348 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@749ebc39{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-03-25 19:42:04,349 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@1f9af742{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2024-03-25 19:42:04,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:04,378 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@4d484961{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2024-03-25 19:42:04,383 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@bf70ce5{HTTP/1.1, (http/1.1)}{0.0.0.0:15003}
2024-03-25 19:42:04,383 [main] INFO  server.Server (Server.java:doStart(415)) - Started @3900ms
2024-03-25 19:42:04,385 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2024-03-25 19:42:04,385 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2024-03-25 19:42:04,386 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of scm listening at http://0.0.0.0:15003
2024-03-25 19:42:04,389 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-25 19:42:04,440 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for OMAudit to [].
2024-03-25 19:42:04,496 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(115)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2024-03-25 19:42:04,499 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(226)) - Configuration does not have ozone.om.address set. Falling back to the default OM address /127.0.0.1:15004
2024-03-25 19:42:04,499 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(254)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2024-03-25 19:42:04,499 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(261)) - OM Node ID is not set. Setting it to the default ID: om1
2024-03-25 19:42:04,502 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-25 19:42:04,505 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = QUOTA (version = 6), software layout = QUOTA (version = 6)
2024-03-25 19:42:04,572 [main] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(113)) - Skipping Upgrade Action QuotaRepairUpgradeAction since it has been finalized.
2024-03-25 19:42:04,574 [main] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(113)) - Skipping Upgrade Action MockOmUpgradeAction since it has been finalized.
2024-03-25 19:42:04,575 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-25 19:42:04,688 [main] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(115)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:15001]
2024-03-25 19:42:04,715 [main] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(115)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:15001]
2024-03-25 19:42:04,884 [main] INFO  om.OzoneManager (OzoneManager.java:<init>(679)) - OM start with adminUsers: [runner]
2024-03-25 19:42:04,902 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-25 19:42:04,925 [main] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(71)) - OmKeyInfo.getCodec ignorePipeline = true
2024-03-25 19:42:05,133 [main] INFO  om.OzoneManager (OzoneManager.java:instantiateServices(813)) - S3 Multi-Tenancy is disabled
2024-03-25 19:42:05,158 [main] INFO  om.OmSnapshotManager (OmSnapshotManager.java:<init>(177)) - Ozone filesystem snapshot feature is enabled.
2024-03-25 19:42:05,165 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.snapshot.diff.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-25 19:42:05,198 [main] INFO  utils.NativeLibraryLoader (NativeLibraryLoader.java:loadLibrary(108)) - Loading Library: ozone_rocksdb_tools
2024-03-25 19:42:05,200 [main] ERROR snapshot.SnapshotDiffManager (SnapshotDiffManager.java:initNativeLibraryForEfficientDiff(287)) - Native Library for raw sst file reading loading failed.
org.apache.hadoop.hdds.utils.NativeLibraryNotLoadedException: Unable to load library ozone_rocksdb_tools from both java.library.path & resource file libozone_rocksdb_tools.so from jar.
	at org.apache.hadoop.hdds.utils.db.managed.ManagedRawSSTFileReader.loadLibrary(ManagedRawSSTFileReader.java:38)
	at org.apache.hadoop.ozone.om.snapshot.SnapshotDiffManager.initNativeLibraryForEfficientDiff(SnapshotDiffManager.java:285)
	at org.apache.hadoop.ozone.om.snapshot.SnapshotDiffManager.<init>(SnapshotDiffManager.java:259)
	at org.apache.hadoop.ozone.om.OmSnapshotManager.<init>(OmSnapshotManager.java:279)
	at org.apache.hadoop.ozone.om.OzoneManager.instantiateServices(OzoneManager.java:865)
	at org.apache.hadoop.ozone.om.OzoneManager.<init>(OzoneManager.java:689)
	at org.apache.hadoop.ozone.om.OzoneManager.createOm(OzoneManager.java:776)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.createOM(MiniOzoneClusterImpl.java:689)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.createAndStartSingleOM(MiniOzoneClusterImpl.java:673)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.build(MiniOzoneClusterImpl.java:535)
	at org.apache.hadoop.ozone.recon.TestReconAndAdminContainerCLI.init(TestReconAndAdminContainerCLI.java:134)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:728)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:156)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptLifecycleMethod(TimeoutExtension.java:128)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptBeforeAllMethod(TimeoutExtension.java:70)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(InterceptingExecutableInvoker.java:103)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:93)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:92)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:86)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeBeforeAllMethods$13(ClassBasedTestDescriptor.java:412)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeBeforeAllMethods(ClassBasedTestDescriptor.java:410)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:216)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:85)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:148)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:198)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:169)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:93)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:58)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:141)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:57)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:103)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:85)
	at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:63)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2024-03-25 19:42:05,247 [main] INFO  om.OzoneManager (OzoneManager.java:addS3GVolumeToDB(4469)) - Created Volume s3v With Owner runner required for S3Gateway operations.
2024-03-25 19:42:05,294 [main] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(311)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2024-03-25 19:42:05,295 [main] WARN  utils.OzoneManagerRatisUtils (OzoneManagerRatisUtils.java:getOMRatisSnapshotDirectory(476)) - ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
2024-03-25 19:42:05,305 [main] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(311)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2024-03-25 19:42:05,339 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(167)) - Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: localhost:15007
2024-03-25 19:42:05,346 [main] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:loadSnapshotInfoFromDB(589)) - TransactionInfo not found in OM DB.
2024-03-25 19:42:05,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:05,500 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-03-25 19:42:05,507 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-03-25 19:42:05,508 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.port = 15007 (fallback to raft.grpc.server.port)
2024-03-25 19:42:05,508 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-03-25 19:42:05,509 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.port = 15007 (fallback to raft.grpc.server.port)
2024-03-25 19:42:05,509 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-03-25 19:42:05,509 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15007 (custom)
2024-03-25 19:42:05,511 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 4194304 (custom)
2024-03-25 19:42:05,513 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2024-03-25 19:42:05,513 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2024-03-25 19:42:05,514 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2024-03-25 19:42:05,521 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-25 19:42:05,523 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-03-25 19:42:05,523 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-03-25 19:42:05,668 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2024-03-25 19:42:05,670 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:42:05,670 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-03-25 19:42:05,670 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:42:05,671 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/ratis] (custom)
2024-03-25 19:42:05,672 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-03-25 19:42:05,673 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-03-25 19:42:05,678 [main] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - om1: addNew group-C5BA1605619E:[om1|localhost:15007] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@5f17910c[Not completed]
2024-03-25 19:42:05,678 [main] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(2174)) - OzoneManager Ratis server initialized at port 15007
2024-03-25 19:42:05,681 [main] INFO  om.OzoneManager (OzoneManager.java:getRpcServer(1233)) - Creating RPC Server
2024-03-25 19:42:05,686 [om1-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - om1: new RaftServerImpl for group-C5BA1605619E:[om1|localhost:15007] with OzoneManagerStateMachine:uninitialized
2024-03-25 19:42:05,688 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2024-03-25 19:42:05,688 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 1200ms (custom)
2024-03-25 19:42:05,688 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-25 19:42:05,688 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2024-03-25 19:42:05,689 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:42:05,689 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-25 19:42:05,689 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:42:05,694 [om1-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - om1@group-C5BA1605619E: ConfigurationManager, init=-1: peers:[om1|localhost:15007]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-25 19:42:05,701 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 120s (custom)
2024-03-25 19:42:05,704 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-25 19:42:05,708 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 300s (custom)
2024-03-25 19:42:05,708 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-25 19:42:05,712 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-25 19:42:05,713 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-25 19:42:05,791 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2024-03-25 19:42:05,794 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:42:05,796 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-25 19:42:05,797 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-25 19:42:05,798 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-25 19:42:05,798 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-25 19:42:06,242 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-25 19:42:06,244 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 127.0.0.1:15004
2024-03-25 19:42:06,245 [Socket Reader #1 for port 15004] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15004
2024-03-25 19:42:06,278 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2024-03-25 19:42:06,293 [main] INFO  om.OzoneManager (OzoneManager.java:start(1655)) - OzoneManager RPC server is listening at localhost/127.0.0.1:15004
2024-03-25 19:42:06,294 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(588)) - Starting OzoneManagerRatisServer om1 at port 15007
2024-03-25 19:42:06,298 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-25 19:42:06,299 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-25 19:42:06,299 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/ratis] (custom)
2024-03-25 19:42:06,328 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2024-03-25 19:42:06,332 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 19166@fv-az1540-867
2024-03-25 19:42:06,339 [om1-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2024-03-25 19:42:06,341 [om1-impl-thread1] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/raft-meta.conf
2024-03-25 19:42:06,343 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-25 19:42:06,351 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-25 19:42:06,352 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2024-03-25 19:42:06,353 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-25 19:42:06,354 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-25 19:42:06,358 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2024-03-25 19:42:06,364 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-25 19:42:06,364 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-25 19:42:06,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:06,365 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2024-03-25 19:42:06,367 [om1-impl-thread1] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[om1@group-C5BA1605619E-cacheEviction-AwaitToRun,5,main] started
2024-03-25 19:42:06,372 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2024-03-25 19:42:06,372 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2024-03-25 19:42:06,372 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2024-03-25 19:42:06,375 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2024-03-25 19:42:06,375 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-25 19:42:06,376 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-25 19:42:06,376 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-25 19:42:06,377 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-25 19:42:06,378 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2024-03-25 19:42:06,383 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 4194312 (custom)
2024-03-25 19:42:06,385 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2024-03-25 19:42:06,386 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-25 19:42:06,386 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-25 19:42:06,387 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2024-03-25 19:42:06,392 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:06,392 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:06,394 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - om1@group-C5BA1605619E: start as a follower, conf=-1: peers:[om1|localhost:15007]|listeners:[], old=null
2024-03-25 19:42:06,395 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-25 19:42:06,396 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-FollowerState
2024-03-25 19:42:06,398 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2024-03-25 19:42:06,400 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-25 19:42:06,400 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-25 19:42:06,401 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2024-03-25 19:42:06,401 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2024-03-25 19:42:06,401 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = true (custom)
2024-03-25 19:42:06,404 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 1s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:42:06,404 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 1200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:42:06,407 [main] INFO  server.RaftServer (RaftServerProxy.java:startImpl(406)) - om1: start RPC server
2024-03-25 19:42:06,451 [main] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - om1: GrpcService started, listening on 15007
2024-03-25 19:42:06,452 [main] INFO  om.OzoneManager (OzoneManager.java:start(1671)) - Version File has different layout version (6) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
2024-03-25 19:42:06,453 [JvmPauseMonitor1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-om1: Started
2024-03-25 19:42:06,479 [main] INFO  client.ScmTopologyClient (ScmTopologyClient.java:start(67)) - Initial network topology fetched from SCM: /.
2024-03-25 19:42:06,498 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for ozoneManager at: http://0.0.0.0:15005
2024-03-25 19:42:06,498 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-25 19:42:06,500 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-03-25 19:42:06,501 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.ozoneManager is not defined
2024-03-25 19:42:06,504 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-25 19:42:06,506 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2024-03-25 19:42:06,506 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-25 19:42:06,506 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-25 19:42:06,508 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of ozoneManager uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/webserver
2024-03-25 19:42:06,512 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15005
2024-03-25 19:42:06,512 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-03-25 19:42:06,514 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-03-25 19:42:06,514 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-03-25 19:42:06,515 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2024-03-25 19:42:06,518 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@5ec357e4{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-03-25 19:42:06,518 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@66f4c5cb{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2024-03-25 19:42:06,523 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@2e4dbcd0{ozoneManager,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2024-03-25 19:42:06,528 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@4bfbc57a{HTTP/1.1, (http/1.1)}{0.0.0.0:15005}
2024-03-25 19:42:06,529 [main] INFO  server.Server (Server.java:doStart(415)) - Started @6046ms
2024-03-25 19:42:06,529 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-03-25 19:42:06,530 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of ozoneManager listening at http://0.0.0.0:15005
2024-03-25 19:42:06,531 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-03-25 19:42:06,538 [IPC Server listener on 15004] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15004: starting
2024-03-25 19:42:06,551 [main] INFO  om.OzoneManager (OzoneManager.java:startTrashEmptier(2127)) - Trash Interval set to 0. Files deleted won't move to trash
2024-03-25 19:42:06,634 [main] INFO  db.CodecBuffer (CodecBuffer.java:set(63)) - Successfully set constructor to org.apache.hadoop.hdds.utils.db.CodecBuffer$$Lambda$950/987961871@30b32799
2024-03-25 19:42:06,734 [main] INFO  recon.ReconServer (StringUtils.java:startupShutdownMessage(132)) - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ReconServer
STARTUP_MSG:   host = fv-az1540-867/10.1.0.27
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.5.0-SNAPSHOT
STARTUP_MSG:   classpath = /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/classes:/home/runner/.m2/repository/org/apache/ozone/ozone-common/1.5.0-SNAPSHOT/ozone-common-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/grpc/grpc-netty/1.58.0/grpc-netty-1.58.0.jar:/home/runner/.m2/repository/io/grpc/grpc-core/1.58.0/grpc-core-1.58.0.jar:/home/runner/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/runner/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.23/animal-sniffer-annotations-1.23.jar:/home/runner/.m2/repository/io/grpc/grpc-context/1.58.0/grpc-context-1.58.0.jar:/home/runner/.m2/repository/io/grpc/grpc-util/1.58.0/grpc-util-1.58.0.jar:/home/runner/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/runner/.m2/repository/io/perfmark/perfmark-api/0.26.0/perfmark-api-0.26.0.jar:/home/runner/.m2/repository/io/netty/netty-codec-http2/4.1.100.Final/netty-codec-http2-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-common/4.1.100.Final/netty-common-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-buffer/4.1.100.Final/netty-buffer-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.100.Final/netty-codec-http-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-proxy/4.1.100.Final/netty-handler-proxy-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-socks/4.1.100.Final/netty-codec-socks-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-classes/2.0.61.Final/netty-tcnative-classes-2.0.61.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-linux-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-osx-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-windows-x86_64.jar:/home/runner/.m2/repository/org/apache/commons/commons-compress/1.26.0/commons-compress-1.26.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.5.0-SNAPSHOT/hdds-common-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-client/1.5.0-SNAPSHOT/hdds-client-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-client/1.5.0-SNAPSHOT/ozone-interface-client-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.3.6/hadoop-hdfs-client-3.3.6.jar:/home/runner/.m2/repository/com/squareup/okhttp3/okhttp/4.12.0/okhttp-4.12.0.jar:/home/runner/.m2/repository/com/squareup/okio/okio/3.6.0/okio-3.6.0.jar:/home/runner/.m2/repository/com/squareup/okio/okio-jvm/3.6.0/okio-jvm-3.6.0.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-jdk8/1.9.22/kotlin-stdlib-jdk8-1.9.22.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-jdk7/1.9.22/kotlin-stdlib-jdk7-1.9.22.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.9.22/kotlin-stdlib-common-1.9.22.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-test-utils/1.5.0-SNAPSHOT/hdds-test-utils-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/assertj/assertj-core/3.12.2/assertj-core-3.12.2.jar:/home/runner/.m2/repository/com/google/guava/guava/32.0.0-jre/guava-32.0.0-jre.jar:/home/runner/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/runner/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/runner/.m2/repository/org/checkerframework/checker-qual/3.33.0/checker-qual-3.33.0.jar:/home/runner/.m2/repository/com/google/j2objc/j2objc-annotations/2.8/j2objc-annotations-2.8.jar:/home/runner/.m2/repository/commons-io/commons-io/2.15.1/commons-io-2.15.1.jar:/home/runner/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.10.2/junit-jupiter-api-5.10.2.jar:/home/runner/.m2/repository/org/opentest4j/opentest4j/1.3.0/opentest4j-1.3.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-commons/1.10.2/junit-platform-commons-1.10.2.jar:/home/runner/.m2/repository/ch/qos/reload4j/reload4j/1.2.25/reload4j-1.2.25.jar:/home/runner/.m2/repository/jakarta/annotation/jakarta.annotation-api/2.1.1/jakarta.annotation-api-2.1.1.jar:/home/runner/.m2/repository/org/slf4j/slf4j-api/2.0.12/slf4j-api-2.0.12.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-api/2.17.1/log4j-api-2.17.1.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.5.0-SNAPSHOT/hdds-server-scm-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-server/1.5.0-SNAPSHOT/hdds-hadoop-dependency-server-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.6/hadoop-hdfs-3.3.6.jar:/home/runner/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.10.5/snappy-java-1.1.10.5.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.5.0-SNAPSHOT/hdds-server-framework-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/bouncycastle/bcprov-jdk18on/1.77/bcprov-jdk18on-1.77.jar:/home/runner/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-text/1.11.0/commons-text-1.11.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.5.0-SNAPSHOT/hdds-server-framework-1.5.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-server/1.5.0-SNAPSHOT/hdds-interface-server-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-admin/1.5.0-SNAPSHOT/hdds-interface-admin-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-managed-rocksdb/1.5.0-SNAPSHOT/hdds-managed-rocksdb-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/rocksdb/rocksdbjni/7.7.3/rocksdbjni-7.7.3.jar:/home/runner/.m2/repository/org/slf4j/slf4j-reload4j/2.0.12/slf4j-reload4j-2.0.12.jar:/home/runner/.m2/repository/org/apache/commons/commons-configuration2/2.10.1/commons-configuration2-2.10.1.jar:/home/runner/.m2/repository/commons-fileupload/commons-fileupload/1.5/commons-fileupload-1.5.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-core/2.17.1/log4j-core-2.17.1.jar:/home/runner/.m2/repository/com/lmax/disruptor/3.4.4/disruptor-3.4.4.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util/9.4.53.v20231009/jetty-util-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-server/9.4.53.v20231009/jetty-server-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-http/9.4.53.v20231009/jetty-http-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-io/9.4.53.v20231009/jetty-io-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.53.v20231009/jetty-servlet-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-security/9.4.53.v20231009/jetty-security-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.53.v20231009/jetty-util-ajax-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.53.v20231009/jetty-webapp-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.53.v20231009/jetty-xml-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server/3.0.1/ratis-server-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/1.0.5/ratis-thirdparty-misc-1.0.5.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-proto/3.0.1/ratis-proto-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-common/3.0.1/ratis-common-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-client/3.0.1/ratis-client-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server-api/3.0.1/ratis-server-api-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics-api/3.0.1/ratis-metrics-api-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics-dropwizard3/3.0.1/ratis-metrics-dropwizard3-3.0.1.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_dropwizard/0.16.0/simpleclient_dropwizard-0.16.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient/0.16.0/simpleclient-0.16.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_common/0.16.0/simpleclient_common-0.16.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.16.1/jackson-datatype-jsr310-2.16.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.16.1/jackson-core-2.16.1.jar:/home/runner/.m2/repository/org/apache/ozone/rocksdb-checkpoint-differ/1.5.0-SNAPSHOT/rocksdb-checkpoint-differ-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/jgrapht/jgrapht-core/1.4.0/jgrapht-core-1.4.0.jar:/home/runner/.m2/repository/org/jheaps/jheaps/0.11/jheaps-0.11.jar:/home/runner/.m2/repository/org/jgrapht/jgrapht-ext/1.4.0/jgrapht-ext-1.4.0.jar:/home/runner/.m2/repository/com/github/vlsi/mxgraph/jgraphx/3.9.8.1/jgraphx-3.9.8.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.5.0-SNAPSHOT/ozone-manager-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/aspectj/aspectjrt/1.9.7/aspectjrt-1.9.7.jar:/home/runner/.m2/repository/org/aspectj/aspectjweaver/1.9.7/aspectjweaver-1.9.7.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-client/1.5.0-SNAPSHOT/hdds-interface-client-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-protobuf_3_7/1.1.1/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-storage/1.5.0-SNAPSHOT/ozone-interface-storage-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-client/1.19.4/jersey-client-1.19.4.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-intg/2.3.0/ranger-intg-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-common/2.3.0/ranger-plugins-common-2.3.0.jar:/home/runner/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-cred/2.3.0/ranger-plugins-cred-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-audit/2.3.0/ranger-plugins-audit-2.3.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-client/9.4.53.v20231009/jetty-client-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpmime/4.5.6/httpmime-4.5.6.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore-nio/4.4.16/httpcore-nio-4.4.16.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpasyncclient/4.1.3/httpasyncclient-4.1.3.jar:/home/runner/.m2/repository/com/carrotsearch/hppc/0.8.0/hppc-0.8.0.jar:/home/runner/.m2/repository/org/apache/orc/orc-core/1.5.8/orc-core-1.5.8.jar:/home/runner/.m2/repository/net/java/dev/jna/jna/5.2.0/jna-5.2.0.jar:/home/runner/.m2/repository/net/java/dev/jna/jna-platform/5.2.0/jna-platform-5.2.0.jar:/home/runner/.m2/repository/com/kstruct/gethostname4j/0.0.2/gethostname4j-0.0.2.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugin-classloader/2.3.0/ranger-plugin-classloader-2.3.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-rocks-native/1.5.0-SNAPSHOT/hdds-rocks-native-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.3.6/hadoop-minikdc-3.3.6.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/runner/.m2/repository/junit/junit/4.13.2/junit-4.13.2.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-s3gateway/1.5.0-SNAPSHOT/ozone-s3gateway-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/home/runner/.m2/repository/org/jboss/weld/servlet/weld-servlet-shaded/3.1.9.Final/weld-servlet-shaded-3.1.9.Final.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.42/jersey-container-servlet-core-2.42.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-common/2.42/jersey-common-2.42.jar:/home/runner/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.42/jersey-cdi1x-2.42.jar:/home/runner/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.42/jersey-hk2-2.42.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.42/jersey-media-jaxb-2.42.jar:/home/runner/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-api/2.6.1/hk2-api-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-utils/2.6.1/hk2-utils-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.6.1/aopalliance-repackaged-2.6.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.16.1/jackson-dataformat-xml-2.16.1.jar:/home/runner/.m2/repository/org/codehaus/woodstox/stax2-api/4.2.2/stax2-api-4.2.2.jar:/home/runner/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.4.0/woodstox-core-5.4.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.16.1/jackson-module-jaxb-annotations-2.16.1.jar:/home/runner/.m2/repository/javax/enterprise/cdi-api/2.0/cdi-api-2.0.jar:/home/runner/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/runner/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/runner/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/runner/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.3/jakarta.xml.bind-api-2.3.3.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-runtime/2.3.9/jaxb-runtime-2.3.9.jar:/home/runner/.m2/repository/org/glassfish/jaxb/txw2/2.3.9/txw2-2.3.9.jar:/home/runner/.m2/repository/com/sun/istack/istack-commons-runtime/3.0.12/istack-commons-runtime-3.0.12.jar:/home/runner/.m2/repository/com/sun/activation/jakarta.activation/1.2.2/jakarta.activation-1.2.2.jar:/home/runner/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.2/jakarta.activation-api-1.2.2.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf/1.58.0/grpc-protobuf-1.58.0.jar:/home/runner/.m2/repository/com/google/api/grpc/proto-google-common-protos/2.22.0/proto-google-common-protos-2.22.0.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf-lite/1.58.0/grpc-protobuf-lite-1.58.0.jar:/home/runner/.m2/repository/io/grpc/grpc-stub/1.58.0/grpc-stub-1.58.0.jar:/home/runner/.m2/repository/io/netty/netty-transport/4.1.100.Final/netty-transport-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver/4.1.100.Final/netty-resolver-4.1.100.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-csi/1.5.0-SNAPSHOT/ozone-csi-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java-util/3.19.6/protobuf-java-util-3.19.6.jar:/home/runner/.m2/repository/com/google/code/gson/gson/2.9.0/gson-2.9.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-config/1.5.0-SNAPSHOT/hdds-config-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.100.Final/netty-transport-native-epoll-4.1.100.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.100.Final/netty-transport-classes-epoll-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.100.Final/netty-transport-native-unix-common-4.1.100.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.5.0-SNAPSHOT/ozone-recon-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-reconcodegen/1.5.0-SNAPSHOT/ozone-reconcodegen-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/inject/guice/6.0.0/guice-6.0.0.jar:/home/runner/.m2/repository/jakarta/inject/jakarta.inject-api/2.0.1/jakarta.inject-api-2.0.1.jar:/home/runner/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-assistedinject/6.0.0/guice-assistedinject-6.0.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-servlet/6.0.0/guice-servlet-6.0.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.42/jersey-container-servlet-2.42.jar:/home/runner/.m2/repository/org/glassfish/hk2/guice-bridge/2.6.1/guice-bridge-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-server/2.42/jersey-server-2.42.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-client/2.42/jersey-client-2.42.jar:/home/runner/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.42/jersey-media-json-jackson-2.42.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.42/jersey-entity-filtering-2.42.jar:/home/runner/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/runner/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/runner/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/runner/.m2/repository/org/xerial/sqlite-jdbc/3.44.1.0/sqlite-jdbc-3.44.1.0.jar:/home/runner/.m2/repository/org/springframework/spring-jdbc/5.3.27/spring-jdbc-5.3.27.jar:/home/runner/.m2/repository/org/springframework/spring-beans/5.3.27/spring-beans-5.3.27.jar:/home/runner/.m2/repository/org/springframework/spring-core/5.3.27/spring-core-5.3.27.jar:/home/runner/.m2/repository/org/springframework/spring-tx/5.3.27/spring-tx-5.3.27.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-client/1.5.0-SNAPSHOT/ozone-client-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-erasurecode/1.5.0-SNAPSHOT/hdds-erasurecode-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem/1.5.0-SNAPSHOT/ozone-filesystem-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem-common/1.5.0-SNAPSHOT/ozone-filesystem-common-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-tools/1.5.0-SNAPSHOT/ozone-tools-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-core/1.12.661/aws-java-sdk-core-1.12.661.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpclient/4.5.14/httpclient-4.5.14.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore/4.4.16/httpcore-4.4.16.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.16.1/jackson-dataformat-cbor-2.16.1.jar:/home/runner/.m2/repository/joda-time/joda-time/2.12.7/joda-time-2.12.7.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.12.661/aws-java-sdk-s3-1.12.661.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.12.661/aws-java-sdk-kms-1.12.661.jar:/home/runner/.m2/repository/com/amazonaws/jmespath-java/1.12.661/jmespath-java-1.12.661.jar:/home/runner/.m2/repository/org/kohsuke/metainf-services/metainf-services/1.11/metainf-services-1.11.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-tools/1.5.0-SNAPSHOT/hdds-tools-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-tools/3.0.1/ratis-tools-3.0.1.jar:/home/runner/.m2/repository/commons-cli/commons-cli/1.6.0/commons-cli-1.6.0.jar:/home/runner/.m2/repository/org/apache/commons/commons-lang3/3.14.0/commons-lang3-3.14.0.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.5.0-SNAPSHOT/ozone-manager-1.5.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.5.0-SNAPSHOT/hdds-common-1.5.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-client/1.5.0-SNAPSHOT/hdds-hadoop-dependency-client-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/info/picocli/picocli/4.7.5/picocli-4.7.5.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.16.1/jackson-annotations-2.16.1.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-annotation-processing/1.5.0-SNAPSHOT/hdds-annotation-processing-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-netty/3.0.1/ratis-netty-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-grpc/3.0.1/ratis-grpc-3.0.1.jar:/home/runner/.m2/repository/org/bouncycastle/bcpkix-jdk18on/1.77/bcpkix-jdk18on-1.77.jar:/home/runner/.m2/repository/org/bouncycastle/bcutil-jdk18on/1.77/bcutil-jdk18on-1.77.jar:/home/runner/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/runner/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/runner/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/runner/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-client/1.8.1/jaeger-client-1.8.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-thrift/1.8.1/jaeger-thrift-1.8.1.jar:/home/runner/.m2/repository/org/apache/thrift/libthrift/0.15.0/libthrift-0.15.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-core/1.8.1/jaeger-core-1.8.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.8.1/jaeger-tracerresolver-1.8.1.jar:/home/runner/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.9.22/kotlin-stdlib-1.9.22.jar:/home/runner/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/runner/.m2/repository/org/yaml/snakeyaml/2.0/snakeyaml-2.0.jar:/home/runner/.m2/repository/io/grpc/grpc-api/1.58.0/grpc-api-1.58.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-launcher/1.10.2/junit-platform-launcher-1.10.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-engine/1.10.2/junit-platform-engine-1.10.2.jar:/home/runner/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.6/hadoop-kms-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-auth/3.3.6/hadoop-auth-3.3.6.jar:/home/runner/.m2/repository/com/nimbusds/nimbus-jose-jwt/9.8.1/nimbus-jose-jwt-9.8.1.jar:/home/runner/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper/3.8.4/zookeeper-3.8.4.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.8.4/zookeeper-jute-3.8.4.jar:/home/runner/.m2/repository/org/apache/yetus/audience-annotations/0.12.0/audience-annotations-0.12.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.1.1/hadoop-shaded-guava-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-core/1.19.4/jersey-core-1.19.4.jar:/home/runner/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-server/1.19.4/jersey-server-1.19.4.jar:/home/runner/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.6/hadoop-common-3.3.6.jar:/home/runner/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/runner/.m2/repository/commons-net/commons-net/3.10.0/commons-net-3.10.0.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-servlet/1.19.4/jersey-servlet-1.19.4.jar:/home/runner/.m2/repository/com/github/pjfanning/jersey-json/1.20/jersey-json-1.20.jar:/home/runner/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/runner/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/runner/.m2/repository/com/google/re2j/re2j/1.7/re2j-1.7.jar:/home/runner/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/runner/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-recipes/5.2.0/curator-recipes-5.2.0.jar:/home/runner/.m2/repository/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/runner/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.16.1/jackson-databind-2.16.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.6/hadoop-kms-3.3.6-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.5.0-SNAPSHOT/hdds-server-scm-1.5.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/com/github/luben/zstd-jni/1.5.2-5/zstd-jni-1.5.2-5.jar:/home/runner/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/runner/.m2/repository/io/netty/netty-codec/4.1.100.Final/netty-codec-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler/4.1.100.Final/netty-handler-4.1.100.Final.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-test/1.5.0-SNAPSHOT/hdds-hadoop-dependency-test-1.5.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.6/hadoop-common-3.3.6-tests.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.6/hadoop-hdfs-3.3.6-tests.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.10.2/junit-jupiter-engine-5.10.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.10.2/junit-jupiter-params-5.10.2.jar:/home/runner/.m2/repository/org/mockito/mockito-core/4.11.0/mockito-core-4.11.0.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy/1.12.19/byte-buddy-1.12.19.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy-agent/1.12.19/byte-buddy-agent-1.12.19.jar:/home/runner/.m2/repository/org/objenesis/objenesis/3.3/objenesis-3.3.jar:/home/runner/.m2/repository/org/mockito/mockito-junit-jupiter/4.11.0/mockito-junit-jupiter-4.11.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.6/hadoop-distcp-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.3.6/hadoop-mapreduce-client-jobclient-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.3.6/hadoop-mapreduce-client-common-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.3.6/hadoop-yarn-common-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.3.6/hadoop-yarn-api-3.3.6.jar:/home/runner/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/runner/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19.4/jersey-guice-1.19.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.16.1/jackson-jaxrs-json-provider-2.16.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.16.1/jackson-jaxrs-base-2.16.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.3.6/hadoop-yarn-client-3.3.6.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.4.51.v20230217/websocket-client-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.4.51.v20230217/websocket-common-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.4.51.v20230217/websocket-api-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/jline/jline/3.9.0/jline-3.9.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.3.6/hadoop-mapreduce-client-core-3.3.6.jar:/home/runner/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/runner/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-annotations/3.3.6/hadoop-annotations-3.3.6.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/../lib/tools.jar:/home/runner/.m2/repository/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.6/hadoop-distcp-3.3.6-tests.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest/2.2/hamcrest-2.2.jar:/home/runner/.m2/repository/org/slf4j/jul-to-slf4j/2.0.12/jul-to-slf4j-2.0.12.jar:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/gradle-enterprise/test-listeners.jar:
STARTUP_MSG:   build = https://github.com/apache/ozone/9bdac501a73498506db7cc8f0c67c6aa95d6b216 ; compiled by 'runner' on 2024-03-25T19:18Z
STARTUP_MSG:   java = 1.8.0_402
STARTUP_MSG:   conf = {hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=false, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.chunk.write.sync=false, hdds.container.close.threshold=0.9f, hdds.container.ipc.port=9859, hdds.container.ipc.random.port=false, hdds.container.ratis.admin.port=9857, hdds.container.ratis.datastream.enabled=true, hdds.container.ratis.datastream.port=9855, hdds.container.ratis.datastream.random.port=false, hdds.container.ratis.enabled=false, hdds.container.ratis.ipc.port=9858, hdds.container.ratis.ipc.random.port=false, hdds.container.ratis.leader.pending.bytes.limit=1GB, hdds.container.ratis.log.appender.queue.byte-limit=8MB, hdds.container.ratis.log.appender.queue.num-elements=1, hdds.container.ratis.log.purge.gap=1000000, hdds.container.ratis.log.queue.byte-limit=4GB, hdds.container.ratis.log.queue.num-elements=1024, hdds.container.ratis.num.container.op.executors=10, hdds.container.ratis.num.write.chunk.threads.per.volume=4, hdds.container.ratis.replication.level=MAJORITY, hdds.container.ratis.rpc.type=GRPC, hdds.container.ratis.segment.preallocated.size=4MB, hdds.container.ratis.segment.size=64MB, hdds.container.ratis.server.port=9856, hdds.container.ratis.statemachine.max.pending.apply-transactions=10000, hdds.container.ratis.statemachinedata.sync.timeout=10s, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=true, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=false, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.factory.classname=org.apache.hadoop.hdds.fs.MockSpaceUsageCheckFactory$None, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.datanode.http.auth.type=simple, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.replication.zerocopy.enabled=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.slow.op.warning.threshold=500ms, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=5GB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=false, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=1s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.leader.election.minimum.timeout.duration=5s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.ratis.server.retry-cache.timeout.duration=600000ms, hdds.ratis.snapshot.threshold=10000, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.scm.http.auth.type=simple, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/SCM.keytab, hdds.scm.kerberos.principal=SCM/_HOST@REALM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=1, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=10m, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneAccessAuthorizer, ozone.acl.enabled=false, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=4MB, ozone.client.datastream.min.packet.size=256KB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=8MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.reconstruct.stripe.write.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.max.retries=3, ozone.client.read.retry.interval=1, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=1MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=2MB, ozone.client.stream.buffer.size=1MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.csi.default-volume-size=1000000000, ozone.csi.mount.command=goofys --endpoint %s %s %s, ozone.csi.s3g.address=http://localhost:9878, ozone.csi.socket=/var/lib/csi.sock, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.http.policy=HTTP_ONLY, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=0.0.0.0:9862, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.client.rpc.timeout=15m, ozone.om.client.trash.core.pool.size=5, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.group.rights=ALL, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.port=8981, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.ha.raft.server.log.appender.wait-time.min=0ms, ozone.om.ha.raft.server.retrycache.expirytime=300s, ozone.om.handler.count.key=20, ozone.om.http-address=0.0.0.0:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.om.http.auth.type=simple, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.init.default.layout.version=-1, ozone.om.kerberos.keytab.file=/etc/security/keytabs/OM.keytab, ozone.om.kerberos.principal=OM/_HOST@REALM, ozone.om.kerberos.principal.pattern=*, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.network.topology.refresh.duration=1h, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=4MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.s3.grpc.server_enabled=false, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1s, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.finalization.ratis.based.timeout=30s, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.user.rights=ALL, ozone.om.volume.listall.allowed=true, ozone.path.deleting.limit.per.task=6000, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.recon.http.auth.type=simple, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=10m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.sql.db.auto.commit=true, ozone.recon.sql.db.conn.idle.max.age=3600s, ozone.recon.sql.db.conn.idle.test=SELECT 1, ozone.recon.sql.db.conn.idle.test.period=60s, ozone.recon.sql.db.conn.max.active=5, ozone.recon.sql.db.conn.max.age=1800s, ozone.recon.sql.db.conn.timeout=30000ms, ozone.recon.sql.db.driver=org.apache.derby.jdbc.EmbeddedDriver, ozone.recon.sql.db.jdbc.url=jdbc:derby:${ozone.recon.db.dir}/ozone_recon_derby.db, ozone.recon.sql.db.jooq.dialect=DERBY, ozone.recon.task.containercounttask.interval=60s, ozone.recon.task.missingcontainer.interval=300s, ozone.recon.task.pipelinesync.interval=300s, ozone.recon.task.safemode.wait.threshold=300s, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.s3g.http.auth.type=simple, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/_HOST@REALM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.metrics.percentiles.intervals.seconds=60, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=false, ozone.s3g.volume.name=s3v, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.handler.count.key=100, ozone.scm.block.size=4MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=1MB, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.handler.count.key=100, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=1s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=5GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.handler.count.key=100, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=1GB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=4MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=20, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=100ms, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=120s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=3, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=3, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=false, ozone.security.http.kerberos.enabled=false, ozone.security.reconfigure.protocol.acl=*, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.test.test.key=value1, ozone.xceiver.client.metrics.percentiles.intervals.seconds=60, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256, test.scm.client.address=localhost, test.scm.client.bind.host=0.0.0.0, test.scm.client.class=java.lang.Object, test.scm.client.compression.enabled=true, test.scm.client.duration=1h, test.scm.client.enabled=true, test.scm.client.port=9878, test.scm.client.threshold=10, test.scm.client.wait=30m, yarn.app.mapreduce.am.container.log.backups=0, yarn.app.mapreduce.am.container.log.limit.kb=0, yarn.app.mapreduce.task.container.log.backups=0, yarn.nodemanager.container.stderr.pattern={*stderr*,*STDERR*}, yarn.nodemanager.container.stderr.tail.bytes=4096, yarn.nodemanager.windows-container.cpu-limit.enabled=false, yarn.nodemanager.windows-container.memory-limit.enabled=false, yarn.resourcemanager.container.liveness-monitor.interval-ms=600000}
************************************************************/
2024-03-25 19:42:06,746 [main] INFO  recon.ReconServer (SignalLogger.java:register(90)) - registered UNIX signal handlers for [TERM, HUP, INT]
2024-03-25 19:42:07,114 [main] INFO  recon.ReconServer (ReconServer.java:call(116)) - Initializing Recon server...
2024-03-25 19:42:07,158 [main] INFO  persistence.DefaultDataSourceProvider (DefaultDataSourceProvider.java:get(51)) - JDBC Url for Recon : jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/recon/ozone_recon_derby.db 
2024-03-25 19:42:07,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:07,602 [om1@group-C5BA1605619E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1205911348ns, electionTimeout:1197ms
2024-03-25 19:42:07,602 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - om1: shutdown om1@group-C5BA1605619E-FollowerState
2024-03-25 19:42:07,603 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-25 19:42:07,605 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-25 19:42:07,605 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderElection1
2024-03-25 19:42:07,609 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - om1@group-C5BA1605619E-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[om1|localhost:15007]|listeners:[], old=null
2024-03-25 19:42:07,610 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - om1@group-C5BA1605619E-LeaderElection1 PRE_VOTE round 0: result PASSED (term=0)
2024-03-25 19:42:07,612 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - om1@group-C5BA1605619E-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[om1|localhost:15007]|listeners:[], old=null
2024-03-25 19:42:07,612 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - om1@group-C5BA1605619E-LeaderElection1 ELECTION round 0: result PASSED (term=1)
2024-03-25 19:42:07,612 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - om1: shutdown om1@group-C5BA1605619E-LeaderElection1
2024-03-25 19:42:07,612 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-25 19:42:07,619 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-03-25 19:42:07,623 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2024-03-25 19:42:07,624 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2024-03-25 19:42:07,627 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2024-03-25 19:42:07,628 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-03-25 19:42:07,628 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-03-25 19:42:07,634 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-03-25 19:42:07,636 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-25 19:42:07,636 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2024-03-25 19:42:07,637 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2024-03-25 19:42:07,637 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-25 19:42:07,639 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderStateImpl
2024-03-25 19:42:07,639 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - om1@group-C5BA1605619E: set firstElectionSinceStartup to false for becomeLeader
2024-03-25 19:42:07,641 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 1937ms
2024-03-25 19:42:07,668 [om1@group-C5BA1605619E-LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-25 19:42:07,684 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-25 19:42:07,699 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2024-03-25 19:42:07,702 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - om1@group-C5BA1605619E: set configuration 0: peers:[om1|localhost:15007]|listeners:[], old=null
2024-03-25 19:42:07,729 [main] INFO  codegen.SqlDbUtils (SqlDbUtils.java:createNewDerbyDatabase(67)) - Created derby database at jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/recon/ozone_recon_derby.db.
2024-03-25 19:42:07,810 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyConfigurationChanged(212)) - Received Configuration change notification from Ratis. New Peer list:
[id: "om1"
address: "localhost:15007"
startupRole: FOLLOWER
]
2024-03-25 19:42:07,812 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-25 19:42:07,966 [main] INFO  impl.ReconContainerMetadataManagerImpl (ReconContainerMetadataManagerImpl.java:initializeTables(141)) - KEY_CONTAINER Table is empty, initializing from CONTAINER_KEY Table ...
2024-03-25 19:42:07,966 [main] INFO  impl.ReconContainerMetadataManagerImpl (ReconContainerMetadataManagerImpl.java:initializeKeyContainerTable(666)) - It took 0.0 seconds to initialized 0 records to KEY_CONTAINER table
2024-03-25 19:42:07,987 [main] INFO  persistence.DefaultDataSourceProvider (DefaultDataSourceProvider.java:get(51)) - JDBC Url for Recon : jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/recon/ozone_recon_derby.db 
2024-03-25 19:42:07,990 [main] INFO  codegen.SqlDbUtils (SqlDbUtils.java:createNewDerbyDatabase(67)) - Created derby database at jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/recon/ozone_recon_derby.db.
2024-03-25 19:42:07,991 [main] INFO  recon.ReconServer (ReconServer.java:call(140)) - Creating Recon Schema.
2024-03-25 19:42:08,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:08,376 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for recon at: http://0.0.0.0:15008
2024-03-25 19:42:08,376 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-25 19:42:08,378 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-03-25 19:42:08,379 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.recon is not defined
2024-03-25 19:42:08,380 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-25 19:42:08,381 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recon
2024-03-25 19:42:08,382 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-25 19:42:08,382 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-25 19:42:08,383 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of recon uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/webserver
2024-03-25 19:42:08,389 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(80)) - Registered task ContainerKeyMapperTask with controller.
2024-03-25 19:42:08,531 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(80)) - Registered task FileSizeCountTask with controller.
2024-03-25 19:42:08,534 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(80)) - Registered task OmTableInsightTask with controller.
2024-03-25 19:42:08,536 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(80)) - Registered task NSSummaryTask with controller.
2024-03-25 19:42:08,540 [main] INFO  ozone.OmUtils (OmUtils.java:getOzoneManagerServiceId(685)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2024-03-25 19:42:08,540 [main] INFO  ozone.OmUtils (OmUtils.java:getOzoneManagerServiceId(704)) - No OzoneManager ServiceID configured.
2024-03-25 19:42:08,541 [main] INFO  protocolPB.OmTransportFactory (OmTransportFactory.java:createFactory(62)) - Loading OM transport implementation org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory as specified by configuration.
2024-03-25 19:42:08,894 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.5.0-SNAPSHOT/hdds-common-1.5.0-SNAPSHOT.jar!/network-topology-default.xml]
2024-03-25 19:42:08,895 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2024-03-25 19:42:08,984 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-03-25 19:42:08,988 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(241)) - Init the HA SequenceIdGenerator.
2024-03-25 19:42:08,992 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(177)) - Entering startup safe mode.
2024-03-25 19:42:08,993 [main] INFO  scm.ReconNodeManager (ReconNodeManager.java:loadExistingNodes(119)) - Loaded 0 nodes from node DB.
2024-03-25 19:42:08,994 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2024-03-25 19:42:08,995 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-25 19:42:08,995 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15009
2024-03-25 19:42:08,996 [Socket Reader #1 for port 15009] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15009
2024-03-25 19:42:08,999 [main] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2024-03-25 19:42:09,020 [main] INFO  recon.ReconServer (ReconServer.java:call(154)) - Initializing support of Recon Features...
2024-03-25 19:42:09,022 [main] INFO  recon.ReconServer (ReconServer.java:call(156)) - Recon server initialized successfully!
2024-03-25 19:42:09,023 [main] INFO  recon.ReconServer (ReconServer.java:start(211)) - Starting Recon server
2024-03-25 19:42:09,023 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Recon metrics system started (again)
2024-03-25 19:42:09,045 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15008
2024-03-25 19:42:09,046 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-03-25 19:42:09,057 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-03-25 19:42:09,058 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-03-25 19:42:09,058 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2024-03-25 19:42:09,059 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7aba0b5a{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-03-25 19:42:09,059 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6b71002{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.5.0-SNAPSHOT/ozone-recon-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-03-25 19:42:09,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:10,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:10,401 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@46c820f4{recon,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/webserver/jetty-0_0_0_0-15008-ozone-recon-1_5_0-SNAPSHOT_jar-_-any-3883044704583405826/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.5.0-SNAPSHOT/ozone-recon-1.5.0-SNAPSHOT.jar!/webapps/recon}
2024-03-25 19:42:10,402 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@47bd0384{HTTP/1.1, (http/1.1)}{0.0.0.0:15008}
2024-03-25 19:42:10,403 [main] INFO  server.Server (Server.java:doStart(415)) - Started @9919ms
2024-03-25 19:42:10,403 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-03-25 19:42:10,404 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of recon listening at http://0.0.0.0:15008
2024-03-25 19:42:10,404 [main] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:start(239)) - Starting Ozone Manager Service Provider.
2024-03-25 19:42:10,408 [main] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:registerOMDBTasks(217)) - Registered OmDeltaRequest task 
2024-03-25 19:42:10,411 [main] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:registerOMDBTasks(227)) - Registered OmSnapshotRequest task 
2024-03-25 19:42:10,411 [main] INFO  recovery.ReconOmMetadataManagerImpl (ReconOmMetadataManagerImpl.java:start(82)) - Starting ReconOMMetadataManagerImpl
2024-03-25 19:42:10,412 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:start(222)) - Starting Recon Task Controller.
2024-03-25 19:42:10,412 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:start(388)) - Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:15009
2024-03-25 19:42:10,569 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:initializePipelinesFromScm(488)) - Obtained 0 pipelines from SCM.
2024-03-25 19:42:10,570 [main] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 0 pipelines in house.
2024-03-25 19:42:10,570 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:start(401)) - SCM DB initialized
2024-03-25 19:42:10,571 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(194)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:15009
2024-03-25 19:42:10,572 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-03-25 19:42:10,572 [IPC Server listener on 15009] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15009: starting
2024-03-25 19:42:11,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:12,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:13,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:14,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:15,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:16,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:17,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:18,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:19,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:20,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:21,370 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:21,592 [main] INFO  scm.ReconScmTask (ReconScmTask.java:register(46)) - Registered ContainerSizeCountTask task 
2024-03-25 19:42:21,592 [main] INFO  scm.ReconScmTask (ReconScmTask.java:start(56)) - Starting ContainerSizeCountTask Thread.
2024-03-25 19:42:21,595 [main] INFO  scm.ReconScmTask (ReconScmTask.java:register(46)) - Registered ContainerHealthTask task 
2024-03-25 19:42:21,595 [main] INFO  scm.ReconScmTask (ReconScmTask.java:start(56)) - Starting ContainerHealthTask Thread.
2024-03-25 19:42:21,597 [main] INFO  scm.ReconScmTask (ReconScmTask.java:register(46)) - Registered PipelineSyncTask task 
2024-03-25 19:42:21,598 [main] INFO  scm.ReconScmTask (ReconScmTask.java:start(56)) - Starting PipelineSyncTask Thread.
2024-03-25 19:42:21,605 [JvmPauseMonitor2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-Recon: Started
2024-03-25 19:42:21,617 [PipelineSyncTask] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 0 pipelines in house.
2024-03-25 19:42:21,624 [PipelineSyncTask] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 25 milliseconds.
2024-03-25 19:42:21,631 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 33 milliseconds to process 0 existing database records.
2024-03-25 19:42:21,634 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:21,667 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-03-25 19:42:21,668 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-03-25 19:42:21,668 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-03-25 19:42:21,682 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(240)) - HddsDatanodeService host:fv-az1540-867 ip:10.1.0.27
2024-03-25 19:42:21,704 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-03-25 19:42:21,707 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(299)) - Datanode State Machine Task Thread Pool size 2
2024-03-25 19:42:21,759 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(125)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/data-0/hdds of storage type : DISK capacity : 9223372036854775807
2024-03-25 19:42:21,761 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/data-0/hdds to VolumeSet
2024-03-25 19:42:21,764 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis to VolumeSet
2024-03-25 19:42:21,767 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 1ms
2024-03-25 19:42:21,808 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for DNAudit to [].
2024-03-25 19:42:21,833 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-03-25 19:42:21,833 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-03-25 19:42:21,834 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15015 (custom)
2024-03-25 19:42:21,834 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-03-25 19:42:21,834 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15014 (custom)
2024-03-25 19:42:21,834 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-03-25 19:42:21,835 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15016 (custom)
2024-03-25 19:42:21,835 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-03-25 19:42:21,835 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:21,835 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-03-25 19:42:21,835 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:42:21,836 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-25 19:42:21,836 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-03-25 19:42:21,836 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-03-25 19:42:21,838 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-03-25 19:42:21,850 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-03-25 19:42:21,850 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-03-25 19:42:21,851 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-03-25 19:42:21,852 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-03-25 19:42:21,853 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-03-25 19:42:21,854 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-03-25 19:42:21,855 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-03-25 19:42:21,870 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for a568c6b4-1a28-494a-b080-2324592b3a72-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-03-25 19:42:21,875 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-03-25 19:42:21,876 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for a568c6b4-1a28-494a-b080-2324592b3a72-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-03-25 19:42:21,877 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-03-25 19:42:21,878 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-03-25 19:42:21,879 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15017 (custom)
2024-03-25 19:42:21,883 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:42:21,884 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-03-25 19:42:21,884 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:42:21,884 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis] (custom)
2024-03-25 19:42:21,884 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-03-25 19:42:21,885 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-03-25 19:42:21,885 [a568c6b4-1a28-494a-b080-2324592b3a72-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - a568c6b4-1a28-494a-b080-2324592b3a72: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/tmp
2024-03-25 19:42:21,886 [a568c6b4-1a28-494a-b080-2324592b3a72-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(269)) - a568c6b4-1a28-494a-b080-2324592b3a72: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/tmp is not a group directory; ignoring it. 
2024-03-25 19:42:21,889 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-03-25 19:42:21,895 [a568c6b4-1a28-494a-b080-2324592b3a72-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x5a82eb56] REGISTERED
2024-03-25 19:42:21,895 [a568c6b4-1a28-494a-b080-2324592b3a72-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x5a82eb56] BIND: 0.0.0.0/0.0.0.0:15017
2024-03-25 19:42:21,896 [a568c6b4-1a28-494a-b080-2324592b3a72-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x5a82eb56, L:/0.0.0.0:15017] ACTIVE
2024-03-25 19:42:21,911 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-03-25 19:42:21,978 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(157)) - Initializing replication supervisor with thread count = 10
2024-03-25 19:42:21,979 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-03-25 19:42:22,025 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15011
2024-03-25 19:42:22,025 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-25 19:42:22,027 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-03-25 19:42:22,027 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-03-25 19:42:22,029 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-25 19:42:22,030 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-03-25 19:42:22,030 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-25 19:42:22,030 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-25 19:42:22,031 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/meta/webserver
2024-03-25 19:42:22,031 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15011
2024-03-25 19:42:22,031 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-03-25 19:42:22,033 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-03-25 19:42:22,033 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-03-25 19:42:22,033 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2024-03-25 19:42:22,034 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2f730434{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-03-25 19:42:22,034 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@5eb645c8{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-03-25 19:42:22,072 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@3a55f8c7{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/meta/webserver/jetty-0_0_0_0-15011-hdds-container-service-1_5_0-SNAPSHOT_jar-_-any-3262742365568199559/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-03-25 19:42:22,075 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@3e21253f{HTTP/1.1, (http/1.1)}{0.0.0.0:15011}
2024-03-25 19:42:22,075 [main] INFO  server.Server (Server.java:doStart(415)) - Started @21592ms
2024-03-25 19:42:22,075 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-03-25 19:42:22,076 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15011
2024-03-25 19:42:22,079 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-25 19:42:22,079 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15012
2024-03-25 19:42:22,079 [Socket Reader #1 for port 15012] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15012
2024-03-25 19:42:22,082 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(327)) - Datanode start with admins: [runner]
2024-03-25 19:42:22,082 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15012
2024-03-25 19:42:22,083 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-03-25 19:42:22,083 [IPC Server listener on 15012] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15012: starting
2024-03-25 19:42:22,085 [a568c6b4-1a28-494a-b080-2324592b3a72-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(555)) - Ozone container server started.
2024-03-25 19:42:22,086 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-03-25 19:42:22,087 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-03-25 19:42:22,087 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-03-25 19:42:22,096 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(240)) - HddsDatanodeService host:fv-az1540-867 ip:10.1.0.27
2024-03-25 19:42:22,113 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-03-25 19:42:22,113 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(299)) - Datanode State Machine Task Thread Pool size 2
2024-03-25 19:42:22,115 [a568c6b4-1a28-494a-b080-2324592b3a72-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-03-25 19:42:22,116 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(125)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/data-0/hdds of storage type : DISK capacity : 9223372036854775807
2024-03-25 19:42:22,117 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/data-0/hdds to VolumeSet
2024-03-25 19:42:22,118 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis to VolumeSet
2024-03-25 19:42:22,118 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 0ms
2024-03-25 19:42:22,121 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-03-25 19:42:22,122 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-03-25 19:42:22,122 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15024 (custom)
2024-03-25 19:42:22,122 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-03-25 19:42:22,122 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15023 (custom)
2024-03-25 19:42:22,122 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-03-25 19:42:22,122 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15025 (custom)
2024-03-25 19:42:22,123 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-03-25 19:42:22,123 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:22,123 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-03-25 19:42:22,123 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:42:22,123 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-25 19:42:22,124 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-03-25 19:42:22,124 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-03-25 19:42:22,126 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-03-25 19:42:22,126 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-03-25 19:42:22,126 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-03-25 19:42:22,127 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-03-25 19:42:22,127 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-03-25 19:42:22,127 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-03-25 19:42:22,127 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-03-25 19:42:22,127 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-03-25 19:42:22,128 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for a6fb26e7-f548-473f-8cf0-48fafe70504d-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-03-25 19:42:22,128 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-03-25 19:42:22,128 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for a6fb26e7-f548-473f-8cf0-48fafe70504d-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-03-25 19:42:22,129 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-03-25 19:42:22,129 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-03-25 19:42:22,129 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15026 (custom)
2024-03-25 19:42:22,130 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:42:22,131 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-03-25 19:42:22,131 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:42:22,132 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis] (custom)
2024-03-25 19:42:22,132 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-03-25 19:42:22,132 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-03-25 19:42:22,133 [a6fb26e7-f548-473f-8cf0-48fafe70504d-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/tmp
2024-03-25 19:42:22,133 [a6fb26e7-f548-473f-8cf0-48fafe70504d-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(269)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/tmp is not a group directory; ignoring it. 
2024-03-25 19:42:22,134 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-03-25 19:42:22,136 [a6fb26e7-f548-473f-8cf0-48fafe70504d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x26e8580d] REGISTERED
2024-03-25 19:42:22,137 [a6fb26e7-f548-473f-8cf0-48fafe70504d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x26e8580d] BIND: 0.0.0.0/0.0.0.0:15026
2024-03-25 19:42:22,138 [a6fb26e7-f548-473f-8cf0-48fafe70504d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x26e8580d, L:/0.0.0.0:15026] ACTIVE
2024-03-25 19:42:22,138 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-03-25 19:42:22,141 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(157)) - Initializing replication supervisor with thread count = 10
2024-03-25 19:42:22,142 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-03-25 19:42:22,145 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15020
2024-03-25 19:42:22,145 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-25 19:42:22,147 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-03-25 19:42:22,148 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-03-25 19:42:22,149 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-25 19:42:22,150 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-03-25 19:42:22,151 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-25 19:42:22,151 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-25 19:42:22,152 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/meta/webserver
2024-03-25 19:42:22,152 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15020
2024-03-25 19:42:22,153 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-03-25 19:42:22,154 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-03-25 19:42:22,154 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-03-25 19:42:22,154 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2024-03-25 19:42:22,155 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@4747a860{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-03-25 19:42:22,156 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7aaefbf8{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-03-25 19:42:22,198 [a568c6b4-1a28-494a-b080-2324592b3a72-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/meta/datanode.id
2024-03-25 19:42:22,213 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@99daa14{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/meta/webserver/jetty-0_0_0_0-15020-hdds-container-service-1_5_0-SNAPSHOT_jar-_-any-7859321929860606578/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-03-25 19:42:22,215 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@3823c031{HTTP/1.1, (http/1.1)}{0.0.0.0:15020}
2024-03-25 19:42:22,215 [main] INFO  server.Server (Server.java:doStart(415)) - Started @21732ms
2024-03-25 19:42:22,215 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-03-25 19:42:22,216 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15020
2024-03-25 19:42:22,216 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-25 19:42:22,217 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15021
2024-03-25 19:42:22,217 [Socket Reader #1 for port 15021] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15021
2024-03-25 19:42:22,220 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(327)) - Datanode start with admins: [runner]
2024-03-25 19:42:22,220 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15021
2024-03-25 19:42:22,225 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-03-25 19:42:22,225 [IPC Server listener on 15021] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15021: starting
2024-03-25 19:42:22,226 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-03-25 19:42:22,226 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-03-25 19:42:22,226 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-03-25 19:42:22,226 [a6fb26e7-f548-473f-8cf0-48fafe70504d-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(555)) - Ozone container server started.
2024-03-25 19:42:22,229 [a6fb26e7-f548-473f-8cf0-48fafe70504d-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-03-25 19:42:22,240 [a6fb26e7-f548-473f-8cf0-48fafe70504d-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/meta/datanode.id
2024-03-25 19:42:22,245 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(240)) - HddsDatanodeService host:fv-az1540-867 ip:10.1.0.27
2024-03-25 19:42:22,261 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-03-25 19:42:22,262 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(299)) - Datanode State Machine Task Thread Pool size 2
2024-03-25 19:42:22,269 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(125)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/data-0/hdds of storage type : DISK capacity : 9223372036854775807
2024-03-25 19:42:22,269 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/data-0/hdds to VolumeSet
2024-03-25 19:42:22,270 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis to VolumeSet
2024-03-25 19:42:22,271 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 0ms
2024-03-25 19:42:22,275 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-03-25 19:42:22,275 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-03-25 19:42:22,275 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15033 (custom)
2024-03-25 19:42:22,275 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-03-25 19:42:22,275 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15032 (custom)
2024-03-25 19:42:22,276 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-03-25 19:42:22,276 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15034 (custom)
2024-03-25 19:42:22,276 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-03-25 19:42:22,276 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:22,276 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-03-25 19:42:22,277 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:42:22,277 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-25 19:42:22,277 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-03-25 19:42:22,277 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-03-25 19:42:22,280 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-03-25 19:42:22,280 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-03-25 19:42:22,281 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-03-25 19:42:22,281 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-03-25 19:42:22,281 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-03-25 19:42:22,281 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-03-25 19:42:22,281 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-03-25 19:42:22,282 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-03-25 19:42:22,282 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for f8c0ec26-9898-49d2-a0ea-132d14d0dc83-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-03-25 19:42:22,283 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-03-25 19:42:22,283 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for f8c0ec26-9898-49d2-a0ea-132d14d0dc83-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-03-25 19:42:22,283 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-03-25 19:42:22,284 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-03-25 19:42:22,284 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15035 (custom)
2024-03-25 19:42:22,284 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:42:22,285 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-03-25 19:42:22,286 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:42:22,286 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x27663235] REGISTERED
2024-03-25 19:42:22,286 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis] (custom)
2024-03-25 19:42:22,286 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x27663235] BIND: 0.0.0.0/0.0.0.0:15035
2024-03-25 19:42:22,286 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-03-25 19:42:22,287 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x27663235, L:/0.0.0.0:15035] ACTIVE
2024-03-25 19:42:22,287 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-03-25 19:42:22,287 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/tmp
2024-03-25 19:42:22,287 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(269)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/tmp is not a group directory; ignoring it. 
2024-03-25 19:42:22,288 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-03-25 19:42:22,289 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-03-25 19:42:22,292 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(157)) - Initializing replication supervisor with thread count = 10
2024-03-25 19:42:22,292 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-03-25 19:42:22,294 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15029
2024-03-25 19:42:22,294 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-25 19:42:22,296 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-03-25 19:42:22,296 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-03-25 19:42:22,298 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-25 19:42:22,299 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-03-25 19:42:22,299 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-25 19:42:22,299 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-25 19:42:22,300 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/meta/webserver
2024-03-25 19:42:22,300 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15029
2024-03-25 19:42:22,300 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-03-25 19:42:22,304 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-03-25 19:42:22,304 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-03-25 19:42:22,305 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2024-03-25 19:42:22,306 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@1769fe0d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-03-25 19:42:22,307 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@3c602531{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-03-25 19:42:22,342 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@f0cf7a4{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/meta/webserver/jetty-0_0_0_0-15029-hdds-container-service-1_5_0-SNAPSHOT_jar-_-any-9121915880533315959/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-03-25 19:42:22,344 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@7b11904c{HTTP/1.1, (http/1.1)}{0.0.0.0:15029}
2024-03-25 19:42:22,344 [main] INFO  server.Server (Server.java:doStart(415)) - Started @21861ms
2024-03-25 19:42:22,344 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-03-25 19:42:22,345 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15029
2024-03-25 19:42:22,345 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-25 19:42:22,345 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15030
2024-03-25 19:42:22,346 [Socket Reader #1 for port 15030] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15030
2024-03-25 19:42:22,349 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(327)) - Datanode start with admins: [runner]
2024-03-25 19:42:22,349 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15030
2024-03-25 19:42:22,349 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-03-25 19:42:22,349 [IPC Server listener on 15030] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15030: starting
2024-03-25 19:42:22,354 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-03-25 19:42:22,356 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-03-25 19:42:22,354 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(555)) - Ozone container server started.
2024-03-25 19:42:22,356 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-03-25 19:42:22,366 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(240)) - HddsDatanodeService host:fv-az1540-867 ip:10.1.0.27
2024-03-25 19:42:22,368 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-03-25 19:42:22,371 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/meta/datanode.id
2024-03-25 19:42:22,371 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:22,391 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-03-25 19:42:22,392 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(299)) - Datanode State Machine Task Thread Pool size 2
2024-03-25 19:42:22,395 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(125)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/data-0/hdds of storage type : DISK capacity : 9223372036854775807
2024-03-25 19:42:22,395 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/data-0/hdds to VolumeSet
2024-03-25 19:42:22,396 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis to VolumeSet
2024-03-25 19:42:22,401 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 0ms
2024-03-25 19:42:22,405 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-03-25 19:42:22,405 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-03-25 19:42:22,406 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15042 (custom)
2024-03-25 19:42:22,406 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-03-25 19:42:22,406 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15041 (custom)
2024-03-25 19:42:22,406 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-03-25 19:42:22,406 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15043 (custom)
2024-03-25 19:42:22,407 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-03-25 19:42:22,407 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:22,407 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-03-25 19:42:22,407 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:42:22,408 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-25 19:42:22,408 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-03-25 19:42:22,408 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-03-25 19:42:22,411 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-03-25 19:42:22,411 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-03-25 19:42:22,412 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-03-25 19:42:22,412 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-03-25 19:42:22,412 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-03-25 19:42:22,412 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-03-25 19:42:22,413 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-03-25 19:42:22,413 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-03-25 19:42:22,413 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 6e65d581-b1bc-41f2-b39b-16d8508d6618-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-03-25 19:42:22,414 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-03-25 19:42:22,414 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 6e65d581-b1bc-41f2-b39b-16d8508d6618-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-03-25 19:42:22,415 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-03-25 19:42:22,415 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-03-25 19:42:22,415 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15044 (custom)
2024-03-25 19:42:22,416 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:42:22,416 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-03-25 19:42:22,416 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:42:22,417 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis] (custom)
2024-03-25 19:42:22,417 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-03-25 19:42:22,417 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-03-25 19:42:22,422 [6e65d581-b1bc-41f2-b39b-16d8508d6618-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x81c3c182] REGISTERED
2024-03-25 19:42:22,423 [6e65d581-b1bc-41f2-b39b-16d8508d6618-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x81c3c182] BIND: 0.0.0.0/0.0.0.0:15044
2024-03-25 19:42:22,423 [6e65d581-b1bc-41f2-b39b-16d8508d6618-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x81c3c182, L:/0.0.0.0:15044] ACTIVE
2024-03-25 19:42:22,423 [6e65d581-b1bc-41f2-b39b-16d8508d6618-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/tmp
2024-03-25 19:42:22,423 [6e65d581-b1bc-41f2-b39b-16d8508d6618-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(269)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/tmp is not a group directory; ignoring it. 
2024-03-25 19:42:22,424 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-03-25 19:42:22,425 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-03-25 19:42:22,427 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(157)) - Initializing replication supervisor with thread count = 10
2024-03-25 19:42:22,427 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-03-25 19:42:22,431 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15038
2024-03-25 19:42:22,431 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-25 19:42:22,432 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-03-25 19:42:22,434 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-03-25 19:42:22,435 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-25 19:42:22,436 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-03-25 19:42:22,436 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-25 19:42:22,436 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-25 19:42:22,437 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/meta/webserver
2024-03-25 19:42:22,437 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15038
2024-03-25 19:42:22,437 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-03-25 19:42:22,439 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-03-25 19:42:22,440 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-03-25 19:42:22,440 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2024-03-25 19:42:22,440 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@41e537cb{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-03-25 19:42:22,441 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7fb342f8{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-03-25 19:42:22,475 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@1469a956{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/meta/webserver/jetty-0_0_0_0-15038-hdds-container-service-1_5_0-SNAPSHOT_jar-_-any-5335744912964472771/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-03-25 19:42:22,477 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@69fbbcf6{HTTP/1.1, (http/1.1)}{0.0.0.0:15038}
2024-03-25 19:42:22,477 [main] INFO  server.Server (Server.java:doStart(415)) - Started @21994ms
2024-03-25 19:42:22,478 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-03-25 19:42:22,478 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15038
2024-03-25 19:42:22,479 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-25 19:42:22,479 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15039
2024-03-25 19:42:22,481 [Socket Reader #1 for port 15039] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15039
2024-03-25 19:42:22,486 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(327)) - Datanode start with admins: [runner]
2024-03-25 19:42:22,492 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15039
2024-03-25 19:42:22,492 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-03-25 19:42:22,492 [IPC Server listener on 15039] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15039: starting
2024-03-25 19:42:22,493 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-03-25 19:42:22,493 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-03-25 19:42:22,496 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-03-25 19:42:22,499 [6e65d581-b1bc-41f2-b39b-16d8508d6618-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(555)) - Ozone container server started.
2024-03-25 19:42:22,502 [6e65d581-b1bc-41f2-b39b-16d8508d6618-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-03-25 19:42:22,509 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(240)) - HddsDatanodeService host:fv-az1540-867 ip:10.1.0.27
2024-03-25 19:42:22,509 [6e65d581-b1bc-41f2-b39b-16d8508d6618-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/meta/datanode.id
2024-03-25 19:42:22,534 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-03-25 19:42:22,534 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(299)) - Datanode State Machine Task Thread Pool size 2
2024-03-25 19:42:22,537 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(125)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/data-0/hdds of storage type : DISK capacity : 9223372036854775807
2024-03-25 19:42:22,537 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/data-0/hdds to VolumeSet
2024-03-25 19:42:22,538 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis to VolumeSet
2024-03-25 19:42:22,539 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 0ms
2024-03-25 19:42:22,542 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-03-25 19:42:22,542 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-03-25 19:42:22,543 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15051 (custom)
2024-03-25 19:42:22,543 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-03-25 19:42:22,543 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15050 (custom)
2024-03-25 19:42:22,543 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-03-25 19:42:22,544 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15052 (custom)
2024-03-25 19:42:22,544 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-03-25 19:42:22,544 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:22,544 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-03-25 19:42:22,544 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:42:22,545 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-25 19:42:22,545 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-03-25 19:42:22,545 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-03-25 19:42:22,548 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-03-25 19:42:22,550 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-03-25 19:42:22,550 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-03-25 19:42:22,551 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-03-25 19:42:22,551 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-03-25 19:42:22,551 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-03-25 19:42:22,552 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-03-25 19:42:22,555 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-03-25 19:42:22,556 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 8de788e1-2c95-4c74-b4ac-29ea2448e86a-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-03-25 19:42:22,556 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-03-25 19:42:22,556 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 8de788e1-2c95-4c74-b4ac-29ea2448e86a-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-03-25 19:42:22,557 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-03-25 19:42:22,557 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-03-25 19:42:22,557 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15053 (custom)
2024-03-25 19:42:22,558 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:42:22,559 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-03-25 19:42:22,559 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:42:22,560 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis] (custom)
2024-03-25 19:42:22,560 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-03-25 19:42:22,560 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-03-25 19:42:22,561 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/tmp
2024-03-25 19:42:22,561 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(269)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/tmp is not a group directory; ignoring it. 
2024-03-25 19:42:22,561 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-03-25 19:42:22,563 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-03-25 19:42:22,565 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(157)) - Initializing replication supervisor with thread count = 10
2024-03-25 19:42:22,565 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-03-25 19:42:22,561 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xeb536e14] REGISTERED
2024-03-25 19:42:22,567 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xeb536e14] BIND: 0.0.0.0/0.0.0.0:15053
2024-03-25 19:42:22,567 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xeb536e14, L:/0.0.0.0:15053] ACTIVE
2024-03-25 19:42:22,575 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15047
2024-03-25 19:42:22,575 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-25 19:42:22,578 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-03-25 19:42:22,579 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-03-25 19:42:22,580 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-25 19:42:22,582 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-03-25 19:42:22,582 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-25 19:42:22,583 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-25 19:42:22,584 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/meta/webserver
2024-03-25 19:42:22,584 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15047
2024-03-25 19:42:22,585 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-03-25 19:42:22,597 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-03-25 19:42:22,597 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-03-25 19:42:22,597 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2024-03-25 19:42:22,598 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@14174dcb{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-03-25 19:42:22,600 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@f45e521{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-03-25 19:42:22,635 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:22,635 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:22,645 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@31e36f74{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/meta/webserver/jetty-0_0_0_0-15047-hdds-container-service-1_5_0-SNAPSHOT_jar-_-any-6814632548654019832/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-03-25 19:42:22,647 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@473754ef{HTTP/1.1, (http/1.1)}{0.0.0.0:15047}
2024-03-25 19:42:22,647 [main] INFO  server.Server (Server.java:doStart(415)) - Started @22164ms
2024-03-25 19:42:22,647 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-03-25 19:42:22,648 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15047
2024-03-25 19:42:22,648 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-25 19:42:22,649 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15048
2024-03-25 19:42:22,649 [Socket Reader #1 for port 15048] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15048
2024-03-25 19:42:22,652 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(327)) - Datanode start with admins: [runner]
2024-03-25 19:42:22,652 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15048
2024-03-25 19:42:22,653 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-03-25 19:42:22,662 [IPC Server listener on 15048] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15048: starting
2024-03-25 19:42:22,663 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 0 of 5 DN Heartbeats.
2024-03-25 19:42:22,664 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-03-25 19:42:22,664 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-25 19:42:22,665 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(555)) - Ozone container server started.
2024-03-25 19:42:22,670 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-03-25 19:42:22,674 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/meta/datanode.id
2024-03-25 19:42:23,371 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:23,636 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:23,637 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:23,664 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 0 of 5 DN Heartbeats.
2024-03-25 19:42:23,664 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-03-25 19:42:23,664 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-25 19:42:24,175 [a568c6b4-1a28-494a-b080-2324592b3a72-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-803237d0-c9dc-4fed-b0b2-099c5dbec3f7/container.db to cache
2024-03-25 19:42:24,175 [a568c6b4-1a28-494a-b080-2324592b3a72-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(420)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-803237d0-c9dc-4fed-b0b2-099c5dbec3f7/container.db for volume DS-803237d0-c9dc-4fed-b0b2-099c5dbec3f7
2024-03-25 19:42:24,183 [a568c6b4-1a28-494a-b080-2324592b3a72-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/data-0/hdds
2024-03-25 19:42:24,183 [a568c6b4-1a28-494a-b080-2324592b3a72-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/data-0/hdds
2024-03-25 19:42:24,184 [a568c6b4-1a28-494a-b080-2324592b3a72-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-03-25 19:42:24,185 [a568c6b4-1a28-494a-b080-2324592b3a72-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/data-0/hdds
2024-03-25 19:42:24,196 [a568c6b4-1a28-494a-b080-2324592b3a72-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/data-0/hdds
2024-03-25 19:42:24,198 [a568c6b4-1a28-494a-b080-2324592b3a72-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis
2024-03-25 19:42:24,198 [a568c6b4-1a28-494a-b080-2324592b3a72-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis
2024-03-25 19:42:24,199 [a568c6b4-1a28-494a-b080-2324592b3a72-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-03-25 19:42:24,204 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-03-25 19:42:24,208 [a568c6b4-1a28-494a-b080-2324592b3a72-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15018
2024-03-25 19:42:24,209 [a568c6b4-1a28-494a-b080-2324592b3a72-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(566)) - Starting XceiverServerRatis a568c6b4-1a28-494a-b080-2324592b3a72
2024-03-25 19:42:24,210 [a568c6b4-1a28-494a-b080-2324592b3a72-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(406)) - a568c6b4-1a28-494a-b080-2324592b3a72: start RPC server
2024-03-25 19:42:24,210 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-03-25 19:42:24,212 [a568c6b4-1a28-494a-b080-2324592b3a72-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - a568c6b4-1a28-494a-b080-2324592b3a72: GrpcService started, listening on 15014
2024-03-25 19:42:24,214 [a568c6b4-1a28-494a-b080-2324592b3a72-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - a568c6b4-1a28-494a-b080-2324592b3a72: GrpcService started, listening on 15016
2024-03-25 19:42:24,218 [a568c6b4-1a28-494a-b080-2324592b3a72-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - a568c6b4-1a28-494a-b080-2324592b3a72: GrpcService started, listening on 15015
2024-03-25 19:42:24,218 [JvmPauseMonitor3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-a568c6b4-1a28-494a-b080-2324592b3a72: Started
2024-03-25 19:42:24,219 [a568c6b4-1a28-494a-b080-2324592b3a72-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis a568c6b4-1a28-494a-b080-2324592b3a72 is started using port 15014 for RATIS
2024-03-25 19:42:24,219 [a568c6b4-1a28-494a-b080-2324592b3a72-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis a568c6b4-1a28-494a-b080-2324592b3a72 is started using port 15015 for RATIS_ADMIN
2024-03-25 19:42:24,219 [a568c6b4-1a28-494a-b080-2324592b3a72-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis a568c6b4-1a28-494a-b080-2324592b3a72 is started using port 15016 for RATIS_SERVER
2024-03-25 19:42:24,219 [a568c6b4-1a28-494a-b080-2324592b3a72-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis a568c6b4-1a28-494a-b080-2324592b3a72 is started using port 15017 for RATIS_DATASTREAM
2024-03-25 19:42:24,223 [a568c6b4-1a28-494a-b080-2324592b3a72-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-03-25 19:42:24,250 [a6fb26e7-f548-473f-8cf0-48fafe70504d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-71af8759-bfa1-4ad0-bcf2-b488489b099b/container.db to cache
2024-03-25 19:42:24,250 [a6fb26e7-f548-473f-8cf0-48fafe70504d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(420)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-71af8759-bfa1-4ad0-bcf2-b488489b099b/container.db for volume DS-71af8759-bfa1-4ad0-bcf2-b488489b099b
2024-03-25 19:42:24,252 [a6fb26e7-f548-473f-8cf0-48fafe70504d-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/data-0/hdds
2024-03-25 19:42:24,252 [a6fb26e7-f548-473f-8cf0-48fafe70504d-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/data-0/hdds
2024-03-25 19:42:24,252 [a6fb26e7-f548-473f-8cf0-48fafe70504d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-03-25 19:42:24,253 [a6fb26e7-f548-473f-8cf0-48fafe70504d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/data-0/hdds
2024-03-25 19:42:24,254 [a6fb26e7-f548-473f-8cf0-48fafe70504d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/data-0/hdds
2024-03-25 19:42:24,256 [a6fb26e7-f548-473f-8cf0-48fafe70504d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis
2024-03-25 19:42:24,256 [a6fb26e7-f548-473f-8cf0-48fafe70504d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis
2024-03-25 19:42:24,260 [a6fb26e7-f548-473f-8cf0-48fafe70504d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-03-25 19:42:24,261 [a6fb26e7-f548-473f-8cf0-48fafe70504d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(75)) - Trying to initialize on demand scanner a second time on a datanode.
2024-03-25 19:42:24,261 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-03-25 19:42:24,262 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-03-25 19:42:24,264 [a6fb26e7-f548-473f-8cf0-48fafe70504d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15027
2024-03-25 19:42:24,264 [a6fb26e7-f548-473f-8cf0-48fafe70504d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(566)) - Starting XceiverServerRatis a6fb26e7-f548-473f-8cf0-48fafe70504d
2024-03-25 19:42:24,270 [a6fb26e7-f548-473f-8cf0-48fafe70504d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(406)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: start RPC server
2024-03-25 19:42:24,271 [a6fb26e7-f548-473f-8cf0-48fafe70504d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: GrpcService started, listening on 15023
2024-03-25 19:42:24,273 [a6fb26e7-f548-473f-8cf0-48fafe70504d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: GrpcService started, listening on 15025
2024-03-25 19:42:24,276 [a6fb26e7-f548-473f-8cf0-48fafe70504d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: GrpcService started, listening on 15024
2024-03-25 19:42:24,276 [a6fb26e7-f548-473f-8cf0-48fafe70504d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis a6fb26e7-f548-473f-8cf0-48fafe70504d is started using port 15023 for RATIS
2024-03-25 19:42:24,276 [JvmPauseMonitor4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-a6fb26e7-f548-473f-8cf0-48fafe70504d: Started
2024-03-25 19:42:24,276 [a6fb26e7-f548-473f-8cf0-48fafe70504d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis a6fb26e7-f548-473f-8cf0-48fafe70504d is started using port 15024 for RATIS_ADMIN
2024-03-25 19:42:24,277 [a6fb26e7-f548-473f-8cf0-48fafe70504d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis a6fb26e7-f548-473f-8cf0-48fafe70504d is started using port 15025 for RATIS_SERVER
2024-03-25 19:42:24,277 [a6fb26e7-f548-473f-8cf0-48fafe70504d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis a6fb26e7-f548-473f-8cf0-48fafe70504d is started using port 15026 for RATIS_DATASTREAM
2024-03-25 19:42:24,283 [a6fb26e7-f548-473f-8cf0-48fafe70504d-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-03-25 19:42:24,371 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:24,401 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-e828a9d5-04d1-4ff4-9efb-57eb4f509c93/container.db to cache
2024-03-25 19:42:24,401 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(420)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-e828a9d5-04d1-4ff4-9efb-57eb4f509c93/container.db for volume DS-e828a9d5-04d1-4ff4-9efb-57eb4f509c93
2024-03-25 19:42:24,403 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/data-0/hdds
2024-03-25 19:42:24,403 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/data-0/hdds
2024-03-25 19:42:24,403 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-03-25 19:42:24,404 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/data-0/hdds
2024-03-25 19:42:24,413 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/data-0/hdds
2024-03-25 19:42:24,414 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis
2024-03-25 19:42:24,414 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis
2024-03-25 19:42:24,415 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-03-25 19:42:24,415 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(75)) - Trying to initialize on demand scanner a second time on a datanode.
2024-03-25 19:42:24,416 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-03-25 19:42:24,418 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15036
2024-03-25 19:42:24,418 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-03-25 19:42:24,418 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(566)) - Starting XceiverServerRatis f8c0ec26-9898-49d2-a0ea-132d14d0dc83
2024-03-25 19:42:24,426 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(406)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: start RPC server
2024-03-25 19:42:24,427 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: GrpcService started, listening on 15032
2024-03-25 19:42:24,429 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: GrpcService started, listening on 15034
2024-03-25 19:42:24,431 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: GrpcService started, listening on 15033
2024-03-25 19:42:24,431 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis f8c0ec26-9898-49d2-a0ea-132d14d0dc83 is started using port 15032 for RATIS
2024-03-25 19:42:24,431 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis f8c0ec26-9898-49d2-a0ea-132d14d0dc83 is started using port 15033 for RATIS_ADMIN
2024-03-25 19:42:24,431 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis f8c0ec26-9898-49d2-a0ea-132d14d0dc83 is started using port 15034 for RATIS_SERVER
2024-03-25 19:42:24,431 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis f8c0ec26-9898-49d2-a0ea-132d14d0dc83 is started using port 15035 for RATIS_DATASTREAM
2024-03-25 19:42:24,431 [JvmPauseMonitor5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-f8c0ec26-9898-49d2-a0ea-132d14d0dc83: Started
2024-03-25 19:42:24,435 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-03-25 19:42:24,524 [6e65d581-b1bc-41f2-b39b-16d8508d6618-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-a11ce00a-a8e8-4457-9c04-884d2480a314/container.db to cache
2024-03-25 19:42:24,525 [6e65d581-b1bc-41f2-b39b-16d8508d6618-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(420)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-a11ce00a-a8e8-4457-9c04-884d2480a314/container.db for volume DS-a11ce00a-a8e8-4457-9c04-884d2480a314
2024-03-25 19:42:24,527 [6e65d581-b1bc-41f2-b39b-16d8508d6618-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/data-0/hdds
2024-03-25 19:42:24,527 [6e65d581-b1bc-41f2-b39b-16d8508d6618-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/data-0/hdds
2024-03-25 19:42:24,527 [6e65d581-b1bc-41f2-b39b-16d8508d6618-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-03-25 19:42:24,528 [6e65d581-b1bc-41f2-b39b-16d8508d6618-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/data-0/hdds
2024-03-25 19:42:24,531 [6e65d581-b1bc-41f2-b39b-16d8508d6618-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/data-0/hdds
2024-03-25 19:42:24,532 [6e65d581-b1bc-41f2-b39b-16d8508d6618-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis
2024-03-25 19:42:24,532 [6e65d581-b1bc-41f2-b39b-16d8508d6618-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis
2024-03-25 19:42:24,533 [6e65d581-b1bc-41f2-b39b-16d8508d6618-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-03-25 19:42:24,533 [6e65d581-b1bc-41f2-b39b-16d8508d6618-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(75)) - Trying to initialize on demand scanner a second time on a datanode.
2024-03-25 19:42:24,534 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-03-25 19:42:24,534 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-03-25 19:42:24,536 [6e65d581-b1bc-41f2-b39b-16d8508d6618-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15045
2024-03-25 19:42:24,536 [6e65d581-b1bc-41f2-b39b-16d8508d6618-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(566)) - Starting XceiverServerRatis 6e65d581-b1bc-41f2-b39b-16d8508d6618
2024-03-25 19:42:24,538 [6e65d581-b1bc-41f2-b39b-16d8508d6618-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(406)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: start RPC server
2024-03-25 19:42:24,540 [6e65d581-b1bc-41f2-b39b-16d8508d6618-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: GrpcService started, listening on 15041
2024-03-25 19:42:24,541 [6e65d581-b1bc-41f2-b39b-16d8508d6618-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: GrpcService started, listening on 15043
2024-03-25 19:42:24,547 [6e65d581-b1bc-41f2-b39b-16d8508d6618-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: GrpcService started, listening on 15042
2024-03-25 19:42:24,547 [6e65d581-b1bc-41f2-b39b-16d8508d6618-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 6e65d581-b1bc-41f2-b39b-16d8508d6618 is started using port 15041 for RATIS
2024-03-25 19:42:24,547 [JvmPauseMonitor6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-6e65d581-b1bc-41f2-b39b-16d8508d6618: Started
2024-03-25 19:42:24,547 [6e65d581-b1bc-41f2-b39b-16d8508d6618-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 6e65d581-b1bc-41f2-b39b-16d8508d6618 is started using port 15042 for RATIS_ADMIN
2024-03-25 19:42:24,548 [6e65d581-b1bc-41f2-b39b-16d8508d6618-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 6e65d581-b1bc-41f2-b39b-16d8508d6618 is started using port 15043 for RATIS_SERVER
2024-03-25 19:42:24,548 [6e65d581-b1bc-41f2-b39b-16d8508d6618-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 6e65d581-b1bc-41f2-b39b-16d8508d6618 is started using port 15044 for RATIS_DATASTREAM
2024-03-25 19:42:24,551 [6e65d581-b1bc-41f2-b39b-16d8508d6618-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-03-25 19:42:24,638 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:24,638 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:24,665 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 0 of 5 DN Heartbeats.
2024-03-25 19:42:24,665 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-03-25 19:42:24,665 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-25 19:42:24,689 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-96cefe10-55c8-478c-92f7-334af2b965c5/container.db to cache
2024-03-25 19:42:24,689 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(420)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-96cefe10-55c8-478c-92f7-334af2b965c5/container.db for volume DS-96cefe10-55c8-478c-92f7-334af2b965c5
2024-03-25 19:42:24,691 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/data-0/hdds
2024-03-25 19:42:24,691 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/data-0/hdds
2024-03-25 19:42:24,691 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-03-25 19:42:24,692 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/data-0/hdds
2024-03-25 19:42:24,693 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/data-0/hdds
2024-03-25 19:42:24,694 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis
2024-03-25 19:42:24,695 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis
2024-03-25 19:42:24,695 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-03-25 19:42:24,695 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(75)) - Trying to initialize on demand scanner a second time on a datanode.
2024-03-25 19:42:24,696 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-03-25 19:42:24,696 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-03-25 19:42:24,697 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15054
2024-03-25 19:42:24,697 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(566)) - Starting XceiverServerRatis 8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:42:24,699 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(406)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: start RPC server
2024-03-25 19:42:24,700 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: GrpcService started, listening on 15050
2024-03-25 19:42:24,700 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: GrpcService started, listening on 15052
2024-03-25 19:42:24,701 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: GrpcService started, listening on 15051
2024-03-25 19:42:24,701 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 8de788e1-2c95-4c74-b4ac-29ea2448e86a is started using port 15050 for RATIS
2024-03-25 19:42:24,702 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 8de788e1-2c95-4c74-b4ac-29ea2448e86a is started using port 15051 for RATIS_ADMIN
2024-03-25 19:42:24,702 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 8de788e1-2c95-4c74-b4ac-29ea2448e86a is started using port 15052 for RATIS_SERVER
2024-03-25 19:42:24,702 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 8de788e1-2c95-4c74-b4ac-29ea2448e86a is started using port 15053 for RATIS_DATASTREAM
2024-03-25 19:42:24,702 [JvmPauseMonitor7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-8de788e1-2c95-4c74-b4ac-29ea2448e86a: Started
2024-03-25 19:42:24,705 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-03-25 19:42:25,372 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:25,639 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:25,639 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:25,665 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 0 of 5 DN Heartbeats.
2024-03-25 19:42:25,665 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-03-25 19:42:25,666 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-25 19:42:26,101 [IPC Server handler 0 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/a568c6b4-1a28-494a-b080-2324592b3a72
2024-03-25 19:42:26,101 [IPC Server handler 4 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/a568c6b4-1a28-494a-b080-2324592b3a72
2024-03-25 19:42:26,103 [IPC Server handler 0 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: a568c6b4-1a28-494a-b080-2324592b3a72{ip: 10.1.0.27, host: fv-az1540-867, ports: [HTTP=15011, CLIENT_RPC=15012, REPLICATION=15018, RATIS=15014, RATIS_ADMIN=15015, RATIS_SERVER=15016, RATIS_DATASTREAM=15017, STANDALONE=15013], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-25 19:42:26,103 [IPC Server handler 4 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: a568c6b4-1a28-494a-b080-2324592b3a72{ip: 10.1.0.27, host: fv-az1540-867, ports: [HTTP=15011, CLIENT_RPC=15012, REPLICATION=15018, RATIS=15014, RATIS_ADMIN=15015, RATIS_SERVER=15016, RATIS_DATASTREAM=15017, STANDALONE=15013], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-25 19:42:26,107 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-25 19:42:26,108 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(138)) - Adding new node a568c6b4-1a28-494a-b080-2324592b3a72 to Node DB.
2024-03-25 19:42:26,108 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:42:26,109 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - ContainerSafeModeRule rule is successfully validated
2024-03-25 19:42:26,109 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:42:26,109 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:42:26,110 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 4 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:42:26,112 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2024-03-25 19:42:26,112 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-25 19:42:26,114 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=8a6654ba-868c-467c-ac57-e84dd4d606bd to datanode:a568c6b4-1a28-494a-b080-2324592b3a72
2024-03-25 19:42:26,124 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 8a6654ba-868c-467c-ac57-e84dd4d606bd, Nodes: a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-25T19:42:26.114Z[Etc/UTC]]
2024-03-25 19:42:26,232 [IPC Server handler 2 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/a6fb26e7-f548-473f-8cf0-48fafe70504d
2024-03-25 19:42:26,232 [IPC Server handler 0 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/a6fb26e7-f548-473f-8cf0-48fafe70504d
2024-03-25 19:42:26,232 [IPC Server handler 2 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: a6fb26e7-f548-473f-8cf0-48fafe70504d{ip: 10.1.0.27, host: fv-az1540-867, ports: [HTTP=15020, CLIENT_RPC=15021, REPLICATION=15027, RATIS=15023, RATIS_ADMIN=15024, RATIS_SERVER=15025, RATIS_DATASTREAM=15026, STANDALONE=15022], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-25 19:42:26,232 [IPC Server handler 0 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: a6fb26e7-f548-473f-8cf0-48fafe70504d{ip: 10.1.0.27, host: fv-az1540-867, ports: [HTTP=15020, CLIENT_RPC=15021, REPLICATION=15027, RATIS=15023, RATIS_ADMIN=15024, RATIS_SERVER=15025, RATIS_DATASTREAM=15026, STANDALONE=15022], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-25 19:42:26,232 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2024-03-25 19:42:26,234 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-25 19:42:26,234 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:42:26,234 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(138)) - Adding new node a6fb26e7-f548-473f-8cf0-48fafe70504d to Node DB.
2024-03-25 19:42:26,234 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:42:26,234 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=eac5a041-cf38-4b57-9357-0ff75a016342 to datanode:a6fb26e7-f548-473f-8cf0-48fafe70504d
2024-03-25 19:42:26,235 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: eac5a041-cf38-4b57-9357-0ff75a016342, Nodes: a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-25T19:42:26.234Z[Etc/UTC]]
2024-03-25 19:42:26,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:26,375 [IPC Server handler 4 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/f8c0ec26-9898-49d2-a0ea-132d14d0dc83
2024-03-25 19:42:26,375 [IPC Server handler 4 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: f8c0ec26-9898-49d2-a0ea-132d14d0dc83{ip: 10.1.0.27, host: fv-az1540-867, ports: [HTTP=15029, CLIENT_RPC=15030, REPLICATION=15036, RATIS=15032, RATIS_ADMIN=15033, RATIS_SERVER=15034, RATIS_DATASTREAM=15035, STANDALONE=15031], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-25 19:42:26,375 [IPC Server handler 2 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/f8c0ec26-9898-49d2-a0ea-132d14d0dc83
2024-03-25 19:42:26,375 [IPC Server handler 2 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: f8c0ec26-9898-49d2-a0ea-132d14d0dc83{ip: 10.1.0.27, host: fv-az1540-867, ports: [HTTP=15029, CLIENT_RPC=15030, REPLICATION=15036, RATIS=15032, RATIS_ADMIN=15033, RATIS_SERVER=15034, RATIS_DATASTREAM=15035, STANDALONE=15031], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-25 19:42:26,376 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-25 19:42:26,376 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2024-03-25 19:42:26,376 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - DataNodeSafeModeRule rule is successfully validated
2024-03-25 19:42:26,376 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(229)) - All SCM safe mode pre check rules have passed
2024-03-25 19:42:26,376 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(225)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2024-03-25 19:42:26,376 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-25 19:42:26,376 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=669638b9-7e75-42f1-82a9-b01fec71537c to datanode:f8c0ec26-9898-49d2-a0ea-132d14d0dc83
2024-03-25 19:42:26,376 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(138)) - Adding new node f8c0ec26-9898-49d2-a0ea-132d14d0dc83 to Node DB.
2024-03-25 19:42:26,377 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 669638b9-7e75-42f1-82a9-b01fec71537c, Nodes: f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-25T19:42:26.376Z[Etc/UTC]]
2024-03-25 19:42:26,380 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=37d82d77-2193-41cd-938d-dc6410947516 to datanode:a568c6b4-1a28-494a-b080-2324592b3a72
2024-03-25 19:42:26,380 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=37d82d77-2193-41cd-938d-dc6410947516 to datanode:a6fb26e7-f548-473f-8cf0-48fafe70504d
2024-03-25 19:42:26,380 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=37d82d77-2193-41cd-938d-dc6410947516 to datanode:f8c0ec26-9898-49d2-a0ea-132d14d0dc83
2024-03-25 19:42:26,382 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 37d82d77-2193-41cd-938d-dc6410947516, Nodes: a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27)a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27)f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-25T19:42:26.380Z[Etc/UTC]]
2024-03-25 19:42:26,505 [IPC Server handler 6 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/6e65d581-b1bc-41f2-b39b-16d8508d6618
2024-03-25 19:42:26,505 [IPC Server handler 1 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/6e65d581-b1bc-41f2-b39b-16d8508d6618
2024-03-25 19:42:26,508 [IPC Server handler 1 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: 6e65d581-b1bc-41f2-b39b-16d8508d6618{ip: 10.1.0.27, host: fv-az1540-867, ports: [HTTP=15038, CLIENT_RPC=15039, REPLICATION=15045, RATIS=15041, RATIS_ADMIN=15042, RATIS_SERVER=15043, RATIS_DATASTREAM=15044, STANDALONE=15040], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-25 19:42:26,508 [IPC Server handler 6 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: 6e65d581-b1bc-41f2-b39b-16d8508d6618{ip: 10.1.0.27, host: fv-az1540-867, ports: [HTTP=15038, CLIENT_RPC=15039, REPLICATION=15045, RATIS=15041, RATIS_ADMIN=15042, RATIS_SERVER=15043, RATIS_DATASTREAM=15044, STANDALONE=15040], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-25 19:42:26,509 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-25 19:42:26,510 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=1c6daf81-1115-4d9e-8b57-7cbe81b705e6 to datanode:6e65d581-b1bc-41f2-b39b-16d8508d6618
2024-03-25 19:42:26,511 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 1c6daf81-1115-4d9e-8b57-7cbe81b705e6, Nodes: 6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-25T19:42:26.510Z[Etc/UTC]]
2024-03-25 19:42:26,512 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(138)) - Adding new node 6e65d581-b1bc-41f2-b39b-16d8508d6618 to Node DB.
2024-03-25 19:42:26,513 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 5 millisec, 6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:42:26,513 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 5 millisec, 6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:42:26,640 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:26,641 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:26,666 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 4 of 5 DN Heartbeats.
2024-03-25 19:42:26,666 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-03-25 19:42:26,666 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-25 19:42:26,671 [IPC Server handler 4 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:42:26,671 [IPC Server handler 1 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(133)) - Added a new node: /default-rack/8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:42:26,671 [IPC Server handler 4 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: 8de788e1-2c95-4c74-b4ac-29ea2448e86a{ip: 10.1.0.27, host: fv-az1540-867, ports: [HTTP=15047, CLIENT_RPC=15048, REPLICATION=15054, RATIS=15050, RATIS_ADMIN=15051, RATIS_SERVER=15052, RATIS_DATASTREAM=15053, STANDALONE=15049], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-25 19:42:26,671 [IPC Server handler 1 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: 8de788e1-2c95-4c74-b4ac-29ea2448e86a{ip: 10.1.0.27, host: fv-az1540-867, ports: [HTTP=15047, CLIENT_RPC=15048, REPLICATION=15054, RATIS=15050, RATIS_ADMIN=15051, RATIS_SERVER=15052, RATIS_DATASTREAM=15053, STANDALONE=15049], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-25 19:42:26,671 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-25 19:42:26,672 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=2db7f802-448f-42c5-98a7-81169fadb40c to datanode:8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:42:26,672 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(138)) - Adding new node 8de788e1-2c95-4c74-b4ac-29ea2448e86a to Node DB.
2024-03-25 19:42:26,673 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 2db7f802-448f-42c5-98a7-81169fadb40c, Nodes: 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-25T19:42:26.672Z[Etc/UTC]]
2024-03-25 19:42:27,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:27,642 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:27,642 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:27,667 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-03-25 19:42:27,667 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-03-25 19:42:27,667 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-25 19:42:28,107 [IPC Server handler 0 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for fv-az1540-867
2024-03-25 19:42:28,233 [IPC Server handler 2 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for fv-az1540-867
2024-03-25 19:42:28,371 [IPC Server handler 4 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for fv-az1540-867
2024-03-25 19:42:28,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:28,506 [IPC Server handler 6 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for fv-az1540-867
2024-03-25 19:42:28,643 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:28,643 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:28,667 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-03-25 19:42:28,668 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-03-25 19:42:28,668 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-25 19:42:28,673 [IPC Server handler 1 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for fv-az1540-867
2024-03-25 19:42:28,675 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:42:28,675 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:42:29,115 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - a568c6b4-1a28-494a-b080-2324592b3a72: addNew group-E84DD4D606BD:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016] returns group-E84DD4D606BD:java.util.concurrent.CompletableFuture@8923d41[Not completed]
2024-03-25 19:42:29,115 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27) moved to stale state. Finalizing its pipelines []
2024-03-25 19:42:29,122 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 0 pipelines in house.
2024-03-25 19:42:29,122 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(110)) - Adding new pipeline PipelineID=669638b9-7e75-42f1-82a9-b01fec71537c from SCM.
2024-03-25 19:42:29,123 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  lib.Interns (Interns.java:removeEldestEntry(50)) - Metrics intern cache overflow at 2011 for MetricsSystem={MetricsSystem=MetricsInfoImpl{name=MetricsSystem, description=MetricsSystem}, MetricsSystem record=MetricsInfoImpl{name=MetricsSystem, description=MetricsSystem record}}
2024-03-25 19:42:29,126 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - a568c6b4-1a28-494a-b080-2324592b3a72: new RaftServerImpl for group-E84DD4D606BD:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016] with ContainerStateMachine:uninitialized
2024-03-25 19:42:29,126 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:42:29,126 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-25 19:42:29,126 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-25 19:42:29,126 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-25 19:42:29,126 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:42:29,127 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-25 19:42:29,127 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:42:29,127 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD: ConfigurationManager, init=-1: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-25 19:42:29,127 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-25 19:42:29,127 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-25 19:42:29,127 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-25 19:42:29,127 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-25 19:42:29,127 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-25 19:42:29,128 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-25 19:42:29,130 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(110)) - Adding new pipeline PipelineID=eac5a041-cf38-4b57-9357-0ff75a016342 from SCM.
2024-03-25 19:42:29,131 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(110)) - Adding new pipeline PipelineID=37d82d77-2193-41cd-938d-dc6410947516 from SCM.
2024-03-25 19:42:29,132 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(110)) - Adding new pipeline PipelineID=8a6654ba-868c-467c-ac57-e84dd4d606bd from SCM.
2024-03-25 19:42:29,134 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(110)) - Adding new pipeline PipelineID=1c6daf81-1115-4d9e-8b57-7cbe81b705e6 from SCM.
2024-03-25 19:42:29,135 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(110)) - Adding new pipeline PipelineID=2db7f802-448f-42c5-98a7-81169fadb40c from SCM.
2024-03-25 19:42:29,136 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 21 milliseconds.
2024-03-25 19:42:29,137 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:42:29,137 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:42:29,137 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-25 19:42:29,137 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-25 19:42:29,137 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-25 19:42:29,137 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-25 19:42:29,138 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-25 19:42:29,138 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-25 19:42:29,138 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis] (custom)
2024-03-25 19:42:29,138 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/8a6654ba-868c-467c-ac57-e84dd4d606bd does not exist. Creating ...
2024-03-25 19:42:29,140 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/8a6654ba-868c-467c-ac57-e84dd4d606bd/in_use.lock acquired by nodename 19166@fv-az1540-867
2024-03-25 19:42:29,143 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/8a6654ba-868c-467c-ac57-e84dd4d606bd has been successfully formatted.
2024-03-25 19:42:29,143 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/8a6654ba-868c-467c-ac57-e84dd4d606bd/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/8a6654ba-868c-467c-ac57-e84dd4d606bd/current/raft-meta.conf
2024-03-25 19:42:29,146 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-E84DD4D606BD: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-25 19:42:29,149 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-25 19:42:29,149 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-25 19:42:29,149 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:29,150 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-25 19:42:29,150 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-25 19:42:29,150 [IPC Server handler 2 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for fv-az1540-867
2024-03-25 19:42:29,152 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/ONE PipelineID=8a6654ba-868c-467c-ac57-e84dd4d606bd reported by a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:29,152 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=8a6654ba-868c-467c-ac57-e84dd4d606bd
2024-03-25 19:42:29,153 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:29,155 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:29,156 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-25 19:42:29,156 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-25 19:42:29,156 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:29,156 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-cacheEviction-AwaitToRun,5,main] started
2024-03-25 19:42:29,156 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/8a6654ba-868c-467c-ac57-e84dd4d606bd
2024-03-25 19:42:29,156 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-25 19:42:29,157 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-25 19:42:29,157 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:29,157 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-25 19:42:29,157 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-25 19:42:29,157 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-25 19:42:29,157 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-25 19:42:29,157 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-25 19:42:29,158 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-25 19:42:29,160 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:29,160 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-25 19:42:29,160 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-25 19:42:29,160 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-25 19:42:29,160 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:29,161 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:29,161 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD: start as a follower, conf=-1: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016]|listeners:[], old=null
2024-03-25 19:42:29,161 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-25 19:42:29,161 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a568c6b4-1a28-494a-b080-2324592b3a72: start a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-FollowerState
2024-03-25 19:42:29,161 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:42:29,162 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E84DD4D606BD,id=a568c6b4-1a28-494a-b080-2324592b3a72
2024-03-25 19:42:29,162 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:42:29,162 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-25 19:42:29,162 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-25 19:42:29,162 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-25 19:42:29,162 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-25 19:42:29,162 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-25 19:42:29,169 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=8a6654ba-868c-467c-ac57-e84dd4d606bd
2024-03-25 19:42:29,169 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=8a6654ba-868c-467c-ac57-e84dd4d606bd.
2024-03-25 19:42:29,170 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - a568c6b4-1a28-494a-b080-2324592b3a72: addNew group-DC6410947516:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025] returns group-DC6410947516:java.util.concurrent.CompletableFuture@40c62774[Not completed]
2024-03-25 19:42:29,171 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - a568c6b4-1a28-494a-b080-2324592b3a72: new RaftServerImpl for group-DC6410947516:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025] with ContainerStateMachine:uninitialized
2024-03-25 19:42:29,171 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:42:29,171 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-25 19:42:29,171 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-25 19:42:29,172 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-25 19:42:29,172 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:42:29,172 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-25 19:42:29,172 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:42:29,172 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516: ConfigurationManager, init=-1: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-25 19:42:29,172 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-25 19:42:29,172 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-25 19:42:29,172 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-25 19:42:29,172 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-25 19:42:29,173 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-25 19:42:29,173 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-25 19:42:29,184 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:42:29,184 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:42:29,184 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-25 19:42:29,184 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-25 19:42:29,184 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-25 19:42:29,184 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-25 19:42:29,184 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-25 19:42:29,185 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-25 19:42:29,185 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis] (custom)
2024-03-25 19:42:29,185 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/37d82d77-2193-41cd-938d-dc6410947516 does not exist. Creating ...
2024-03-25 19:42:29,186 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/37d82d77-2193-41cd-938d-dc6410947516/in_use.lock acquired by nodename 19166@fv-az1540-867
2024-03-25 19:42:29,187 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/37d82d77-2193-41cd-938d-dc6410947516 has been successfully formatted.
2024-03-25 19:42:29,187 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/37d82d77-2193-41cd-938d-dc6410947516/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/37d82d77-2193-41cd-938d-dc6410947516/current/raft-meta.conf
2024-03-25 19:42:29,188 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-DC6410947516: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-25 19:42:29,188 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-25 19:42:29,188 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-25 19:42:29,188 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:29,188 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-25 19:42:29,188 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-25 19:42:29,195 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:29,196 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=37d82d77-2193-41cd-938d-dc6410947516 reported by a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:29,201 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:29,202 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-25 19:42:29,202 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-25 19:42:29,202 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:29,203 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-cacheEviction-AwaitToRun,5,main] started
2024-03-25 19:42:29,203 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/37d82d77-2193-41cd-938d-dc6410947516
2024-03-25 19:42:29,204 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-25 19:42:29,204 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-25 19:42:29,204 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:29,204 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-25 19:42:29,204 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-25 19:42:29,204 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-25 19:42:29,204 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-25 19:42:29,205 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-25 19:42:29,205 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-25 19:42:29,207 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:29,207 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-25 19:42:29,207 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-25 19:42:29,207 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-25 19:42:29,208 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:29,208 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:29,209 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516: start as a follower, conf=-1: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null
2024-03-25 19:42:29,209 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-25 19:42:29,210 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a568c6b4-1a28-494a-b080-2324592b3a72: start a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-FollowerState
2024-03-25 19:42:29,213 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DC6410947516,id=a568c6b4-1a28-494a-b080-2324592b3a72
2024-03-25 19:42:29,214 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-25 19:42:29,214 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-25 19:42:29,214 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-25 19:42:29,214 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-25 19:42:29,214 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-25 19:42:29,215 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:42:29,216 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:42:29,218 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=37d82d77-2193-41cd-938d-dc6410947516
2024-03-25 19:42:29,240 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: addNew group-0FF75A016342:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025] returns group-0FF75A016342:java.util.concurrent.CompletableFuture@3d23e474[Not completed]
2024-03-25 19:42:29,241 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: new RaftServerImpl for group-0FF75A016342:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025] with ContainerStateMachine:uninitialized
2024-03-25 19:42:29,241 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:42:29,241 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-25 19:42:29,241 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-25 19:42:29,241 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-25 19:42:29,242 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:42:29,242 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-25 19:42:29,242 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:42:29,242 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342: ConfigurationManager, init=-1: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-25 19:42:29,242 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-25 19:42:29,242 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-25 19:42:29,242 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-25 19:42:29,242 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-25 19:42:29,242 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-25 19:42:29,242 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-25 19:42:29,247 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:42:29,247 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:42:29,247 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-25 19:42:29,247 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-25 19:42:29,247 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-25 19:42:29,247 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-25 19:42:29,247 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-25 19:42:29,247 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-25 19:42:29,248 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis] (custom)
2024-03-25 19:42:29,248 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/eac5a041-cf38-4b57-9357-0ff75a016342 does not exist. Creating ...
2024-03-25 19:42:29,250 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/eac5a041-cf38-4b57-9357-0ff75a016342/in_use.lock acquired by nodename 19166@fv-az1540-867
2024-03-25 19:42:29,251 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/eac5a041-cf38-4b57-9357-0ff75a016342 has been successfully formatted.
2024-03-25 19:42:29,252 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/eac5a041-cf38-4b57-9357-0ff75a016342/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/eac5a041-cf38-4b57-9357-0ff75a016342/current/raft-meta.conf
2024-03-25 19:42:29,256 [IPC Server handler 7 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for fv-az1540-867
2024-03-25 19:42:29,254 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-0FF75A016342: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-25 19:42:29,260 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-25 19:42:29,260 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:42:29,260 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-25 19:42:29,260 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=eac5a041-cf38-4b57-9357-0ff75a016342
2024-03-25 19:42:29,261 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:29,261 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:29,261 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-25 19:42:29,261 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-25 19:42:29,261 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 4 millisec, a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:42:29,262 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/ONE PipelineID=eac5a041-cf38-4b57-9357-0ff75a016342 reported by a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:29,263 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:29,264 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-25 19:42:29,264 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-25 19:42:29,264 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:29,264 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-cacheEviction-AwaitToRun,5,main] started
2024-03-25 19:42:29,265 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/eac5a041-cf38-4b57-9357-0ff75a016342
2024-03-25 19:42:29,266 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-25 19:42:29,266 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-25 19:42:29,266 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:29,266 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-25 19:42:29,266 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-25 19:42:29,266 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-25 19:42:29,266 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-25 19:42:29,266 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-25 19:42:29,267 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-25 19:42:29,269 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:29,269 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-25 19:42:29,269 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-25 19:42:29,269 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-25 19:42:29,269 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:29,269 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:29,273 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342: start as a follower, conf=-1: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null
2024-03-25 19:42:29,274 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-25 19:42:29,274 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: start a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-FollowerState
2024-03-25 19:42:29,274 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:42:29,278 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:42:29,274 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0FF75A016342,id=a6fb26e7-f548-473f-8cf0-48fafe70504d
2024-03-25 19:42:29,278 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-25 19:42:29,278 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-25 19:42:29,278 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-25 19:42:29,278 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-25 19:42:29,278 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-25 19:42:29,279 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=eac5a041-cf38-4b57-9357-0ff75a016342
2024-03-25 19:42:29,279 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=eac5a041-cf38-4b57-9357-0ff75a016342.
2024-03-25 19:42:29,283 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: addNew group-DC6410947516:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025] returns group-DC6410947516:java.util.concurrent.CompletableFuture@391c6708[Not completed]
2024-03-25 19:42:29,284 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: new RaftServerImpl for group-DC6410947516:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025] with ContainerStateMachine:uninitialized
2024-03-25 19:42:29,284 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:42:29,284 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-25 19:42:29,284 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-25 19:42:29,285 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-25 19:42:29,285 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:42:29,285 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-25 19:42:29,285 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:42:29,285 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516: ConfigurationManager, init=-1: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-25 19:42:29,285 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-25 19:42:29,285 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-25 19:42:29,285 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-25 19:42:29,285 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-25 19:42:29,286 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-25 19:42:29,286 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-25 19:42:29,288 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:42:29,289 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:42:29,289 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-25 19:42:29,289 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-25 19:42:29,289 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-25 19:42:29,289 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-25 19:42:29,289 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-25 19:42:29,289 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-25 19:42:29,291 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis] (custom)
2024-03-25 19:42:29,291 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/37d82d77-2193-41cd-938d-dc6410947516 does not exist. Creating ...
2024-03-25 19:42:29,292 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/37d82d77-2193-41cd-938d-dc6410947516/in_use.lock acquired by nodename 19166@fv-az1540-867
2024-03-25 19:42:29,294 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/37d82d77-2193-41cd-938d-dc6410947516 has been successfully formatted.
2024-03-25 19:42:29,295 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/37d82d77-2193-41cd-938d-dc6410947516/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/37d82d77-2193-41cd-938d-dc6410947516/current/raft-meta.conf
2024-03-25 19:42:29,295 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-DC6410947516: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-25 19:42:29,295 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-25 19:42:29,295 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-25 19:42:29,295 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:29,295 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-25 19:42:29,296 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-25 19:42:29,297 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=37d82d77-2193-41cd-938d-dc6410947516 reported by a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:29,299 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:29,300 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:29,300 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-25 19:42:29,300 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-25 19:42:29,300 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:29,301 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-cacheEviction-AwaitToRun,5,main] started
2024-03-25 19:42:29,301 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/37d82d77-2193-41cd-938d-dc6410947516
2024-03-25 19:42:29,301 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-25 19:42:29,301 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-25 19:42:29,301 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:29,301 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-25 19:42:29,301 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-25 19:42:29,301 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-25 19:42:29,301 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-25 19:42:29,301 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-25 19:42:29,302 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-25 19:42:29,303 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:29,303 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-25 19:42:29,303 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-25 19:42:29,303 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-25 19:42:29,304 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:29,304 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:29,304 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516: start as a follower, conf=-1: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null
2024-03-25 19:42:29,304 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-25 19:42:29,304 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: start a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-FollowerState
2024-03-25 19:42:29,304 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:42:29,304 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DC6410947516,id=a6fb26e7-f548-473f-8cf0-48fafe70504d
2024-03-25 19:42:29,305 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-25 19:42:29,305 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-25 19:42:29,305 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-25 19:42:29,305 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-25 19:42:29,305 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-25 19:42:29,305 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:42:29,306 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=37d82d77-2193-41cd-938d-dc6410947516
2024-03-25 19:42:29,369 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: addNew group-B01FEC71537C:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034] returns group-B01FEC71537C:java.util.concurrent.CompletableFuture@30216e4e[Not completed]
2024-03-25 19:42:29,371 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: new RaftServerImpl for group-B01FEC71537C:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034] with ContainerStateMachine:uninitialized
2024-03-25 19:42:29,371 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:42:29,371 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-25 19:42:29,371 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-25 19:42:29,372 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-25 19:42:29,372 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:42:29,372 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-25 19:42:29,372 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:42:29,372 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C: ConfigurationManager, init=-1: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-25 19:42:29,372 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-25 19:42:29,372 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-25 19:42:29,372 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-25 19:42:29,372 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-25 19:42:29,373 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-25 19:42:29,373 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-25 19:42:29,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:29,376 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:42:29,377 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:42:29,377 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-25 19:42:29,377 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-25 19:42:29,377 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-25 19:42:29,377 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-25 19:42:29,377 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-25 19:42:29,377 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-25 19:42:29,377 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis] (custom)
2024-03-25 19:42:29,378 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/669638b9-7e75-42f1-82a9-b01fec71537c does not exist. Creating ...
2024-03-25 19:42:29,379 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/669638b9-7e75-42f1-82a9-b01fec71537c/in_use.lock acquired by nodename 19166@fv-az1540-867
2024-03-25 19:42:29,381 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/669638b9-7e75-42f1-82a9-b01fec71537c has been successfully formatted.
2024-03-25 19:42:29,381 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/669638b9-7e75-42f1-82a9-b01fec71537c/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/669638b9-7e75-42f1-82a9-b01fec71537c/current/raft-meta.conf
2024-03-25 19:42:29,381 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-B01FEC71537C: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-25 19:42:29,381 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-25 19:42:29,382 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-25 19:42:29,382 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:29,382 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-25 19:42:29,382 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-25 19:42:29,384 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=669638b9-7e75-42f1-82a9-b01fec71537c
2024-03-25 19:42:29,384 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:29,386 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-25 19:42:29,386 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-25 19:42:29,387 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:29,387 [IPC Server handler 9 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for fv-az1540-867
2024-03-25 19:42:29,387 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/ONE PipelineID=669638b9-7e75-42f1-82a9-b01fec71537c reported by f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:29,387 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:29,388 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-cacheEviction-AwaitToRun,5,main] started
2024-03-25 19:42:29,388 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/669638b9-7e75-42f1-82a9-b01fec71537c
2024-03-25 19:42:29,388 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-25 19:42:29,388 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-25 19:42:29,389 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:29,389 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-25 19:42:29,389 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-25 19:42:29,389 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-25 19:42:29,389 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-25 19:42:29,389 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-25 19:42:29,389 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-25 19:42:29,391 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:29,391 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-25 19:42:29,391 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-25 19:42:29,391 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-25 19:42:29,392 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:29,392 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:29,396 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C: start as a follower, conf=-1: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034]|listeners:[], old=null
2024-03-25 19:42:29,396 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-25 19:42:29,396 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 9 millisec, f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:42:29,396 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: start f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-FollowerState
2024-03-25 19:42:29,396 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 9 millisec, f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:42:29,397 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B01FEC71537C,id=f8c0ec26-9898-49d2-a0ea-132d14d0dc83
2024-03-25 19:42:29,397 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-25 19:42:29,397 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-25 19:42:29,397 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-25 19:42:29,397 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-25 19:42:29,398 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-25 19:42:29,398 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:42:29,398 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:42:29,400 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=669638b9-7e75-42f1-82a9-b01fec71537c
2024-03-25 19:42:29,401 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=669638b9-7e75-42f1-82a9-b01fec71537c.
2024-03-25 19:42:29,401 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: addNew group-DC6410947516:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025] returns group-DC6410947516:java.util.concurrent.CompletableFuture@341eec92[Not completed]
2024-03-25 19:42:29,402 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: new RaftServerImpl for group-DC6410947516:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025] with ContainerStateMachine:uninitialized
2024-03-25 19:42:29,402 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:42:29,402 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-25 19:42:29,403 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-25 19:42:29,403 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-25 19:42:29,403 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:42:29,403 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-25 19:42:29,403 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:42:29,403 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516: ConfigurationManager, init=-1: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-25 19:42:29,403 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-25 19:42:29,403 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-25 19:42:29,403 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-25 19:42:29,403 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-25 19:42:29,404 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-25 19:42:29,404 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-25 19:42:29,410 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:42:29,411 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:42:29,411 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-25 19:42:29,411 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-25 19:42:29,412 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-25 19:42:29,412 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-25 19:42:29,412 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-25 19:42:29,412 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-25 19:42:29,413 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis] (custom)
2024-03-25 19:42:29,413 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/37d82d77-2193-41cd-938d-dc6410947516 does not exist. Creating ...
2024-03-25 19:42:29,414 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/37d82d77-2193-41cd-938d-dc6410947516/in_use.lock acquired by nodename 19166@fv-az1540-867
2024-03-25 19:42:29,415 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/37d82d77-2193-41cd-938d-dc6410947516 has been successfully formatted.
2024-03-25 19:42:29,415 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/37d82d77-2193-41cd-938d-dc6410947516/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/37d82d77-2193-41cd-938d-dc6410947516/current/raft-meta.conf
2024-03-25 19:42:29,416 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-DC6410947516: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-25 19:42:29,416 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27) moved to stale state. Finalizing its pipelines [PipelineID=669638b9-7e75-42f1-82a9-b01fec71537c, PipelineID=37d82d77-2193-41cd-938d-dc6410947516]
2024-03-25 19:42:29,418 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-25 19:42:29,418 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-25 19:42:29,418 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:29,418 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-25 19:42:29,419 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-25 19:42:29,419 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=669638b9-7e75-42f1-82a9-b01fec71537c moved to CLOSED state
2024-03-25 19:42:29,420 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=37d82d77-2193-41cd-938d-dc6410947516 moved to CLOSED state
2024-03-25 19:42:29,421 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:29,421 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-25 19:42:29,422 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-25 19:42:29,422 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:29,425 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 6 pipelines in house.
2024-03-25 19:42:29,429 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 10 milliseconds.
2024-03-25 19:42:29,430 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:29,433 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-cacheEviction-AwaitToRun,5,main] started
2024-03-25 19:42:29,433 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/37d82d77-2193-41cd-938d-dc6410947516
2024-03-25 19:42:29,433 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-25 19:42:29,434 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-25 19:42:29,434 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:29,434 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-25 19:42:29,434 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-25 19:42:29,434 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-25 19:42:29,434 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-25 19:42:29,434 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-25 19:42:29,435 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-25 19:42:29,438 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:29,438 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-25 19:42:29,438 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-25 19:42:29,438 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-25 19:42:29,439 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:29,439 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:29,439 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516: start as a follower, conf=-1: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null
2024-03-25 19:42:29,440 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-25 19:42:29,440 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: start f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-FollowerState
2024-03-25 19:42:29,440 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:42:29,440 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:42:29,440 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DC6410947516,id=f8c0ec26-9898-49d2-a0ea-132d14d0dc83
2024-03-25 19:42:29,441 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-25 19:42:29,441 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-25 19:42:29,441 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-25 19:42:29,441 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-25 19:42:29,442 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-25 19:42:29,442 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=37d82d77-2193-41cd-938d-dc6410947516
2024-03-25 19:42:29,503 [6e65d581-b1bc-41f2-b39b-16d8508d6618-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: addNew group-7CBE81B705E6:[6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043] returns group-7CBE81B705E6:java.util.concurrent.CompletableFuture@4c77f629[Not completed]
2024-03-25 19:42:29,504 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: new RaftServerImpl for group-7CBE81B705E6:[6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043] with ContainerStateMachine:uninitialized
2024-03-25 19:42:29,504 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:42:29,505 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-25 19:42:29,505 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-25 19:42:29,505 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-25 19:42:29,505 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:42:29,505 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-25 19:42:29,505 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:42:29,505 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6: ConfigurationManager, init=-1: peers:[6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-25 19:42:29,505 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-25 19:42:29,505 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-25 19:42:29,505 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-25 19:42:29,510 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-25 19:42:29,510 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-25 19:42:29,510 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-25 19:42:29,517 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27) moved to stale state. Finalizing its pipelines [PipelineID=1c6daf81-1115-4d9e-8b57-7cbe81b705e6]
2024-03-25 19:42:29,517 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:42:29,517 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:42:29,517 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-25 19:42:29,517 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-25 19:42:29,517 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-25 19:42:29,517 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-25 19:42:29,518 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-25 19:42:29,518 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-25 19:42:29,518 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis] (custom)
2024-03-25 19:42:29,518 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=1c6daf81-1115-4d9e-8b57-7cbe81b705e6 moved to CLOSED state
2024-03-25 19:42:29,518 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/1c6daf81-1115-4d9e-8b57-7cbe81b705e6 does not exist. Creating ...
2024-03-25 19:42:29,521 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 6 pipelines in house.
2024-03-25 19:42:29,525 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/1c6daf81-1115-4d9e-8b57-7cbe81b705e6/in_use.lock acquired by nodename 19166@fv-az1540-867
2024-03-25 19:42:29,526 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/1c6daf81-1115-4d9e-8b57-7cbe81b705e6 has been successfully formatted.
2024-03-25 19:42:29,546 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/1c6daf81-1115-4d9e-8b57-7cbe81b705e6/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/1c6daf81-1115-4d9e-8b57-7cbe81b705e6/current/raft-meta.conf
2024-03-25 19:42:29,543 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 25 milliseconds.
2024-03-25 19:42:29,548 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-7CBE81B705E6: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-25 19:42:29,549 [IPC Server handler 12 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for fv-az1540-867
2024-03-25 19:42:29,551 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-25 19:42:29,551 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-25 19:42:29,551 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:29,551 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-25 19:42:29,551 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-25 19:42:29,554 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/ONE PipelineID=1c6daf81-1115-4d9e-8b57-7cbe81b705e6 reported by 6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:29,555 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=1c6daf81-1115-4d9e-8b57-7cbe81b705e6
2024-03-25 19:42:29,555 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:29,558 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:29,559 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-25 19:42:29,559 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-25 19:42:29,559 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:29,559 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-cacheEviction-AwaitToRun,5,main] started
2024-03-25 19:42:29,559 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/1c6daf81-1115-4d9e-8b57-7cbe81b705e6
2024-03-25 19:42:29,560 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-25 19:42:29,560 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-25 19:42:29,560 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:29,560 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-25 19:42:29,560 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-25 19:42:29,560 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-25 19:42:29,560 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-25 19:42:29,560 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-25 19:42:29,561 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-25 19:42:29,562 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:29,562 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-25 19:42:29,563 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-25 19:42:29,563 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-25 19:42:29,563 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:29,563 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:29,563 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6: start as a follower, conf=-1: peers:[6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043]|listeners:[], old=null
2024-03-25 19:42:29,563 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-25 19:42:29,564 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: start 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-FollowerState
2024-03-25 19:42:29,564 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:42:29,564 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7CBE81B705E6,id=6e65d581-b1bc-41f2-b39b-16d8508d6618
2024-03-25 19:42:29,564 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:42:29,564 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-25 19:42:29,564 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-25 19:42:29,564 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-25 19:42:29,565 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-25 19:42:29,565 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-25 19:42:29,565 [6e65d581-b1bc-41f2-b39b-16d8508d6618-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=1c6daf81-1115-4d9e-8b57-7cbe81b705e6
2024-03-25 19:42:29,565 [6e65d581-b1bc-41f2-b39b-16d8508d6618-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=1c6daf81-1115-4d9e-8b57-7cbe81b705e6.
2024-03-25 19:42:29,644 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:29,645 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:29,668 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-03-25 19:42:29,668 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-03-25 19:42:29,668 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-25 19:42:29,694 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 11 millisec, 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:42:29,694 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 12 millisec, 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:42:29,697 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: addNew group-81169FADB40C:[8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052] returns group-81169FADB40C:java.util.concurrent.CompletableFuture@30bd8db1[Not completed]
2024-03-25 19:42:29,700 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: new RaftServerImpl for group-81169FADB40C:[8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052] with ContainerStateMachine:uninitialized
2024-03-25 19:42:29,701 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:42:29,707 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-25 19:42:29,707 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-25 19:42:29,707 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-25 19:42:29,708 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:42:29,708 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-25 19:42:29,708 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:42:29,709 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C: ConfigurationManager, init=-1: peers:[8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-25 19:42:29,709 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-25 19:42:29,710 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-25 19:42:29,710 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-25 19:42:29,710 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-25 19:42:29,711 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-25 19:42:29,711 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-25 19:42:29,719 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27) moved to stale state. Finalizing its pipelines [PipelineID=2db7f802-448f-42c5-98a7-81169fadb40c]
2024-03-25 19:42:29,728 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=2db7f802-448f-42c5-98a7-81169fadb40c moved to CLOSED state
2024-03-25 19:42:29,733 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:42:29,733 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:42:29,733 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-25 19:42:29,733 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-25 19:42:29,733 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-25 19:42:29,733 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-25 19:42:29,733 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-25 19:42:29,733 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-25 19:42:29,733 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis] (custom)
2024-03-25 19:42:29,734 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/2db7f802-448f-42c5-98a7-81169fadb40c does not exist. Creating ...
2024-03-25 19:42:29,734 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/2db7f802-448f-42c5-98a7-81169fadb40c/in_use.lock acquired by nodename 19166@fv-az1540-867
2024-03-25 19:42:29,735 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/2db7f802-448f-42c5-98a7-81169fadb40c has been successfully formatted.
2024-03-25 19:42:29,736 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/2db7f802-448f-42c5-98a7-81169fadb40c/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/2db7f802-448f-42c5-98a7-81169fadb40c/current/raft-meta.conf
2024-03-25 19:42:29,736 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 6 pipelines in house.
2024-03-25 19:42:29,736 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-81169FADB40C: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-25 19:42:29,737 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-25 19:42:29,737 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-25 19:42:29,740 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=2db7f802-448f-42c5-98a7-81169fadb40c
2024-03-25 19:42:29,741 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:29,739 [IPC Server handler 2 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for fv-az1540-867
2024-03-25 19:42:29,741 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:29,746 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-25 19:42:29,746 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-25 19:42:29,746 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 17 milliseconds.
2024-03-25 19:42:29,748 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:29,749 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-25 19:42:29,749 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-25 19:42:29,749 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:29,749 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-cacheEviction-AwaitToRun,5,main] started
2024-03-25 19:42:29,749 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/2db7f802-448f-42c5-98a7-81169fadb40c
2024-03-25 19:42:29,753 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-25 19:42:29,754 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-25 19:42:29,754 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:29,754 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-25 19:42:29,754 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-25 19:42:29,754 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-25 19:42:29,754 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-25 19:42:29,754 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-25 19:42:29,754 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-25 19:42:29,756 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:29,756 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-25 19:42:29,756 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-25 19:42:29,756 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-25 19:42:29,756 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:29,757 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:29,764 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C: start as a follower, conf=-1: peers:[8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:42:29,764 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-25 19:42:29,764 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: start 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-FollowerState
2024-03-25 19:42:29,764 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:42:29,764 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-81169FADB40C,id=8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:42:29,764 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-25 19:42:29,765 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-25 19:42:29,765 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-25 19:42:29,765 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-25 19:42:29,765 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-25 19:42:29,765 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=37d82d77-2193-41cd-938d-dc6410947516.
2024-03-25 19:42:29,766 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=2db7f802-448f-42c5-98a7-81169fadb40c
2024-03-25 19:42:29,766 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=2db7f802-448f-42c5-98a7-81169fadb40c.
2024-03-25 19:42:29,769 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:42:29,774 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=37d82d77-2193-41cd-938d-dc6410947516.
2024-03-25 19:42:29,777 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=37d82d77-2193-41cd-938d-dc6410947516.
2024-03-25 19:42:30,297 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=37d82d77-2193-41cd-938d-dc6410947516 reported by a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:30,297 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:30,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:30,418 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=37d82d77-2193-41cd-938d-dc6410947516 reported by f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:30,418 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:30,548 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:30,646 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:30,646 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:30,669 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-03-25 19:42:30,669 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-03-25 19:42:30,669 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-25 19:42:30,737 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/ONE PipelineID=2db7f802-448f-42c5-98a7-81169fadb40c reported by 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:30,738 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:31,189 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=37d82d77-2193-41cd-938d-dc6410947516 reported by a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:31,189 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:31,296 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=37d82d77-2193-41cd-938d-dc6410947516 reported by a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:31,297 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:31,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:31,647 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:31,647 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:31,669 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-03-25 19:42:31,669 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-03-25 19:42:31,670 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-25 19:42:32,190 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=37d82d77-2193-41cd-938d-dc6410947516 reported by a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:32,190 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:32,297 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:32,297 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=37d82d77-2193-41cd-938d-dc6410947516 reported by a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:32,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:32,418 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=37d82d77-2193-41cd-938d-dc6410947516 reported by f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:32,421 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:32,549 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:32,648 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:32,648 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:32,670 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-03-25 19:42:32,670 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-03-25 19:42:32,670 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-25 19:42:32,739 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:33,297 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:33,297 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=37d82d77-2193-41cd-938d-dc6410947516 reported by a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:33,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:33,417 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=37d82d77-2193-41cd-938d-dc6410947516 reported by f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:33,418 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:33,548 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:33,650 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:33,650 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:33,670 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-03-25 19:42:33,671 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-03-25 19:42:33,671 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-25 19:42:34,164 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5002885185ns, electionTimeout:5002ms
2024-03-25 19:42:34,164 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a568c6b4-1a28-494a-b080-2324592b3a72: shutdown a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-FollowerState
2024-03-25 19:42:34,164 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-25 19:42:34,165 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-25 19:42:34,165 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a568c6b4-1a28-494a-b080-2324592b3a72: start a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2
2024-03-25 19:42:34,167 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016]|listeners:[], old=null
2024-03-25 19:42:34,167 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2 PRE_VOTE round 0: result PASSED (term=0)
2024-03-25 19:42:34,168 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016]|listeners:[], old=null
2024-03-25 19:42:34,168 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2 ELECTION round 0: result PASSED (term=1)
2024-03-25 19:42:34,168 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a568c6b4-1a28-494a-b080-2324592b3a72: shutdown a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2
2024-03-25 19:42:34,168 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-25 19:42:34,168 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-03-25 19:42:34,169 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-25 19:42:34,169 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-03-25 19:42:34,169 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-03-25 19:42:34,170 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-03-25 19:42:34,170 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-03-25 19:42:34,170 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-03-25 19:42:34,170 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-25 19:42:34,170 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:42:34,170 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-25 19:42:34,170 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-25 19:42:34,170 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a568c6b4-1a28-494a-b080-2324592b3a72: start a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderStateImpl
2024-03-25 19:42:34,170 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD: set firstElectionSinceStartup to false for becomeLeader
2024-03-25 19:42:34,171 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-E84DD4D606BD with new leaderId: a568c6b4-1a28-494a-b080-2324592b3a72
2024-03-25 19:42:34,171 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD: change Leader from null to a568c6b4-1a28-494a-b080-2324592b3a72 at term 1 for becomeLeader, leader elected after 5043ms
2024-03-25 19:42:34,171 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-25 19:42:34,172 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-25 19:42:34,174 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderElection2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD: set configuration 0: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016]|listeners:[], old=null
2024-03-25 19:42:34,176 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=37d82d77-2193-41cd-938d-dc6410947516 reported by a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:34,176 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:34,183 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/8a6654ba-868c-467c-ac57-e84dd4d606bd/current/log_inprogress_0
2024-03-25 19:42:34,186 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-25 19:42:34,296 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:34,296 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=37d82d77-2193-41cd-938d-dc6410947516 reported by a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:34,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:34,410 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5200066114ns, electionTimeout:5194ms
2024-03-25 19:42:34,411 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a568c6b4-1a28-494a-b080-2324592b3a72: shutdown a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-FollowerState
2024-03-25 19:42:34,411 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-25 19:42:34,411 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-25 19:42:34,411 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a568c6b4-1a28-494a-b080-2324592b3a72: start a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3
2024-03-25 19:42:34,413 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5108548193ns, electionTimeout:5107ms
2024-03-25 19:42:34,413 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null
2024-03-25 19:42:34,413 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: shutdown a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-FollowerState
2024-03-25 19:42:34,413 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-25 19:42:34,413 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-25 19:42:34,413 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: start a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-LeaderElection4
2024-03-25 19:42:34,415 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-LeaderElection4 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null
2024-03-25 19:42:34,418 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=37d82d77-2193-41cd-938d-dc6410947516 reported by f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:34,418 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:34,425 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5151453659ns, electionTimeout:5147ms
2024-03-25 19:42:34,425 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: shutdown a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-FollowerState
2024-03-25 19:42:34,425 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-25 19:42:34,427 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-25 19:42:34,427 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:42:34,433 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:42:34,433 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034
2024-03-25 19:42:34,427 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: start a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5
2024-03-25 19:42:34,433 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025
2024-03-25 19:42:34,433 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-LeaderElection4-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016
2024-03-25 19:42:34,433 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-LeaderElection4-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034
2024-03-25 19:42:34,433 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:42:34,433 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:42:34,442 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null
2024-03-25 19:42:34,462 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5 PRE_VOTE round 0: result PASSED (term=0)
2024-03-25 19:42:34,467 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516: receive requestVote(PRE_VOTE, a568c6b4-1a28-494a-b080-2324592b3a72, group-DC6410947516, 0, (t:0, i:0))
2024-03-25 19:42:34,469 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5 ELECTION round 0: submit vote requests at term 1 for -1: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null
2024-03-25 19:42:34,469 [grpc-default-executor-0] INFO  impl.VoteContext (VoteContext.java:log(49)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-FOLLOWER: accept PRE_VOTE from a568c6b4-1a28-494a-b080-2324592b3a72: our priority 0 <= candidate's priority 1
2024-03-25 19:42:34,469 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5 ELECTION round 0: result PASSED (term=1)
2024-03-25 19:42:34,470 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: shutdown a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5
2024-03-25 19:42:34,470 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-25 19:42:34,470 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-03-25 19:42:34,470 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-25 19:42:34,470 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-03-25 19:42:34,471 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-03-25 19:42:34,471 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-03-25 19:42:34,471 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-03-25 19:42:34,472 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-03-25 19:42:34,472 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-25 19:42:34,472 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:42:34,472 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-25 19:42:34,472 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-25 19:42:34,472 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: start a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderStateImpl
2024-03-25 19:42:34,472 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342: set firstElectionSinceStartup to false for becomeLeader
2024-03-25 19:42:34,477 [grpc-default-executor-0] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516 replies to PRE_VOTE vote request: a568c6b4-1a28-494a-b080-2324592b3a72<-f8c0ec26-9898-49d2-a0ea-132d14d0dc83#0:OK-t0. Peer's state: f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516:t0, leader=null, voted=, raftlog=Memoized:f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null
2024-03-25 19:42:34,478 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516: receive requestVote(PRE_VOTE, a568c6b4-1a28-494a-b080-2324592b3a72, group-DC6410947516, 0, (t:0, i:0))
2024-03-25 19:42:34,474 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516: receive requestVote(PRE_VOTE, a6fb26e7-f548-473f-8cf0-48fafe70504d, group-DC6410947516, 0, (t:0, i:0))
2024-03-25 19:42:34,480 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-CANDIDATE: reject PRE_VOTE from a6fb26e7-f548-473f-8cf0-48fafe70504d: our priority 1 > candidate's priority 0
2024-03-25 19:42:34,480 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516 replies to PRE_VOTE vote request: a6fb26e7-f548-473f-8cf0-48fafe70504d<-a568c6b4-1a28-494a-b080-2324592b3a72#0:FAIL-t0. Peer's state: a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516:t0, leader=null, voted=, raftlog=Memoized:a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null
2024-03-25 19:42:34,478 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-CANDIDATE: accept PRE_VOTE from a568c6b4-1a28-494a-b080-2324592b3a72: our priority 0 <= candidate's priority 1
2024-03-25 19:42:34,477 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-0FF75A016342 with new leaderId: a6fb26e7-f548-473f-8cf0-48fafe70504d
2024-03-25 19:42:34,482 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516 replies to PRE_VOTE vote request: a568c6b4-1a28-494a-b080-2324592b3a72<-a6fb26e7-f548-473f-8cf0-48fafe70504d#0:OK-t0. Peer's state: a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516:t0, leader=null, voted=, raftlog=Memoized:a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null
2024-03-25 19:42:34,480 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516: receive requestVote(PRE_VOTE, a6fb26e7-f548-473f-8cf0-48fafe70504d, group-DC6410947516, 0, (t:0, i:0))
2024-03-25 19:42:34,482 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342: change Leader from null to a6fb26e7-f548-473f-8cf0-48fafe70504d at term 1 for becomeLeader, leader elected after 5230ms
2024-03-25 19:42:34,483 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-FOLLOWER: accept PRE_VOTE from a6fb26e7-f548-473f-8cf0-48fafe70504d: our priority 0 <= candidate's priority 0
2024-03-25 19:42:34,484 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516 replies to PRE_VOTE vote request: a6fb26e7-f548-473f-8cf0-48fafe70504d<-f8c0ec26-9898-49d2-a0ea-132d14d0dc83#0:OK-t0. Peer's state: f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516:t0, leader=null, voted=, raftlog=Memoized:f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null
2024-03-25 19:42:34,484 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-25 19:42:34,485 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=37d82d77-2193-41cd-938d-dc6410947516 reported by a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:34,486 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderElection5] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342: set configuration 0: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null
2024-03-25 19:42:34,484 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-25 19:42:34,485 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:34,489 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5092768195ns, electionTimeout:5090ms
2024-03-25 19:42:34,489 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: shutdown f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-FollowerState
2024-03-25 19:42:34,489 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-25 19:42:34,489 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-25 19:42:34,490 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: start f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6
2024-03-25 19:42:34,490 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-LeaderElection4: PRE_VOTE REJECTED received 1 response(s) and 0 exception(s):
2024-03-25 19:42:34,492 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034]|listeners:[], old=null
2024-03-25 19:42:34,492 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6 PRE_VOTE round 0: result PASSED (term=0)
2024-03-25 19:42:34,492 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: a6fb26e7-f548-473f-8cf0-48fafe70504d<-a568c6b4-1a28-494a-b080-2324592b3a72#0:FAIL-t0
2024-03-25 19:42:34,493 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-LeaderElection4 PRE_VOTE round 0: result REJECTED
2024-03-25 19:42:34,490 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2024-03-25 19:42:34,493 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: a568c6b4-1a28-494a-b080-2324592b3a72<-f8c0ec26-9898-49d2-a0ea-132d14d0dc83#0:OK-t0
2024-03-25 19:42:34,493 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3 PRE_VOTE round 0: result PASSED
2024-03-25 19:42:34,493 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-LeaderElection4] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2024-03-25 19:42:34,493 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: shutdown a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-LeaderElection4
2024-03-25 19:42:34,493 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: start a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-FollowerState
2024-03-25 19:42:34,494 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-LeaderElection4] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516: set firstElectionSinceStartup to false for REJECTED
2024-03-25 19:42:34,494 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6 ELECTION round 0: submit vote requests at term 1 for -1: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034]|listeners:[], old=null
2024-03-25 19:42:34,494 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6 ELECTION round 0: result PASSED (term=1)
2024-03-25 19:42:34,494 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null
2024-03-25 19:42:34,494 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: shutdown f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6
2024-03-25 19:42:34,494 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-25 19:42:34,494 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-03-25 19:42:34,497 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/eac5a041-cf38-4b57-9357-0ff75a016342/current/log_inprogress_0
2024-03-25 19:42:34,497 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:42:34,497 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:42:34,508 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-25 19:42:34,509 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-25 19:42:34,509 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-03-25 19:42:34,510 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-03-25 19:42:34,510 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-03-25 19:42:34,510 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-03-25 19:42:34,511 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-03-25 19:42:34,511 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-25 19:42:34,511 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:42:34,511 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-25 19:42:34,511 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-25 19:42:34,511 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: start f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderStateImpl
2024-03-25 19:42:34,511 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C: set firstElectionSinceStartup to false for becomeLeader
2024-03-25 19:42:34,511 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-B01FEC71537C with new leaderId: f8c0ec26-9898-49d2-a0ea-132d14d0dc83
2024-03-25 19:42:34,512 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C: change Leader from null to f8c0ec26-9898-49d2-a0ea-132d14d0dc83 at term 1 for becomeLeader, leader elected after 5139ms
2024-03-25 19:42:34,512 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-25 19:42:34,514 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516: receive requestVote(ELECTION, a568c6b4-1a28-494a-b080-2324592b3a72, group-DC6410947516, 1, (t:0, i:0))
2024-03-25 19:42:34,514 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-FOLLOWER: accept ELECTION from a568c6b4-1a28-494a-b080-2324592b3a72: our priority 0 <= candidate's priority 1
2024-03-25 19:42:34,515 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=37d82d77-2193-41cd-938d-dc6410947516 reported by f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:34,515 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-25 19:42:34,515 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:a568c6b4-1a28-494a-b080-2324592b3a72
2024-03-25 19:42:34,515 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: shutdown a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-FollowerState
2024-03-25 19:42:34,515 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: start a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-FollowerState
2024-03-25 19:42:34,516 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516 replies to ELECTION vote request: a568c6b4-1a28-494a-b080-2324592b3a72<-a6fb26e7-f548-473f-8cf0-48fafe70504d#0:OK-t1. Peer's state: a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516:t1, leader=null, voted=a568c6b4-1a28-494a-b080-2324592b3a72, raftlog=Memoized:a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null
2024-03-25 19:42:34,517 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3: ELECTION PASSED received 1 response(s) and 0 exception(s):
2024-03-25 19:42:34,518 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: a568c6b4-1a28-494a-b080-2324592b3a72<-a6fb26e7-f548-473f-8cf0-48fafe70504d#0:OK-t1
2024-03-25 19:42:34,518 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3 ELECTION round 0: result PASSED
2024-03-25 19:42:34,518 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a568c6b4-1a28-494a-b080-2324592b3a72: shutdown a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3
2024-03-25 19:42:34,518 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-25 19:42:34,518 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-03-25 19:42:34,518 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-25 19:42:34,518 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-03-25 19:42:34,518 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-03-25 19:42:34,518 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-03-25 19:42:34,518 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-03-25 19:42:34,519 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-03-25 19:42:34,519 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-25 19:42:34,519 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:42:34,519 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-25 19:42:34,519 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-25 19:42:34,520 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-FollowerState was interrupted
2024-03-25 19:42:34,526 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderElection6] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C: set configuration 0: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034]|listeners:[], old=null
2024-03-25 19:42:34,520 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516: receive requestVote(ELECTION, a568c6b4-1a28-494a-b080-2324592b3a72, group-DC6410947516, 1, (t:0, i:0))
2024-03-25 19:42:34,530 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-FOLLOWER: accept ELECTION from a568c6b4-1a28-494a-b080-2324592b3a72: our priority 0 <= candidate's priority 1
2024-03-25 19:42:34,530 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:a568c6b4-1a28-494a-b080-2324592b3a72
2024-03-25 19:42:34,530 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: shutdown f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-FollowerState
2024-03-25 19:42:34,520 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-25 19:42:34,531 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-03-25 19:42:34,531 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:34,531 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2024-03-25 19:42:34,538 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: start f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-FollowerState
2024-03-25 19:42:34,538 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-FollowerState was interrupted
2024-03-25 19:42:34,538 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0s (custom)
2024-03-25 19:42:34,539 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/669638b9-7e75-42f1-82a9-b01fec71537c/current/log_inprogress_0
2024-03-25 19:42:34,542 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-03-25 19:42:34,542 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:42:34,543 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-03-25 19:42:34,543 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-03-25 19:42:34,543 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-03-25 19:42:34,543 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:42:34,544 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-25 19:42:34,545 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516: set firstElectionSinceStartup to false for candidate:a568c6b4-1a28-494a-b080-2324592b3a72
2024-03-25 19:42:34,547 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516 replies to ELECTION vote request: a568c6b4-1a28-494a-b080-2324592b3a72<-f8c0ec26-9898-49d2-a0ea-132d14d0dc83#0:OK-t1. Peer's state: f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516:t1, leader=null, voted=a568c6b4-1a28-494a-b080-2324592b3a72, raftlog=Memoized:f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null
2024-03-25 19:42:34,547 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-25 19:42:34,552 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-03-25 19:42:34,553 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:34,553 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2024-03-25 19:42:34,553 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0s (custom)
2024-03-25 19:42:34,553 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-03-25 19:42:34,554 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:42:34,554 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-03-25 19:42:34,554 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-03-25 19:42:34,554 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-03-25 19:42:34,554 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:42:34,555 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-25 19:42:34,556 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a568c6b4-1a28-494a-b080-2324592b3a72: start a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderStateImpl
2024-03-25 19:42:34,556 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516: set firstElectionSinceStartup to false for becomeLeader
2024-03-25 19:42:34,556 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-DC6410947516 with new leaderId: a568c6b4-1a28-494a-b080-2324592b3a72
2024-03-25 19:42:34,556 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516: change Leader from null to a568c6b4-1a28-494a-b080-2324592b3a72 at term 1 for becomeLeader, leader elected after 5383ms
2024-03-25 19:42:34,558 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=37d82d77-2193-41cd-938d-dc6410947516 reported by a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:34,558 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=37d82d77-2193-41cd-938d-dc6410947516
2024-03-25 19:42:34,558 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2024-03-25 19:42:34,559 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - HealthyPipelineSafeModeRule rule is successfully validated
2024-03-25 19:42:34,559 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2024-03-25 19:42:34,559 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2024-03-25 19:42:34,559 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(225)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2024-03-25 19:42:34,559 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(258)) - Service BackgroundPipelineCreator transitions to RUNNING.
2024-03-25 19:42:34,559 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(79)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2024-03-25 19:42:34,559 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(79)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2024-03-25 19:42:34,559 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:notifyStatusChanged(247)) - notifyStatusChanged:RUNNING
2024-03-25 19:42:34,559 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(1403)) - Service ReplicationManager transitions to RUNNING.
2024-03-25 19:42:34,560 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-25 19:42:34,560 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(134)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2024-03-25 19:42:34,561 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderElection3] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516: set configuration 0: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null
2024-03-25 19:42:34,561 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-25 19:42:34,569 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/37d82d77-2193-41cd-938d-dc6410947516/current/log_inprogress_0
2024-03-25 19:42:34,595 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-DC6410947516 with new leaderId: a568c6b4-1a28-494a-b080-2324592b3a72
2024-03-25 19:42:34,597 [a6fb26e7-f548-473f-8cf0-48fafe70504d-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-DC6410947516 with new leaderId: a568c6b4-1a28-494a-b080-2324592b3a72
2024-03-25 19:42:34,598 [a6fb26e7-f548-473f-8cf0-48fafe70504d-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516: change Leader from null to a568c6b4-1a28-494a-b080-2324592b3a72 at term 1 for appendEntries, leader elected after 5311ms
2024-03-25 19:42:34,599 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516: change Leader from null to a568c6b4-1a28-494a-b080-2324592b3a72 at term 1 for appendEntries, leader elected after 5191ms
2024-03-25 19:42:34,610 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516: set configuration 0: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null
2024-03-25 19:42:34,612 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-25 19:42:34,612 [a6fb26e7-f548-473f-8cf0-48fafe70504d-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516: set configuration 0: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null
2024-03-25 19:42:34,612 [a6fb26e7-f548-473f-8cf0-48fafe70504d-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-25 19:42:34,613 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-25 19:42:34,614 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-25 19:42:34,625 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/37d82d77-2193-41cd-938d-dc6410947516/current/log_inprogress_0
2024-03-25 19:42:34,626 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/37d82d77-2193-41cd-938d-dc6410947516/current/log_inprogress_0
2024-03-25 19:42:34,633 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-25 19:42:34,651 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:34,651 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:34,671 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-03-25 19:42:34,671 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Cluster exits safe mode
2024-03-25 19:42:34,671 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-03-25 19:42:34,672 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(59)) - No unit for hdds.scmclient.rpc.timeout(60000) assuming MILLISECONDS
2024-03-25 19:42:34,672 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(59)) - No unit for hdds.scmclient.max.retry.timeout(6000) assuming MILLISECONDS
2024-03-25 19:42:34,675 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(59)) - No unit for hdds.scmclient.rpc.timeout(60000) assuming MILLISECONDS
2024-03-25 19:42:34,675 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(59)) - No unit for hdds.scmclient.max.retry.timeout(6000) assuming MILLISECONDS
2024-03-25 19:42:34,736 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5172847592ns, electionTimeout:5172ms
2024-03-25 19:42:34,761 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: shutdown 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-FollowerState
2024-03-25 19:42:34,761 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-25 19:42:34,761 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-25 19:42:34,761 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: start 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7
2024-03-25 19:42:34,763 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043]|listeners:[], old=null
2024-03-25 19:42:34,769 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7 PRE_VOTE round 0: result PASSED (term=0)
2024-03-25 19:42:34,776 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7 ELECTION round 0: submit vote requests at term 1 for -1: peers:[6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043]|listeners:[], old=null
2024-03-25 19:42:34,776 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7 ELECTION round 0: result PASSED (term=1)
2024-03-25 19:42:34,776 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: shutdown 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7
2024-03-25 19:42:34,777 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-25 19:42:34,777 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-03-25 19:42:34,777 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-25 19:42:34,778 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-03-25 19:42:34,778 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-03-25 19:42:34,778 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-03-25 19:42:34,778 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-03-25 19:42:34,778 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-03-25 19:42:34,778 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-25 19:42:34,779 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:42:34,779 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-25 19:42:34,779 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-25 19:42:34,779 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: start 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderStateImpl
2024-03-25 19:42:34,779 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6: set firstElectionSinceStartup to false for becomeLeader
2024-03-25 19:42:34,779 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-7CBE81B705E6 with new leaderId: 6e65d581-b1bc-41f2-b39b-16d8508d6618
2024-03-25 19:42:34,779 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6: change Leader from null to 6e65d581-b1bc-41f2-b39b-16d8508d6618 at term 1 for becomeLeader, leader elected after 5273ms
2024-03-25 19:42:34,779 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-25 19:42:34,780 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-25 19:42:34,784 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderElection7] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6: set configuration 0: peers:[6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043]|listeners:[], old=null
2024-03-25 19:42:34,790 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/1c6daf81-1115-4d9e-8b57-7cbe81b705e6/current/log_inprogress_0
2024-03-25 19:42:34,792 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-25 19:42:34,794 [main] INFO  protocolPB.OmTransportFactory (OmTransportFactory.java:createFactory(62)) - Loading OM transport implementation org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory as specified by configuration.
2024-03-25 19:42:34,833 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5068890568ns, electionTimeout:5063ms
2024-03-25 19:42:34,833 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: shutdown 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-FollowerState
2024-03-25 19:42:34,833 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-25 19:42:34,833 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-25 19:42:34,833 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: start 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8
2024-03-25 19:42:34,837 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:42:34,837 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8 PRE_VOTE round 0: result PASSED (term=0)
2024-03-25 19:42:34,841 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8 ELECTION round 0: submit vote requests at term 1 for -1: peers:[8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:42:34,841 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8 ELECTION round 0: result PASSED (term=1)
2024-03-25 19:42:34,841 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: shutdown 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8
2024-03-25 19:42:34,842 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-25 19:42:34,842 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-03-25 19:42:34,842 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-25 19:42:34,842 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-03-25 19:42:34,843 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-03-25 19:42:34,843 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-03-25 19:42:34,843 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-03-25 19:42:34,843 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-03-25 19:42:34,843 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-25 19:42:34,843 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:42:34,843 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-25 19:42:34,843 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-25 19:42:34,844 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: start 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderStateImpl
2024-03-25 19:42:34,844 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C: set firstElectionSinceStartup to false for becomeLeader
2024-03-25 19:42:34,844 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-81169FADB40C with new leaderId: 8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:42:34,844 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C: change Leader from null to 8de788e1-2c95-4c74-b4ac-29ea2448e86a at term 1 for becomeLeader, leader elected after 5134ms
2024-03-25 19:42:34,850 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-25 19:42:34,851 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-25 19:42:34,857 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderElection8] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C: set configuration 0: peers:[8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:42:34,860 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/2db7f802-448f-42c5-98a7-81169fadb40c/current/log_inprogress_0
2024-03-25 19:42:34,863 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-25 19:42:35,030 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(464)) - Creating Volume: vol1, with user20368 as owner and space quota set to -1 bytes, counts quota set to -1
2024-03-25 19:42:35,072 [om1-OMStateMachineApplyTransactionThread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(198)) - created volume:vol1 for user:user20368
2024-03-25 19:42:35,080 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(71)) - OmKeyInfo.getCodec ignorePipeline = true
2024-03-25 19:42:35,080 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(71)) - OmKeyInfo.getCodec ignorePipeline = true
2024-03-25 19:42:35,080 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(71)) - OmKeyInfo.getCodec ignorePipeline = true
2024-03-25 19:42:35,080 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(71)) - OmKeyInfo.getCodec ignorePipeline = true
2024-03-25 19:42:35,080 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(71)) - OmKeyInfo.getCodec ignorePipeline = true
2024-03-25 19:42:35,089 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(690)) - Creating Bucket: vol1/bucket1, with bucket layout FILE_SYSTEM_OPTIMIZED, runner as owner, Versioning false, Storage Type set to DISK and Encryption set to false, Replication Type set to server-side default replication type, Namespace Quota set to -1, Space Quota set to -1 
2024-03-25 19:42:35,106 [om1-OMStateMachineApplyTransactionThread - 0] INFO  bucket.OMBucketCreateRequest (OMBucketCreateRequest.java:validateAndUpdateCache(293)) - created bucket: bucket1 of layout FILE_SYSTEM_OPTIMIZED in volume: vol1
2024-03-25 19:42:35,155 [IPC Server handler 0 on default port 15001] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(145)) - Allocate a batch for containerId, change lastId from 0 to 1000.
2024-03-25 19:42:35,165 [IPC Server handler 0 on default port 15001] WARN  ha.SequenceIdGenerator (SequenceIdGenerator.java:allocateBatch(258)) - Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 113750153625600000.
2024-03-25 19:42:35,166 [IPC Server handler 0 on default port 15001] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(145)) - Allocate a batch for localId, change lastId from 113750153625600000 to 113750153625601000.
2024-03-25 19:42:35,239 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - XceiverClientMetrics metrics system started (again)
2024-03-25 19:42:35,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:35,415 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: ICR, size: 1}
2024-03-25 19:42:35,417 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 5 millisec, a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), {type: ICR, size: 1}
2024-03-25 19:42:35,425 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 13 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: ICR, size: 1}
2024-03-25 19:42:35,427 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:addNewContainer(246)) - Successfully added container #1 to Recon.
2024-03-25 19:42:35,433 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 22 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: ICR, size: 1}
2024-03-25 19:42:35,438 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), {type: ICR, size: 1}
2024-03-25 19:42:35,442 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:addNewContainer(246)) - Successfully added container #1 to Recon.
2024-03-25 19:42:35,445 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 7 millisec, f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27), {type: ICR, size: 1}
2024-03-25 19:42:35,446 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 33 millisec, a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), {type: ICR, size: 1}
2024-03-25 19:42:35,447 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 9 millisec, f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27), {type: ICR, size: 1}
Connecting to Recon: http://0.0.0.0:15008/api/v1/triggerdbsync/om ...
2024-03-25 19:42:35,657 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:35,668 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 10 milliseconds for processing 1 containers.
2024-03-25 19:42:35,669 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:35,669 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:35,669 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:35,669 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:35,669 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:35,669 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:35,670 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:35,682 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:42:35,683 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(537)) - Obtaining full snapshot from Ozone Manager
2024-03-25 19:42:35,702 [qtp1908051795-406] INFO  utils.DBCheckpointServlet (DBCheckpointServlet.java:doGet(301)) - Received GET request to obtain DB checkpoint snapshot
2024-03-25 19:42:36,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:36,418 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 4 millisec, a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:42:36,533 [qtp1908051795-406] INFO  om.OMDBCheckpointServlet (OMDBCheckpointServlet.java:getCheckpoint(246)) - Compaction pausing 1 started.
2024-03-25 19:42:36,562 [qtp1908051795-406] INFO  db.RDBCheckpointManager (RDBCheckpointManager.java:createCheckpoint(89)) - Created checkpoint in rocksDB at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/db.checkpoints/om.db_checkpoint_1711395756542 in 20 milliseconds
2024-03-25 19:42:36,565 [qtp1908051795-406] INFO  om.OMDBCheckpointServlet (OMDBCheckpointServlet.java:getCheckpoint(258)) - Compaction pausing 1 ended. Elapsed ms: 32
2024-03-25 19:42:36,583 [qtp1908051795-406] INFO  utils.DBCheckpointServlet (DBCheckpointServlet.java:generateSnapshotCheckpoint(225)) - Time taken to write the checkpoint to response output stream: 18 milliseconds
2024-03-25 19:42:36,584 [qtp1908051795-406] INFO  utils.DBCheckpointServlet (DBCheckpointServlet.java:generateSnapshotCheckpoint(228)) - Excluded SST [] from the latest checkpoint.
2024-03-25 19:42:36,597 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:updateReconOmDBWithNewSnapshot(390)) - Got new checkpoint from OM : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/recon/om.snapshot.db_1711395755683
2024-03-25 19:42:36,597 [qtp1908051795-406] INFO  db.RocksDBCheckpoint (RocksDBCheckpoint.java:cleanupCheckpoint(78)) - Cleaning up RocksDB checkpoint at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/db.checkpoints/om.db_checkpoint_1711395756542
2024-03-25 19:42:36,598 [Recon-SyncOM-1] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(71)) - OmKeyInfo.getCodec ignorePipeline = true
2024-03-25 19:42:36,632 [Recon-SyncOM-1] INFO  recovery.ReconOmMetadataManagerImpl (ReconOmMetadataManagerImpl.java:initializeNewRdbStore(107)) - Created OM DB handle from snapshot at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/recon/om.snapshot.db_1711395755683.
2024-03-25 19:42:36,639 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(550)) - Calling reprocess on Recon tasks.
2024-03-25 19:42:36,671 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:36,673 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:42:36,673 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:36,673 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:36,673 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:36,673 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:36,674 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:36,674 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:36,674 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:36,770 [ReconTaskThread-0] INFO  tasks.OmTableInsightTask (OmTableInsightTask.java:reprocess(137)) - Completed a 'reprocess' run of OmTableInsightTask.
2024-03-25 19:42:36,772 [Recon-NSSummaryTask-1] INFO  tasks.NSSummaryTaskWithLegacy (NSSummaryTaskWithLegacy.java:reprocessWithLegacy(267)) - Completed a reprocess run of NSSummaryTaskWithLegacy
2024-03-25 19:42:36,773 [Recon-NSSummaryTask-1] INFO  tasks.NSSummaryTaskWithOBS (NSSummaryTaskWithOBS.java:reprocessWithOBS(110)) - Completed a reprocess run of NSSummaryTaskWithOBS
2024-03-25 19:42:36,774 [Recon-NSSummaryTask-0] INFO  tasks.NSSummaryTaskWithFSO (NSSummaryTaskWithFSO.java:reprocessWithFSO(213)) - Completed a reprocess run of NSSummaryTaskWithFSO
2024-03-25 19:42:36,774 [ReconTaskThread-0] INFO  tasks.NSSummaryTask (NSSummaryTask.java:reprocess(169)) - Task execution time: 3 milliseconds
2024-03-25 19:42:36,774 [ReconTaskThread-0] INFO  tasks.ContainerKeyMapperTask (ContainerKeyMapperTask.java:reprocess(97)) - Starting a 'reprocess' run of ContainerKeyMapperTask.
2024-03-25 19:42:36,775 [ReconTaskThread-0] INFO  impl.ReconContainerMetadataManagerImpl (ReconContainerMetadataManagerImpl.java:initializeTables(141)) - KEY_CONTAINER Table is empty, initializing from CONTAINER_KEY Table ...
2024-03-25 19:42:36,775 [ReconTaskThread-0] INFO  impl.ReconContainerMetadataManagerImpl (ReconContainerMetadataManagerImpl.java:initializeKeyContainerTable(666)) - It took 0.0 seconds to initialized 0 records to KEY_CONTAINER table
2024-03-25 19:42:36,791 [ReconTaskThread-0] INFO  tasks.ContainerKeyMapperTask (ContainerKeyMapperTask.java:reprocess(140)) - Completed 'reprocess' of ContainerKeyMapperTask.
2024-03-25 19:42:36,791 [ReconTaskThread-0] INFO  tasks.ContainerKeyMapperTask (ContainerKeyMapperTask.java:reprocess(143)) - It took me 0.017 seconds to process 1 keys.
2024-03-25 19:42:36,803 [ReconTaskThread-0] INFO  tasks.FileSizeCountTask (FileSizeCountTask.java:reprocess(84)) - Deleted 0 records from "FILE_COUNT_BY_SIZE"
2024-03-25 19:42:36,812 [ReconTaskThread-0] INFO  tasks.FileSizeCountTask (FileSizeCountTask.java:reprocess(99)) - Completed a 'reprocess' run of FileSizeCountTask.
2024-03-25 19:42:37,377 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-03-25 19:42:37,675 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:37,677 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:42:37,677 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:37,677 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:37,677 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:37,677 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:37,677 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:37,678 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:37,678 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:37,798 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27) moved to HEALTHY state.
2024-03-25 19:42:37,799 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-25 19:42:37,799 [IPC Server handler 13 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startMaintenance(446)) - Starting Maintenance for node a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27)
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
2024-03-25 19:42:37,818 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:42:37,820 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:42:37,820 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:42:37,832 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:42:37,832 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:42:37,841 [qtp850601250-458] INFO  impl.Tools (JooqLogger.java:info(338)) - Kotlin is available, but not kotlin-reflect. Add the kotlin-reflect dependency to better use Kotlin features like data classes
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-03-25 19:42:38,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:42:38,411 [IPC Server handler 19 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-03-25 19:42:38,413 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:42:38,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@56eb96a8. There are 2 pipelines
2024-03-25 19:42:38,441 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(55)) - Admin start on datanode a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27). Finalizing its pipelines [PipelineID=37d82d77-2193-41cd-938d-dc6410947516, PipelineID=8a6654ba-868c-467c-ac57-e84dd4d606bd]
2024-03-25 19:42:38,442 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-25 19:42:38,445 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(484)) - Container #1 closed for pipeline=PipelineID=37d82d77-2193-41cd-938d-dc6410947516
2024-03-25 19:42:38,445 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #1, current state: CLOSING
2024-03-25 19:42:38,446 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=37d82d77-2193-41cd-938d-dc6410947516 moved to CLOSED state
2024-03-25 19:42:38,446 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=8a6654ba-868c-467c-ac57-e84dd4d606bd moved to CLOSED state
2024-03-25 19:42:38,679 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:38,681 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:42:38,681 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:38,681 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:38,681 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:38,681 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:38,681 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:38,681 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:38,681 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:38,835 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:42:38,835 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:42:38,835 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:42:38,837 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:42:38,837 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:42:39,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=37d82d77-2193-41cd-938d-dc6410947516, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-03-25T19:42:38.444Z, pipelineID=PipelineID=37d82d77-2193-41cd-938d-dc6410947516, owner=omServiceIdDefault} to f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27) with datanode deadline 1711396329379 and scm deadline 1711396359379
2024-03-25 19:42:39,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=37d82d77-2193-41cd-938d-dc6410947516, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-03-25T19:42:38.444Z, pipelineID=PipelineID=37d82d77-2193-41cd-938d-dc6410947516, owner=omServiceIdDefault} to a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27) with datanode deadline 1711396329380 and scm deadline 1711396359380
2024-03-25 19:42:39,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=37d82d77-2193-41cd-938d-dc6410947516, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-03-25T19:42:38.444Z, pipelineID=PipelineID=37d82d77-2193-41cd-938d-dc6410947516, owner=omServiceIdDefault} to a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27) with datanode deadline 1711396329380 and scm deadline 1711396359380
2024-03-25 19:42:39,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:42:39,413 [a568c6b4-1a28-494a-b080-2324592b3a72-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to ENTERING_MAINTENANCE, scaling executor pool size to 20
2024-03-25 19:42:39,413 [IPC Server handler 16 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-03-25 19:42:39,416 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:42:39,416 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:42:39,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@56eb96a8. There are 2 pipelines
2024-03-25 19:42:39,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-25 19:42:39,682 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-25 19:42:39,685 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:42:39,685 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:39,685 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:39,685 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:39,685 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:39,685 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:39,685 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:39,685 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:39,839 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:42:39,839 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:42:39,839 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:42:39,841 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:42:39,841 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:42:40,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=37d82d77-2193-41cd-938d-dc6410947516, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-03-25T19:42:38.444Z, pipelineID=PipelineID=37d82d77-2193-41cd-938d-dc6410947516, owner=omServiceIdDefault} to f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27) with datanode deadline 1711396330380 and scm deadline 1711396360380
2024-03-25 19:42:40,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=37d82d77-2193-41cd-938d-dc6410947516, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-03-25T19:42:38.444Z, pipelineID=PipelineID=37d82d77-2193-41cd-938d-dc6410947516, owner=omServiceIdDefault} to a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27) with datanode deadline 1711396330381 and scm deadline 1711396360381
2024-03-25 19:42:40,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=37d82d77-2193-41cd-938d-dc6410947516, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-03-25T19:42:38.444Z, pipelineID=PipelineID=37d82d77-2193-41cd-938d-dc6410947516, owner=omServiceIdDefault} to a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27) with datanode deadline 1711396330381 and scm deadline 1711396360381
2024-03-25 19:42:40,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:42:40,411 [IPC Server handler 10 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-03-25 19:42:40,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@56eb96a8. There are 2 pipelines
2024-03-25 19:42:40,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-25 19:42:40,686 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:40,691 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 4 milliseconds for processing 1 containers.
2024-03-25 19:42:40,691 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:40,691 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:40,691 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:40,691 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:40,691 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:40,691 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:40,691 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:40,785 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, 6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:42:40,786 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, 6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:42:40,843 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:42:40,843 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:42:40,843 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:42:40,846 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:42:40,846 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:42:41,381 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=37d82d77-2193-41cd-938d-dc6410947516, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-03-25T19:42:38.444Z, pipelineID=PipelineID=37d82d77-2193-41cd-938d-dc6410947516, owner=omServiceIdDefault} to f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27) with datanode deadline 1711396331381 and scm deadline 1711396361381
2024-03-25 19:42:41,382 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=37d82d77-2193-41cd-938d-dc6410947516, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-03-25T19:42:38.444Z, pipelineID=PipelineID=37d82d77-2193-41cd-938d-dc6410947516, owner=omServiceIdDefault} to a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27) with datanode deadline 1711396331381 and scm deadline 1711396361381
2024-03-25 19:42:41,382 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=37d82d77-2193-41cd-938d-dc6410947516, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-03-25T19:42:38.444Z, pipelineID=PipelineID=37d82d77-2193-41cd-938d-dc6410947516, owner=omServiceIdDefault} to a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27) with datanode deadline 1711396331382 and scm deadline 1711396361382
2024-03-25 19:42:41,382 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:42:41,413 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:42:41,422 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:checkContainerStateAndUpdate(199)) - Container #1 has state OPEN, but given state is CLOSING.
2024-03-25 19:42:41,428 [a6fb26e7-f548-473f-8cf0-48fafe70504d-CloseContainerThread-0] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-03-25 19:42:41,428 [a568c6b4-1a28-494a-b080-2324592b3a72-ContainerOp-37d82d77-2193-41cd-938d-dc6410947516-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-03-25 19:42:41,429 [a568c6b4-1a28-494a-b080-2324592b3a72-ContainerOp-37d82d77-2193-41cd-938d-dc6410947516-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-03-25 19:42:41,432 [a568c6b4-1a28-494a-b080-2324592b3a72-ContainerOp-37d82d77-2193-41cd-938d-dc6410947516-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(437)) - Container 1 is closed with bcsId 2.
2024-03-25 19:42:41,434 [a6fb26e7-f548-473f-8cf0-48fafe70504d-CloseContainerThread-0] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-03-25 19:42:41,445 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@56eb96a8. There are 2 pipelines
2024-03-25 19:42:41,445 [a6fb26e7-f548-473f-8cf0-48fafe70504d-CloseContainerThread-1] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-03-25 19:42:41,445 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-25 19:42:41,452 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(312)) - Moving container #1 to CLOSED state, datanode a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27) reported CLOSED replica with index 0.
2024-03-25 19:42:41,453 [FixedThreadPoolWithAffinityExecutor-8-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(312)) - Moving container #1 to CLOSED state, datanode a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27) reported CLOSED replica with index 0.
2024-03-25 19:42:41,459 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-ContainerOp-37d82d77-2193-41cd-938d-dc6410947516-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-03-25 19:42:41,459 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-ContainerOp-37d82d77-2193-41cd-938d-dc6410947516-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-03-25 19:42:41,466 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-CloseContainerThread-1] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-03-25 19:42:41,467 [a6fb26e7-f548-473f-8cf0-48fafe70504d-ContainerOp-37d82d77-2193-41cd-938d-dc6410947516-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-03-25 19:42:41,467 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-CloseContainerThread-0] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-03-25 19:42:41,468 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-ContainerOp-37d82d77-2193-41cd-938d-dc6410947516-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(437)) - Container 1 is closed with bcsId 2.
2024-03-25 19:42:41,467 [a6fb26e7-f548-473f-8cf0-48fafe70504d-CloseContainerThread-2] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-03-25 19:42:41,468 [a6fb26e7-f548-473f-8cf0-48fafe70504d-ContainerOp-37d82d77-2193-41cd-938d-dc6410947516-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-03-25 19:42:41,474 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-CloseContainerThread-2] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-03-25 19:42:41,476 [a6fb26e7-f548-473f-8cf0-48fafe70504d-ContainerOp-37d82d77-2193-41cd-938d-dc6410947516-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(437)) - Container 1 is closed with bcsId 2.
2024-03-25 19:42:41,692 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:41,694 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 3 milliseconds for processing 1 containers.
2024-03-25 19:42:41,695 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:41,695 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:41,695 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:41,695 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:41,695 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:41,695 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:41,695 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:41,848 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:42:41,848 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:42:41,848 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:42:41,849 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:42:41,849 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:42:42,384 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:42:42,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@56eb96a8. There are 2 pipelines
2024-03-25 19:42:42,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-25 19:42:42,696 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:42,699 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:42:42,699 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:42,699 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:42,699 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:42,699 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:42,699 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:42,699 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:42,699 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:42,852 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:42:42,852 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:42:42,852 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:42:42,853 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:42:42,854 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:42:43,385 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:42:43,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@56eb96a8. There are 2 pipelines
2024-03-25 19:42:43,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-25 19:42:43,700 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:43,703 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:42:43,703 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:43,703 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:43,703 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:43,703 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:43,703 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:43,703 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:43,703 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:43,856 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:42:43,856 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:42:43,856 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:42:43,858 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:42:43,858 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:42:44,385 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:42:44,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@56eb96a8. There are 2 pipelines
2024-03-25 19:42:44,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-25 19:42:44,704 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:44,707 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:42:44,707 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:44,707 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:44,707 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:44,707 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:44,707 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:44,707 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:44,707 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:44,860 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:42:44,860 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:42:44,860 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:42:44,863 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:42:44,863 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:42:45,275 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=37d82d77-2193-41cd-938d-dc6410947516 since it stays at CLOSED stage.
2024-03-25 19:42:45,276 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=37d82d77-2193-41cd-938d-dc6410947516 close command to datanode a568c6b4-1a28-494a-b080-2324592b3a72
2024-03-25 19:42:45,276 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=37d82d77-2193-41cd-938d-dc6410947516 close command to datanode a6fb26e7-f548-473f-8cf0-48fafe70504d
2024-03-25 19:42:45,276 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=37d82d77-2193-41cd-938d-dc6410947516 close command to datanode f8c0ec26-9898-49d2-a0ea-132d14d0dc83
2024-03-25 19:42:45,277 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 37d82d77-2193-41cd-938d-dc6410947516, Nodes: a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27)a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27)f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:a568c6b4-1a28-494a-b080-2324592b3a72, CreationTimestamp2024-03-25T19:42:26.380Z[Etc/UTC]] removed.
2024-03-25 19:42:45,277 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=8a6654ba-868c-467c-ac57-e84dd4d606bd since it stays at CLOSED stage.
2024-03-25 19:42:45,277 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=8a6654ba-868c-467c-ac57-e84dd4d606bd close command to datanode a568c6b4-1a28-494a-b080-2324592b3a72
2024-03-25 19:42:45,277 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 8a6654ba-868c-467c-ac57-e84dd4d606bd, Nodes: a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:a568c6b4-1a28-494a-b080-2324592b3a72, CreationTimestamp2024-03-25T19:42:26.114Z[Etc/UTC]] removed.
2024-03-25 19:42:45,386 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:42:45,442 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(472)) - org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@56eb96a8 has 1 sufficientlyReplicated, 0 deleting, 0 underReplicated and 0 unclosed containers
2024-03-25 19:42:45,442 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:putIntoMaintenance(529)) - Datanode a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27) has entered maintenance
2024-03-25 19:42:45,442 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-25 19:42:45,442 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27) moved to HEALTHY state.
2024-03-25 19:42:45,443 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-25 19:42:45,444 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 to datanode:f8c0ec26-9898-49d2-a0ea-132d14d0dc83
2024-03-25 19:42:45,444 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 to datanode:6e65d581-b1bc-41f2-b39b-16d8508d6618
2024-03-25 19:42:45,444 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 to datanode:8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:42:45,445 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: b272cc68-1415-4b0a-8697-67f90e925935, Nodes: f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27)6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27)8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-25T19:42:45.444Z[Etc/UTC]]
2024-03-25 19:42:45,454 [IPC Server handler 11 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2024-03-25 19:42:45,456 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=37d82d77-2193-41cd-938d-dc6410947516 is not found
2024-03-25 19:42:45,457 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=8a6654ba-868c-467c-ac57-e84dd4d606bd is not found
2024-03-25 19:42:45,475 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=37d82d77-2193-41cd-938d-dc6410947516 is not found
2024-03-25 19:42:45,479 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=37d82d77-2193-41cd-938d-dc6410947516 is not found
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-03-25 19:42:45,530 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27) moved to HEALTHY state.
2024-03-25 19:42:45,530 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-25 19:42:45,530 [IPC Server handler 2 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startMaintenance(446)) - Starting Maintenance for node a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27)
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-03-25 19:42:45,708 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:45,710 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:42:45,710 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:45,710 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:45,710 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:45,710 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:45,711 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:45,711 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:45,711 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:45,865 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:42:45,865 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:42:45,865 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:42:45,867 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:42:45,867 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:42:46,387 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:42:46,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@2133796f. There are 1 pipelines
2024-03-25 19:42:46,441 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(55)) - Admin start on datanode a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27). Finalizing its pipelines [PipelineID=eac5a041-cf38-4b57-9357-0ff75a016342]
2024-03-25 19:42:46,442 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=eac5a041-cf38-4b57-9357-0ff75a016342 moved to CLOSED state
2024-03-25 19:42:46,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-25 19:42:46,452 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - a568c6b4-1a28-494a-b080-2324592b3a72: remove    LEADER a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516:t1, leader=a568c6b4-1a28-494a-b080-2324592b3a72, voted=a568c6b4-1a28-494a-b080-2324592b3a72, raftlog=Memoized:a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-SegmentedRaftLog:OPENED:c8, conf=0: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null RUNNING
2024-03-25 19:42:46,454 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516: shutdown
2024-03-25 19:42:46,454 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DC6410947516,id=a568c6b4-1a28-494a-b080-2324592b3a72
2024-03-25 19:42:46,454 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - a568c6b4-1a28-494a-b080-2324592b3a72: shutdown a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-LeaderStateImpl
2024-03-25 19:42:46,454 [a568c6b4-1a28-494a-b080-2324592b3a72-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_MAINTENANCE, scaling executor pool size to 20
2024-03-25 19:42:46,454 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-PendingRequests: sendNotLeaderResponses
2024-03-25 19:42:46,457 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516->a6fb26e7-f548-473f-8cf0-48fafe70504d-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516->a6fb26e7-f548-473f-8cf0-48fafe70504d-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-03-25 19:42:46,457 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516->f8c0ec26-9898-49d2-a0ea-132d14d0dc83-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516->f8c0ec26-9898-49d2-a0ea-132d14d0dc83-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-03-25 19:42:46,459 [IPC Server handler 11 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2024-03-25 19:42:46,465 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: Completed APPEND_ENTRIES, lastRequest: a568c6b4-1a28-494a-b080-2324592b3a72->f8c0ec26-9898-49d2-a0ea-132d14d0dc83#19-t1,previous=(t:1, i:7),leaderCommit=7,initializing? false,entries: size=1, first=(t:1, i:8), METADATAENTRY(c:7)
2024-03-25 19:42:46,465 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: Completed APPEND_ENTRIES, lastReply: null
2024-03-25 19:42:46,465 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: Completed APPEND_ENTRIES, lastRequest: a568c6b4-1a28-494a-b080-2324592b3a72->a6fb26e7-f548-473f-8cf0-48fafe70504d#20-t1,previous=(t:1, i:7),leaderCommit=7,initializing? false,entries: size=1, first=(t:1, i:8), METADATAENTRY(c:7)
2024-03-25 19:42:46,465 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-StateMachineUpdater: set stopIndex = 8
2024-03-25 19:42:46,466 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-DC6410947516: Taking a snapshot at:(t:1, i:8) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/37d82d77-2193-41cd-938d-dc6410947516/sm/snapshot.1_8
2024-03-25 19:42:46,467 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516->f8c0ec26-9898-49d2-a0ea-132d14d0dc83-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-25 19:42:46,465 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: Completed APPEND_ENTRIES, lastReply: null
2024-03-25 19:42:46,470 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516->a6fb26e7-f548-473f-8cf0-48fafe70504d-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-25 19:42:46,467 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: Completed APPEND_ENTRIES, lastRequest: null
2024-03-25 19:42:46,467 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: Completed APPEND_ENTRIES, lastRequest: null
2024-03-25 19:42:46,475 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "a568c6b4-1a28-494a-b080-2324592b3a72"
  replyId: "f8c0ec26-9898-49d2-a0ea-132d14d0dc83"
  raftGroupId {
    id: "7\330-w!\223A\315\223\215\334d\020\224u\026"
  }
  callId: 23
  success: true
}
term: 1
nextIndex: 9
followerCommit: 8
matchIndex: 18446744073709551615
isHearbeat: true

2024-03-25 19:42:46,475 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "a568c6b4-1a28-494a-b080-2324592b3a72"
  replyId: "a6fb26e7-f548-473f-8cf0-48fafe70504d"
  raftGroupId {
    id: "7\330-w!\223A\315\223\215\334d\020\224u\026"
  }
  callId: 25
  success: true
}
term: 1
nextIndex: 9
followerCommit: 8
matchIndex: 18446744073709551615
isHearbeat: true

2024-03-25 19:42:46,475 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516->f8c0ec26-9898-49d2-a0ea-132d14d0dc83-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-25 19:42:46,475 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: remove  FOLLOWER f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516:t1, leader=a568c6b4-1a28-494a-b080-2324592b3a72, voted=a568c6b4-1a28-494a-b080-2324592b3a72, raftlog=Memoized:f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-SegmentedRaftLog:OPENED:c8, conf=0: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null RUNNING
2024-03-25 19:42:46,475 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516: shutdown
2024-03-25 19:42:46,475 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DC6410947516,id=f8c0ec26-9898-49d2-a0ea-132d14d0dc83
2024-03-25 19:42:46,476 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: shutdown f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-FollowerState
2024-03-25 19:42:46,476 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-StateMachineUpdater: set stopIndex = 8
2024-03-25 19:42:46,476 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-DC6410947516: Taking a snapshot at:(t:1, i:8) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/37d82d77-2193-41cd-938d-dc6410947516/sm/snapshot.1_8
2024-03-25 19:42:46,477 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516->a6fb26e7-f548-473f-8cf0-48fafe70504d-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-25 19:42:46,477 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: remove  FOLLOWER a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516:t1, leader=a568c6b4-1a28-494a-b080-2324592b3a72, voted=a568c6b4-1a28-494a-b080-2324592b3a72, raftlog=Memoized:a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-SegmentedRaftLog:OPENED:c8, conf=0: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016, f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null RUNNING
2024-03-25 19:42:46,477 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516: shutdown
2024-03-25 19:42:46,477 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DC6410947516,id=a6fb26e7-f548-473f-8cf0-48fafe70504d
2024-03-25 19:42:46,477 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: shutdown a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-FollowerState
2024-03-25 19:42:46,478 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-StateMachineUpdater: set stopIndex = 8
2024-03-25 19:42:46,478 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-DC6410947516: Taking a snapshot at:(t:1, i:8) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/37d82d77-2193-41cd-938d-dc6410947516/sm/snapshot.1_8
2024-03-25 19:42:46,478 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:42:46,478 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:42:46,478 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-FollowerState was interrupted
2024-03-25 19:42:46,482 [IPC Server handler 5 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-03-25 19:42:46,481 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=37d82d77-2193-41cd-938d-dc6410947516 is not found
2024-03-25 19:42:46,480 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-FollowerState was interrupted
2024-03-25 19:42:46,483 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:42:46,508 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-DC6410947516: Finished taking a snapshot at:(t:1, i:8) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/37d82d77-2193-41cd-938d-dc6410947516/sm/snapshot.1_8 took: 30 ms
2024-03-25 19:42:46,508 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-DC6410947516: Finished taking a snapshot at:(t:1, i:8) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/37d82d77-2193-41cd-938d-dc6410947516/sm/snapshot.1_8 took: 32 ms
2024-03-25 19:42:46,508 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-DC6410947516: Finished taking a snapshot at:(t:1, i:8) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/37d82d77-2193-41cd-938d-dc6410947516/sm/snapshot.1_8 took: 42 ms
2024-03-25 19:42:46,509 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-StateMachineUpdater: Took a snapshot at index 8
2024-03-25 19:42:46,509 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-StateMachineUpdater: Took a snapshot at index 8
2024-03-25 19:42:46,509 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 8
2024-03-25 19:42:46,509 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 8
2024-03-25 19:42:46,510 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-StateMachineUpdater: Took a snapshot at index 8
2024-03-25 19:42:46,510 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 8
2024-03-25 19:42:46,512 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516: applyIndex: 8
2024-03-25 19:42:46,512 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516: applyIndex: 8
2024-03-25 19:42:46,513 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-25 19:42:46,513 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516: applyIndex: 8
2024-03-25 19:42:46,516 [a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-25 19:42:46,516 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-25 19:42:46,712 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:46,714 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:42:46,714 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:46,714 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:46,714 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:46,714 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:46,714 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:46,715 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:46,715 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:46,868 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:42:46,869 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:42:46,869 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:42:46,870 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:42:46,871 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:42:47,387 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:42:47,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@2133796f. There are 1 pipelines
2024-03-25 19:42:47,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-25 19:42:47,449 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516-SegmentedRaftLogWorker close()
2024-03-25 19:42:47,450 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516-SegmentedRaftLogWorker close()
2024-03-25 19:42:47,451 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516-SegmentedRaftLogWorker close()
2024-03-25 19:42:47,456 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=8a6654ba-868c-467c-ac57-e84dd4d606bd is not found
2024-03-25 19:42:47,457 [IPC Server handler 18 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27) as the reported value (IN_MAINTENANCE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-03-25 19:42:47,457 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-DC6410947516: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/37d82d77-2193-41cd-938d-dc6410947516
2024-03-25 19:42:47,457 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-DC6410947516: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/37d82d77-2193-41cd-938d-dc6410947516
2024-03-25 19:42:47,458 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=37d82d77-2193-41cd-938d-dc6410947516
org.apache.ratis.protocol.exceptions.GroupMismatchException: a568c6b4-1a28-494a-b080-2324592b3a72: group-DC6410947516 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-25 19:42:47,458 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-DC6410947516: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/37d82d77-2193-41cd-938d-dc6410947516
2024-03-25 19:42:47,458 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=37d82d77-2193-41cd-938d-dc6410947516
org.apache.ratis.protocol.exceptions.GroupMismatchException: a6fb26e7-f548-473f-8cf0-48fafe70504d: group-DC6410947516 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-25 19:42:47,458 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=37d82d77-2193-41cd-938d-dc6410947516
org.apache.ratis.protocol.exceptions.GroupMismatchException: f8c0ec26-9898-49d2-a0ea-132d14d0dc83: group-DC6410947516 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-25 19:42:47,458 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - a568c6b4-1a28-494a-b080-2324592b3a72: remove    LEADER a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD:t1, leader=a568c6b4-1a28-494a-b080-2324592b3a72, voted=a568c6b4-1a28-494a-b080-2324592b3a72, raftlog=Memoized:a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-SegmentedRaftLog:OPENED:c0, conf=0: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016]|listeners:[], old=null RUNNING
2024-03-25 19:42:47,459 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD: shutdown
2024-03-25 19:42:47,459 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-E84DD4D606BD,id=a568c6b4-1a28-494a-b080-2324592b3a72
2024-03-25 19:42:47,461 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - a568c6b4-1a28-494a-b080-2324592b3a72: shutdown a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-LeaderStateImpl
2024-03-25 19:42:47,461 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-PendingRequests: sendNotLeaderResponses
2024-03-25 19:42:47,461 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-StateMachineUpdater: set stopIndex = 0
2024-03-25 19:42:47,461 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: new RaftServerImpl for group-67F90E925935:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052] with ContainerStateMachine:uninitialized
2024-03-25 19:42:47,461 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:42:47,462 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-25 19:42:47,462 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-25 19:42:47,462 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-25 19:42:47,462 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:42:47,462 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-25 19:42:47,462 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:42:47,460 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:42:47,459 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 4 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:42:47,459 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: addNew group-67F90E925935:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052] returns group-67F90E925935:java.util.concurrent.CompletableFuture@1a4c2542[Not completed]
2024-03-25 19:42:47,462 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935: ConfigurationManager, init=-1: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-25 19:42:47,461 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-E84DD4D606BD: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/8a6654ba-868c-467c-ac57-e84dd4d606bd/sm/snapshot.1_0
2024-03-25 19:42:47,463 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-25 19:42:47,463 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-25 19:42:47,463 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-25 19:42:47,463 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-25 19:42:47,462 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 7 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:42:47,464 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-E84DD4D606BD: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/8a6654ba-868c-467c-ac57-e84dd4d606bd/sm/snapshot.1_0 took: 3 ms
2024-03-25 19:42:47,462 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 6 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:42:47,464 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-StateMachineUpdater: Took a snapshot at index 0
2024-03-25 19:42:47,463 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-25 19:42:47,464 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-25 19:42:47,464 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-25 19:42:47,465 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD: applyIndex: 0
2024-03-25 19:42:47,465 [a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-25 19:42:47,468 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:42:47,468 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:42:47,468 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-25 19:42:47,468 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-25 19:42:47,469 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-25 19:42:47,469 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-25 19:42:47,469 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-25 19:42:47,469 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-25 19:42:47,469 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis] (custom)
2024-03-25 19:42:47,469 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/b272cc68-1415-4b0a-8697-67f90e925935 does not exist. Creating ...
2024-03-25 19:42:47,470 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/b272cc68-1415-4b0a-8697-67f90e925935/in_use.lock acquired by nodename 19166@fv-az1540-867
2024-03-25 19:42:47,471 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/b272cc68-1415-4b0a-8697-67f90e925935 has been successfully formatted.
2024-03-25 19:42:47,472 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/b272cc68-1415-4b0a-8697-67f90e925935/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/b272cc68-1415-4b0a-8697-67f90e925935/current/raft-meta.conf
2024-03-25 19:42:47,472 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-67F90E925935: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-25 19:42:47,472 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-25 19:42:47,472 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-25 19:42:47,473 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:47,473 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-25 19:42:47,473 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-25 19:42:47,473 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=b272cc68-1415-4b0a-8697-67f90e925935. Trying to get from SCM.
2024-03-25 19:42:47,482 [IPC Server handler 24 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-03-25 19:42:47,487 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 5 millisec, a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:42:47,488 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 6 millisec, a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:42:47,488 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:47,489 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-25 19:42:47,489 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-25 19:42:47,489 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:47,494 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(86)) - Adding new pipeline Pipeline[ Id: b272cc68-1415-4b0a-8697-67f90e925935, Nodes: f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27)6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27)8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-25T19:42:45.444Z[Etc/UTC]] to Recon pipeline metadata.
2024-03-25 19:42:47,495 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 reported by f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:47,501 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-cacheEviction-AwaitToRun,5,main] started
2024-03-25 19:42:47,501 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/b272cc68-1415-4b0a-8697-67f90e925935
2024-03-25 19:42:47,502 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-25 19:42:47,502 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-25 19:42:47,502 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:47,502 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-25 19:42:47,502 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-25 19:42:47,502 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-25 19:42:47,502 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-25 19:42:47,502 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-25 19:42:47,502 [a6fb26e7-f548-473f-8cf0-48fafe70504d-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to ENTERING_MAINTENANCE, scaling executor pool size to 20
2024-03-25 19:42:47,503 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-25 19:42:47,505 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:47,505 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-25 19:42:47,505 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-25 19:42:47,505 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-25 19:42:47,505 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:47,505 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:47,509 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935: start as a follower, conf=-1: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:42:47,509 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-25 19:42:47,510 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: start f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-FollowerState
2024-03-25 19:42:47,513 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-67F90E925935,id=f8c0ec26-9898-49d2-a0ea-132d14d0dc83
2024-03-25 19:42:47,513 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:42:47,514 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-25 19:42:47,514 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:42:47,514 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-25 19:42:47,514 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-25 19:42:47,514 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-25 19:42:47,514 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-25 19:42:47,515 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=b272cc68-1415-4b0a-8697-67f90e925935
2024-03-25 19:42:47,527 [grpc-default-executor-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: addNew group-67F90E925935:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052] returns group-67F90E925935:java.util.concurrent.CompletableFuture@674fa6bb[Not completed]
2024-03-25 19:42:47,528 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: new RaftServerImpl for group-67F90E925935:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052] with ContainerStateMachine:uninitialized
2024-03-25 19:42:47,528 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:42:47,529 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-25 19:42:47,529 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-25 19:42:47,529 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-25 19:42:47,529 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:42:47,529 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-25 19:42:47,529 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:42:47,529 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935: ConfigurationManager, init=-1: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-25 19:42:47,529 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-25 19:42:47,529 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-25 19:42:47,529 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-25 19:42:47,530 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-25 19:42:47,530 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-25 19:42:47,530 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-25 19:42:47,532 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:42:47,532 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:42:47,533 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-25 19:42:47,533 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-25 19:42:47,533 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-25 19:42:47,533 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-25 19:42:47,533 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-25 19:42:47,534 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-25 19:42:47,534 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis] (custom)
2024-03-25 19:42:47,534 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/b272cc68-1415-4b0a-8697-67f90e925935 does not exist. Creating ...
2024-03-25 19:42:47,535 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/b272cc68-1415-4b0a-8697-67f90e925935/in_use.lock acquired by nodename 19166@fv-az1540-867
2024-03-25 19:42:47,536 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/b272cc68-1415-4b0a-8697-67f90e925935 has been successfully formatted.
2024-03-25 19:42:47,537 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/b272cc68-1415-4b0a-8697-67f90e925935/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/b272cc68-1415-4b0a-8697-67f90e925935/current/raft-meta.conf
2024-03-25 19:42:47,537 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-67F90E925935: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-25 19:42:47,537 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-25 19:42:47,539 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 reported by 6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:47,539 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-25 19:42:47,539 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:47,539 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-25 19:42:47,540 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-25 19:42:47,542 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:47,542 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-25 19:42:47,542 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-25 19:42:47,542 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:47,545 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-cacheEviction-AwaitToRun,5,main] started
2024-03-25 19:42:47,545 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/b272cc68-1415-4b0a-8697-67f90e925935
2024-03-25 19:42:47,546 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-25 19:42:47,546 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-25 19:42:47,546 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:47,546 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-25 19:42:47,546 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-25 19:42:47,546 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-25 19:42:47,546 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-25 19:42:47,546 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-25 19:42:47,547 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-25 19:42:47,548 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:47,548 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-25 19:42:47,548 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-25 19:42:47,548 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-25 19:42:47,548 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:47,548 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:47,557 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935: start as a follower, conf=-1: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:42:47,558 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-25 19:42:47,558 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: start 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-FollowerState
2024-03-25 19:42:47,565 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:42:47,566 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-67F90E925935,id=6e65d581-b1bc-41f2-b39b-16d8508d6618
2024-03-25 19:42:47,566 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:42:47,569 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-25 19:42:47,569 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-25 19:42:47,570 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-25 19:42:47,570 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-25 19:42:47,570 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-25 19:42:47,611 [grpc-default-executor-1] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: addNew group-67F90E925935:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052] returns group-67F90E925935:java.util.concurrent.CompletableFuture@2d2a7ca9[Not completed]
2024-03-25 19:42:47,612 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: new RaftServerImpl for group-67F90E925935:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052] with ContainerStateMachine:uninitialized
2024-03-25 19:42:47,612 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:42:47,612 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-25 19:42:47,612 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-25 19:42:47,612 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-25 19:42:47,612 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:42:47,612 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-25 19:42:47,612 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:42:47,613 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935: ConfigurationManager, init=-1: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-25 19:42:47,613 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-25 19:42:47,613 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-25 19:42:47,613 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-25 19:42:47,613 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-25 19:42:47,613 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-25 19:42:47,613 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-25 19:42:47,615 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:42:47,615 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:42:47,615 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-25 19:42:47,615 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-25 19:42:47,615 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-25 19:42:47,616 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-25 19:42:47,616 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-25 19:42:47,616 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-25 19:42:47,616 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis] (custom)
2024-03-25 19:42:47,616 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/b272cc68-1415-4b0a-8697-67f90e925935 does not exist. Creating ...
2024-03-25 19:42:47,618 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/b272cc68-1415-4b0a-8697-67f90e925935/in_use.lock acquired by nodename 19166@fv-az1540-867
2024-03-25 19:42:47,619 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/b272cc68-1415-4b0a-8697-67f90e925935 has been successfully formatted.
2024-03-25 19:42:47,619 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/b272cc68-1415-4b0a-8697-67f90e925935/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/b272cc68-1415-4b0a-8697-67f90e925935/current/raft-meta.conf
2024-03-25 19:42:47,620 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-67F90E925935: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-25 19:42:47,620 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-25 19:42:47,620 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-25 19:42:47,620 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:47,620 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-25 19:42:47,620 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-25 19:42:47,621 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 reported by 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:47,623 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:47,623 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-25 19:42:47,624 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-25 19:42:47,624 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:47,625 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-cacheEviction-AwaitToRun,5,main] started
2024-03-25 19:42:47,625 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/b272cc68-1415-4b0a-8697-67f90e925935
2024-03-25 19:42:47,626 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-25 19:42:47,626 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-25 19:42:47,626 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:47,626 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-25 19:42:47,626 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-25 19:42:47,626 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-25 19:42:47,626 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-25 19:42:47,626 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-25 19:42:47,627 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-25 19:42:47,628 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:47,628 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-25 19:42:47,628 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-25 19:42:47,628 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-25 19:42:47,629 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:47,629 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:47,629 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935: start as a follower, conf=-1: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:42:47,629 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-25 19:42:47,629 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: start 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-FollowerState
2024-03-25 19:42:47,637 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:42:47,638 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:42:47,637 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-67F90E925935,id=8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:42:47,638 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-25 19:42:47,638 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-25 19:42:47,638 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-25 19:42:47,639 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-25 19:42:47,639 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-25 19:42:47,659 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=b272cc68-1415-4b0a-8697-67f90e925935.
2024-03-25 19:42:47,716 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:47,730 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 15 milliseconds for processing 1 containers.
2024-03-25 19:42:47,731 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:47,731 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:47,731 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:47,731 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	TOTAL_KEYS -> 1 , CONTAINER_COUNT -> 1 , TOTAL_USED_BYTES -> 7 , 
2024-03-25 19:42:47,731 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:47,731 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:47,731 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:47,873 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:42:47,873 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:42:47,873 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:42:47,875 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:42:47,875 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:42:48,187 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD-SegmentedRaftLogWorker close()
2024-03-25 19:42:48,189 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-E84DD4D606BD: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/8a6654ba-868c-467c-ac57-e84dd4d606bd
2024-03-25 19:42:48,190 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=8a6654ba-868c-467c-ac57-e84dd4d606bd
org.apache.ratis.protocol.exceptions.GroupMismatchException: a568c6b4-1a28-494a-b080-2324592b3a72: group-E84DD4D606BD not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-25 19:42:48,388 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:42:48,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@2133796f. There are 1 pipelines
2024-03-25 19:42:48,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-25 19:42:48,473 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 reported by f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:48,538 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 reported by 6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:48,734 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 3 milliseconds to process 1 existing database records.
2024-03-25 19:42:48,736 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:42:48,736 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:48,736 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:48,736 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:48,736 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:48,736 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:48,736 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:48,736 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:48,876 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:42:48,877 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:42:48,877 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:42:48,879 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:42:48,879 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:42:49,377 [UnderReplicatedProcessor] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:chooseNodeInternal(669)) - No available node in (scope="/" excludedScope="[/default-rack/f8c0ec26-9898-49d2-a0ea-132d14d0dc83, /default-rack/a6fb26e7-f548-473f-8cf0-48fafe70504d, /default-rack/a568c6b4-1a28-494a-b080-2324592b3a72]" excludedNodes="[f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27), a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27)]"  ancestorGen="1").
2024-03-25 19:42:49,377 [UnderReplicatedProcessor] WARN  algorithms.SCMContainerPlacementRackAware (SCMContainerPlacementRackAware.java:chooseNode(485)) - Failed to find the datanode for container. excludedNodes:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27), a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27)], affinityNode:
2024-03-25 19:42:49,379 [UnderReplicatedProcessor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [replicateContainerCommand: containerId=1, replicaIndex=0, targetNode=8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27), priority=NORMAL] for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-03-25T19:42:41.453Z, pipelineID=PipelineID=37d82d77-2193-41cd-938d-dc6410947516, owner=omServiceIdDefault} to f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27) with datanode deadline 1711396339379 and scm deadline 1711396369379
2024-03-25 19:42:49,380 [UnderReplicatedProcessor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(138)) - Processed 1 containers with health state counts {UNDER_REPLICATED=1}, failed processing 0, deferred due to load 0
2024-03-25 19:42:49,389 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:42:49,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@2133796f. There are 1 pipelines
2024-03-25 19:42:49,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-25 19:42:49,473 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 reported by f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:49,621 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 reported by 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:49,738 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 1 existing database records.
2024-03-25 19:42:49,740 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:42:49,740 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:49,740 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:49,740 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:49,740 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:49,740 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:49,740 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:49,740 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:49,881 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:42:49,881 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:42:49,881 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:42:49,883 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:42:49,883 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:42:50,389 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:42:50,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@2133796f. There are 1 pipelines
2024-03-25 19:42:50,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-25 19:42:50,473 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 reported by f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:50,477 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-ContainerReplicationThread-0] INFO  replication.PushReplicator (PushReplicator.java:replicate(58)) - Starting replication of container 1 to 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27) using NO_COMPRESSION
2024-03-25 19:42:50,498 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-ContainerReplicationThread-0] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(116)) - Sent 16384 bytes for container 1
2024-03-25 19:42:50,503 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-ReplicationContainerReader-1] INFO  replication.SendContainerRequestHandler (SendContainerRequestHandler.java:onNext(96)) - Accepting container 1
2024-03-25 19:42:50,503 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-ReplicationContainerReader-1] INFO  replication.SendContainerRequestHandler (SendContainerRequestHandler.java:onCompleted(131)) - Container 1 is downloaded with size 16384, starting to import.
2024-03-25 19:42:50,540 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 reported by 6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:50,544 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-ReplicationContainerReader-1] INFO  replication.SendContainerRequestHandler (SendContainerRequestHandler.java:onCompleted(137)) - Container 1 is replicated successfully
2024-03-25 19:42:50,547 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27), {type: ICR, size: 1}
2024-03-25 19:42:50,553 [grpc-default-executor-1] INFO  replication.GrpcContainerUploader (GrpcContainerUploader.java:onCompleted(132)) - Finished uploading container 1 to 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:50,553 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(369)) - Successful DONE replicateContainerCommand: containerId=1, replicaIndex=0, targetNode=8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27), priority=NORMAL, transferred 16384 bytes
2024-03-25 19:42:50,741 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:processExistingDBRecords(299)) - DELETED existing unhealthy container record...for Container: 1
2024-03-25 19:42:50,751 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 11 milliseconds to process 1 existing database records.
2024-03-25 19:42:50,753 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:42:50,753 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:50,753 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:50,753 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:50,753 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:50,753 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:50,753 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:50,753 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:50,885 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:42:50,885 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:42:50,885 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:42:50,887 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:42:50,887 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:42:51,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:42:51,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@2133796f. There are 1 pipelines
2024-03-25 19:42:51,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-25 19:42:51,472 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 reported by f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:51,539 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 reported by 6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:51,545 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 reported by 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:51,754 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:51,756 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 3 milliseconds for processing 1 containers.
2024-03-25 19:42:51,756 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:51,757 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:51,757 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:51,757 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:51,757 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:51,757 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:51,757 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:51,889 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:42:51,890 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:42:51,890 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:42:51,892 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:42:51,892 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:42:52,390 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:42:52,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@2133796f. There are 1 pipelines
2024-03-25 19:42:52,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-25 19:42:52,473 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 reported by f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:52,567 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5057390030ns, electionTimeout:5053ms
2024-03-25 19:42:52,567 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: shutdown f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-FollowerState
2024-03-25 19:42:52,567 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-25 19:42:52,568 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-25 19:42:52,568 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: start f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-LeaderElection9
2024-03-25 19:42:52,570 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-LeaderElection9 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:42:52,570 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-LeaderElection9-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043
2024-03-25 19:42:52,570 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-LeaderElection9-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052
2024-03-25 19:42:52,570 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:42:52,571 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:42:52,580 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935: receive requestVote(PRE_VOTE, f8c0ec26-9898-49d2-a0ea-132d14d0dc83, group-67F90E925935, 0, (t:0, i:0))
2024-03-25 19:42:52,580 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-FOLLOWER: reject PRE_VOTE from f8c0ec26-9898-49d2-a0ea-132d14d0dc83: our priority 1 > candidate's priority 0
2024-03-25 19:42:52,581 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935 replies to PRE_VOTE vote request: f8c0ec26-9898-49d2-a0ea-132d14d0dc83<-8de788e1-2c95-4c74-b4ac-29ea2448e86a#0:FAIL-t0. Peer's state: 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935:t0, leader=null, voted=, raftlog=Memoized:8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:42:52,581 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935: receive requestVote(PRE_VOTE, f8c0ec26-9898-49d2-a0ea-132d14d0dc83, group-67F90E925935, 0, (t:0, i:0))
2024-03-25 19:42:52,581 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-FOLLOWER: accept PRE_VOTE from f8c0ec26-9898-49d2-a0ea-132d14d0dc83: our priority 0 <= candidate's priority 0
2024-03-25 19:42:52,581 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935 replies to PRE_VOTE vote request: f8c0ec26-9898-49d2-a0ea-132d14d0dc83<-6e65d581-b1bc-41f2-b39b-16d8508d6618#0:OK-t0. Peer's state: 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935:t0, leader=null, voted=, raftlog=Memoized:6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:42:52,584 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-LeaderElection9: PRE_VOTE REJECTED received 2 response(s) and 0 exception(s):
2024-03-25 19:42:52,584 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: f8c0ec26-9898-49d2-a0ea-132d14d0dc83<-6e65d581-b1bc-41f2-b39b-16d8508d6618#0:OK-t0
2024-03-25 19:42:52,584 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 1: f8c0ec26-9898-49d2-a0ea-132d14d0dc83<-8de788e1-2c95-4c74-b4ac-29ea2448e86a#0:FAIL-t0
2024-03-25 19:42:52,584 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-LeaderElection9 PRE_VOTE round 0: result REJECTED
2024-03-25 19:42:52,584 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-LeaderElection9] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2024-03-25 19:42:52,585 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: shutdown f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-LeaderElection9
2024-03-25 19:42:52,585 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: start f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-FollowerState
2024-03-25 19:42:52,585 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-LeaderElection9] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935: set firstElectionSinceStartup to false for REJECTED
2024-03-25 19:42:52,670 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5040376553ns, electionTimeout:5031ms
2024-03-25 19:42:52,670 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: shutdown 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-FollowerState
2024-03-25 19:42:52,670 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-25 19:42:52,671 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-25 19:42:52,671 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: start 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10
2024-03-25 19:42:52,672 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:42:52,672 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034
2024-03-25 19:42:52,672 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043
2024-03-25 19:42:52,672 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:42:52,673 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:42:52,680 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935: receive requestVote(PRE_VOTE, 8de788e1-2c95-4c74-b4ac-29ea2448e86a, group-67F90E925935, 0, (t:0, i:0))
2024-03-25 19:42:52,680 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935: receive requestVote(PRE_VOTE, 8de788e1-2c95-4c74-b4ac-29ea2448e86a, group-67F90E925935, 0, (t:0, i:0))
2024-03-25 19:42:52,681 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-FOLLOWER: accept PRE_VOTE from 8de788e1-2c95-4c74-b4ac-29ea2448e86a: our priority 0 <= candidate's priority 1
2024-03-25 19:42:52,681 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935 replies to PRE_VOTE vote request: 8de788e1-2c95-4c74-b4ac-29ea2448e86a<-f8c0ec26-9898-49d2-a0ea-132d14d0dc83#0:OK-t0. Peer's state: f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935:t0, leader=null, voted=, raftlog=Memoized:f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:42:52,680 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-FOLLOWER: accept PRE_VOTE from 8de788e1-2c95-4c74-b4ac-29ea2448e86a: our priority 0 <= candidate's priority 1
2024-03-25 19:42:52,681 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935 replies to PRE_VOTE vote request: 8de788e1-2c95-4c74-b4ac-29ea2448e86a<-6e65d581-b1bc-41f2-b39b-16d8508d6618#0:OK-t0. Peer's state: 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935:t0, leader=null, voted=, raftlog=Memoized:6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:42:52,683 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2024-03-25 19:42:52,683 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 8de788e1-2c95-4c74-b4ac-29ea2448e86a<-6e65d581-b1bc-41f2-b39b-16d8508d6618#0:OK-t0
2024-03-25 19:42:52,686 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10 PRE_VOTE round 0: result PASSED
2024-03-25 19:42:52,687 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10 ELECTION round 0: submit vote requests at term 1 for -1: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:42:52,687 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:42:52,687 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:42:52,689 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935: receive requestVote(ELECTION, 8de788e1-2c95-4c74-b4ac-29ea2448e86a, group-67F90E925935, 1, (t:0, i:0))
2024-03-25 19:42:52,689 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-FOLLOWER: accept ELECTION from 8de788e1-2c95-4c74-b4ac-29ea2448e86a: our priority 0 <= candidate's priority 1
2024-03-25 19:42:52,689 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:42:52,689 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: shutdown f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-FollowerState
2024-03-25 19:42:52,689 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-FollowerState was interrupted
2024-03-25 19:42:52,690 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: start f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-FollowerState
2024-03-25 19:42:52,690 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935: receive requestVote(ELECTION, 8de788e1-2c95-4c74-b4ac-29ea2448e86a, group-67F90E925935, 1, (t:0, i:0))
2024-03-25 19:42:52,694 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-FOLLOWER: accept ELECTION from 8de788e1-2c95-4c74-b4ac-29ea2448e86a: our priority 0 <= candidate's priority 1
2024-03-25 19:42:52,694 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:42:52,694 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: shutdown 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-FollowerState
2024-03-25 19:42:52,695 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: start 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-FollowerState
2024-03-25 19:42:52,695 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-FollowerState was interrupted
2024-03-25 19:42:52,695 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935: set firstElectionSinceStartup to false for candidate:8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:42:52,696 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935 replies to ELECTION vote request: 8de788e1-2c95-4c74-b4ac-29ea2448e86a<-f8c0ec26-9898-49d2-a0ea-132d14d0dc83#0:OK-t1. Peer's state: f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935:t1, leader=null, voted=8de788e1-2c95-4c74-b4ac-29ea2448e86a, raftlog=Memoized:f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:42:52,697 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935 replies to ELECTION vote request: 8de788e1-2c95-4c74-b4ac-29ea2448e86a<-6e65d581-b1bc-41f2-b39b-16d8508d6618#0:OK-t1. Peer's state: 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935:t1, leader=null, voted=8de788e1-2c95-4c74-b4ac-29ea2448e86a, raftlog=Memoized:6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:42:52,697 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10: ELECTION PASSED received 1 response(s) and 0 exception(s):
2024-03-25 19:42:52,697 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 8de788e1-2c95-4c74-b4ac-29ea2448e86a<-f8c0ec26-9898-49d2-a0ea-132d14d0dc83#0:OK-t1
2024-03-25 19:42:52,697 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10 ELECTION round 0: result PASSED
2024-03-25 19:42:52,698 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: shutdown 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10
2024-03-25 19:42:52,698 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-25 19:42:52,698 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-03-25 19:42:52,699 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-25 19:42:52,699 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-03-25 19:42:52,699 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-03-25 19:42:52,699 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-03-25 19:42:52,699 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-03-25 19:42:52,700 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-03-25 19:42:52,700 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-25 19:42:52,700 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:42:52,700 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-25 19:42:52,700 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-25 19:42:52,700 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-03-25 19:42:52,700 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:52,701 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2024-03-25 19:42:52,701 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0s (custom)
2024-03-25 19:42:52,703 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-03-25 19:42:52,703 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:42:52,703 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-03-25 19:42:52,704 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-03-25 19:42:52,704 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-03-25 19:42:52,704 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:42:52,704 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-25 19:42:52,705 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-03-25 19:42:52,705 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:52,705 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2024-03-25 19:42:52,705 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0s (custom)
2024-03-25 19:42:52,705 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-03-25 19:42:52,706 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:42:52,706 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-03-25 19:42:52,706 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-03-25 19:42:52,706 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-03-25 19:42:52,706 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:42:52,706 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-25 19:42:52,706 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: start 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderStateImpl
2024-03-25 19:42:52,706 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935: set firstElectionSinceStartup to false for becomeLeader
2024-03-25 19:42:52,707 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-67F90E925935 with new leaderId: 8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:42:52,707 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935: change Leader from null to 8de788e1-2c95-4c74-b4ac-29ea2448e86a at term 1 for becomeLeader, leader elected after 5093ms
2024-03-25 19:42:52,707 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-25 19:42:52,707 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-25 19:42:52,709 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 reported by 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:52,711 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderElection10] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935: set configuration 0: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:42:52,724 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=b272cc68-1415-4b0a-8697-67f90e925935
2024-03-25 19:42:52,725 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/b272cc68-1415-4b0a-8697-67f90e925935/current/log_inprogress_0
2024-03-25 19:42:52,728 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-67F90E925935 with new leaderId: 8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:42:52,730 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935: change Leader from null to 8de788e1-2c95-4c74-b4ac-29ea2448e86a at term 1 for appendEntries, leader elected after 5265ms
2024-03-25 19:42:52,735 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935: set configuration 0: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:42:52,736 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-25 19:42:52,738 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-25 19:42:52,738 [6e65d581-b1bc-41f2-b39b-16d8508d6618-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-67F90E925935 with new leaderId: 8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:42:52,739 [6e65d581-b1bc-41f2-b39b-16d8508d6618-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935: change Leader from null to 8de788e1-2c95-4c74-b4ac-29ea2448e86a at term 1 for appendEntries, leader elected after 5209ms
2024-03-25 19:42:52,745 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/b272cc68-1415-4b0a-8697-67f90e925935/current/log_inprogress_0
2024-03-25 19:42:52,746 [6e65d581-b1bc-41f2-b39b-16d8508d6618-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935: set configuration 0: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:42:52,746 [6e65d581-b1bc-41f2-b39b-16d8508d6618-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-25 19:42:52,747 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-25 19:42:52,749 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-25 19:42:52,754 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/b272cc68-1415-4b0a-8697-67f90e925935/current/log_inprogress_0
2024-03-25 19:42:52,758 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:52,760 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:42:52,760 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:52,760 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:52,760 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:52,760 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:52,760 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:52,760 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:52,760 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:52,893 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:42:52,893 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:42:52,894 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:42:52,895 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:42:52,895 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:42:53,278 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=eac5a041-cf38-4b57-9357-0ff75a016342 since it stays at CLOSED stage.
2024-03-25 19:42:53,278 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=eac5a041-cf38-4b57-9357-0ff75a016342 close command to datanode a6fb26e7-f548-473f-8cf0-48fafe70504d
2024-03-25 19:42:53,279 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: eac5a041-cf38-4b57-9357-0ff75a016342, Nodes: a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:a6fb26e7-f548-473f-8cf0-48fafe70504d, CreationTimestamp2024-03-25T19:42:26.234Z[Etc/UTC]] removed.
2024-03-25 19:42:53,391 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:42:53,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(472)) - org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@2133796f has 1 sufficientlyReplicated, 0 deleting, 0 underReplicated and 0 unclosed containers
2024-03-25 19:42:53,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:putIntoMaintenance(529)) - Datanode a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27) has entered maintenance
2024-03-25 19:42:53,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-25 19:42:53,441 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27) moved to HEALTHY state.
2024-03-25 19:42:53,441 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-25 19:42:53,483 [IPC Server handler 5 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2024-03-25 19:42:53,484 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=eac5a041-cf38-4b57-9357-0ff75a016342 is not found
2024-03-25 19:42:53,558 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d, f8c0ec26-9898-49d2-a0ea-132d14d0dc83]
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-03-25 19:42:53,579 [IPC Server handler 15 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:recommission(401)) - Queued node a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27) for recommission
2024-03-25 19:42:53,579 [IPC Server handler 15 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:recommission(401)) - Queued node a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27) for recommission
2024-03-25 19:42:53,761 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-25 19:42:53,763 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:42:53,763 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:53,763 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:53,763 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:53,763 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:53,763 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:53,763 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:53,764 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:53,897 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:42:53,897 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:42:53,897 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:42:53,899 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:42:53,899 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:42:54,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:42:54,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:processCancelledNodes(292)) - Recommissioned node org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@56eb96a8
2024-03-25 19:42:54,441 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27) moved to HEALTHY state.
2024-03-25 19:42:54,441 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-25 19:42:54,441 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27) moved to HEALTHY state.
2024-03-25 19:42:54,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:processCancelledNodes(292)) - Recommissioned node org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@2133796f
2024-03-25 19:42:54,441 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-25 19:42:54,441 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=9fcebae3-2819-4af1-b2d2-739850c3a563 to datanode:a568c6b4-1a28-494a-b080-2324592b3a72
2024-03-25 19:42:54,442 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 9fcebae3-2819-4af1-b2d2-739850c3a563, Nodes: a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-25T19:42:54.441Z[Etc/UTC]]
2024-03-25 19:42:54,443 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=f8263715-53d5-4884-b6a7-837c047ac986 to datanode:a6fb26e7-f548-473f-8cf0-48fafe70504d
2024-03-25 19:42:54,444 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: f8263715-53d5-4884-b6a7-837c047ac986, Nodes: a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-25T19:42:54.443Z[Etc/UTC]]
2024-03-25 19:42:54,453 [IPC Server handler 12 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27) as the reported value (IN_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-03-25 19:42:54,454 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:42:54,483 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: remove    LEADER a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342:t1, leader=a6fb26e7-f548-473f-8cf0-48fafe70504d, voted=a6fb26e7-f548-473f-8cf0-48fafe70504d, raftlog=Memoized:a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-SegmentedRaftLog:OPENED:c0, conf=0: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null RUNNING
2024-03-25 19:42:54,483 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342: shutdown
2024-03-25 19:42:54,483 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-0FF75A016342,id=a6fb26e7-f548-473f-8cf0-48fafe70504d
2024-03-25 19:42:54,483 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: shutdown a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-LeaderStateImpl
2024-03-25 19:42:54,483 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-PendingRequests: sendNotLeaderResponses
2024-03-25 19:42:54,484 [a6fb26e7-f548-473f-8cf0-48fafe70504d-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_MAINTENANCE, scaling executor pool size to 20
2024-03-25 19:42:54,484 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-StateMachineUpdater: set stopIndex = 0
2024-03-25 19:42:54,484 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-0FF75A016342: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/eac5a041-cf38-4b57-9357-0ff75a016342/sm/snapshot.1_0
2024-03-25 19:42:54,484 [IPC Server handler 6 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-03-25 19:42:54,484 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:42:54,484 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-0FF75A016342: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/eac5a041-cf38-4b57-9357-0ff75a016342/sm/snapshot.1_0 took: 1 ms
2024-03-25 19:42:54,485 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:42:54,485 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-StateMachineUpdater: Took a snapshot at index 0
2024-03-25 19:42:54,485 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-25 19:42:54,485 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=eac5a041-cf38-4b57-9357-0ff75a016342 is not found
2024-03-25 19:42:54,485 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342: applyIndex: 0
2024-03-25 19:42:54,485 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-25 19:42:54,500 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342-SegmentedRaftLogWorker close()
2024-03-25 19:42:54,502 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-0FF75A016342: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/eac5a041-cf38-4b57-9357-0ff75a016342
2024-03-25 19:42:54,502 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=eac5a041-cf38-4b57-9357-0ff75a016342
org.apache.ratis.protocol.exceptions.GroupMismatchException: a6fb26e7-f548-473f-8cf0-48fafe70504d: group-0FF75A016342 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-03-25 19:42:54,622 [IPC Server handler 9 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startDecommission(357)) - Starting Decommission for node f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:54,622 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27) moved to HEALTHY state.
2024-03-25 19:42:54,622 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-03-25 19:42:54,764 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:54,766 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:42:54,767 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:54,767 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:54,767 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:54,767 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:54,767 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:54,767 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:54,767 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:54,901 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:42:54,901 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:42:54,901 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:42:54,902 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:42:54,903 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:42:55,392 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:42:55,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d4626a5a. There are 2 pipelines
2024-03-25 19:42:55,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-25 19:42:55,441 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(55)) - Admin start on datanode f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27). Finalizing its pipelines [PipelineID=669638b9-7e75-42f1-82a9-b01fec71537c, PipelineID=b272cc68-1415-4b0a-8697-67f90e925935]
2024-03-25 19:42:55,442 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=669638b9-7e75-42f1-82a9-b01fec71537c moved to CLOSED state
2024-03-25 19:42:55,442 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 moved to CLOSED state
2024-03-25 19:42:55,452 [IPC Server handler 20 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27) as the reported value (IN_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-03-25 19:42:55,473 [IPC Server handler 10 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (DECOMMISSIONING, 0)
2024-03-25 19:42:55,482 [IPC Server handler 26 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27) as the reported value (IN_MAINTENANCE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-03-25 19:42:55,482 [IPC Server handler 5 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27) as the reported value (IN_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-03-25 19:42:55,768 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:55,770 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:42:55,770 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:55,770 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:55,770 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:55,770 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:55,770 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:55,770 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:55,770 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:55,904 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:42:55,904 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:42:55,904 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:42:55,906 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:42:55,906 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:42:56,393 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:42:56,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d4626a5a. There are 2 pipelines
2024-03-25 19:42:56,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-25 19:42:56,452 [IPC Server handler 20 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27) as the reported value (IN_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-03-25 19:42:56,453 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - a568c6b4-1a28-494a-b080-2324592b3a72: addNew group-739850C3A563:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016] returns group-739850C3A563:java.util.concurrent.CompletableFuture@64ef0c87[Not completed]
2024-03-25 19:42:56,454 [a568c6b4-1a28-494a-b080-2324592b3a72-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-03-25 19:42:56,454 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - a568c6b4-1a28-494a-b080-2324592b3a72: new RaftServerImpl for group-739850C3A563:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016] with ContainerStateMachine:uninitialized
2024-03-25 19:42:56,455 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:42:56,455 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-25 19:42:56,455 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-25 19:42:56,455 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-25 19:42:56,455 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:42:56,455 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-25 19:42:56,455 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:42:56,455 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563: ConfigurationManager, init=-1: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-25 19:42:56,455 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-25 19:42:56,455 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-25 19:42:56,455 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-25 19:42:56,456 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-25 19:42:56,456 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-25 19:42:56,456 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-25 19:42:56,458 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:42:56,458 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:42:56,458 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-25 19:42:56,458 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-25 19:42:56,458 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-25 19:42:56,458 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 5 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:42:56,458 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-25 19:42:56,458 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 6 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:42:56,459 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-25 19:42:56,459 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-25 19:42:56,459 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis] (custom)
2024-03-25 19:42:56,459 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/9fcebae3-2819-4af1-b2d2-739850c3a563 does not exist. Creating ...
2024-03-25 19:42:56,461 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/9fcebae3-2819-4af1-b2d2-739850c3a563/in_use.lock acquired by nodename 19166@fv-az1540-867
2024-03-25 19:42:56,462 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/9fcebae3-2819-4af1-b2d2-739850c3a563 has been successfully formatted.
2024-03-25 19:42:56,463 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/9fcebae3-2819-4af1-b2d2-739850c3a563/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/9fcebae3-2819-4af1-b2d2-739850c3a563/current/raft-meta.conf
2024-03-25 19:42:56,463 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-739850C3A563: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-25 19:42:56,463 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-25 19:42:56,463 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-25 19:42:56,463 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:56,464 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-25 19:42:56,464 [IPC Server handler 22 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2024-03-25 19:42:56,464 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=9fcebae3-2819-4af1-b2d2-739850c3a563. Trying to get from SCM.
2024-03-25 19:42:56,464 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-25 19:42:56,465 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(86)) - Adding new pipeline Pipeline[ Id: 9fcebae3-2819-4af1-b2d2-739850c3a563, Nodes: a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-25T19:42:54.441Z[Etc/UTC]] to Recon pipeline metadata.
2024-03-25 19:42:56,465 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=9fcebae3-2819-4af1-b2d2-739850c3a563
2024-03-25 19:42:56,466 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/ONE PipelineID=9fcebae3-2819-4af1-b2d2-739850c3a563 reported by a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27)
2024-03-25 19:42:56,466 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:56,467 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-25 19:42:56,467 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-25 19:42:56,467 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:56,467 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-cacheEviction-AwaitToRun,5,main] started
2024-03-25 19:42:56,467 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/9fcebae3-2819-4af1-b2d2-739850c3a563
2024-03-25 19:42:56,467 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-25 19:42:56,467 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-25 19:42:56,467 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:56,467 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-25 19:42:56,468 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-25 19:42:56,468 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-25 19:42:56,468 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-25 19:42:56,468 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-25 19:42:56,468 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-25 19:42:56,470 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:56,470 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-25 19:42:56,470 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-25 19:42:56,470 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-25 19:42:56,470 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:56,470 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:56,471 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563: start as a follower, conf=-1: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016]|listeners:[], old=null
2024-03-25 19:42:56,471 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-25 19:42:56,471 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a568c6b4-1a28-494a-b080-2324592b3a72: start a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-FollowerState
2024-03-25 19:42:56,472 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:42:56,472 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:42:56,472 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-739850C3A563,id=a568c6b4-1a28-494a-b080-2324592b3a72
2024-03-25 19:42:56,473 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-25 19:42:56,473 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-25 19:42:56,473 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-25 19:42:56,473 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-25 19:42:56,473 [a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-25 19:42:56,474 [IPC Server handler 5 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (DECOMMISSIONING, 0)
2024-03-25 19:42:56,475 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=9fcebae3-2819-4af1-b2d2-739850c3a563
2024-03-25 19:42:56,475 [a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=9fcebae3-2819-4af1-b2d2-739850c3a563.
2024-03-25 19:42:56,482 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: addNew group-837C047AC986:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025] returns group-837C047AC986:java.util.concurrent.CompletableFuture@49e693c7[Not completed]
2024-03-25 19:42:56,483 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: new RaftServerImpl for group-837C047AC986:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025] with ContainerStateMachine:uninitialized
2024-03-25 19:42:56,483 [a6fb26e7-f548-473f-8cf0-48fafe70504d-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-03-25 19:42:56,483 [IPC Server handler 24 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2024-03-25 19:42:56,483 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:42:56,484 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-25 19:42:56,484 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-25 19:42:56,484 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-25 19:42:56,484 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:42:56,484 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-25 19:42:56,484 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:42:56,484 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986: ConfigurationManager, init=-1: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-25 19:42:56,485 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-25 19:42:56,485 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-25 19:42:56,485 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-25 19:42:56,485 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-25 19:42:56,485 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-25 19:42:56,485 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-25 19:42:56,486 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:42:56,486 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:42:56,488 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:42:56,488 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:42:56,488 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-25 19:42:56,488 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-25 19:42:56,488 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-25 19:42:56,488 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-25 19:42:56,488 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-25 19:42:56,488 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-25 19:42:56,488 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis] (custom)
2024-03-25 19:42:56,489 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/f8263715-53d5-4884-b6a7-837c047ac986 does not exist. Creating ...
2024-03-25 19:42:56,489 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/f8263715-53d5-4884-b6a7-837c047ac986/in_use.lock acquired by nodename 19166@fv-az1540-867
2024-03-25 19:42:56,490 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/f8263715-53d5-4884-b6a7-837c047ac986 has been successfully formatted.
2024-03-25 19:42:56,491 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/f8263715-53d5-4884-b6a7-837c047ac986/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/f8263715-53d5-4884-b6a7-837c047ac986/current/raft-meta.conf
2024-03-25 19:42:56,491 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-837C047AC986: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-25 19:42:56,491 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-25 19:42:56,492 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-25 19:42:56,492 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:56,492 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-25 19:42:56,492 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-25 19:42:56,492 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=f8263715-53d5-4884-b6a7-837c047ac986
2024-03-25 19:42:56,492 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=f8263715-53d5-4884-b6a7-837c047ac986. Trying to get from SCM.
2024-03-25 19:42:56,495 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(86)) - Adding new pipeline Pipeline[ Id: f8263715-53d5-4884-b6a7-837c047ac986, Nodes: a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:a6fb26e7-f548-473f-8cf0-48fafe70504d, CreationTimestamp2024-03-25T19:42:54.443Z[Etc/UTC]] to Recon pipeline metadata.
2024-03-25 19:42:56,496 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:56,496 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-25 19:42:56,497 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-25 19:42:56,497 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:56,497 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-cacheEviction-AwaitToRun,5,main] started
2024-03-25 19:42:56,498 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/f8263715-53d5-4884-b6a7-837c047ac986
2024-03-25 19:42:56,498 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-25 19:42:56,498 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-25 19:42:56,498 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:42:56,498 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-25 19:42:56,498 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-25 19:42:56,498 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-25 19:42:56,498 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-25 19:42:56,498 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-25 19:42:56,499 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-25 19:42:56,501 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:42:56,501 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-25 19:42:56,501 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-25 19:42:56,501 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-25 19:42:56,501 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:56,501 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-25 19:42:56,505 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986: start as a follower, conf=-1: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null
2024-03-25 19:42:56,506 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-25 19:42:56,506 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: start a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-FollowerState
2024-03-25 19:42:56,506 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-837C047AC986,id=a6fb26e7-f548-473f-8cf0-48fafe70504d
2024-03-25 19:42:56,506 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-25 19:42:56,506 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-25 19:42:56,506 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-25 19:42:56,506 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-25 19:42:56,506 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-25 19:42:56,508 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=f8263715-53d5-4884-b6a7-837c047ac986
2024-03-25 19:42:56,508 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=f8263715-53d5-4884-b6a7-837c047ac986.
2024-03-25 19:42:56,508 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:42:56,509 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:42:56,771 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-25 19:42:56,775 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 3 milliseconds for processing 1 containers.
2024-03-25 19:42:56,775 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	TOTAL_KEYS -> 1 , CONTAINER_COUNT -> 1 , TOTAL_USED_BYTES -> 7 , 
2024-03-25 19:42:56,775 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:56,775 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:56,775 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:56,775 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:56,777 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:56,777 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:56,908 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:42:56,908 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:42:56,908 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:42:56,910 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:42:56,910 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:42:57,393 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:42:57,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d4626a5a. There are 2 pipelines
2024-03-25 19:42:57,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-25 19:42:57,473 [IPC Server handler 5 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (DECOMMISSIONING, 0)
2024-03-25 19:42:57,475 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to DECOMMISSIONING, scaling executor pool size to 20
2024-03-25 19:42:57,779 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 1 existing database records.
2024-03-25 19:42:57,780 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:42:57,780 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:57,781 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:57,781 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:57,781 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:57,781 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:57,781 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:57,781 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:57,911 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:42:57,912 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:42:57,912 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:42:57,913 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:42:57,913 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:42:58,375 [OverReplicatedProcessor] INFO  replication.RatisOverReplicationHandler (RatisOverReplicationHandler.java:processAndSendCommands(115)) - Container #1 is over replicated. Actual replica count is 4, with 0 pending delete(s). Expected replica count is 3.
2024-03-25 19:42:58,376 [OverReplicatedProcessor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [deleteContainerCommand: containerID: 1, replicaIndex: 0, force: true] for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-03-25T19:42:41.453Z, pipelineID=PipelineID=37d82d77-2193-41cd-938d-dc6410947516, owner=omServiceIdDefault} to f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27) with datanode deadline 1711396348376 and scm deadline 1711396378376
2024-03-25 19:42:58,376 [OverReplicatedProcessor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(138)) - Processed 1 containers with health state counts {OVER_REPLICATED=1}, failed processing 0, deferred due to load 0
2024-03-25 19:42:58,394 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:42:58,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d4626a5a. There are 2 pipelines
2024-03-25 19:42:58,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-25 19:42:58,474 [IPC Server handler 23 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27) as the reported value (DECOMMISSIONING, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-03-25 19:42:58,782 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:processExistingDBRecords(299)) - DELETED existing unhealthy container record...for Container: 1
2024-03-25 19:42:58,783 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 3 milliseconds to process 1 existing database records.
2024-03-25 19:42:58,785 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:42:58,785 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:58,785 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:58,785 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:58,785 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:58,785 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:58,785 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:58,786 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:58,915 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:42:58,915 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:42:58,915 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:42:58,917 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:42:58,917 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:42:59,394 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:42:59,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d4626a5a. There are 2 pipelines
2024-03-25 19:42:59,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-25 19:42:59,476 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-DeleteContainerThread-0] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:markContainerForDelete(424)) - Moving container /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/current/containerDir0/1 to state DELETED from state:CLOSED
2024-03-25 19:42:59,786 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:42:59,789 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:42:59,789 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:59,789 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:59,789 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:42:59,789 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:42:59,789 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:42:59,789 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:42:59,789 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:42:59,919 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:42:59,919 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:42:59,919 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:42:59,920 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:42:59,921 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:00,383 [UnderReplicatedProcessor] INFO  replication.RatisUnderReplicationHandler (RatisUnderReplicationHandler.java:verifyUnderReplication(314)) - The container #1 state changed and it's not under replicated any more.
2024-03-25 19:43:00,383 [UnderReplicatedProcessor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(138)) - Processed 1 containers with health state counts {UNDER_REPLICATED=1}, failed processing 0, deferred due to load 0
2024-03-25 19:43:00,395 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:43:00,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d4626a5a. There are 2 pipelines
2024-03-25 19:43:00,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-03-25 19:43:00,790 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-25 19:43:00,792 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:43:00,792 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:00,793 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:00,793 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:00,793 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:00,793 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:00,793 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:00,793 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:00,922 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:00,922 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:00,922 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:00,924 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:00,924 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:01,279 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=669638b9-7e75-42f1-82a9-b01fec71537c since it stays at CLOSED stage.
2024-03-25 19:43:01,280 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=669638b9-7e75-42f1-82a9-b01fec71537c close command to datanode f8c0ec26-9898-49d2-a0ea-132d14d0dc83
2024-03-25 19:43:01,280 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 669638b9-7e75-42f1-82a9-b01fec71537c, Nodes: f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:f8c0ec26-9898-49d2-a0ea-132d14d0dc83, CreationTimestamp2024-03-25T19:42:26.376Z[Etc/UTC]] removed.
2024-03-25 19:43:01,280 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 since it stays at CLOSED stage.
2024-03-25 19:43:01,280 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 close command to datanode f8c0ec26-9898-49d2-a0ea-132d14d0dc83
2024-03-25 19:43:01,280 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 close command to datanode 6e65d581-b1bc-41f2-b39b-16d8508d6618
2024-03-25 19:43:01,280 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 close command to datanode 8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:43:01,281 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: b272cc68-1415-4b0a-8697-67f90e925935, Nodes: f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27)6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27)8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:8de788e1-2c95-4c74-b4ac-29ea2448e86a, CreationTimestamp2024-03-25T19:42:45.444Z[Etc/UTC]] removed.
2024-03-25 19:43:01,395 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:43:01,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(472)) - org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d4626a5a has 0 sufficientlyReplicated, 0 deleting, 0 underReplicated and 0 unclosed containers
2024-03-25 19:43:01,441 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:completeDecommission(522)) - Datanode f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27) has completed the admin workflow. The operational state has been set to DECOMMISSIONED
2024-03-25 19:43:01,441 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27) moved to HEALTHY state.
2024-03-25 19:43:01,441 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-25 19:43:01,442 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:01,442 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 to datanode:8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:43:01,442 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 to datanode:6e65d581-b1bc-41f2-b39b-16d8508d6618
2024-03-25 19:43:01,443 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 to datanode:a6fb26e7-f548-473f-8cf0-48fafe70504d
2024-03-25 19:43:01,443 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 8d5f7d5e-0312-4916-b232-13e9e73e6d29, Nodes: 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27)6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27)a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-25T19:43:01.442Z[Etc/UTC]]
2024-03-25 19:43:01,478 [IPC Server handler 13 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27) as the reported value (DECOMMISSIONING, 0) does not match the value stored in SCM (DECOMMISSIONED, 0)
2024-03-25 19:43:01,479 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=669638b9-7e75-42f1-82a9-b01fec71537c is not found
2024-03-25 19:43:01,479 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 is not found
2024-03-25 19:43:01,540 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 is not found
2024-03-25 19:43:01,541 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, 6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:43:01,542 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, 6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:43:01,594 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5122886110ns, electionTimeout:5122ms
2024-03-25 19:43:01,594 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a568c6b4-1a28-494a-b080-2324592b3a72: shutdown a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-FollowerState
2024-03-25 19:43:01,594 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-25 19:43:01,595 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-25 19:43:01,596 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a568c6b4-1a28-494a-b080-2324592b3a72: start a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11
2024-03-25 19:43:01,597 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016]|listeners:[], old=null
2024-03-25 19:43:01,597 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11 PRE_VOTE round 0: result PASSED (term=0)
2024-03-25 19:43:01,598 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11 ELECTION round 0: submit vote requests at term 1 for -1: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016]|listeners:[], old=null
2024-03-25 19:43:01,598 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11 ELECTION round 0: result PASSED (term=1)
2024-03-25 19:43:01,598 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a568c6b4-1a28-494a-b080-2324592b3a72: shutdown a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11
2024-03-25 19:43:01,598 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-25 19:43:01,599 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-03-25 19:43:01,599 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-25 19:43:01,599 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-03-25 19:43:01,599 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-03-25 19:43:01,599 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-03-25 19:43:01,600 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-03-25 19:43:01,600 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-03-25 19:43:01,600 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-25 19:43:01,600 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:43:01,600 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-25 19:43:01,600 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-25 19:43:01,600 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a568c6b4-1a28-494a-b080-2324592b3a72: start a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderStateImpl
2024-03-25 19:43:01,600 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563: set firstElectionSinceStartup to false for becomeLeader
2024-03-25 19:43:01,600 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-739850C3A563 with new leaderId: a568c6b4-1a28-494a-b080-2324592b3a72
2024-03-25 19:43:01,600 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563: change Leader from null to a568c6b4-1a28-494a-b080-2324592b3a72 at term 1 for becomeLeader, leader elected after 5144ms
2024-03-25 19:43:01,601 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-25 19:43:01,601 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-25 19:43:01,605 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderElection11] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563: set configuration 0: peers:[a568c6b4-1a28-494a-b080-2324592b3a72|10.1.0.27:15016]|listeners:[], old=null
2024-03-25 19:43:01,611 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/9fcebae3-2819-4af1-b2d2-739850c3a563/current/log_inprogress_0
2024-03-25 19:43:01,615 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-25 19:43:01,669 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5163121160ns, electionTimeout:5160ms
2024-03-25 19:43:01,669 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: shutdown a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-FollowerState
2024-03-25 19:43:01,669 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-25 19:43:01,670 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-25 19:43:01,670 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: start a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12
2024-03-25 19:43:01,671 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null
2024-03-25 19:43:01,671 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12 PRE_VOTE round 0: result PASSED (term=0)
2024-03-25 19:43:01,672 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12 ELECTION round 0: submit vote requests at term 1 for -1: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null
2024-03-25 19:43:01,672 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12 ELECTION round 0: result PASSED (term=1)
2024-03-25 19:43:01,672 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: shutdown a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12
2024-03-25 19:43:01,673 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-25 19:43:01,673 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-03-25 19:43:01,673 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-25 19:43:01,673 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-03-25 19:43:01,673 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-03-25 19:43:01,673 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-03-25 19:43:01,674 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-03-25 19:43:01,674 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-03-25 19:43:01,674 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-25 19:43:01,674 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:43:01,674 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-25 19:43:01,674 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-25 19:43:01,674 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: start a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderStateImpl
2024-03-25 19:43:01,674 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986: set firstElectionSinceStartup to false for becomeLeader
2024-03-25 19:43:01,674 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-837C047AC986 with new leaderId: a6fb26e7-f548-473f-8cf0-48fafe70504d
2024-03-25 19:43:01,674 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986: change Leader from null to a6fb26e7-f548-473f-8cf0-48fafe70504d at term 1 for becomeLeader, leader elected after 5189ms
2024-03-25 19:43:01,674 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-25 19:43:01,675 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-25 19:43:01,679 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderElection12] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986: set configuration 0: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025]|listeners:[], old=null
2024-03-25 19:43:01,682 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/f8263715-53d5-4884-b6a7-837c047ac986/current/log_inprogress_0
2024-03-25 19:43:01,684 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-25 19:43:01,794 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:01,796 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:43:01,796 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:01,796 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:01,796 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:01,796 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:01,796 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:01,796 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:01,796 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:01,926 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:01,926 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:01,926 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:01,928 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:01,928 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:02,395 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:43:02,442 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:02,479 [IPC Server handler 13 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27) as the reported value (DECOMMISSIONING, 0) does not match the value stored in SCM (DECOMMISSIONED, 0)
2024-03-25 19:43:02,479 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=669638b9-7e75-42f1-82a9-b01fec71537c is not found
2024-03-25 19:43:02,480 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 is not found
2024-03-25 19:43:02,539 [6e65d581-b1bc-41f2-b39b-16d8508d6618-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: remove  FOLLOWER 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935:t1, leader=8de788e1-2c95-4c74-b4ac-29ea2448e86a, voted=8de788e1-2c95-4c74-b4ac-29ea2448e86a, raftlog=Memoized:6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-SegmentedRaftLog:OPENED:c0, conf=0: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null RUNNING
2024-03-25 19:43:02,539 [6e65d581-b1bc-41f2-b39b-16d8508d6618-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935: shutdown
2024-03-25 19:43:02,539 [6e65d581-b1bc-41f2-b39b-16d8508d6618-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-67F90E925935,id=6e65d581-b1bc-41f2-b39b-16d8508d6618
2024-03-25 19:43:02,539 [6e65d581-b1bc-41f2-b39b-16d8508d6618-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: shutdown 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-FollowerState
2024-03-25 19:43:02,539 [6e65d581-b1bc-41f2-b39b-16d8508d6618-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-StateMachineUpdater: set stopIndex = 0
2024-03-25 19:43:02,539 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-FollowerState was interrupted
2024-03-25 19:43:02,539 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-67F90E925935: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/b272cc68-1415-4b0a-8697-67f90e925935/sm/snapshot.1_0
2024-03-25 19:43:02,541 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-67F90E925935: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/b272cc68-1415-4b0a-8697-67f90e925935/sm/snapshot.1_0 took: 2 ms
2024-03-25 19:43:02,541 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-StateMachineUpdater: Took a snapshot at index 0
2024-03-25 19:43:02,541 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-25 19:43:02,542 [6e65d581-b1bc-41f2-b39b-16d8508d6618-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935: applyIndex: 0
2024-03-25 19:43:02,545 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-25 19:43:02,707 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: remove    LEADER 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935:t1, leader=8de788e1-2c95-4c74-b4ac-29ea2448e86a, voted=8de788e1-2c95-4c74-b4ac-29ea2448e86a, raftlog=Memoized:8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-SegmentedRaftLog:OPENED:c0, conf=0: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null RUNNING
2024-03-25 19:43:02,707 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935: shutdown
2024-03-25 19:43:02,707 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-67F90E925935,id=8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:43:02,707 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: shutdown 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-LeaderStateImpl
2024-03-25 19:43:02,707 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935->f8c0ec26-9898-49d2-a0ea-132d14d0dc83-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935->f8c0ec26-9898-49d2-a0ea-132d14d0dc83-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-03-25 19:43:02,707 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935->6e65d581-b1bc-41f2-b39b-16d8508d6618-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935->6e65d581-b1bc-41f2-b39b-16d8508d6618-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-03-25 19:43:02,707 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-PendingRequests: sendNotLeaderResponses
2024-03-25 19:43:02,708 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-StateMachineUpdater: set stopIndex = 0
2024-03-25 19:43:02,710 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: Completed APPEND_ENTRIES, lastRequest: 8de788e1-2c95-4c74-b4ac-29ea2448e86a->6e65d581-b1bc-41f2-b39b-16d8508d6618#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "f8c0ec26-9898-49d2-a0ea-132d14d0dc83"
address: "10.1.0.27:15034"
dataStreamAddress: "10.1.0.27:15035"
clientAddress: "10.1.0.27:15032"
adminAddress: "10.1.0.27:15033"
startupRole: FOLLOWER
,id: "6e65d581-b1bc-41f2-b39b-16d8508d6618"
address: "10.1.0.27:15043"
dataStreamAddress: "10.1.0.27:15044"
clientAddress: "10.1.0.27:15041"
adminAddress: "10.1.0.27:15042"
startupRole: FOLLOWER
,id: "8de788e1-2c95-4c74-b4ac-29ea2448e86a"
address: "10.1.0.27:15052"
priority: 1
dataStreamAddress: "10.1.0.27:15053"
clientAddress: "10.1.0.27:15050"
adminAddress: "10.1.0.27:15051"
startupRole: FOLLOWER
, old:)
2024-03-25 19:43:02,710 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: Completed APPEND_ENTRIES, lastReply: null
2024-03-25 19:43:02,709 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: Completed APPEND_ENTRIES, lastRequest: null
2024-03-25 19:43:02,711 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "8de788e1-2c95-4c74-b4ac-29ea2448e86a"
  replyId: "6e65d581-b1bc-41f2-b39b-16d8508d6618"
  raftGroupId {
    id: "\262r\314h\024\025K\n\206\227g\371\016\222Y5"
  }
  callId: 7
  success: true
}
term: 1
nextIndex: 1
matchIndex: 18446744073709551615
isHearbeat: true

2024-03-25 19:43:02,711 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935->6e65d581-b1bc-41f2-b39b-16d8508d6618-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-25 19:43:02,711 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935->6e65d581-b1bc-41f2-b39b-16d8508d6618-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-25 19:43:02,711 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 is not found
2024-03-25 19:43:02,709 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: Completed APPEND_ENTRIES, lastRequest: 8de788e1-2c95-4c74-b4ac-29ea2448e86a->f8c0ec26-9898-49d2-a0ea-132d14d0dc83#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "f8c0ec26-9898-49d2-a0ea-132d14d0dc83"
address: "10.1.0.27:15034"
dataStreamAddress: "10.1.0.27:15035"
clientAddress: "10.1.0.27:15032"
adminAddress: "10.1.0.27:15033"
startupRole: FOLLOWER
,id: "6e65d581-b1bc-41f2-b39b-16d8508d6618"
address: "10.1.0.27:15043"
dataStreamAddress: "10.1.0.27:15044"
clientAddress: "10.1.0.27:15041"
adminAddress: "10.1.0.27:15042"
startupRole: FOLLOWER
,id: "8de788e1-2c95-4c74-b4ac-29ea2448e86a"
address: "10.1.0.27:15052"
priority: 1
dataStreamAddress: "10.1.0.27:15053"
clientAddress: "10.1.0.27:15050"
adminAddress: "10.1.0.27:15051"
startupRole: FOLLOWER
, old:)
2024-03-25 19:43:02,712 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: Completed APPEND_ENTRIES, lastReply: null
2024-03-25 19:43:02,709 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: Completed APPEND_ENTRIES, lastRequest: null
2024-03-25 19:43:02,712 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935->f8c0ec26-9898-49d2-a0ea-132d14d0dc83-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-25 19:43:02,708 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-67F90E925935: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/b272cc68-1415-4b0a-8697-67f90e925935/sm/snapshot.1_0
2024-03-25 19:43:02,712 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "8de788e1-2c95-4c74-b4ac-29ea2448e86a"
  replyId: "f8c0ec26-9898-49d2-a0ea-132d14d0dc83"
  raftGroupId {
    id: "\262r\314h\024\025K\n\206\227g\371\016\222Y5"
  }
  callId: 5
  success: true
}
term: 1
nextIndex: 1
matchIndex: 18446744073709551615
isHearbeat: true

2024-03-25 19:43:02,713 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-67F90E925935: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/b272cc68-1415-4b0a-8697-67f90e925935/sm/snapshot.1_0 took: 4 ms
2024-03-25 19:43:02,714 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-StateMachineUpdater: Took a snapshot at index 0
2024-03-25 19:43:02,715 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-25 19:43:02,715 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935: applyIndex: 0
2024-03-25 19:43:02,715 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935->f8c0ec26-9898-49d2-a0ea-132d14d0dc83-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-25 19:43:02,716 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-25 19:43:02,728 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935-SegmentedRaftLogWorker close()
2024-03-25 19:43:02,730 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-67F90E925935: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/b272cc68-1415-4b0a-8697-67f90e925935
2024-03-25 19:43:02,730 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=b272cc68-1415-4b0a-8697-67f90e925935
org.apache.ratis.protocol.exceptions.GroupMismatchException: 8de788e1-2c95-4c74-b4ac-29ea2448e86a: group-67F90E925935 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-25 19:43:02,731 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: addNew group-13E9E73E6D29:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052] returns group-13E9E73E6D29:java.util.concurrent.CompletableFuture@7180878a[Not completed]
2024-03-25 19:43:02,732 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: new RaftServerImpl for group-13E9E73E6D29:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052] with ContainerStateMachine:uninitialized
2024-03-25 19:43:02,732 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:43:02,732 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-25 19:43:02,732 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-25 19:43:02,732 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-25 19:43:02,732 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:43:02,732 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-25 19:43:02,733 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:43:02,733 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29: ConfigurationManager, init=-1: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-25 19:43:02,733 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-25 19:43:02,733 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-25 19:43:02,733 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-25 19:43:02,733 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-25 19:43:02,733 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-25 19:43:02,733 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-25 19:43:02,735 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:43:02,736 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:43:02,736 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-25 19:43:02,736 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-25 19:43:02,736 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-25 19:43:02,736 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-25 19:43:02,736 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-25 19:43:02,736 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-25 19:43:02,736 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis] (custom)
2024-03-25 19:43:02,736 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29 does not exist. Creating ...
2024-03-25 19:43:02,737 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29/in_use.lock acquired by nodename 19166@fv-az1540-867
2024-03-25 19:43:02,738 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29 has been successfully formatted.
2024-03-25 19:43:02,739 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29/current/raft-meta.conf
2024-03-25 19:43:02,739 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-13E9E73E6D29: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-25 19:43:02,739 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-25 19:43:02,739 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-25 19:43:02,740 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:43:02,740 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-25 19:43:02,740 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-25 19:43:02,740 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29. Trying to get from SCM.
2024-03-25 19:43:02,741 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(86)) - Adding new pipeline Pipeline[ Id: 8d5f7d5e-0312-4916-b232-13e9e73e6d29, Nodes: 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27)6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27)a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-25T19:43:01.442Z[Etc/UTC]] to Recon pipeline metadata.
2024-03-25 19:43:02,742 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:43:02,742 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-25 19:43:02,742 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-25 19:43:02,742 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:43:02,742 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 reported by 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27)
2024-03-25 19:43:02,745 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-cacheEviction-AwaitToRun,5,main] started
2024-03-25 19:43:02,745 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29
2024-03-25 19:43:02,745 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-25 19:43:02,745 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-25 19:43:02,746 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:43:02,746 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-25 19:43:02,746 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-25 19:43:02,746 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-25 19:43:02,746 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-25 19:43:02,746 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-25 19:43:02,747 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-25 19:43:02,748 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:43:02,749 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-25 19:43:02,749 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-25 19:43:02,749 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-25 19:43:02,749 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-25 19:43:02,749 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-25 19:43:02,749 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29: start as a follower, conf=-1: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:43:02,749 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-25 19:43:02,750 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: start 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-FollowerState
2024-03-25 19:43:02,750 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-13E9E73E6D29,id=8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:43:02,750 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-25 19:43:02,750 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-25 19:43:02,750 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-25 19:43:02,750 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:43:02,750 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-25 19:43:02,751 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:43:02,751 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-25 19:43:02,764 [6e65d581-b1bc-41f2-b39b-16d8508d6618-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935-SegmentedRaftLogWorker close()
2024-03-25 19:43:02,766 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29
2024-03-25 19:43:02,766 [6e65d581-b1bc-41f2-b39b-16d8508d6618-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-67F90E925935: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/b272cc68-1415-4b0a-8697-67f90e925935
2024-03-25 19:43:02,766 [6e65d581-b1bc-41f2-b39b-16d8508d6618-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=b272cc68-1415-4b0a-8697-67f90e925935
org.apache.ratis.protocol.exceptions.GroupMismatchException: 6e65d581-b1bc-41f2-b39b-16d8508d6618: group-67F90E925935 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-25 19:43:02,796 [6e65d581-b1bc-41f2-b39b-16d8508d6618-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: addNew group-13E9E73E6D29:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052] returns group-13E9E73E6D29:java.util.concurrent.CompletableFuture@d4afc12[Not completed]
2024-03-25 19:43:02,797 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: new RaftServerImpl for group-13E9E73E6D29:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052] with ContainerStateMachine:uninitialized
2024-03-25 19:43:02,797 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:43:02,798 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-25 19:43:02,798 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-25 19:43:02,798 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-25 19:43:02,798 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:43:02,798 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-25 19:43:02,798 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:43:02,798 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29: ConfigurationManager, init=-1: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-25 19:43:02,798 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-25 19:43:02,798 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-25 19:43:02,798 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-25 19:43:02,798 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-25 19:43:02,798 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-25 19:43:02,798 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-25 19:43:02,800 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:02,803 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 3 milliseconds for processing 1 containers.
2024-03-25 19:43:02,803 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:02,803 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:02,803 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:02,804 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:02,805 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:02,805 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:02,805 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:02,809 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:43:02,809 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:43:02,809 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-25 19:43:02,809 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-25 19:43:02,809 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-25 19:43:02,809 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-25 19:43:02,811 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-25 19:43:02,812 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-25 19:43:02,812 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis] (custom)
2024-03-25 19:43:02,812 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29 does not exist. Creating ...
2024-03-25 19:43:02,814 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29/in_use.lock acquired by nodename 19166@fv-az1540-867
2024-03-25 19:43:02,815 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29 has been successfully formatted.
2024-03-25 19:43:02,815 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29/current/raft-meta.conf
2024-03-25 19:43:02,818 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-13E9E73E6D29: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-25 19:43:02,819 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-25 19:43:02,819 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-25 19:43:02,819 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:43:02,819 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-25 19:43:02,819 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-25 19:43:02,821 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:43:02,822 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-25 19:43:02,822 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-25 19:43:02,822 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:43:02,825 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-cacheEviction-AwaitToRun,5,main] started
2024-03-25 19:43:02,825 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29
2024-03-25 19:43:02,826 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-25 19:43:02,826 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-25 19:43:02,826 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:43:02,826 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-25 19:43:02,826 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-25 19:43:02,826 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-25 19:43:02,826 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-25 19:43:02,826 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-25 19:43:02,827 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-25 19:43:02,829 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 reported by 6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27)
2024-03-25 19:43:02,830 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:43:02,831 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-25 19:43:02,832 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-25 19:43:02,832 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-25 19:43:02,833 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-25 19:43:02,834 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-25 19:43:02,835 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: new RaftServerImpl for group-13E9E73E6D29:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052] with ContainerStateMachine:uninitialized
2024-03-25 19:43:02,835 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:43:02,834 [grpc-default-executor-5] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: addNew group-13E9E73E6D29:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052] returns group-13E9E73E6D29:java.util.concurrent.CompletableFuture@3971a038[Not completed]
2024-03-25 19:43:02,835 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-25 19:43:02,836 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-25 19:43:02,836 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-25 19:43:02,836 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:43:02,836 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-25 19:43:02,836 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:43:02,836 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29: ConfigurationManager, init=-1: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-25 19:43:02,836 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-25 19:43:02,836 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-25 19:43:02,836 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-25 19:43:02,836 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-25 19:43:02,836 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-25 19:43:02,836 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-25 19:43:02,839 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:43:02,839 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:43:02,839 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-25 19:43:02,839 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-25 19:43:02,839 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-25 19:43:02,839 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-25 19:43:02,839 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-25 19:43:02,839 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-25 19:43:02,839 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis] (custom)
2024-03-25 19:43:02,839 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29 does not exist. Creating ...
2024-03-25 19:43:02,841 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29: start as a follower, conf=-1: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:43:02,841 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-25 19:43:02,842 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: start 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-FollowerState
2024-03-25 19:43:02,842 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29/in_use.lock acquired by nodename 19166@fv-az1540-867
2024-03-25 19:43:02,842 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:43:02,843 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:43:02,842 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-13E9E73E6D29,id=6e65d581-b1bc-41f2-b39b-16d8508d6618
2024-03-25 19:43:02,843 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-25 19:43:02,844 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-25 19:43:02,844 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-25 19:43:02,845 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-25 19:43:02,845 [6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-25 19:43:02,845 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29 has been successfully formatted.
2024-03-25 19:43:02,846 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29/current/raft-meta.conf
2024-03-25 19:43:02,847 [6e65d581-b1bc-41f2-b39b-16d8508d6618-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29
2024-03-25 19:43:02,847 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-13E9E73E6D29: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-03-25 19:43:02,855 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-03-25 19:43:02,855 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 reported by a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27)
2024-03-25 19:43:02,855 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-03-25 19:43:02,856 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:43:02,856 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-25 19:43:02,856 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-25 19:43:02,863 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:43:02,864 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-25 19:43:02,864 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-25 19:43:02,864 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:43:02,864 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-cacheEviction-AwaitToRun,5,main] started
2024-03-25 19:43:02,864 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29
2024-03-25 19:43:02,865 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-03-25 19:43:02,865 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-03-25 19:43:02,865 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-03-25 19:43:02,865 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-03-25 19:43:02,865 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-03-25 19:43:02,865 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-03-25 19:43:02,867 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-25 19:43:02,867 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-03-25 19:43:02,867 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-03-25 19:43:02,869 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:43:02,869 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-03-25 19:43:02,869 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-03-25 19:43:02,869 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-03-25 19:43:02,870 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-25 19:43:02,870 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-25 19:43:02,871 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29: start as a follower, conf=-1: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:43:02,872 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-25 19:43:02,872 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: start a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-FollowerState
2024-03-25 19:43:02,873 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-13E9E73E6D29,id=a6fb26e7-f548-473f-8cf0-48fafe70504d
2024-03-25 19:43:02,873 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-25 19:43:02,873 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-25 19:43:02,873 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-03-25 19:43:02,873 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-03-25 19:43:02,873 [a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-25 19:43:02,874 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:43:02,874 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:43:02,886 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29.
2024-03-25 19:43:02,894 [6e65d581-b1bc-41f2-b39b-16d8508d6618-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29.
2024-03-25 19:43:02,929 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:02,929 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:02,929 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:02,931 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:02,931 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:03,396 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:43:03,443 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:03,478 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: remove    LEADER f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C:t1, leader=f8c0ec26-9898-49d2-a0ea-132d14d0dc83, voted=f8c0ec26-9898-49d2-a0ea-132d14d0dc83, raftlog=Memoized:f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-SegmentedRaftLog:OPENED:c0, conf=0: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034]|listeners:[], old=null RUNNING
2024-03-25 19:43:03,478 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C: shutdown
2024-03-25 19:43:03,478 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B01FEC71537C,id=f8c0ec26-9898-49d2-a0ea-132d14d0dc83
2024-03-25 19:43:03,478 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: shutdown f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-LeaderStateImpl
2024-03-25 19:43:03,478 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-PendingRequests: sendNotLeaderResponses
2024-03-25 19:43:03,479 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-StateMachineUpdater: set stopIndex = 0
2024-03-25 19:43:03,479 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to DECOMMISSIONED, scaling executor pool size to 20
2024-03-25 19:43:03,479 [IPC Server handler 24 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27) as the reported value (DECOMMISSIONED, 0) does not match the value stored in SCM (DECOMMISSIONING, 0)
2024-03-25 19:43:03,480 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-B01FEC71537C: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/669638b9-7e75-42f1-82a9-b01fec71537c/sm/snapshot.1_0
2024-03-25 19:43:03,480 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-B01FEC71537C: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/669638b9-7e75-42f1-82a9-b01fec71537c/sm/snapshot.1_0 took: 1 ms
2024-03-25 19:43:03,481 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-StateMachineUpdater: Took a snapshot at index 0
2024-03-25 19:43:03,481 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-25 19:43:03,481 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=669638b9-7e75-42f1-82a9-b01fec71537c is not found
2024-03-25 19:43:03,481 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 is not found
2024-03-25 19:43:03,481 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C: applyIndex: 0
2024-03-25 19:43:03,482 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-25 19:43:03,552 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C-SegmentedRaftLogWorker close()
2024-03-25 19:43:03,554 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-B01FEC71537C: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/669638b9-7e75-42f1-82a9-b01fec71537c
2024-03-25 19:43:03,555 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=669638b9-7e75-42f1-82a9-b01fec71537c
org.apache.ratis.protocol.exceptions.GroupMismatchException: f8c0ec26-9898-49d2-a0ea-132d14d0dc83: group-B01FEC71537C not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-25 19:43:03,555 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: remove  FOLLOWER f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935:t1, leader=8de788e1-2c95-4c74-b4ac-29ea2448e86a, voted=8de788e1-2c95-4c74-b4ac-29ea2448e86a, raftlog=Memoized:f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-SegmentedRaftLog:OPENED:c0, conf=0: peers:[f8c0ec26-9898-49d2-a0ea-132d14d0dc83|10.1.0.27:15034, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null RUNNING
2024-03-25 19:43:03,555 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935: shutdown
2024-03-25 19:43:03,555 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-67F90E925935,id=f8c0ec26-9898-49d2-a0ea-132d14d0dc83
2024-03-25 19:43:03,555 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: shutdown f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-FollowerState
2024-03-25 19:43:03,555 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-StateMachineUpdater: set stopIndex = 0
2024-03-25 19:43:03,555 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-FollowerState was interrupted
2024-03-25 19:43:03,558 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-67F90E925935: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/b272cc68-1415-4b0a-8697-67f90e925935/sm/snapshot.1_0
2024-03-25 19:43:03,559 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-67F90E925935: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/b272cc68-1415-4b0a-8697-67f90e925935/sm/snapshot.1_0 took: 0 ms
2024-03-25 19:43:03,559 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-StateMachineUpdater: Took a snapshot at index 0
2024-03-25 19:43:03,560 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-25 19:43:03,560 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935: applyIndex: 0
2024-03-25 19:43:03,560 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-25 19:43:03,750 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935-SegmentedRaftLogWorker close()
2024-03-25 19:43:03,752 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83@group-67F90E925935: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/ratis/b272cc68-1415-4b0a-8697-67f90e925935
2024-03-25 19:43:03,752 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=b272cc68-1415-4b0a-8697-67f90e925935
org.apache.ratis.protocol.exceptions.GroupMismatchException: f8c0ec26-9898-49d2-a0ea-132d14d0dc83: group-67F90E925935 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-25 19:43:03,805 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:03,807 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:43:03,808 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:03,808 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:03,808 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:03,808 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:03,808 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:03,808 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:03,808 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:03,849 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 reported by a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27)
2024-03-25 19:43:03,932 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:03,932 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:03,932 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:03,934 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:03,934 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:04,396 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:43:04,443 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:04,740 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 reported by 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27)
2024-03-25 19:43:04,809 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:04,811 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:43:04,811 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:04,811 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:04,811 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:04,811 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:04,811 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:04,811 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:04,811 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:04,820 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 reported by 6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27)
2024-03-25 19:43:04,849 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 reported by a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27)
2024-03-25 19:43:04,936 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:04,936 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:04,936 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:04,937 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:04,937 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:05,397 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:43:05,444 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:05,740 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 reported by 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27)
2024-03-25 19:43:05,812 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:05,814 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:43:05,814 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:05,814 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:05,814 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:05,814 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:05,814 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:05,814 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:05,814 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:05,820 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 reported by 6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27)
2024-03-25 19:43:05,850 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 reported by a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27)
2024-03-25 19:43:05,939 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:05,939 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:05,939 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:05,941 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:05,941 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:06,398 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:43:06,444 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:06,815 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-25 19:43:06,817 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:43:06,817 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:06,817 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:06,817 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:06,817 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:06,817 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:06,817 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:06,817 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:06,943 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:06,943 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:06,943 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:06,945 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:06,945 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:07,398 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:43:07,444 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:07,741 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 reported by 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27)
2024-03-25 19:43:07,818 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-25 19:43:07,820 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:43:07,820 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:07,820 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:07,820 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:07,820 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:07,820 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:07,820 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:07,821 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:07,826 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 reported by 6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27)
2024-03-25 19:43:07,848 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 reported by a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27)
2024-03-25 19:43:07,909 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5159909640ns, electionTimeout:5158ms
2024-03-25 19:43:07,910 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: shutdown 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-FollowerState
2024-03-25 19:43:07,910 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-25 19:43:07,910 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-25 19:43:07,910 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: start 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13
2024-03-25 19:43:07,911 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:43:07,912 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025
2024-03-25 19:43:07,912 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:43:07,912 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:43:07,914 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29: receive requestVote(PRE_VOTE, 8de788e1-2c95-4c74-b4ac-29ea2448e86a, group-13E9E73E6D29, 0, (t:0, i:0))
2024-03-25 19:43:07,914 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-FOLLOWER: accept PRE_VOTE from 8de788e1-2c95-4c74-b4ac-29ea2448e86a: our priority 0 <= candidate's priority 1
2024-03-25 19:43:07,914 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29 replies to PRE_VOTE vote request: 8de788e1-2c95-4c74-b4ac-29ea2448e86a<-6e65d581-b1bc-41f2-b39b-16d8508d6618#0:OK-t0. Peer's state: 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29:t0, leader=null, voted=, raftlog=Memoized:6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:43:07,916 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2024-03-25 19:43:07,916 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 8de788e1-2c95-4c74-b4ac-29ea2448e86a<-6e65d581-b1bc-41f2-b39b-16d8508d6618#0:OK-t0
2024-03-25 19:43:07,916 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13 PRE_VOTE round 0: result PASSED
2024-03-25 19:43:07,917 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:43:07,917 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13 ELECTION round 0: submit vote requests at term 1 for -1: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:43:07,917 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:43:07,918 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-03-25 19:43:07,918 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-25 19:43:07,921 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29: receive requestVote(PRE_VOTE, 8de788e1-2c95-4c74-b4ac-29ea2448e86a, group-13E9E73E6D29, 0, (t:0, i:0))
2024-03-25 19:43:07,921 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29: receive requestVote(ELECTION, 8de788e1-2c95-4c74-b4ac-29ea2448e86a, group-13E9E73E6D29, 1, (t:0, i:0))
2024-03-25 19:43:07,921 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-FOLLOWER: accept PRE_VOTE from 8de788e1-2c95-4c74-b4ac-29ea2448e86a: our priority 0 <= candidate's priority 1
2024-03-25 19:43:07,921 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29 replies to PRE_VOTE vote request: 8de788e1-2c95-4c74-b4ac-29ea2448e86a<-a6fb26e7-f548-473f-8cf0-48fafe70504d#0:OK-t0. Peer's state: a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29:t0, leader=null, voted=, raftlog=Memoized:a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:43:07,922 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-FOLLOWER: accept ELECTION from 8de788e1-2c95-4c74-b4ac-29ea2448e86a: our priority 0 <= candidate's priority 1
2024-03-25 19:43:07,922 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29: receive requestVote(ELECTION, 8de788e1-2c95-4c74-b4ac-29ea2448e86a, group-13E9E73E6D29, 1, (t:0, i:0))
2024-03-25 19:43:07,923 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-FOLLOWER: accept ELECTION from 8de788e1-2c95-4c74-b4ac-29ea2448e86a: our priority 0 <= candidate's priority 1
2024-03-25 19:43:07,923 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:43:07,923 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: shutdown 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-FollowerState
2024-03-25 19:43:07,923 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: start 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-FollowerState
2024-03-25 19:43:07,923 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:43:07,923 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: shutdown a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-FollowerState
2024-03-25 19:43:07,923 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: start a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-FollowerState
2024-03-25 19:43:07,923 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29: set firstElectionSinceStartup to false for candidate:8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:43:07,923 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29: set firstElectionSinceStartup to false for candidate:8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:43:07,923 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-FollowerState was interrupted
2024-03-25 19:43:07,923 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-FollowerState was interrupted
2024-03-25 19:43:07,927 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29 replies to ELECTION vote request: 8de788e1-2c95-4c74-b4ac-29ea2448e86a<-a6fb26e7-f548-473f-8cf0-48fafe70504d#0:OK-t1. Peer's state: a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29:t1, leader=null, voted=8de788e1-2c95-4c74-b4ac-29ea2448e86a, raftlog=Memoized:a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:43:07,927 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29 replies to ELECTION vote request: 8de788e1-2c95-4c74-b4ac-29ea2448e86a<-6e65d581-b1bc-41f2-b39b-16d8508d6618#0:OK-t1. Peer's state: 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29:t1, leader=null, voted=8de788e1-2c95-4c74-b4ac-29ea2448e86a, raftlog=Memoized:6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:43:07,928 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13: ELECTION PASSED received 1 response(s) and 0 exception(s):
2024-03-25 19:43:07,928 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 8de788e1-2c95-4c74-b4ac-29ea2448e86a<-a6fb26e7-f548-473f-8cf0-48fafe70504d#0:OK-t1
2024-03-25 19:43:07,928 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13 ELECTION round 0: result PASSED
2024-03-25 19:43:07,928 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: shutdown 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13
2024-03-25 19:43:07,928 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-25 19:43:07,928 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-03-25 19:43:07,929 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-25 19:43:07,929 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-03-25 19:43:07,929 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-03-25 19:43:07,929 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-03-25 19:43:07,929 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-03-25 19:43:07,929 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-03-25 19:43:07,929 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-25 19:43:07,929 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:43:07,930 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-25 19:43:07,930 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-25 19:43:07,930 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-03-25 19:43:07,930 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:43:07,930 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2024-03-25 19:43:07,930 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0s (custom)
2024-03-25 19:43:07,931 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-03-25 19:43:07,931 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:43:07,931 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-03-25 19:43:07,931 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-03-25 19:43:07,931 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-03-25 19:43:07,931 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:43:07,931 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-25 19:43:07,932 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-03-25 19:43:07,932 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:43:07,932 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2024-03-25 19:43:07,933 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0s (custom)
2024-03-25 19:43:07,933 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-03-25 19:43:07,934 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:43:07,934 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-03-25 19:43:07,935 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-03-25 19:43:07,935 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-03-25 19:43:07,935 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:43:07,935 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-25 19:43:07,936 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: start 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderStateImpl
2024-03-25 19:43:07,936 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29: set firstElectionSinceStartup to false for becomeLeader
2024-03-25 19:43:07,936 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-13E9E73E6D29 with new leaderId: 8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:43:07,937 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29: change Leader from null to 8de788e1-2c95-4c74-b4ac-29ea2448e86a at term 1 for becomeLeader, leader elected after 5203ms
2024-03-25 19:43:07,938 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-25 19:43:07,938 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 reported by 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27)
2024-03-25 19:43:07,938 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29
2024-03-25 19:43:07,939 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-25 19:43:07,939 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderElection13] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29: set configuration 0: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:43:07,946 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:07,946 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:07,946 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:07,948 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:07,948 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:07,948 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29/current/log_inprogress_0
2024-03-25 19:43:07,949 [6e65d581-b1bc-41f2-b39b-16d8508d6618-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-13E9E73E6D29 with new leaderId: 8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:43:07,950 [6e65d581-b1bc-41f2-b39b-16d8508d6618-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29: change Leader from null to 8de788e1-2c95-4c74-b4ac-29ea2448e86a at term 1 for appendEntries, leader elected after 5151ms
2024-03-25 19:43:07,950 [a6fb26e7-f548-473f-8cf0-48fafe70504d-server-thread2] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-13E9E73E6D29 with new leaderId: 8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:43:07,950 [a6fb26e7-f548-473f-8cf0-48fafe70504d-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29: change Leader from null to 8de788e1-2c95-4c74-b4ac-29ea2448e86a at term 1 for appendEntries, leader elected after 5113ms
2024-03-25 19:43:07,953 [a6fb26e7-f548-473f-8cf0-48fafe70504d-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29: set configuration 0: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:43:07,954 [a6fb26e7-f548-473f-8cf0-48fafe70504d-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-25 19:43:07,954 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-25 19:43:07,957 [6e65d581-b1bc-41f2-b39b-16d8508d6618-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29: set configuration 0: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:43:07,959 [6e65d581-b1bc-41f2-b39b-16d8508d6618-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-25 19:43:07,959 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-03-25 19:43:07,969 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29/current/log_inprogress_0
2024-03-25 19:43:07,969 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29/current/log_inprogress_0
2024-03-25 19:43:07,973 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-25 19:43:08,399 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:43:08,445 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:08,821 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:08,824 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:43:08,824 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:08,824 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:08,824 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:08,824 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:08,824 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:08,824 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:08,824 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:08,949 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:08,950 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:08,950 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:08,951 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:08,951 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:09,399 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:43:09,445 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:09,825 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:09,827 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:43:09,827 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:09,827 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:09,827 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:09,827 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:09,827 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:09,827 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:09,828 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:09,953 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:09,953 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:09,953 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:09,955 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:09,955 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:10,400 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:43:10,446 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:10,579 [Recon-SyncSCMContainerInfo-0] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:syncWithSCMContainerInfo(557)) - Got list of containers from SCM : 1
2024-03-25 19:43:10,605 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 4 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:43:10,606 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 4 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:43:10,828 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-25 19:43:10,830 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:43:10,830 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:10,830 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:10,830 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:10,830 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:10,830 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:10,831 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:10,831 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:10,956 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:10,957 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:10,957 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:10,958 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:10,958 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:11,400 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:43:11,446 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:11,829 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:43:11,831 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:11,833 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:43:11,833 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:11,834 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:11,834 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:11,834 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:11,834 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:11,834 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:11,834 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:11,852 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:43:11,852 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 4 millisec, a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:43:11,960 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:11,960 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:11,960 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:11,961 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:11,962 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:12,401 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:43:12,446 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:12,835 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:12,837 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:43:12,837 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:12,837 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:12,837 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:12,837 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:12,837 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:12,837 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:12,837 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:12,963 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:12,964 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:12,964 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:12,965 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:12,965 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:13,401 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:43:13,447 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:13,838 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-25 19:43:13,840 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:43:13,840 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:13,840 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:13,840 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:13,840 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:13,840 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:13,840 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:13,840 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:13,967 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:13,967 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:13,967 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:13,969 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:13,969 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:14,402 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:43:14,447 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:14,841 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:14,843 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:43:14,843 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:14,843 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:14,843 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:14,844 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:14,844 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:14,844 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:14,844 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:14,849 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:43:14,850 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:43:14,970 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:14,970 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:14,970 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:14,972 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:14,972 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:15,402 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:43:15,448 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:15,844 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:15,846 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:43:15,846 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:15,846 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:15,846 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:15,847 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:15,847 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:15,847 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:15,847 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:15,974 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:15,974 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:15,974 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:15,975 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:15,975 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:16,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:43:16,448 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:16,847 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:16,850 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:43:16,850 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:16,850 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:16,850 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:16,850 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:16,850 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:16,850 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:16,850 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:16,977 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:16,977 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:16,977 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:16,979 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:16,979 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:17,403 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:43:17,449 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:17,851 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-25 19:43:17,853 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:43:17,853 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:17,853 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:17,853 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:17,853 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:17,853 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:17,853 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:17,853 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:17,980 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:17,981 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:17,981 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:17,983 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:17,983 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:18,404 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:43:18,449 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:18,854 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-25 19:43:18,856 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:43:18,856 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:18,856 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:18,856 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:18,857 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:18,857 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:18,857 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:18,857 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:18,985 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:18,985 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:18,985 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:18,987 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:18,987 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:19,404 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:43:19,449 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:19,605 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:43:19,606 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:43:19,857 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:19,860 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:43:19,860 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:19,860 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:19,860 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:19,860 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:19,860 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:19,860 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:19,860 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:19,988 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:19,989 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:19,989 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:19,990 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:19,990 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:20,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:43:20,450 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:20,861 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:20,863 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:43:20,863 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:20,863 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:20,863 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:20,863 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:20,863 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:20,863 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:20,864 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:20,992 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:20,992 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:20,992 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:20,994 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:20,994 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:21,405 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:43:21,450 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:21,608 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:43:21,610 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:43:21,611 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:43:21,611 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 5 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:43:21,627 [ContainerSizeCountTask] INFO  tasks.ContainerSizeCountTask (ContainerSizeCountTask.java:run(101)) - Deleted 0 records from "CONTAINER_COUNT_BY_SIZE"
2024-03-25 19:43:21,637 [ContainerSizeCountTask] INFO  tasks.ContainerSizeCountTask (ContainerSizeCountTask.java:process(200)) - Completed a 'process' run of ContainerSizeCountTask.
2024-03-25 19:43:21,637 [ContainerSizeCountTask] INFO  tasks.ContainerSizeCountTask (ContainerSizeCountTask.java:run(114)) - Elapsed Time in milliseconds for Process() execution: 10
2024-03-25 19:43:21,864 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:21,868 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 3 milliseconds for processing 1 containers.
2024-03-25 19:43:21,868 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:21,868 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:21,868 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:21,868 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:21,868 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:21,868 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:21,868 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:21,996 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:21,996 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:21,996 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:21,998 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:21,998 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:22,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:43:22,451 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:22,869 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:22,871 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:43:22,871 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:22,871 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:22,871 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:22,871 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:22,871 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:22,871 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:22,871 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:22,999 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:23,000 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:23,000 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:23,001 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:23,001 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:23,406 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:43:23,451 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:23,872 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-25 19:43:23,874 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:43:23,874 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:23,874 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:23,874 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:23,874 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:23,874 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:23,874 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:23,874 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:24,003 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:24,003 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:24,003 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:24,005 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:24,005 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:24,223 [a568c6b4-1a28-494a-b080-2324592b3a72-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-03-25 19:43:24,283 [a6fb26e7-f548-473f-8cf0-48fafe70504d-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-03-25 19:43:24,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:43:24,436 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-03-25 19:43:24,452 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:24,551 [6e65d581-b1bc-41f2-b39b-16d8508d6618-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-03-25 19:43:24,706 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-03-25 19:43:24,875 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-25 19:43:24,878 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:43:24,878 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:24,878 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:24,878 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:24,878 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:24,878 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:24,878 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:24,878 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:25,007 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:25,007 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:25,007 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:25,008 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:25,009 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:25,407 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:43:25,452 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:25,879 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:25,881 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:43:25,881 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:25,881 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:25,881 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:25,881 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:25,881 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:25,881 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:25,881 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:26,010 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:26,011 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:26,011 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:26,012 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:26,012 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:26,408 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:43:26,452 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:26,882 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:26,884 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:43:26,884 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:26,884 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:26,884 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:26,884 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:26,884 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:26,884 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:26,884 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:27,014 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:27,014 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:27,014 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:27,016 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:27,016 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:27,408 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:43:27,453 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:27,885 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:27,887 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:43:27,887 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:27,887 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:27,887 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:27,887 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:27,887 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:27,887 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:27,887 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:28,018 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:28,018 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:28,018 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:28,019 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:28,019 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:28,409 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:43:28,453 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:28,888 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:28,890 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:43:28,890 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:28,890 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:28,890 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:28,890 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:28,890 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:28,890 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:28,890 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:29,021 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:29,021 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:29,022 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:29,023 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:29,023 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:29,409 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:43:29,453 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:29,891 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:29,893 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 3 milliseconds for processing 1 containers.
2024-03-25 19:43:29,894 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:29,894 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:29,894 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:29,894 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:29,894 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:29,894 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:29,894 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:30,025 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:30,025 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:30,025 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:30,027 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:30,027 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:30,410 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-03-25 19:43:30,454 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
2024-03-25 19:43:30,895 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:30,897 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-03-25 19:43:30,897 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:30,897 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:30,897 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:30,897 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:30,897 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:30,897 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:30,897 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:31,028 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:31,028 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:31,028 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:31,030 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:31,030 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:31,410 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-03-25 19:43:31,454 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a, a568c6b4-1a28-494a-b080-2324592b3a72, a6fb26e7-f548-473f-8cf0-48fafe70504d]
====> [2] DECOMMISSIONING, DECOMMISSIONED, false TIMED OUT. PRINTING THREAD DUMP. <====

Timestamp: 2024-03-25 07:43:31,535

"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@74a8b8bd" daemon prio=5 tid=637 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 45 on default port 15009" daemon prio=5 tid=516 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=596 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 21 on default port 15001" daemon prio=5 tid=174 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"JvmPauseMonitor3" daemon prio=5 tid=735 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$554/718511919.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 86 on default port 15009" daemon prio=5 tid=557 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp850601250-459" daemon prio=5 tid=459 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 72 on default port 15002" daemon prio=5 tid=325 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15004"  prio=5 tid=382 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 16 on default port 15000" daemon prio=5 tid=69 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a568c6b4-1a28-494a-b080-2324592b3a72-PipelineCommandHandlerThread-0"  prio=5 tid=830 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-CommandProcessorThread" daemon prio=5 tid=716 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:684)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1388/1874810059.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 15004" daemon prio=5 tid=431 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ExpiredContainerReplicaOpScrubber" daemon prio=5 tid=21 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:107)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$489/464583224.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-ChunkReader-ELG-0" daemon prio=5 tid=755 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 70 on default port 15000" daemon prio=5 tid=123 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 94 on default port 15000" daemon prio=5 tid=147 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a568c6b4-1a28-494a-b080-2324592b3a72-ChunkReader-ELG-0" daemon prio=5 tid=736 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 91 on default port 15000" daemon prio=5 tid=144 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a568c6b4-1a28-494a-b080-2324592b3a72-DatanodeReportManager-0" daemon prio=5 tid=599 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 60 on default port 15001" daemon prio=5 tid=213 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"timer7" daemon prio=5 tid=950 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 87 on default port 15000" daemon prio=5 tid=140 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 48 on default port 15000" daemon prio=5 tid=101 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 41 on default port 15000" daemon prio=5 tid=94 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 64 on default port 15000" daemon prio=5 tid=117 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SSL Certificates Store Monitor" daemon prio=5 tid=1080 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"qtp1908051795-405" daemon prio=5 tid=405 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 15004" daemon prio=5 tid=430 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1194 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-2" daemon prio=5 tid=868 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 74 on default port 15002" daemon prio=5 tid=327 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp850601250-462" daemon prio=5 tid=462 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.reservedWait(ReservedThreadExecutor.java:324)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:399)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-DatanodeReportManager-4" daemon prio=5 tid=715 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 77 on default port 15001" daemon prio=5 tid=230 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1-SnapshotDirectoryCleaningService#0" daemon prio=5 tid=402 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 68 on default port 15001" daemon prio=5 tid=221 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a568c6b4-1a28-494a-b080-2324592b3a72-DatanodeReportManager-4" daemon prio=5 tid=603 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-FollowerState" daemon prio=5 tid=1180 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"IPC Server handler 9 on default port 15001" daemon prio=5 tid=162 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 25 on default port 15000" daemon prio=5 tid=78 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Timer-1" daemon prio=5 tid=435 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"qtp729326364-668" daemon prio=5 tid=668 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29->6e65d581-b1bc-41f2-b39b-16d8508d6618-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=1183 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:286)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:254)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:80)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1629/1904623040.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Parameter Sending Thread for 0.0.0.0/0.0.0.0:15009" daemon prio=5 tid=724 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferQueue.awaitFulfill(SynchronousQueue.java:764)
        at java.util.concurrent.SynchronousQueue$TransferQueue.transfer(SynchronousQueue.java:695)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1105)
        at java.lang.Thread.run(Thread.java:750)
"timer2" daemon prio=5 tid=923 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 2 on default port 15009" daemon prio=5 tid=473 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 96 on default port 15002" daemon prio=5 tid=349 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 20 on default port 15000" daemon prio=5 tid=73 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"RatisPipelineUtilsThread-0"  prio=5 tid=19 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.run(BackgroundPipelineCreator.java:179)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator$$Lambda$487/1424392446.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement"  prio=5 tid=885 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-DatanodeReportManager-0" daemon prio=5 tid=627 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-BlockDeletingService#0" daemon prio=5 tid=775 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-LeaderStateImpl" daemon prio=5 tid=438 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:762)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@7502268d" daemon prio=5 tid=693 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 80 on default port 15009" daemon prio=5 tid=551 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"CompactionDagPruningService" daemon prio=5 tid=371 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 91 on default port 15002" daemon prio=5 tid=344 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 40 on default port 15001" daemon prio=5 tid=193 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"client-write-TID-0" daemon prio=5 tid=958 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 20 on default port 15002" daemon prio=5 tid=273 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 98 on default port 15009" daemon prio=5 tid=569 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-ChunkWriter-0-0" daemon prio=5 tid=807 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 92 on default port 15000" daemon prio=5 tid=145 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 42 on default port 15002" daemon prio=5 tid=295 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 85 on default port 15001" daemon prio=5 tid=238 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=48 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 74 on default port 15009" daemon prio=5 tid=545 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-DatanodeStateMachineTaskThread-0"  prio=5 tid=717 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2022138586-699" daemon prio=5 tid=699 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-DatanodeReportManager-4" daemon prio=5 tid=659 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp671888763-584" daemon prio=5 tid=584 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=31 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer5" daemon prio=5 tid=946 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 15 on default port 15002" daemon prio=5 tid=268 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 81 on default port 15009" daemon prio=5 tid=552 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 6 on default port 15009" daemon prio=5 tid=477 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 31 on default port 15009" daemon prio=5 tid=502 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 4 on default port 15002" daemon prio=5 tid=257 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 90 on default port 15009" daemon prio=5 tid=561 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 55 on default port 15000" daemon prio=5 tid=108 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 27 on default port 15000" daemon prio=5 tid=80 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 55 on default port 15002" daemon prio=5 tid=308 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 6 on default port 15000" daemon prio=5 tid=59 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp729326364-671" daemon prio=5 tid=671 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 55 on default port 15009" daemon prio=5 tid=526 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a568c6b4-1a28-494a-b080-2324592b3a72-PeriodicHDDSVolumeChecker" daemon prio=5 tid=726 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 31 on default port 15001" daemon prio=5 tid=184 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 2 on default port 15004" daemon prio=5 tid=416 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 73 on default port 15002" daemon prio=5 tid=326 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 18 on default port 15009" daemon prio=5 tid=489 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 19 on default port 15004" daemon prio=5 tid=433 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 95 on default port 15000" daemon prio=5 tid=148 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 61 on default port 15002" daemon prio=5 tid=314 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-BlockDeletingService#0" daemon prio=5 tid=813 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 15004" daemon prio=5 tid=427 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-BlockDeletingService#1" daemon prio=5 tid=816 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 97 on default port 15002" daemon prio=5 tid=350 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-194-thread-1"  prio=5 tid=666 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-142-thread-1"  prio=5 tid=610 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 39 on default port 15009" daemon prio=5 tid=510 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server idle connection scanner for port 15012" daemon prio=5 tid=594 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"BackgroundPipelineScrubber" daemon prio=5 tid=20 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:107)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$489/464583224.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-ChunkWriter-2-0" daemon prio=5 tid=809 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-groupManagement"  prio=5 tid=376 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 57 on default port 15001" daemon prio=5 tid=210 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 65 on default port 15000" daemon prio=5 tid=118 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=453 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor5" daemon prio=5 tid=773 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$554/718511919.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ReplicationMonitor" daemon prio=5 tid=22 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:931)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager$$Lambda$503/26462224.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 84 on default port 15001" daemon prio=5 tid=237 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-SegmentedRaftLogWorker"  prio=5 tid=872 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$917/527921443.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 27 on default port 15002" daemon prio=5 tid=280 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a568c6b4-1a28-494a-b080-2324592b3a72-DatanodeStateMachineDaemonThread" daemon prio=5 tid=598 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:369)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:556)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1386/996581381.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 99 on default port 15002" daemon prio=5 tid=352 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"process reaper" daemon prio=10 tid=12 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 15009" daemon prio=5 tid=471 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 65 on default port 15002" daemon prio=5 tid=318 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=36 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"MutableQuantiles-0" daemon prio=5 tid=945 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 33 on default port 15009" daemon prio=5 tid=504 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-DatanodeReportManager-2" daemon prio=5 tid=657 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 79 on default port 15009" daemon prio=5 tid=550 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 30 on default port 15000" daemon prio=5 tid=83 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"PartialTableCache-Cleanup-0" daemon prio=5 tid=960 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-MultipartUploadCleanupService#0" daemon prio=5 tid=403 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a568c6b4-1a28-494a-b080-2324592b3a72-CloseContainerThread-2"  prio=5 tid=1077 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-DatanodeReportManager-4" daemon prio=5 tid=631 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 92 on default port 15001" daemon prio=5 tid=245 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1908051795-407" daemon prio=5 tid=407 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp729326364-670-acceptor-0@4b4b8704-ServerConnector@69fbbcf6{HTTP/1.1, (http/1.1)}{0.0.0.0:15038}" daemon prio=3 tid=670 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp1443696949-641-acceptor-0@17f048f4-ServerConnector@7b11904c{HTTP/1.1, (http/1.1)}{0.0.0.0:15029}" daemon prio=3 tid=641 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 94 on default port 15002" daemon prio=5 tid=347 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp911539378-611" daemon prio=5 tid=611 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-worker-ELG-3-1" daemon prio=5 tid=854 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:312)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:376)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"pool-168-thread-1"  prio=5 tid=638 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"null-request--thread1" daemon prio=5 tid=948 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 15001" daemon prio=5 tid=167 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 27 on default port 15001" daemon prio=5 tid=180 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 84 on default port 15009" daemon prio=5 tid=555 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 21 on default port 15000" daemon prio=5 tid=74 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-DatanodeStateMachineTaskThread-1"  prio=5 tid=760 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-ChunkWriter-2-0" daemon prio=5 tid=790 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 41 on default port 15001" daemon prio=5 tid=194 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 75 on default port 15009" daemon prio=5 tid=546 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0"  prio=5 tid=842 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 79 on default port 15001" daemon prio=5 tid=232 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a568c6b4-1a28-494a-b080-2324592b3a72-BlockDeletingService#0" daemon prio=5 tid=737 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 93 on default port 15000" daemon prio=5 tid=146 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-server-thread3" daemon prio=5 tid=1189 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-5f7f672e-1"  prio=5 tid=619 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 70 on default port 15001" daemon prio=5 tid=223 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 1 on default port 15002" daemon prio=5 tid=254 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 36 on default port 15009" daemon prio=5 tid=507 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Session-HouseKeeper-be7f4b5-1"  prio=5 tid=647 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor7" daemon prio=5 tid=811 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$554/718511919.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 15001" daemon prio=5 tid=159 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 35 on default port 15000" daemon prio=5 tid=88 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-ReplicationContainerReader-1" daemon prio=5 tid=1106 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 44 on default port 15001" daemon prio=5 tid=197 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 44 on default port 15009" daemon prio=5 tid=515 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 41 on default port 15002" daemon prio=5 tid=294 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 77 on default port 15000" daemon prio=5 tid=130 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 10 on default port 15000" daemon prio=5 tid=63 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=47 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=651 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"qtp1908051795-408-acceptor-0@586b9d09-ServerConnector@4bfbc57a{HTTP/1.1, (http/1.1)}{0.0.0.0:15005}" daemon prio=3 tid=408 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"ContainerMetadataScanner" daemon prio=5 tid=748 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server listener on 15048" daemon prio=5 tid=704 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"a568c6b4-1a28-494a-b080-2324592b3a72-BlockDeletingService#2" daemon prio=5 tid=1191 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=777 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SSL Certificates Store Monitor" daemon prio=5 tid=1082 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 76 on default port 15000" daemon prio=5 tid=129 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"PartialTableCache-Cleanup-0" daemon prio=5 tid=959 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 80 on default port 15002" daemon prio=5 tid=333 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 68 on default port 15000" daemon prio=5 tid=121 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server idle connection scanner for port 15002" daemon prio=5 tid=29 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 51 on default port 15002" daemon prio=5 tid=304 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 10 on default port 15002" daemon prio=5 tid=263 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 15 on default port 15000" daemon prio=5 tid=68 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"JvmPauseMonitor2" daemon prio=5 tid=574 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$554/718511919.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 28 on default port 15001" daemon prio=5 tid=181 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1192 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 65 on default port 15009" daemon prio=5 tid=536 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp911539378-618" daemon prio=5 tid=618 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-cacheEviction-AwaitToRun" daemon prio=5 tid=1135 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 29 on default port 15000" daemon prio=5 tid=82 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 5 on default port 15001" daemon prio=5 tid=158 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 62 on default port 15000" daemon prio=5 tid=115 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1196 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Recon-FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=456 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-ChunkWriter-1-0" daemon prio=5 tid=808 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Recon-FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=450 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp911539378-616" daemon prio=5 tid=616 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 15004" daemon prio=5 tid=417 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 74 on default port 15001" daemon prio=5 tid=227 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=448 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-BlockDeletingService#2" daemon prio=5 tid=1193 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 15009" daemon prio=5 tid=484 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1@group-C5BA1605619E-StateMachineUpdater" daemon prio=5 tid=390 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 51 on default port 15009" daemon prio=5 tid=522 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 75 on default port 15002" daemon prio=5 tid=328 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1443696949-640" daemon prio=5 tid=640 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 15000" daemon prio=5 tid=72 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=739 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 40 on default port 15000" daemon prio=5 tid=93 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1@group-C5BA1605619E-cacheEviction-AwaitToRun" daemon prio=5 tid=387 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.lang.Thread.run(Thread.java:750)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-DeleteContainerThread-0"  prio=5 tid=1143 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 96 on default port 15000" daemon prio=5 tid=149 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp850601250-464" daemon prio=5 tid=464 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-5b9d3ef-1"  prio=5 tid=591 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 81 on default port 15000" daemon prio=5 tid=134 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SSL Certificates Store Monitor" daemon prio=5 tid=1132 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 21 on default port 15002" daemon prio=5 tid=274 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a568c6b4-1a28-494a-b080-2324592b3a72-DatanodeReportManager-2" daemon prio=5 tid=601 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=708 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 15009" daemon prio=5 tid=485 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"surefire-forkedjvm-command-thread" daemon prio=5 tid=10 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.FileInputStream.readBytes(Native Method)
        at java.io.FileInputStream.read(FileInputStream.java:255)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
        at java.io.DataInputStream.readInt(DataInputStream.java:387)
        at org.apache.maven.surefire.booter.MasterProcessCommand.decode(MasterProcessCommand.java:113)
        at org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:383)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-worker-ELG-3-4" daemon prio=5 tid=862 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:312)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:376)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 73 on default port 15001" daemon prio=5 tid=226 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1-KeyDeletingService#0" daemon prio=5 tid=397 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2022138586-697-acceptor-0@1f55dd65-ServerConnector@473754ef{HTTP/1.1, (http/1.1)}{0.0.0.0:15047}" daemon prio=3 tid=697 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 23 on default port 15001" daemon prio=5 tid=176 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=757 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 15002" daemon prio=5 tid=27 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 52 on default port 15002" daemon prio=5 tid=305 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 97 on default port 15000" daemon prio=5 tid=150 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-DatanodeStateMachineTaskThread-1"  prio=5 tid=741 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 30 on default port 15001" daemon prio=5 tid=183 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-DatanodeReportManager-0" daemon prio=5 tid=655 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 15001" daemon prio=5 tid=169 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Connector-Scheduler-4bfbc57a-1"  prio=5 tid=968 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 85 on default port 15002" daemon prio=5 tid=338 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=635 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 44 on default port 15002" daemon prio=5 tid=297 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a568c6b4-1a28-494a-b080-2324592b3a72-CommandProcessorThread" daemon prio=5 tid=604 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:684)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1388/1874810059.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 89 on default port 15000" daemon prio=5 tid=142 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PeriodicHDDSVolumeChecker" daemon prio=5 tid=764 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-cacheEviction-AwaitToRun" daemon prio=5 tid=886 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 15000" daemon prio=5 tid=53 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 12 on default port 15000" daemon prio=5 tid=65 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 64 on default port 15009" daemon prio=5 tid=535 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 59 on default port 15002" daemon prio=5 tid=312 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 65 on default port 15001" daemon prio=5 tid=218 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 43 on default port 15009" daemon prio=5 tid=514 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1190 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 53 on default port 15009" daemon prio=5 tid=524 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 64 on default port 15001" daemon prio=5 tid=217 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 22 on default port 15009" daemon prio=5 tid=493 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 25 on default port 15002" daemon prio=5 tid=278 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1908051795-411" daemon prio=5 tid=411 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.reservedWait(ReservedThreadExecutor.java:324)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:399)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"om1-OpenKeyCleanupService#0" daemon prio=5 tid=399 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp439694398-360" daemon prio=5 tid=360 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"om1-client-thread1" daemon prio=5 tid=937 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 67 on default port 15000" daemon prio=5 tid=120 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 7 on default port 15004" daemon prio=5 tid=421 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 12 on default port 15002" daemon prio=5 tid=265 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-SyncOM-1"  prio=5 tid=965 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 57 on default port 15002" daemon prio=5 tid=310 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 87 on default port 15001" daemon prio=5 tid=240 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp2022138586-695" daemon prio=5 tid=695 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-OpenPipelineForHealthyPipelineSafeModeRule" daemon prio=5 tid=833 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 15002" daemon prio=5 tid=266 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 83 on default port 15001" daemon prio=5 tid=236 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 40 on default port 15009" daemon prio=5 tid=511 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 16 on default port 15002" daemon prio=5 tid=269 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 40 on default port 15002" daemon prio=5 tid=293 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 86 on default port 15001" daemon prio=5 tid=239 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15002"  prio=5 tid=28 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 12 on default port 15004" daemon prio=5 tid=426 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 92 on default port 15009" daemon prio=5 tid=563 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server listener on 15012" daemon prio=5 tid=592 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 26 on default port 15000" daemon prio=5 tid=79 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 59 on default port 15000" daemon prio=5 tid=112 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-BlockDeletingService#2" daemon prio=5 tid=1197 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 78 on default port 15000" daemon prio=5 tid=131 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"surefire-forkedjvm-ping-30s" daemon prio=5 tid=11 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-StateMachineUpdater" daemon prio=5 tid=1167 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.lang.Thread.run(Thread.java:750)
"Reference Handler" daemon prio=10 tid=2 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
        at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
"IPC Server handler 31 on default port 15002" daemon prio=5 tid=284 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 11 on default port 15002" daemon prio=5 tid=264 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 6 on default port 15002" daemon prio=5 tid=259 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 1 on default port 15004" daemon prio=5 tid=415 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 32 on default port 15009" daemon prio=5 tid=503 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 52 on default port 15000" daemon prio=5 tid=105 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 60 on default port 15009" daemon prio=5 tid=531 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 66 on default port 15001" daemon prio=5 tid=219 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=691 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 34 on default port 15002" daemon prio=5 tid=287 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 27 on default port 15009" daemon prio=5 tid=498 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=51 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Recon-SyncSCMContainerInfo-0"  prio=5 tid=470 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-server-thread1" daemon prio=5 tid=1186 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 66 on default port 15009" daemon prio=5 tid=537 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 20 on default port 15009" daemon prio=5 tid=491 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-DatanodeReportManager-2" daemon prio=5 tid=685 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp439694398-358-acceptor-0@9ceb28b-ServerConnector@bf70ce5{HTTP/1.1, (http/1.1)}{0.0.0.0:15003}" daemon prio=3 tid=358 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-ContainerReplicationThread-0" daemon prio=5 tid=1104 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.PriorityBlockingQueue.take(PriorityBlockingQueue.java:549)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 63 on default port 15002" daemon prio=5 tid=316 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a568c6b4-1a28-494a-b080-2324592b3a72-BlockDeletingService#1" daemon prio=5 tid=740 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 47 on default port 15002" daemon prio=5 tid=300 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-ChunkReader-ELG-0" daemon prio=5 tid=812 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Recon-EventQueue-PipelineReportForReconPipelineReportHandler" daemon prio=5 tid=820 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 87 on default port 15002" daemon prio=5 tid=340 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"PipelineSyncTask" daemon prio=5 tid=573 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.recon.scm.PipelineSyncTask.run(PipelineSyncTask.java:76)
        at org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda$1299/1127738540.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 37 on default port 15001" daemon prio=5 tid=190 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 76 on default port 15002" daemon prio=5 tid=329 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 14 on default port 15000" daemon prio=5 tid=67 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-executor-4" daemon prio=5 tid=927 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 54 on default port 15002" daemon prio=5 tid=307 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 89 on default port 15009" daemon prio=5 tid=560 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15039"  prio=5 tid=677 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 88 on default port 15009" daemon prio=5 tid=559 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server idle connection scanner for port 15001" daemon prio=5 tid=34 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 11 on default port 15000" daemon prio=5 tid=64 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=679 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"SSL Certificates Store Monitor" daemon prio=5 tid=1051 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-ChunkWriter-3-0" daemon prio=5 tid=791 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-DatanodeReportManager-0" daemon prio=5 tid=683 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache-Cleanup-0" daemon prio=5 tid=939 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 62 on default port 15002" daemon prio=5 tid=315 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 68 on default port 15009" daemon prio=5 tid=539 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=707 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"IPC Server handler 88 on default port 15001" daemon prio=5 tid=241 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderStateImpl" daemon prio=5 tid=1147 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:762)
"IPC Server handler 36 on default port 15002" daemon prio=5 tid=289 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerHealthTask" daemon prio=5 tid=572 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.recon.fsck.ContainerHealthTask.run(ContainerHealthTask.java:111)
        at org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda$1299/1127738540.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"a568c6b4-1a28-494a-b080-2324592b3a72-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=720 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 15001" daemon prio=5 tid=166 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-SegmentedRaftLogWorker"  prio=5 tid=1140 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$917/527921443.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-StateMachineUpdater" daemon prio=5 tid=874 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.lang.Thread.run(Thread.java:750)
"qtp671888763-588" daemon prio=5 tid=588 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 99 on default port 15000" daemon prio=5 tid=152 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"LeaseManager#LeaseMonitor" daemon prio=5 tid=354 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1037)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1328)
        at java.util.concurrent.Semaphore.tryAcquire(Semaphore.java:409)
        at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:285)
        at java.lang.Thread.run(Thread.java:750)
"LeakDetector-ManagedRocksObject0" daemon prio=5 tid=17 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at org.apache.hadoop.hdds.utils.LeakDetector.run(LeakDetector.java:80)
        at org.apache.hadoop.hdds.utils.LeakDetector$$Lambda$436/731584462.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 15009" daemon prio=5 tid=474 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 93 on default port 15002" daemon prio=5 tid=346 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=45 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-124-thread-1" daemon prio=5 tid=747 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 15002" daemon prio=5 tid=255 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-DatanodeReportManager-0" daemon prio=5 tid=711 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-124540b5-1"  prio=5 tid=675 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 88 on default port 15002" daemon prio=5 tid=341 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SSL Certificates Store Monitor" daemon prio=5 tid=441 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29->a6fb26e7-f548-473f-8cf0-48fafe70504d-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=1182 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:286)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:254)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:80)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1629/1904623040.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache-Cleanup-0" daemon prio=5 tid=944 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 73 on default port 15000" daemon prio=5 tid=126 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"gradle-enterprise-test-client-gradle-enterprise-test-listener"  prio=5 tid=14 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:403)
        at com.gradle.maven.scan.extension.test.listener.obfuscated.k.a.a(SourceFile:130)
        at com.gradle.maven.scan.extension.test.listener.obfuscated.k.a.b(SourceFile:93)
        at com.gradle.maven.scan.extension.test.listener.obfuscated.k.a$$Lambda$256/215614514.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 15009" daemon prio=5 tid=483 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"junit-jupiter-timeout-watcher"  prio=10 tid=1045 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 45 on default port 15002" daemon prio=5 tid=298 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 17 on default port 15001" daemon prio=5 tid=170 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 7 on default port 15001" daemon prio=5 tid=160 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=446 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"IPC Server handler 90 on default port 15000" daemon prio=5 tid=143 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SSL Certificates Store Monitor" daemon prio=5 tid=1134 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 17 on default port 15000" daemon prio=5 tid=70 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-DatanodeReportManager-4" daemon prio=5 tid=687 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Client (1615502727) connection to 0.0.0.0/0.0.0.0:15002 from runner" daemon prio=5 tid=721 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1026)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1077)
"grpc-default-executor-5" daemon prio=5 tid=928 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-20a101bb-1"  prio=5 tid=466 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 32 on default port 15002" daemon prio=5 tid=285 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 32 on default port 15000" daemon prio=5 tid=85 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 23 on default port 15000" daemon prio=5 tid=76 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 73 on default port 15009" daemon prio=5 tid=544 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-CommandProcessorThread" daemon prio=5 tid=660 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:684)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1388/1874810059.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 95 on default port 15002" daemon prio=5 tid=348 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"JvmPauseMonitor1" daemon prio=5 tid=392 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$554/718511919.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 15002" daemon prio=5 tid=267 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-server-thread2" daemon prio=5 tid=1185 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-worker-ELG-3-3" daemon prio=5 tid=859 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:312)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:376)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 15001" daemon prio=5 tid=153 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 52 on default port 15009" daemon prio=5 tid=523 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 29 on default port 15002" daemon prio=5 tid=282 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-220-thread-1"  prio=5 tid=694 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=663 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 79 on default port 15002" daemon prio=5 tid=332 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerMetadataScanner" daemon prio=5 tid=729 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server handler 59 on default port 15009" daemon prio=5 tid=530 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-ChunkWriter-2-0" daemon prio=5 tid=771 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor0" daemon prio=5 tid=355 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$554/718511919.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 89 on default port 15001" daemon prio=5 tid=242 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-DatanodeStateMachineTaskThread-0"  prio=5 tid=689 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 83 on default port 15002" daemon prio=5 tid=336 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 10 on default port 15004" daemon prio=5 tid=424 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 60 on default port 15000" daemon prio=5 tid=113 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 91 on default port 15009" daemon prio=5 tid=562 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-EventQueue-StaleNodeForReconStaleNodeHandler" daemon prio=5 tid=832 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=50 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 83 on default port 15009" daemon prio=5 tid=554 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp439694398-361" daemon prio=5 tid=361 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-DatanodeCommandForSCMNodeManager"  prio=5 tid=824 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 15001" daemon prio=5 tid=165 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-cacheEviction-AwaitToRun" daemon prio=5 tid=1157 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 15001" daemon prio=5 tid=156 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server listener on 15039" daemon prio=5 tid=676 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/data-0/hdds)" daemon prio=5 tid=806 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-DatanodeStateMachineDaemonThread" daemon prio=5 tid=682 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:369)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:556)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1386/996581381.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-PeriodicHDDSVolumeChecker" daemon prio=5 tid=802 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 15030" daemon prio=5 tid=653 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=758 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/data-0/hdds)" daemon prio=5 tid=730 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server handler 62 on default port 15009" daemon prio=5 tid=533 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderStateImpl" daemon prio=5 tid=935 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:762)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-ChunkWriter-0-0" daemon prio=5 tid=750 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-BlockDeletingService#2" daemon prio=5 tid=1195 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 15009" daemon prio=5 tid=445 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-ChunkWriter-2-0" daemon prio=5 tid=752 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-BlockDeletingService#1" daemon prio=5 tid=778 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 15009"  prio=5 tid=444 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"a568c6b4-1a28-494a-b080-2324592b3a72-DatanodeReportManager-3" daemon prio=5 tid=602 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 56 on default port 15002" daemon prio=5 tid=309 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerMetadataScanner" daemon prio=5 tid=786 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server handler 4 on default port 15004" daemon prio=5 tid=418 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 23 on default port 15002" daemon prio=5 tid=276 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule" daemon prio=5 tid=819 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1908051795-410" daemon prio=5 tid=410 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 76 on default port 15009" daemon prio=5 tid=547 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15000"  prio=5 tid=38 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 1 on default port 15000" daemon prio=5 tid=54 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"NetworkTopologyPoller" daemon prio=5 tid=396 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=799 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 15009" daemon prio=5 tid=478 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 41 on default port 15009" daemon prio=5 tid=512 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Session-HouseKeeper-6e18bc2f-1"  prio=5 tid=365 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 15002" daemon prio=5 tid=272 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp671888763-585-acceptor-0@72a78124-ServerConnector@3e21253f{HTTP/1.1, (http/1.1)}{0.0.0.0:15011}" daemon prio=3 tid=585 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 25 on default port 15009" daemon prio=5 tid=496 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 72 on default port 15001" daemon prio=5 tid=225 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 53 on default port 15001" daemon prio=5 tid=206 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 17 on default port 15009" daemon prio=5 tid=488 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=762 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-StateMachineUpdater" daemon prio=5 tid=1153 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.lang.Thread.run(Thread.java:750)
"a568c6b4-1a28-494a-b080-2324592b3a72-ChunkWriter-2-0" daemon prio=5 tid=733 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SSL Certificates Store Monitor" daemon prio=5 tid=1081 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"om1-DirectoryDeletingService#0" daemon prio=5 tid=398 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-SnapshotDiffCleanupService#0" daemon prio=5 tid=372 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=384 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"qtp671888763-586" daemon prio=5 tid=586 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 15004" daemon prio=5 tid=381 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/data-0/hdds)" daemon prio=5 tid=787 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"qtp729326364-667" daemon prio=5 tid=667 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 59 on default port 15001" daemon prio=5 tid=212 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-ChunkWriter-3-0" daemon prio=5 tid=753 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-cacheEviction-AwaitToRun" daemon prio=5 tid=1150 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.lang.Thread.run(Thread.java:750)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-PeriodicHDDSVolumeChecker" daemon prio=5 tid=783 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=814 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 26 on default port 15009" daemon prio=5 tid=497 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=829 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 15001" daemon prio=5 tid=163 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-StateMachineUpdater" daemon prio=5 tid=1138 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.lang.Thread.run(Thread.java:750)
"qtp1443696949-645" daemon prio=5 tid=645 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 15004" daemon prio=5 tid=420 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp439694398-363" daemon prio=5 tid=363 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 81 on default port 15001" daemon prio=5 tid=234 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=46 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=738 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 46 on default port 15009" daemon prio=5 tid=517 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 50 on default port 15002" daemon prio=5 tid=303 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-StateMachineUpdater" daemon prio=5 tid=892 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.lang.Thread.run(Thread.java:750)
"qtp1443696949-639" daemon prio=5 tid=639 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Connector-Scheduler-47bd0384-1"  prio=5 tid=964 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-177-thread-1" daemon prio=5 tid=785 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-OMStateMachineApplyTransactionThread - 0" daemon prio=5 tid=938 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 71 on default port 15001" daemon prio=5 tid=224 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=623 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"IPC Server handler 70 on default port 15009" daemon prio=5 tid=541 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-66-thread-1"  prio=5 tid=404 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-BlockDeletingService#1" daemon prio=5 tid=797 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"main"  prio=5 tid=1 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.Thread.dumpThreads(Native Method)
        at java.lang.Thread.getAllStackTraces(Thread.java:1615)
        at org.apache.ozone.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:83)
        at org.apache.ozone.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:69)
        at org.apache.ozone.test.TimedOutTestsListener.lambda$executionFinished$0(TimedOutTestsListener.java:55)
        at org.apache.ozone.test.TimedOutTestsListener$$Lambda$2396/1951917964.accept(Unknown Source)
        at java.util.Optional.ifPresent(Optional.java:159)
        at org.apache.ozone.test.TimedOutTestsListener.executionFinished(TimedOutTestsListener.java:51)
        at org.junit.platform.launcher.core.CompositeTestExecutionListener.lambda$executionFinished$10(CompositeTestExecutionListener.java:73)
        at org.junit.platform.launcher.core.CompositeTestExecutionListener$$Lambda$2360/57499447.accept(Unknown Source)
        at org.junit.platform.launcher.core.CompositeTestExecutionListener.lambda$notifyEach$19(CompositeTestExecutionListener.java:102)
        at org.junit.platform.launcher.core.CompositeTestExecutionListener$$Lambda$247/1687087217.accept(Unknown Source)
        at org.junit.platform.commons.util.CollectionUtils.forEachInReverseOrder(CollectionUtils.java:221)
        at org.junit.platform.launcher.core.IterationOrder$2.forEach(IterationOrder.java:30)
        at org.junit.platform.launcher.core.CompositeTestExecutionListener.notifyEach(CompositeTestExecutionListener.java:100)
        at org.junit.platform.launcher.core.CompositeTestExecutionListener.executionFinished(CompositeTestExecutionListener.java:72)
        at org.junit.platform.launcher.core.ExecutionListenerAdapter.executionFinished(ExecutionListenerAdapter.java:56)
        at org.junit.platform.launcher.core.CompositeEngineExecutionListener.lambda$executionFinished$6(CompositeEngineExecutionListener.java:59)
        at org.junit.platform.launcher.core.CompositeEngineExecutionListener$$Lambda$2351/251162624.accept(Unknown Source)
        at org.junit.platform.launcher.core.CompositeEngineExecutionListener.lambda$notifyEach$11(CompositeEngineExecutionListener.java:74)
        at org.junit.platform.launcher.core.CompositeEngineExecutionListener$$Lambda$296/61814127.accept(Unknown Source)
        at org.junit.platform.commons.util.CollectionUtils.forEachInReverseOrder(CollectionUtils.java:221)
        at org.junit.platform.launcher.core.IterationOrder$2.forEach(IterationOrder.java:30)
        at org.junit.platform.launcher.core.CompositeEngineExecutionListener.notifyEach(CompositeEngineExecutionListener.java:72)
        at org.junit.platform.launcher.core.CompositeEngineExecutionListener.executionFinished(CompositeEngineExecutionListener.java:58)
        at org.junit.platform.launcher.core.DelegatingEngineExecutionListener.executionFinished(DelegatingEngineExecutionListener.java:46)
        at org.junit.platform.launcher.core.StackTracePruningEngineExecutionListener.executionFinished(StackTracePruningEngineExecutionListener.java:46)
        at org.junit.platform.launcher.core.DelegatingEngineExecutionListener.executionFinished(DelegatingEngineExecutionListener.java:46)
        at org.junit.platform.launcher.core.OutcomeDelayingEngineExecutionListener.executionFinished(OutcomeDelayingEngineExecutionListener.java:63)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.reportCompletion(NodeTestTask.java:195)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:226)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:204)
        at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:142)
        at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.lambda$execute$2(TestTemplateTestDescriptor.java:110)
        at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor$$Lambda$2086/1582099675.accept(Unknown Source)
        at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)
        at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:647)
        at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:272)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)
        at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
        at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
        at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
        at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
        at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
        at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
        at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:272)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384)
        at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
        at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
        at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
        at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
        at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
        at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
        at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:272)
        at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384)
        at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
        at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
        at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
        at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
        at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
        at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
        at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:110)
        at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:44)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$317/2054077982.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$316/1098737173.invoke(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$315/1476061571.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService$$Lambda$321/1220813917.accept(Unknown Source)
        at java.util.ArrayList.forEach(ArrayList.java:1259)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$317/2054077982.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$316/1098737173.invoke(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$315/1476061571.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService$$Lambda$321/1220813917.accept(Unknown Source)
        at java.util.ArrayList.forEach(ArrayList.java:1259)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$317/2054077982.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$316/1098737173.invoke(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$315/1476061571.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
        at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
        at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:198)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:169)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:93)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:58)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator$$Lambda$235/1720746883.accept(Unknown Source)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:141)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:57)
        at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:103)
        at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:85)
        at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
        at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:63)
        at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
        at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
        at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
        at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-ChunkReader-ELG-0" daemon prio=5 tid=793 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 15004" daemon prio=5 tid=428 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 47 on default port 15009" daemon prio=5 tid=518 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1-SnapshotDeletingService#0" daemon prio=5 tid=401 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 61 on default port 15001" daemon prio=5 tid=214 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 58 on default port 15009" daemon prio=5 tid=529 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15048"  prio=5 tid=705 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-ReplicationContainerReader-0" daemon prio=5 tid=1105 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SSL Certificates Store Monitor" daemon prio=5 tid=1133 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 0 on default port 15002" daemon prio=5 tid=253 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=607 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-PipelineCommandHandlerThread-0"  prio=5 tid=875 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp911539378-614" daemon prio=5 tid=614 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-ChunkWriter-3-0" daemon prio=5 tid=772 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Recon-FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=452 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SSL Certificates Store Monitor" daemon prio=5 tid=1131 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 34 on default port 15001" daemon prio=5 tid=187 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Session-HouseKeeper-62a83af9-1"  prio=5 tid=703 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp439694398-359" daemon prio=5 tid=359 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-cacheEviction-AwaitToRun" daemon prio=5 tid=1139 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.lang.Thread.run(Thread.java:750)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-DatanodeStateMachineTaskThread-1"  prio=5 tid=798 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-DatanodeCommandQueueUpdatedForDatanodeCommandCountUpdatedHandler" daemon prio=5 tid=827 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a568c6b4-1a28-494a-b080-2324592b3a72-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=579 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-0" daemon prio=5 tid=856 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SSL Certificates Store Monitor" daemon prio=5 tid=1130 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 36 on default port 15001" daemon prio=5 tid=189 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp2022138586-696" daemon prio=5 tid=696 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache-Cleanup-0" daemon prio=5 tid=943 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 29 on default port 15001" daemon prio=5 tid=182 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 88 on default port 15000" daemon prio=5 tid=141 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp911539378-615" daemon prio=5 tid=615 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 58 on default port 15002" daemon prio=5 tid=311 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 63 on default port 15000" daemon prio=5 tid=116 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-BlockDeletingService#0" daemon prio=5 tid=794 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 67 on default port 15009" daemon prio=5 tid=538 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=451 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 15000" daemon prio=5 tid=58 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1908051795-406" daemon prio=5 tid=406 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule" daemon prio=5 tid=821 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=680 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Parameter Sending Thread for localhost/127.0.0.1:15004" daemon prio=5 tid=967 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferQueue.awaitFulfill(SynchronousQueue.java:764)
        at java.util.concurrent.SynchronousQueue$TransferQueue.transfer(SynchronousQueue.java:695)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1105)
        at java.lang.Thread.run(Thread.java:750)
"a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-StateMachineUpdater" daemon prio=5 tid=1142 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.lang.Thread.run(Thread.java:750)
"SSL Certificates Store Monitor" daemon prio=5 tid=1128 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server Responder" daemon prio=5 tid=35 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"qtp850601250-465" daemon prio=5 tid=465 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp439694398-364" daemon prio=5 tid=364 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 15000" daemon prio=5 tid=55 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-CommandProcessorThread" daemon prio=5 tid=688 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:684)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1388/1874810059.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForPipelineReportHandler" daemon prio=5 tid=823 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 15002" daemon prio=5 tid=262 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SSL Certificates Store Monitor" daemon prio=5 tid=440 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"qtp2022138586-702" daemon prio=5 tid=702 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 58 on default port 15001" daemon prio=5 tid=211 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 7 on default port 15002" daemon prio=5 tid=260 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderStateImpl" daemon prio=5 tid=931 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:762)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-ChunkWriter-1-0" daemon prio=5 tid=751 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 99 on default port 15009" daemon prio=5 tid=570 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-DatanodeReportManager-1" daemon prio=5 tid=628 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 28 on default port 15002" daemon prio=5 tid=281 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 67 on default port 15002" daemon prio=5 tid=320 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 50 on default port 15000" daemon prio=5 tid=103 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 97 on default port 15001" daemon prio=5 tid=250 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1908051795-412" daemon prio=5 tid=412 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"a568c6b4-1a28-494a-b080-2324592b3a72-CloseContainerThread-1"  prio=5 tid=1057 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 63 on default port 15009" daemon prio=5 tid=534 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-ChunkWriter-0-0" daemon prio=5 tid=788 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 72 on default port 15009" daemon prio=5 tid=543 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-ChunkReader-ELG-0" daemon prio=5 tid=774 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"pool-33-thread-1"  prio=5 tid=1055 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp671888763-587" daemon prio=5 tid=587 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 48 on default port 15002" daemon prio=5 tid=301 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server listener on 15001" daemon prio=5 tid=32 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-cacheEviction-AwaitToRun" daemon prio=5 tid=871 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 71 on default port 15000" daemon prio=5 tid=124 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-boss-ELG-1-1" daemon prio=5 tid=391 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"qtp2022138586-701" daemon prio=5 tid=701 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 15000" daemon prio=5 tid=57 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 26 on default port 15001" daemon prio=5 tid=179 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-BlockDeletingService#1" daemon prio=5 tid=759 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=385 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1443696949-644" daemon prio=5 tid=644 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=40 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"FullTableCache-Cleanup-0" daemon prio=5 tid=940 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 44 on default port 15000" daemon prio=5 tid=97 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-EventQueue-NewNodeForReconNewNodeHandler" daemon prio=5 tid=818 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-BlockDeletingService#0" daemon prio=5 tid=756 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=44 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DatanodeAdminManager-0" daemon prio=5 tid=25 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-ChunkWriter-1-0" daemon prio=5 tid=770 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=743 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-DatanodeReportManager-3" daemon prio=5 tid=630 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 71 on default port 15009" daemon prio=5 tid=542 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 8 on default port 15004" daemon prio=5 tid=422 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 57 on default port 15000" daemon prio=5 tid=110 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 39 on default port 15002" daemon prio=5 tid=292 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=455 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=624 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=817 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 98 on default port 15000" daemon prio=5 tid=151 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@5d2a4c69" daemon prio=5 tid=609 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 15001" daemon prio=5 tid=164 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 33 on default port 15000" daemon prio=5 tid=86 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-DatanodeReportManager-1" daemon prio=5 tid=684 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-groupManagement"  prio=5 tid=853 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 15009" daemon prio=5 tid=490 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 94 on default port 15009" daemon prio=5 tid=565 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 48 on default port 15001" daemon prio=5 tid=201 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-ChunkWriter-1-0" daemon prio=5 tid=789 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-DatanodeStateMachineTaskThread-1"  prio=5 tid=779 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 93 on default port 15009" daemon prio=5 tid=564 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a568c6b4-1a28-494a-b080-2324592b3a72-DatanodeStateMachineTaskThread-1"  prio=5 tid=718 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 61 on default port 15009" daemon prio=5 tid=532 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Client (1615502727) connection to localhost/127.0.0.1:15004 from runner" daemon prio=5 tid=966 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1026)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1077)
"SCMHeartbeatProcessor-0" daemon prio=5 tid=18 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 15002" daemon prio=5 tid=256 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Session-HouseKeeper-57c175f0-1"  prio=5 tid=413 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-OMDoubleBufferFlushThread" daemon prio=5 tid=374 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.canFlush(OzoneManagerDoubleBuffer.java:570)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.flushTransactions(OzoneManagerDoubleBuffer.java:294)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer$$Lambda$707/691941729.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 47 on default port 15000" daemon prio=5 tid=100 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 23 on default port 15009" daemon prio=5 tid=494 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-DatanodeReportManager-2" daemon prio=5 tid=713 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 82 on default port 15002" daemon prio=5 tid=335 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp439694398-362" daemon prio=5 tid=362 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Timer for 'StorageContainerManager' metrics system" daemon prio=5 tid=52 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server listener on 15030" daemon prio=5 tid=648 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"UnderReplicatedProcessor" daemon prio=5 tid=23 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:174)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@25acc9dd" daemon prio=5 tid=665 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.lang.Thread.run(Thread.java:750)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-PipelineCommandHandlerThread-0"  prio=5 tid=869 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=776 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 54 on default port 15001" daemon prio=5 tid=207 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp671888763-590" daemon prio=5 tid=590 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor6" daemon prio=5 tid=792 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$554/718511919.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 42 on default port 15009" daemon prio=5 tid=513 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 71 on default port 15002" daemon prio=5 tid=324 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 57 on default port 15009" daemon prio=5 tid=528 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a568c6b4-1a28-494a-b080-2324592b3a72-ChunkWriter-0-0" daemon prio=5 tid=731 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-DatanodeReportManager-1" daemon prio=5 tid=712 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 78 on default port 15009" daemon prio=5 tid=549 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=780 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=652 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 15001" daemon prio=5 tid=157 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 84 on default port 15002" daemon prio=5 tid=337 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 64 on default port 15002" daemon prio=5 tid=317 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 20 on default port 15001" daemon prio=5 tid=173 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 80 on default port 15001" daemon prio=5 tid=233 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-CloseContainerForCloseContainerEventHandler" daemon prio=5 tid=1054 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 15001" daemon prio=5 tid=168 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 54 on default port 15009" daemon prio=5 tid=525 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 82 on default port 15001" daemon prio=5 tid=235 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 50 on default port 15009" daemon prio=5 tid=521 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 46 on default port 15001" daemon prio=5 tid=199 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 53 on default port 15000" daemon prio=5 tid=106 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 77 on default port 15002" daemon prio=5 tid=330 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 37 on default port 15002" daemon prio=5 tid=290 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 29 on default port 15009" daemon prio=5 tid=500 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=800 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 15009" daemon prio=5 tid=482 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 93 on default port 15001" daemon prio=5 tid=246 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 51 on default port 15001" daemon prio=5 tid=204 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-server-thread1" daemon prio=5 tid=1184 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 60 on default port 15002" daemon prio=5 tid=313 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15001"  prio=5 tid=33 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 66 on default port 15000" daemon prio=5 tid=119 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-CloseContainerThread-0"  prio=5 tid=1067 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=742 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-groupManagement"  prio=5 tid=843 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 85 on default port 15000" daemon prio=5 tid=138 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-groupManagement"  prio=5 tid=870 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a568c6b4-1a28-494a-b080-2324592b3a72-CloseContainerThread-0"  prio=5 tid=1056 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 15001" daemon prio=5 tid=171 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 69 on default port 15002" daemon prio=5 tid=322 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1443696949-643" daemon prio=5 tid=643 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=781 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 32 on default port 15001" daemon prio=5 tid=185 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 38 on default port 15009" daemon prio=5 tid=509 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 86 on default port 15000" daemon prio=5 tid=139 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule" daemon prio=5 tid=822 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1443696949-646" daemon prio=5 tid=646 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 15039" daemon prio=5 tid=678 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 38 on default port 15000" daemon prio=5 tid=91 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a568c6b4-1a28-494a-b080-2324592b3a72-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=719 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 76 on default port 15001" daemon prio=5 tid=229 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 30 on default port 15002" daemon prio=5 tid=283 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-ChunkWriter-3-0" daemon prio=5 tid=810 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"derby.rawStoreDaemon" daemon prio=5 tid=436 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.derby.impl.services.daemon.BasicDaemon.rest(Unknown Source)
        at org.apache.derby.impl.services.daemon.BasicDaemon.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 63 on default port 15001" daemon prio=5 tid=216 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Timer-0"  prio=5 tid=393 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler" daemon prio=5 tid=1053 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 15009" daemon prio=5 tid=486 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"JvmPauseMonitor4" daemon prio=5 tid=754 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$554/718511919.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 38 on default port 15001" daemon prio=5 tid=191 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp729326364-673" daemon prio=5 tid=673 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp2022138586-700" daemon prio=5 tid=700 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 15004" daemon prio=5 tid=425 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 15 on default port 15004" daemon prio=5 tid=429 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-203-thread-1" daemon prio=5 tid=804 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 51 on default port 15000" daemon prio=5 tid=104 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 68 on default port 15002" daemon prio=5 tid=321 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server idle connection scanner for port 15021" daemon prio=5 tid=622 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@6f7e46ea" daemon prio=5 tid=581 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 15002" daemon prio=5 tid=270 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=828 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 92 on default port 15002" daemon prio=5 tid=345 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-SegmentedRaftLogWorker"  prio=5 tid=890 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$917/527921443.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SCMHeartbeatProcessor-0" daemon prio=5 tid=442 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2022138586-698" daemon prio=5 tid=698 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 15009" daemon prio=5 tid=443 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"a568c6b4-1a28-494a-b080-2324592b3a72-DatanodeReportManager-1" daemon prio=5 tid=600 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 38 on default port 15002" daemon prio=5 tid=291 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a568c6b4-1a28-494a-b080-2324592b3a72-DatanodeStateMachineTaskThread-0"  prio=5 tid=605 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 15004" daemon prio=5 tid=423 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 31 on default port 15000" daemon prio=5 tid=84 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 61 on default port 15000" daemon prio=5 tid=114 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Finalizer" daemon prio=8 tid=3 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:188)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-DatanodeStateMachineTaskThread-0"  prio=5 tid=661 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-DatanodeReportManager-3" daemon prio=5 tid=658 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=30 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"IPC Server handler 24 on default port 15000" daemon prio=5 tid=77 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 85 on default port 15009" daemon prio=5 tid=556 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 62 on default port 15001" daemon prio=5 tid=215 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-SegmentedRaftLogWorker"  prio=5 tid=1136 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$917/527921443.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 33 on default port 15002" daemon prio=5 tid=286 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"prometheus" daemon prio=5 tid=366 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.hadoop.metrics2.impl.SinkQueue.waitForData(SinkQueue.java:114)
        at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:83)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:135)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:89)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-CommandProcessorThread" daemon prio=5 tid=632 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:684)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1388/1874810059.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-CloseContainerThread-0"  prio=5 tid=1058 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 15021" daemon prio=5 tid=625 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 81 on default port 15002" daemon prio=5 tid=334 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-DatanodeReportManager-2" daemon prio=5 tid=629 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-SegmentedRaftLogWorker"  prio=5 tid=1151 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$917/527921443.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-99-thread-1" daemon prio=5 tid=728 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 21 on default port 15009" daemon prio=5 tid=492 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-BlockDeletingService#2" daemon prio=5 tid=1199 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 66 on default port 15002" daemon prio=5 tid=319 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 34 on default port 15009" daemon prio=5 tid=505 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp729326364-669" daemon prio=5 tid=669 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 15004" daemon prio=5 tid=414 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 90 on default port 15002" daemon prio=5 tid=343 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 49 on default port 15002" daemon prio=5 tid=302 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 82 on default port 15000" daemon prio=5 tid=135 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp729326364-672" daemon prio=5 tid=672 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-PipelineCommandHandlerThread-0"  prio=5 tid=852 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerSizeCountTask" daemon prio=5 tid=571 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ozone.recon.tasks.ContainerSizeCountTask.run(ContainerSizeCountTask.java:94)
        at org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda$1299/1127738540.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=795 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 95 on default port 15009" daemon prio=5 tid=566 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 43 on default port 15002" daemon prio=5 tid=296 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 98 on default port 15002" daemon prio=5 tid=351 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 69 on default port 15000" daemon prio=5 tid=122 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 46 on default port 15002" daemon prio=5 tid=299 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 18 on default port 15002" daemon prio=5 tid=271 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 24 on default port 15001" daemon prio=5 tid=177 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1908051795-409" daemon prio=5 tid=409 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 69 on default port 15001" daemon prio=5 tid=222 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 52 on default port 15001" daemon prio=5 tid=205 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-PeriodicHDDSVolumeChecker" daemon prio=5 tid=745 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 67 on default port 15001" daemon prio=5 tid=220 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 49 on default port 15009" daemon prio=5 tid=520 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 8 on default port 15000" daemon prio=5 tid=61 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 9 on default port 15000" daemon prio=5 tid=62 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 50 on default port 15001" daemon prio=5 tid=203 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler" daemon prio=5 tid=1048 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 15002" daemon prio=5 tid=261 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 70 on default port 15002" daemon prio=5 tid=323 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-DatanodeReportManager-1" daemon prio=5 tid=656 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 83 on default port 15000" daemon prio=5 tid=136 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a568c6b4-1a28-494a-b080-2324592b3a72-ChunkWriter-1-0" daemon prio=5 tid=732 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 35 on default port 15002" daemon prio=5 tid=288 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 45 on default port 15001" daemon prio=5 tid=198 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 42 on default port 15001" daemon prio=5 tid=195 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 87 on default port 15009" daemon prio=5 tid=558 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=42 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 99 on default port 15001" daemon prio=5 tid=252 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=447 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 35 on default port 15001" daemon prio=5 tid=188 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-DatanodeStateMachineDaemonThread" daemon prio=5 tid=710 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:369)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:556)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1386/996581381.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 53 on default port 15002" daemon prio=5 tid=306 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerMetadataScanner" daemon prio=5 tid=767 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"OverReplicatedProcessor" daemon prio=5 tid=24 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:174)
        at java.lang.Thread.run(Thread.java:750)
"timer1" daemon prio=5 tid=920 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a-DatanodeReportManager-3" daemon prio=5 tid=714 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 46 on default port 15000" daemon prio=5 tid=99 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=43 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-3" daemon prio=5 tid=909 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 15009" daemon prio=5 tid=487 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 89 on default port 15002" daemon prio=5 tid=342 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 79 on default port 15000" daemon prio=5 tid=132 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-DatanodeStateMachineDaemonThread" daemon prio=5 tid=654 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:369)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:556)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1386/996581381.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"timer4" daemon prio=5 tid=929 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 56 on default port 15001" daemon prio=5 tid=209 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=449 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-DatanodeReportManager-3" daemon prio=5 tid=686 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 15012" daemon prio=5 tid=597 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 43 on default port 15001" daemon prio=5 tid=196 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SCMBlockDeletingService#0" daemon prio=5 tid=353 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1198 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 48 on default port 15009" daemon prio=5 tid=519 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 9 on default port 15009" daemon prio=5 tid=480 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-SegmentedRaftLogWorker"  prio=5 tid=1165 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$917/527921443.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderStateImpl" daemon prio=5 tid=1149 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:762)
"IPC Server handler 75 on default port 15001" daemon prio=5 tid=228 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-FollowerState" daemon prio=5 tid=1179 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"ContainerMetadataScanner" daemon prio=5 tid=805 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server handler 82 on default port 15009" daemon prio=5 tid=553 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp729326364-674" daemon prio=5 tid=674 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 95 on default port 15001" daemon prio=5 tid=248 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp850601250-461" daemon prio=5 tid=461 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/data-0/hdds)" daemon prio=5 tid=768 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"a568c6b4-1a28-494a-b080-2324592b3a72-ChunkWriter-3-0" daemon prio=5 tid=734 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 58 on default port 15000" daemon prio=5 tid=111 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15039" daemon prio=5 tid=681 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp911539378-613-acceptor-0@3b39eb35-ServerConnector@3823c031{HTTP/1.1, (http/1.1)}{0.0.0.0:15020}" daemon prio=3 tid=613 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 26 on default port 15002" daemon prio=5 tid=279 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 91 on default port 15001" daemon prio=5 tid=244 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 5 on default port 15004" daemon prio=5 tid=419 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 84 on default port 15000" daemon prio=5 tid=137 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 22 on default port 15002" daemon prio=5 tid=275 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-73-thread-1"  prio=5 tid=439 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 15001" daemon prio=5 tid=155 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-DatanodeStateMachineDaemonThread" daemon prio=5 tid=626 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:369)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:556)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1386/996581381.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 15009" daemon prio=5 tid=475 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SSL Certificates Store Monitor" daemon prio=5 tid=1052 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-ChunkWriter-0-0" daemon prio=5 tid=769 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-DatanodeStateMachineTaskThread-0"  prio=5 tid=633 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a568c6b4-1a28-494a-b080-2324592b3a72-groupManagement"  prio=5 tid=831 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 15021"  prio=5 tid=621 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 22 on default port 15001" daemon prio=5 tid=175 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp911539378-617" daemon prio=5 tid=617 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-1" daemon prio=5 tid=857 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 15021" daemon prio=5 tid=620 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 96 on default port 15001" daemon prio=5 tid=249 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=49 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-server-thread3" daemon prio=5 tid=1187 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 75 on default port 15000" daemon prio=5 tid=128 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"timer6" daemon prio=5 tid=949 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 36 on default port 15000" daemon prio=5 tid=89 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp671888763-583" daemon prio=5 tid=583 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=761 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 15000" daemon prio=5 tid=60 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SSL Certificates Store Monitor" daemon prio=5 tid=963 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 77 on default port 15009" daemon prio=5 tid=548 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-cacheEviction-AwaitToRun" daemon prio=5 tid=1161 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.lang.Thread.run(Thread.java:750)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-CloseContainerThread-2"  prio=5 tid=1069 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SSL Certificates Store Monitor" daemon prio=5 tid=1083 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"om1@group-C5BA1605619E-SegmentedRaftLogWorker"  prio=5 tid=388 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$917/527921443.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1443696949-642" daemon prio=5 tid=642 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 15000" daemon prio=5 tid=66 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 96 on default port 15009" daemon prio=5 tid=567 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=815 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 54 on default port 15000" daemon prio=5 tid=107 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 49 on default port 15000" daemon prio=5 tid=102 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 5 on default port 15002" daemon prio=5 tid=258 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Client (1615502727) connection to 0.0.0.0/0.0.0.0:15009 from runner" daemon prio=5 tid=723 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1026)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1077)
"qtp671888763-589" daemon prio=5 tid=589 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 15009" daemon prio=5 tid=472 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 18 on default port 15000" daemon prio=5 tid=71 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 33 on default port 15001" daemon prio=5 tid=186 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 72 on default port 15000" daemon prio=5 tid=125 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp850601250-460-acceptor-0@22ce651f-ServerConnector@47bd0384{HTTP/1.1, (http/1.1)}{0.0.0.0:15008}" daemon prio=3 tid=460 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 15001" daemon prio=5 tid=172 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 22 on default port 15000" daemon prio=5 tid=75 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp911539378-612" daemon prio=5 tid=612 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 25 on default port 15001" daemon prio=5 tid=178 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 56 on default port 15009" daemon prio=5 tid=527 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-StateMachineUpdater" daemon prio=5 tid=1160 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 49 on default port 15001" daemon prio=5 tid=202 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 80 on default port 15000" daemon prio=5 tid=133 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 69 on default port 15009" daemon prio=5 tid=540 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 24 on default port 15009" daemon prio=5 tid=495 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 3 on default port 15000" daemon prio=5 tid=56 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp850601250-458" daemon prio=5 tid=458 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Parameter Sending Thread for 0.0.0.0/0.0.0.0:15002" daemon prio=5 tid=722 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferQueue.awaitFulfill(SynchronousQueue.java:764)
        at java.util.concurrent.SynchronousQueue$TransferQueue.transfer(SynchronousQueue.java:695)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1105)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 15009" daemon prio=5 tid=476 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=454 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 45 on default port 15000" daemon prio=5 tid=98 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/data-0/hdds)" daemon prio=5 tid=749 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server handler 39 on default port 15000" daemon prio=5 tid=92 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 28 on default port 15000" daemon prio=5 tid=81 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1-SstFilteringService#0" daemon prio=5 tid=400 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 74 on default port 15000" daemon prio=5 tid=127 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 97 on default port 15009" daemon prio=5 tid=568 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 94 on default port 15001" daemon prio=5 tid=247 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=457 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 39 on default port 15001" daemon prio=5 tid=192 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6e65d581-b1bc-41f2-b39b-16d8508d6618-server-thread2" daemon prio=5 tid=1188 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=595 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"IPC Server handler 42 on default port 15000" daemon prio=5 tid=95 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Signal Dispatcher" daemon prio=9 tid=4 runnable
java.lang.Thread.State: RUNNABLE
"timer3" daemon prio=5 tid=926 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 90 on default port 15001" daemon prio=5 tid=243 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=41 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 34 on default port 15000" daemon prio=5 tid=87 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 55 on default port 15001" daemon prio=5 tid=208 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-151-thread-1" daemon prio=5 tid=766 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 15012"  prio=5 tid=593 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 37 on default port 15009" daemon prio=5 tid=508 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 10 on default port 15009" daemon prio=5 tid=481 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 18 on default port 15004" daemon prio=5 tid=432 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 1 on default port 15001" daemon prio=5 tid=154 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-SegmentedRaftLogWorker"  prio=5 tid=1158 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$917/527921443.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 15000" daemon prio=5 tid=37 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 28 on default port 15009" daemon prio=5 tid=499 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp439694398-357" daemon prio=5 tid=357 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$594/402497467.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"pool-116-thread-1"  prio=5 tid=582 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 15000" daemon prio=5 tid=39 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp850601250-463" daemon prio=5 tid=463 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.reservedWait(ReservedThreadExecutor.java:324)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:399)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 15030" daemon prio=5 tid=650 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 78 on default port 15002" daemon prio=5 tid=331 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-34-thread-1"  prio=5 tid=356 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer0" daemon prio=5 tid=951 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"grpc-default-worker-ELG-3-2" daemon prio=5 tid=855 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:312)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:376)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"ReconTaskThread-0"  prio=5 tid=1042 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 15048" daemon prio=5 tid=709 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15030"  prio=5 tid=649 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server idle connection scanner for port 15048" daemon prio=5 tid=706 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 35 on default port 15009" daemon prio=5 tid=506 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 98 on default port 15001" daemon prio=5 tid=251 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-CloseContainerThread-1"  prio=5 tid=1059 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 47 on default port 15001" daemon prio=5 tid=200 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a6fb26e7-f548-473f-8cf0-48fafe70504d-CloseContainerThread-2"  prio=5 tid=1060 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 86 on default port 15002" daemon prio=5 tid=339 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=796 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 37 on default port 15000" daemon prio=5 tid=90 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 43 on default port 15000" daemon prio=5 tid=96 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 8 on default port 15009" daemon prio=5 tid=479 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 30 on default port 15009" daemon prio=5 tid=501 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"f8c0ec26-9898-49d2-a0ea-132d14d0dc83-CloseContainerThread-1"  prio=5 tid=1068 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 24 on default port 15002" daemon prio=5 tid=277 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 56 on default port 15000" daemon prio=5 tid=109 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server idle connection scanner for port 15004" daemon prio=5 tid=383 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 8 on default port 15001" daemon prio=5 tid=161 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderStateImpl" daemon prio=5 tid=1181 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:762)
"IPC Server handler 78 on default port 15001" daemon prio=5 tid=231 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)

2024-03-25 19:43:31,657 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:addNewContainer(246)) - Successfully added container #2 to Recon.
2024-03-25 19:43:31,658 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 15 millisec, 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27), {type: ICR, size: 1}
Connecting to Recon: http://0.0.0.0:15008/api/v1/triggerdbsync/om ...
2024-03-25 19:43:31,694 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:31,695 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:31,695 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-03-25 19:43:31,711 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 2, SequenceNumber diff: 7, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:31,712 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 7 records
2024-03-25 19:43:31,787 [ReconTaskThread-0] INFO  tasks.OmTableInsightTask (OmTableInsightTask.java:process(211)) - Completed a 'process' run of OmTableInsightTask.
2024-03-25 19:43:31,791 [ReconTaskThread-0] INFO  tasks.NSSummaryTaskWithFSO (NSSummaryTaskWithFSO.java:processWithFSO(165)) - Completed a process run of NSSummaryTaskWithFSO
2024-03-25 19:43:31,791 [ReconTaskThread-0] INFO  tasks.NSSummaryTaskWithLegacy (NSSummaryTaskWithLegacy.java:processWithLegacy(205)) - Completed a process run of NSSummaryTaskWithLegacy
2024-03-25 19:43:31,792 [ReconTaskThread-0] INFO  tasks.NSSummaryTaskWithOBS (NSSummaryTaskWithOBS.java:processWithOBS(206)) - Completed a process run of NSSummaryTaskWithOBS
2024-03-25 19:43:31,798 [ReconTaskThread-0] INFO  tasks.ContainerKeyMapperTask (ContainerKeyMapperTask.java:process(261)) - ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
2024-03-25 19:43:31,833 [ReconTaskThread-0] INFO  tasks.FileSizeCountTask (FileSizeCountTask.java:process(201)) - Completed a 'process' run of FileSizeCountTask.
2024-03-25 19:43:31,898 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:31,900 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 2 containers.
2024-03-25 19:43:31,900 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:31,900 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:31,900 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:31,900 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:31,900 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:31,900 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:31,900 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:32,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-03-25 19:43:32,705 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-03-25 19:43:32,705 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-03-25 19:43:32,706 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-03-25 19:43:32,706 [main] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/data-0/hdds) is shutting down. 
2024-03-25 19:43:32,707 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-03-25 19:43:32,707 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/data-0/hdds, DS-96cefe10-55c8-478c-92f7-334af2b965c5) exiting.
2024-03-25 19:43:32,708 [main] INFO  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:shutdownScanner(206)) - On-demand container scanner is shutting down.
2024-03-25 19:43:32,713 [main] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(416)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: close
2024-03-25 19:43:32,714 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29: shutdown
2024-03-25 19:43:32,714 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C: shutdown
2024-03-25 19:43:32,714 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-03-25 19:43:32,714 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-81169FADB40C,id=8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:43:32,714 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: shutdown 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-LeaderStateImpl
2024-03-25 19:43:32,714 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-PendingRequests: sendNotLeaderResponses
2024-03-25 19:43:32,714 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-13E9E73E6D29,id=8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:43:32,715 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: shutdown 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-LeaderStateImpl
2024-03-25 19:43:32,715 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-PendingRequests: sendNotLeaderResponses
2024-03-25 19:43:32,721 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29->6e65d581-b1bc-41f2-b39b-16d8508d6618-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29->6e65d581-b1bc-41f2-b39b-16d8508d6618-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-03-25 19:43:32,715 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29->a6fb26e7-f548-473f-8cf0-48fafe70504d-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29->a6fb26e7-f548-473f-8cf0-48fafe70504d-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-03-25 19:43:32,722 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: Completed APPEND_ENTRIES, lastRequest: null
2024-03-25 19:43:32,722 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "8de788e1-2c95-4c74-b4ac-29ea2448e86a"
  replyId: "6e65d581-b1bc-41f2-b39b-16d8508d6618"
  raftGroupId {
    id: "\215_}^\003\022I\026\2622\023\351\347>m)"
  }
  callId: 11
  success: true
}
term: 1
nextIndex: 1
matchIndex: 18446744073709551615
isHearbeat: true

2024-03-25 19:43:32,723 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-StateMachineUpdater: set stopIndex = 3
2024-03-25 19:43:32,723 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-81169FADB40C: Taking a snapshot at:(t:1, i:3) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/2db7f802-448f-42c5-98a7-81169fadb40c/sm/snapshot.1_3
2024-03-25 19:43:32,724 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: Completed APPEND_ENTRIES, lastRequest: null
2024-03-25 19:43:32,725 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "8de788e1-2c95-4c74-b4ac-29ea2448e86a"
  replyId: "a6fb26e7-f548-473f-8cf0-48fafe70504d"
  raftGroupId {
    id: "\215_}^\003\022I\026\2622\023\351\347>m)"
  }
  callId: 13
  success: true
}
term: 1
nextIndex: 1
matchIndex: 18446744073709551615
isHearbeat: true

2024-03-25 19:43:32,726 [grpc-default-executor-3] WARN  server.GrpcClientProtocolService (LogUtils.java:warn(121)) - 0-OrderedRequestStreamObserver0: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2024-03-25 19:43:32,727 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: Completed APPEND_ENTRIES, lastRequest: 8de788e1-2c95-4c74-b4ac-29ea2448e86a->6e65d581-b1bc-41f2-b39b-16d8508d6618#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "a6fb26e7-f548-473f-8cf0-48fafe70504d"
address: "10.1.0.27:15025"
dataStreamAddress: "10.1.0.27:15026"
clientAddress: "10.1.0.27:15023"
adminAddress: "10.1.0.27:15024"
startupRole: FOLLOWER
,id: "6e65d581-b1bc-41f2-b39b-16d8508d6618"
address: "10.1.0.27:15043"
dataStreamAddress: "10.1.0.27:15044"
clientAddress: "10.1.0.27:15041"
adminAddress: "10.1.0.27:15042"
startupRole: FOLLOWER
,id: "8de788e1-2c95-4c74-b4ac-29ea2448e86a"
address: "10.1.0.27:15052"
priority: 1
dataStreamAddress: "10.1.0.27:15053"
clientAddress: "10.1.0.27:15050"
adminAddress: "10.1.0.27:15051"
startupRole: FOLLOWER
, old:)
2024-03-25 19:43:32,727 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: Completed APPEND_ENTRIES, lastReply: null
2024-03-25 19:43:32,727 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-StateMachineUpdater: set stopIndex = 0
2024-03-25 19:43:32,727 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-13E9E73E6D29: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29/sm/snapshot.1_0
2024-03-25 19:43:32,728 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-13E9E73E6D29: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29/sm/snapshot.1_0 took: 0 ms
2024-03-25 19:43:32,728 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-StateMachineUpdater: Took a snapshot at index 0
2024-03-25 19:43:32,728 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-25 19:43:32,729 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29: applyIndex: 0
2024-03-25 19:43:32,729 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29->6e65d581-b1bc-41f2-b39b-16d8508d6618-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-25 19:43:32,729 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-81169FADB40C: Finished taking a snapshot at:(t:1, i:3) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/2db7f802-448f-42c5-98a7-81169fadb40c/sm/snapshot.1_3 took: 7 ms
2024-03-25 19:43:32,730 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-StateMachineUpdater: Took a snapshot at index 3
2024-03-25 19:43:32,730 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 3
2024-03-25 19:43:32,734 [Thread-944] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - a6fb26e7-f548-473f-8cf0-48fafe70504d Close channels
2024-03-25 19:43:32,735 [Thread-945] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618 Close channels
2024-03-25 19:43:32,734 [Thread-943] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83 Close channels
2024-03-25 19:43:32,738 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-25 19:43:32,740 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C: applyIndex: 3
2024-03-25 19:43:32,740 [8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-25 19:43:32,741 [grpc-default-executor-7] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29->a6fb26e7-f548-473f-8cf0-48fafe70504d-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-25 19:43:32,742 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29->6e65d581-b1bc-41f2-b39b-16d8508d6618-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-25 19:43:32,742 [grpc-default-executor-2] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(226)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29->6e65d581-b1bc-41f2-b39b-16d8508d6618-GrpcLogAppender: Failed to getClient for 6e65d581-b1bc-41f2-b39b-16d8508d6618
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 8de788e1-2c95-4c74-b4ac-29ea2448e86a is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:65)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:114)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:196)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:201)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$800(GrpcLogAppender.java:62)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:547)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:479)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:567)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:71)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:735)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:716)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-25 19:43:32,742 [grpc-default-executor-7] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(226)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29->a6fb26e7-f548-473f-8cf0-48fafe70504d-GrpcLogAppender: Failed to getClient for a6fb26e7-f548-473f-8cf0-48fafe70504d
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 8de788e1-2c95-4c74-b4ac-29ea2448e86a is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:65)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:114)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:196)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:201)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$800(GrpcLogAppender.java:62)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:547)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:479)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener$3.run(DelayedClientCall.java:489)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.delayOrExecute(DelayedClientCall.java:453)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.onClose(DelayedClientCall.java:486)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:567)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:71)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:735)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:716)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-25 19:43:32,744 [grpc-default-executor-6] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: Completed APPEND_ENTRIES, lastRequest: 8de788e1-2c95-4c74-b4ac-29ea2448e86a->a6fb26e7-f548-473f-8cf0-48fafe70504d#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "a6fb26e7-f548-473f-8cf0-48fafe70504d"
address: "10.1.0.27:15025"
dataStreamAddress: "10.1.0.27:15026"
clientAddress: "10.1.0.27:15023"
adminAddress: "10.1.0.27:15024"
startupRole: FOLLOWER
,id: "6e65d581-b1bc-41f2-b39b-16d8508d6618"
address: "10.1.0.27:15043"
dataStreamAddress: "10.1.0.27:15044"
clientAddress: "10.1.0.27:15041"
adminAddress: "10.1.0.27:15042"
startupRole: FOLLOWER
,id: "8de788e1-2c95-4c74-b4ac-29ea2448e86a"
address: "10.1.0.27:15052"
priority: 1
dataStreamAddress: "10.1.0.27:15053"
clientAddress: "10.1.0.27:15050"
adminAddress: "10.1.0.27:15051"
startupRole: FOLLOWER
, old:)
2024-03-25 19:43:32,744 [grpc-default-executor-6] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: Completed APPEND_ENTRIES, lastReply: null
2024-03-25 19:43:32,745 [grpc-default-executor-7] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29->a6fb26e7-f548-473f-8cf0-48fafe70504d-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-25 19:43:32,745 [grpc-default-executor-7] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(226)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29->a6fb26e7-f548-473f-8cf0-48fafe70504d-GrpcLogAppender: Failed to getClient for a6fb26e7-f548-473f-8cf0-48fafe70504d
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 8de788e1-2c95-4c74-b4ac-29ea2448e86a is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:65)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:114)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:196)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:201)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$800(GrpcLogAppender.java:62)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:547)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:479)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:567)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:71)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:735)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:716)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-25 19:43:32,748 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-03-25 19:43:32,748 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: shutdown server GrpcServerProtocolService now
2024-03-25 19:43:32,752 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: shutdown server GrpcServerProtocolService successfully
2024-03-25 19:43:32,752 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-03-25 19:43:32,752 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-03-25 19:43:32,762 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xeb536e14, L:/0.0.0.0:15053] CLOSE
2024-03-25 19:43:32,762 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xeb536e14, L:/0.0.0.0:15053] INACTIVE
2024-03-25 19:43:32,763 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xeb536e14, L:/0.0.0.0:15053] UNREGISTERED
2024-03-25 19:43:32,837 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:32,837 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:32,837 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-03-25 19:43:32,839 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:32,839 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:32,901 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:32,902 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 2 containers.
2024-03-25 19:43:32,903 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:32,903 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:32,903 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:32,903 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:32,903 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:32,903 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:32,903 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:32,952 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29-SegmentedRaftLogWorker close()
2024-03-25 19:43:33,412 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-03-25 19:43:33,644 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C-SegmentedRaftLogWorker close()
2024-03-25 19:43:33,645 [JvmPauseMonitor7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-8de788e1-2c95-4c74-b4ac-29ea2448e86a: Stopped
2024-03-25 19:43:33,840 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:33,840 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:33,841 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-03-25 19:43:33,842 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:33,842 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:33,904 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:33,905 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 2 containers.
2024-03-25 19:43:33,906 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:33,906 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:33,906 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:33,906 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:33,906 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:33,906 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:33,906 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:34,413 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-03-25 19:43:34,844 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:34,844 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:34,844 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-03-25 19:43:34,845 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:34,845 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:34,906 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:34,908 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 2 containers.
2024-03-25 19:43:34,908 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:34,908 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:34,908 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:34,908 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:34,908 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:34,909 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:34,909 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:35,413 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-03-25 19:43:35,656 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27) moved to stale state. Finalizing its pipelines [PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29, PipelineID=2db7f802-448f-42c5-98a7-81169fadb40c]
2024-03-25 19:43:35,657 [main] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-803237d0-c9dc-4fed-b0b2-099c5dbec3f7/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-71af8759-bfa1-4ad0-bcf2-b488489b099b/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-e828a9d5-04d1-4ff4-9efb-57eb4f509c93/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-a11ce00a-a8e8-4457-9c04-884d2480a314/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-96cefe10-55c8-478c-92f7-334af2b965c5/container.db]
2024-03-25 19:43:35,657 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 moved to CLOSED state
2024-03-25 19:43:35,658 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(484)) - Container #2 closed for pipeline=PipelineID=2db7f802-448f-42c5-98a7-81169fadb40c
2024-03-25 19:43:35,659 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #2, current state: CLOSING
2024-03-25 19:43:35,659 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=2db7f802-448f-42c5-98a7-81169fadb40c moved to CLOSED state
2024-03-25 19:43:35,662 [main] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-96cefe10-55c8-478c-92f7-334af2b965c5/container.db from cache
2024-03-25 19:43:35,662 [main] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(451)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-96cefe10-55c8-478c-92f7-334af2b965c5/container.db for volume DS-96cefe10-55c8-478c-92f7-334af2b965c5
2024-03-25 19:43:35,662 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-03-25 19:43:35,663 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-03-25 19:43:35,663 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(638)) - Ozone container server stopped.
2024-03-25 19:43:35,665 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@31e36f74{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-03-25 19:43:35,667 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@473754ef{HTTP/1.1, (http/1.1)}{0.0.0.0:15047}
2024-03-25 19:43:35,667 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-03-25 19:43:35,667 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@f45e521{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2024-03-25 19:43:35,668 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@14174dcb{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-03-25 19:43:35,669 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-03-25 19:43:35,669 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15048
2024-03-25 19:43:35,670 [IPC Server listener on 15048] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15048
2024-03-25 19:43:35,670 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-03-25 19:43:35,671 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a]
2024-03-25 19:43:35,723 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27) moved to stale state. Finalizing its pipelines [PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29, PipelineID=b272cc68-1415-4b0a-8697-67f90e925935, PipelineID=2db7f802-448f-42c5-98a7-81169fadb40c]
2024-03-25 19:43:35,724 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 moved to CLOSED state
2024-03-25 19:43:35,724 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 moved to CLOSED state
2024-03-25 19:43:35,725 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(484)) - Container #2 closed for pipeline=PipelineID=2db7f802-448f-42c5-98a7-81169fadb40c
2024-03-25 19:43:35,725 [Recon-EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #2, current state: CLOSING
2024-03-25 19:43:35,725 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=2db7f802-448f-42c5-98a7-81169fadb40c moved to CLOSED state
2024-03-25 19:43:35,726 [Recon-EventQueue-DatanodeCommandForReconNodeManager] DEBUG scm.ReconNodeManager (ReconNodeManager.java:onMessage(213)) - Ignoring unsupported command closeContainerCommand for Datanode 8de788e1-2c95-4c74-b4ac-29ea2448e86a.
2024-03-25 19:43:35,731 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 10 pipelines in house.
2024-03-25 19:43:35,732 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(152)) - Removing invalid pipeline PipelineID=669638b9-7e75-42f1-82a9-b01fec71537c from Recon.
2024-03-25 19:43:35,733 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 669638b9-7e75-42f1-82a9-b01fec71537c, Nodes: f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:f8c0ec26-9898-49d2-a0ea-132d14d0dc83, CreationTimestamp2024-03-25T19:42:26.376Z[Etc/UTC]] removed.
2024-03-25 19:43:35,733 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(152)) - Removing invalid pipeline PipelineID=eac5a041-cf38-4b57-9357-0ff75a016342 from Recon.
2024-03-25 19:43:35,734 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: eac5a041-cf38-4b57-9357-0ff75a016342, Nodes: a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:a6fb26e7-f548-473f-8cf0-48fafe70504d, CreationTimestamp2024-03-25T19:42:26.234Z[Etc/UTC]] removed.
2024-03-25 19:43:35,734 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(152)) - Removing invalid pipeline PipelineID=37d82d77-2193-41cd-938d-dc6410947516 from Recon.
2024-03-25 19:43:35,735 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 37d82d77-2193-41cd-938d-dc6410947516, Nodes: a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27)a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27)f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:a568c6b4-1a28-494a-b080-2324592b3a72, CreationTimestamp2024-03-25T19:42:26.380Z[Etc/UTC]] removed.
2024-03-25 19:43:35,735 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(152)) - Removing invalid pipeline PipelineID=b272cc68-1415-4b0a-8697-67f90e925935 from Recon.
2024-03-25 19:43:35,735 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: b272cc68-1415-4b0a-8697-67f90e925935, Nodes: f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27)6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27)8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:8de788e1-2c95-4c74-b4ac-29ea2448e86a, CreationTimestamp2024-03-25T19:42:45.444Z[Etc/UTC]] removed.
2024-03-25 19:43:35,736 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(152)) - Removing invalid pipeline PipelineID=8a6654ba-868c-467c-ac57-e84dd4d606bd from Recon.
2024-03-25 19:43:35,736 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 8a6654ba-868c-467c-ac57-e84dd4d606bd, Nodes: a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:a568c6b4-1a28-494a-b080-2324592b3a72, CreationTimestamp2024-03-25T19:42:26.114Z[Etc/UTC]] removed.
2024-03-25 19:43:35,737 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 12 milliseconds.
2024-03-25 19:43:35,847 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:35,847 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:35,847 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-03-25 19:43:35,849 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:35,849 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:35,909 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:35,911 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 2 containers.
2024-03-25 19:43:35,911 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:35,911 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:35,912 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:35,912 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:35,912 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:35,912 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:35,912 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:36,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 2, pipelineID: PipelineID=2db7f802-448f-42c5-98a7-81169fadb40c, force: false] for container ContainerInfo{id=#2, state=CLOSING, stateEnterTime=2024-03-25T19:43:35.657Z, pipelineID=PipelineID=2db7f802-448f-42c5-98a7-81169fadb40c, owner=omServiceIdDefault} to 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27) with datanode deadline 1711396386414 and scm deadline 1711396416414
2024-03-25 19:43:36,414 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-03-25 19:43:36,671 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a]
2024-03-25 19:43:36,850 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:36,850 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:36,850 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-03-25 19:43:36,855 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:36,855 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:36,912 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:36,914 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 2 containers.
2024-03-25 19:43:36,914 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:36,914 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:36,914 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:36,914 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:36,914 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:36,914 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:36,915 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:37,415 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 2, pipelineID: PipelineID=2db7f802-448f-42c5-98a7-81169fadb40c, force: false] for container ContainerInfo{id=#2, state=CLOSING, stateEnterTime=2024-03-25T19:43:35.657Z, pipelineID=PipelineID=2db7f802-448f-42c5-98a7-81169fadb40c, owner=omServiceIdDefault} to 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27) with datanode deadline 1711396387415 and scm deadline 1711396417415
2024-03-25 19:43:37,415 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-03-25 19:43:37,609 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:43:37,610 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:43:37,672 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [8de788e1-2c95-4c74-b4ac-29ea2448e86a]
2024-03-25 19:43:37,853 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:43:37,854 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), {type: FCR, size: 1}
2024-03-25 19:43:37,856 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:37,857 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:37,857 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-03-25 19:43:37,858 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:37,858 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:37,915 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-03-25 19:43:37,917 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 2 containers.
2024-03-25 19:43:37,917 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:37,917 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:37,917 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:37,917 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:37,917 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:37,918 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:37,918 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:38,415 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 2, pipelineID: PipelineID=2db7f802-448f-42c5-98a7-81169fadb40c, force: false] for container ContainerInfo{id=#2, state=CLOSING, stateEnterTime=2024-03-25T19:43:35.657Z, pipelineID=PipelineID=2db7f802-448f-42c5-98a7-81169fadb40c, owner=omServiceIdDefault} to 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27) with datanode deadline 1711396388415 and scm deadline 1711396418415
2024-03-25 19:43:38,416 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-03-25 19:43:38,446 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-FollowerState: change to CANDIDATE, lastRpcElapsedTime:7950944933ns, electionTimeout:5049ms
2024-03-25 19:43:38,446 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: shutdown a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-FollowerState
2024-03-25 19:43:38,446 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2024-03-25 19:43:38,446 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-03-25 19:43:38,446 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: start a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14
2024-03-25 19:43:38,447 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29: change Leader from 8de788e1-2c95-4c74-b4ac-29ea2448e86a to null at term 1 for PRE_VOTE
2024-03-25 19:43:38,447 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14 PRE_VOTE round 0: submit vote requests at term 1 for 0: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:43:38,447 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043
2024-03-25 19:43:38,447 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052
2024-03-25 19:43:38,455 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29: receive requestVote(PRE_VOTE, a6fb26e7-f548-473f-8cf0-48fafe70504d, group-13E9E73E6D29, 1, (t:1, i:0))
2024-03-25 19:43:38,455 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-FOLLOWER: accept PRE_VOTE from a6fb26e7-f548-473f-8cf0-48fafe70504d: our priority 0 <= candidate's priority 0
2024-03-25 19:43:38,455 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29 replies to PRE_VOTE vote request: a6fb26e7-f548-473f-8cf0-48fafe70504d<-6e65d581-b1bc-41f2-b39b-16d8508d6618#0:OK-t1. Peer's state: 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29:t1, leader=8de788e1-2c95-4c74-b4ac-29ea2448e86a, voted=8de788e1-2c95-4c74-b4ac-29ea2448e86a, raftlog=Memoized:6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-SegmentedRaftLog:OPENED:c0, conf=0: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:43:38,463 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(136)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-03-25 19:43:38,463 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14: PRE_VOTE PASSED received 1 response(s) and 1 exception(s):
2024-03-25 19:43:38,463 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: a6fb26e7-f548-473f-8cf0-48fafe70504d<-6e65d581-b1bc-41f2-b39b-16d8508d6618#0:OK-t1
2024-03-25 19:43:38,463 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(136)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-03-25 19:43:38,463 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14 PRE_VOTE round 0: result PASSED
2024-03-25 19:43:38,464 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14 ELECTION round 0: submit vote requests at term 2 for 0: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:43:38,465 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(136)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-03-25 19:43:38,466 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29: receive requestVote(ELECTION, a6fb26e7-f548-473f-8cf0-48fafe70504d, group-13E9E73E6D29, 2, (t:1, i:0))
2024-03-25 19:43:38,466 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-FOLLOWER: accept ELECTION from a6fb26e7-f548-473f-8cf0-48fafe70504d: our priority 0 <= candidate's priority 0
2024-03-25 19:43:38,466 [grpc-default-executor-6] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29: change Leader from 8de788e1-2c95-4c74-b4ac-29ea2448e86a to null at term 2 for updateCurrentTerm
2024-03-25 19:43:38,467 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:a6fb26e7-f548-473f-8cf0-48fafe70504d
2024-03-25 19:43:38,467 [grpc-default-executor-6] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: shutdown 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-FollowerState
2024-03-25 19:43:38,467 [grpc-default-executor-6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: start 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-FollowerState
2024-03-25 19:43:38,467 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-FollowerState was interrupted
2024-03-25 19:43:38,468 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29 replies to ELECTION vote request: a6fb26e7-f548-473f-8cf0-48fafe70504d<-6e65d581-b1bc-41f2-b39b-16d8508d6618#0:OK-t2. Peer's state: 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29:t2, leader=null, voted=a6fb26e7-f548-473f-8cf0-48fafe70504d, raftlog=Memoized:6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-SegmentedRaftLog:OPENED:c0, conf=0: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:43:38,469 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14: ELECTION PASSED received 1 response(s) and 1 exception(s):
2024-03-25 19:43:38,469 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: a6fb26e7-f548-473f-8cf0-48fafe70504d<-6e65d581-b1bc-41f2-b39b-16d8508d6618#0:OK-t2
2024-03-25 19:43:38,469 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(136)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-03-25 19:43:38,469 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14 ELECTION round 0: result PASSED
2024-03-25 19:43:38,469 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: shutdown a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14
2024-03-25 19:43:38,469 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2024-03-25 19:43:38,469 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-03-25 19:43:38,470 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-25 19:43:38,470 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-03-25 19:43:38,470 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-03-25 19:43:38,470 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-03-25 19:43:38,470 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-03-25 19:43:38,470 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-03-25 19:43:38,470 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-25 19:43:38,470 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:43:38,471 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-03-25 19:43:38,471 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-25 19:43:38,471 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-03-25 19:43:38,471 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:43:38,471 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2024-03-25 19:43:38,471 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0s (custom)
2024-03-25 19:43:38,471 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-03-25 19:43:38,471 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:43:38,471 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-03-25 19:43:38,471 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-03-25 19:43:38,471 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-03-25 19:43:38,472 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:43:38,472 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-25 19:43:38,472 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-03-25 19:43:38,472 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:43:38,472 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2024-03-25 19:43:38,472 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0s (custom)
2024-03-25 19:43:38,472 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-03-25 19:43:38,472 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:43:38,472 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-03-25 19:43:38,472 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-03-25 19:43:38,472 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-03-25 19:43:38,472 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:43:38,473 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-25 19:43:38,473 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: start a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderStateImpl
2024-03-25 19:43:38,473 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-13E9E73E6D29 with new leaderId: a6fb26e7-f548-473f-8cf0-48fafe70504d
2024-03-25 19:43:38,473 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29: change Leader from null to a6fb26e7-f548-473f-8cf0-48fafe70504d at term 2 for becomeLeader, leader elected after 26ms
2024-03-25 19:43:38,473 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(435)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2024-03-25 19:43:38,474 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderElection14] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29: set configuration 1: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:43:38,475 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(591)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-SegmentedRaftLogWorker: Rolled log segment from /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29/current/log_inprogress_0 to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29/current/log_0-0
2024-03-25 19:43:38,475 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_1 at position 0
2024-03-25 19:43:38,481 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(121)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29->8de788e1-2c95-4c74-b4ac-29ea2448e86a-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-03-25 19:43:38,482 [FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:43:38,482 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:43:38,482 [Recon-FixedThreadPoolWithAffinityExecutor-8-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:43:38,491 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29/current/log_inprogress_1
2024-03-25 19:43:38,491 [grpc-default-executor-2] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(217)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29->8de788e1-2c95-4c74-b4ac-29ea2448e86a-GrpcLogAppender: Follower failed (request=null, errorCount=1); keep nextIndex (1) unchanged and retry.
2024-03-25 19:43:38,491 [6e65d581-b1bc-41f2-b39b-16d8508d6618-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-13E9E73E6D29 with new leaderId: a6fb26e7-f548-473f-8cf0-48fafe70504d
2024-03-25 19:43:38,491 [6e65d581-b1bc-41f2-b39b-16d8508d6618-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29: change Leader from null to a6fb26e7-f548-473f-8cf0-48fafe70504d at term 2 for appendEntries, leader elected after 24ms
2024-03-25 19:43:38,495 [grpc-default-executor-5] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(217)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29->8de788e1-2c95-4c74-b4ac-29ea2448e86a-GrpcLogAppender: Follower failed (request=null, errorCount=3); keep nextIndex (2) unchanged and retry.
2024-03-25 19:43:38,501 [6e65d581-b1bc-41f2-b39b-16d8508d6618-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29: set configuration 1: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null
2024-03-25 19:43:38,502 [6e65d581-b1bc-41f2-b39b-16d8508d6618-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:rollLogSegment(435)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2024-03-25 19:43:38,502 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(591)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-SegmentedRaftLogWorker: Rolled log segment from /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29/current/log_inprogress_0 to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29/current/log_0-0
2024-03-25 19:43:38,503 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_1 at position 0
2024-03-25 19:43:38,510 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29/current/log_inprogress_1
2024-03-25 19:43:38,513 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 1 >= startIndex == 1
2024-03-25 19:43:38,514 [grpc-default-executor-2] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(217)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29->8de788e1-2c95-4c74-b4ac-29ea2448e86a-GrpcLogAppender: Follower failed (request=null, errorCount=5); keep nextIndex (3) unchanged and retry.
2024-03-25 19:43:38,662 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(95)) - A dead datanode is detected. 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27)
2024-03-25 19:43:38,664 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 close command to datanode 8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:43:38,664 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 close command to datanode 6e65d581-b1bc-41f2-b39b-16d8508d6618
2024-03-25 19:43:38,664 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 close command to datanode a6fb26e7-f548-473f-8cf0-48fafe70504d
2024-03-25 19:43:38,664 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 8d5f7d5e-0312-4916-b232-13e9e73e6d29, Nodes: 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27)6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27)a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:a6fb26e7-f548-473f-8cf0-48fafe70504d, CreationTimestamp2024-03-25T19:43:01.442Z[Etc/UTC]] removed.
2024-03-25 19:43:38,664 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=2db7f802-448f-42c5-98a7-81169fadb40c close command to datanode 8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:43:38,665 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 2db7f802-448f-42c5-98a7-81169fadb40c, Nodes: 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:8de788e1-2c95-4c74-b4ac-29ea2448e86a, CreationTimestamp2024-03-25T19:42:26.672Z[Etc/UTC]] removed.
2024-03-25 19:43:38,666 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(108)) - Clearing command queue of size 6 for DN 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27)
2024-03-25 19:43:38,666 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(211)) - Removed a node: /default-rack/8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:43:38,672 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 0 replicas on []
2024-03-25 19:43:38,725 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(95)) - A dead datanode is detected. 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27)
2024-03-25 19:43:38,726 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 8d5f7d5e-0312-4916-b232-13e9e73e6d29, Nodes: 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27)6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27)a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:a6fb26e7-f548-473f-8cf0-48fafe70504d, CreationTimestamp2024-03-25T19:43:01.442Z[Etc/UTC]] removed.
2024-03-25 19:43:38,726 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 2db7f802-448f-42c5-98a7-81169fadb40c, Nodes: 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:8de788e1-2c95-4c74-b4ac-29ea2448e86a, CreationTimestamp2024-03-25T19:42:26.672Z[Etc/UTC]] removed.
2024-03-25 19:43:38,727 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(108)) - Clearing command queue of size 0 for DN 8de788e1-2c95-4c74-b4ac-29ea2448e86a(fv-az1540-867/10.1.0.27)
2024-03-25 19:43:38,727 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(211)) - Removed a node: /default-rack/8de788e1-2c95-4c74-b4ac-29ea2448e86a
2024-03-25 19:43:38,736 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-03-25 19:43:38,746 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:generateUnhealthyRecords(483)) - Non-empty container 2 is missing. It has 1 keys and 7 bytes used according to SCM metadata. Please visit Recon's missing container page for a list of keys (and their metadata) mapped to this container.
2024-03-25 19:43:38,748 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 12 milliseconds for processing 2 containers.
2024-03-25 19:43:38,748 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:38,748 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:38,749 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:38,749 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	TOTAL_KEYS -> 1 , CONTAINER_COUNT -> 1 , TOTAL_USED_BYTES -> 7 , 
2024-03-25 19:43:38,749 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:38,749 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	TOTAL_KEYS -> 1 , CONTAINER_COUNT -> 1 , TOTAL_USED_BYTES -> 7 , 
2024-03-25 19:43:38,749 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:38,750 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 3 pipelines in house.
2024-03-25 19:43:38,758 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 9 milliseconds.
2024-03-25 19:43:38,768 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  tasks.ContainerSizeCountTask (ContainerSizeCountTask.java:process(200)) - Completed a 'process' run of ContainerSizeCountTask.
2024-03-25 19:43:38,829 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29. Trying to get from SCM.
2024-03-25 19:43:38,830 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 is not found
2024-03-25 19:43:38,832 [IPC Server handler 28 on default port 15000] INFO  ipc.Server (Server.java:logException(3109)) - IPC Server handler 28 on default port 15000, call Call#894 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from fv-az1540-867:33866 / 10.1.0.27:33866
org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 not found
	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:158)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManagerImpl.getPipeline(PipelineStateManagerImpl.java:138)
	at sun.reflect.GeneratedMethodAccessor26.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeLocal(SCMHAInvocationHandler.java:92)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:75)
	at com.sun.proxy.$Proxy28.getPipeline(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.getPipeline(PipelineManagerImpl.java:335)
	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:761)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:960)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:607)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:89)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:232)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-03-25 19:43:38,840 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] ERROR scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(79)) - Could not find pipeline PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 at SCM.
2024-03-25 19:43:38,840 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] ERROR pipeline.PipelineReportHandler (PipelineReportHandler.java:onMessage(98)) - Could not find pipeline id: "8d5f7d5e-0312-4916-b232-13e9e73e6d29"
uuid128 {
  mostSigBits: -8259745348842272490
  leastSigBits: -5606396690794910423
}

2024-03-25 19:43:38,859 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:38,860 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:38,860 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-03-25 19:43:38,861 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:38,861 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:38,920 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 2 milliseconds to process 2 existing database records.
2024-03-25 19:43:38,921 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 2 containers.
2024-03-25 19:43:38,921 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:38,921 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:38,922 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:38,922 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:38,922 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:38,922 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:38,922 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:39,416 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-03-25 19:43:39,474 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29. Trying to get from SCM.
2024-03-25 19:43:39,474 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 is not found
2024-03-25 19:43:39,474 [IPC Server handler 4 on default port 15000] INFO  ipc.Server (Server.java:logException(3109)) - IPC Server handler 4 on default port 15000, call Call#899 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from fv-az1540-867:33866 / 10.1.0.27:33866
org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 not found
	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:158)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManagerImpl.getPipeline(PipelineStateManagerImpl.java:138)
	at sun.reflect.GeneratedMethodAccessor26.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeLocal(SCMHAInvocationHandler.java:92)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:75)
	at com.sun.proxy.$Proxy28.getPipeline(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.getPipeline(PipelineManagerImpl.java:335)
	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:761)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:960)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:607)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:89)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:232)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-03-25 19:43:39,476 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] ERROR scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(79)) - Could not find pipeline PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 at SCM.
2024-03-25 19:43:39,476 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] ERROR pipeline.PipelineReportHandler (PipelineReportHandler.java:onMessage(98)) - Could not find pipeline id: "8d5f7d5e-0312-4916-b232-13e9e73e6d29"
uuid128 {
  mostSigBits: -8259745348842272490
  leastSigBits: -5606396690794910423
}

Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/MISSING ...
2024-03-25 19:43:39,702 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-03-25 19:43:39,702 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-03-25 19:43:39,702 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-03-25 19:43:39,718 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(240)) - HddsDatanodeService host:fv-az1540-867 ip:10.1.0.27
2024-03-25 19:43:39,729 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-03-25 19:43:39,729 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(299)) - Datanode State Machine Task Thread Pool size 2
2024-03-25 19:43:39,731 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(125)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/data-0/hdds of storage type : DISK capacity : 9223372036854775807
2024-03-25 19:43:39,731 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/data-0/hdds to VolumeSet
2024-03-25 19:43:39,732 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis to VolumeSet
2024-03-25 19:43:39,744 [ForkJoinPool.commonPool-worker-1] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-96cefe10-55c8-478c-92f7-334af2b965c5/container.db to cache
2024-03-25 19:43:39,744 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:loadDbStore(373)) - SchemaV3 db is loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-96cefe10-55c8-478c-92f7-334af2b965c5/container.db for volume DS-96cefe10-55c8-478c-92f7-334af2b965c5
2024-03-25 19:43:39,744 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 12ms
2024-03-25 19:43:39,748 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-03-25 19:43:39,748 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-03-25 19:43:39,748 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15051 (custom)
2024-03-25 19:43:39,748 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-03-25 19:43:39,748 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15050 (custom)
2024-03-25 19:43:39,749 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-03-25 19:43:39,749 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15052 (custom)
2024-03-25 19:43:39,749 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-03-25 19:43:39,749 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-03-25 19:43:39,749 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-03-25 19:43:39,750 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:43:39,750 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-03-25 19:43:39,750 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-03-25 19:43:39,750 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-03-25 19:43:39,753 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-03-25 19:43:39,753 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-03-25 19:43:39,753 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-03-25 19:43:39,754 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-03-25 19:43:39,754 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-03-25 19:43:39,754 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-03-25 19:43:39,754 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-03-25 19:43:39,754 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-03-25 19:43:39,754 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 8de788e1-2c95-4c74-b4ac-29ea2448e86a-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-03-25 19:43:39,755 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-03-25 19:43:39,755 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 8de788e1-2c95-4c74-b4ac-29ea2448e86a-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-03-25 19:43:39,756 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-03-25 19:43:39,756 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-03-25 19:43:39,756 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15053 (custom)
2024-03-25 19:43:39,757 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:43:39,757 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-03-25 19:43:39,757 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:43:39,757 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis] (custom)
2024-03-25 19:43:39,758 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-03-25 19:43:39,758 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-03-25 19:43:39,757 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x16e39373] REGISTERED
2024-03-25 19:43:39,758 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x16e39373] BIND: 0.0.0.0/0.0.0.0:15053
2024-03-25 19:43:39,759 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x16e39373, L:/0.0.0.0:15053] ACTIVE
2024-03-25 19:43:39,759 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/2db7f802-448f-42c5-98a7-81169fadb40c
2024-03-25 19:43:39,759 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: addNew group-81169FADB40C:[] returns group-81169FADB40C:java.util.concurrent.CompletableFuture@5aaa59dd[Not completed]
2024-03-25 19:43:39,759 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29
2024-03-25 19:43:39,759 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: addNew group-13E9E73E6D29:[] returns group-13E9E73E6D29:java.util.concurrent.CompletableFuture@5e95c650[Not completed]
2024-03-25 19:43:39,760 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/tmp
2024-03-25 19:43:39,760 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(269)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/ratis/tmp is not a group directory; ignoring it. 
2024-03-25 19:43:39,760 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: new RaftServerImpl for group-81169FADB40C:[] with ContainerStateMachine:uninitialized
2024-03-25 19:43:39,760 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:43:39,760 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-25 19:43:39,760 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-25 19:43:39,761 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-25 19:43:39,761 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:43:39,761 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-25 19:43:39,761 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:43:39,761 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-81169FADB40C: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-25 19:43:39,761 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-25 19:43:39,761 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-25 19:43:39,761 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-25 19:43:39,761 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-25 19:43:39,761 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-25 19:43:39,761 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-25 19:43:39,763 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:43:39,763 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:43:39,764 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-25 19:43:39,764 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-25 19:43:39,764 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-25 19:43:39,764 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-25 19:43:39,764 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-03-25 19:43:39,764 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a: new RaftServerImpl for group-13E9E73E6D29:[] with ContainerStateMachine:uninitialized
2024-03-25 19:43:39,765 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-03-25 19:43:39,765 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-25 19:43:39,765 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-03-25 19:43:39,765 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-03-25 19:43:39,765 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-25 19:43:39,765 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-03-25 19:43:39,765 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-25 19:43:39,765 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a@group-13E9E73E6D29: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-25 19:43:39,765 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-03-25 19:43:39,765 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-03-25 19:43:39,765 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-03-25 19:43:39,765 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-25 19:43:39,766 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-03-25 19:43:39,766 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-25 19:43:39,767 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-03-25 19:43:39,767 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-03-25 19:43:39,768 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-25 19:43:39,768 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-03-25 19:43:39,768 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-03-25 19:43:39,768 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-03-25 19:43:39,769 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-03-25 19:43:39,770 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(157)) - Initializing replication supervisor with thread count = 10
2024-03-25 19:43:39,770 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-03-25 19:43:39,773 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15047
2024-03-25 19:43:39,773 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-25 19:43:39,775 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-03-25 19:43:39,775 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-03-25 19:43:39,776 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-25 19:43:39,777 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-03-25 19:43:39,777 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-25 19:43:39,777 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-25 19:43:39,778 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/meta/webserver
2024-03-25 19:43:39,778 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15047
2024-03-25 19:43:39,779 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-03-25 19:43:39,780 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-03-25 19:43:39,780 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-03-25 19:43:39,780 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2024-03-25 19:43:39,781 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@32c8b088{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-03-25 19:43:39,781 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@e2b05e8{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-03-25 19:43:39,816 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@7135c05{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/meta/webserver/jetty-0_0_0_0-15047-hdds-container-service-1_5_0-SNAPSHOT_jar-_-any-5660678797011475430/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-03-25 19:43:39,818 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@12eb66a6{HTTP/1.1, (http/1.1)}{0.0.0.0:15047}
2024-03-25 19:43:39,819 [main] INFO  server.Server (Server.java:doStart(415)) - Started @99335ms
2024-03-25 19:43:39,819 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-03-25 19:43:39,819 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15047
2024-03-25 19:43:39,820 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-25 19:43:39,820 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15048
2024-03-25 19:43:39,820 [Socket Reader #1 for port 15048] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15048
2024-03-25 19:43:39,822 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(327)) - Datanode start with admins: [runner]
2024-03-25 19:43:39,822 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15048
2024-03-25 19:43:39,823 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-03-25 19:43:39,823 [IPC Server listener on 15048] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15048: starting
2024-03-25 19:43:39,827 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(555)) - Ozone container server started.
2024-03-25 19:43:39,829 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(396)) - Shutting down the Mini Ozone Cluster
2024-03-25 19:43:39,830 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 is not found
2024-03-25 19:43:39,831 [main] INFO  db.CodecTestUtil (CodecTestUtil.java:gc(50)) - gc 0
2024-03-25 19:43:40,092 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:40,092 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:40,092 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-03-25 19:43:40,094 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: remove    LEADER a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29:t2, leader=a6fb26e7-f548-473f-8cf0-48fafe70504d, voted=a6fb26e7-f548-473f-8cf0-48fafe70504d, raftlog=Memoized:a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-SegmentedRaftLog:OPENED:c2, conf=1: peers:[a6fb26e7-f548-473f-8cf0-48fafe70504d|10.1.0.27:15025, 6e65d581-b1bc-41f2-b39b-16d8508d6618|10.1.0.27:15043, 8de788e1-2c95-4c74-b4ac-29ea2448e86a|10.1.0.27:15052]|listeners:[], old=null RUNNING
2024-03-25 19:43:40,094 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29: shutdown
2024-03-25 19:43:40,094 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-13E9E73E6D29,id=a6fb26e7-f548-473f-8cf0-48fafe70504d
2024-03-25 19:43:40,094 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: shutdown a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-LeaderStateImpl
2024-03-25 19:43:40,094 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29->6e65d581-b1bc-41f2-b39b-16d8508d6618-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29->6e65d581-b1bc-41f2-b39b-16d8508d6618-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-03-25 19:43:40,094 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-PendingRequests: sendNotLeaderResponses
2024-03-25 19:43:40,097 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29. Trying to get from SCM.
2024-03-25 19:43:40,097 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29->8de788e1-2c95-4c74-b4ac-29ea2448e86a-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29->8de788e1-2c95-4c74-b4ac-29ea2448e86a-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-03-25 19:43:40,098 [IPC Server handler 31 on default port 15000] INFO  ipc.Server (Server.java:logException(3109)) - IPC Server handler 31 on default port 15000, call Call#909 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from fv-az1540-867:33866 / 10.1.0.27:33866
org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 not found
	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:158)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManagerImpl.getPipeline(PipelineStateManagerImpl.java:138)
	at sun.reflect.GeneratedMethodAccessor26.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeLocal(SCMHAInvocationHandler.java:92)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:75)
	at com.sun.proxy.$Proxy28.getPipeline(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.getPipeline(PipelineManagerImpl.java:335)
	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:761)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:960)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:607)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:89)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:232)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-03-25 19:43:40,098 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-StateMachineUpdater: set stopIndex = 2
2024-03-25 19:43:40,100 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] ERROR scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(79)) - Could not find pipeline PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 at SCM.
2024-03-25 19:43:40,101 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] ERROR pipeline.PipelineReportHandler (PipelineReportHandler.java:onMessage(98)) - Could not find pipeline id: "8d5f7d5e-0312-4916-b232-13e9e73e6d29"
uuid128 {
  mostSigBits: -8259745348842272490
  leastSigBits: -5606396690794910423
}

2024-03-25 19:43:40,101 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 4 millisec, 6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:43:40,101 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 4 millisec, 6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27), {type: FCR, size: 0}
2024-03-25 19:43:40,101 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-13E9E73E6D29: Taking a snapshot at:(t:2, i:2) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29/sm/snapshot.2_2
2024-03-25 19:43:40,102 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 10 milliseconds to process 2 existing database records.
2024-03-25 19:43:40,103 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 2 containers.
2024-03-25 19:43:40,103 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:40,104 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:40,104 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:40,104 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:40,104 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:40,104 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:40,104 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:40,105 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-13E9E73E6D29: Finished taking a snapshot at:(t:2, i:2) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29/sm/snapshot.2_2 took: 4 ms
2024-03-25 19:43:40,106 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-StateMachineUpdater: Took a snapshot at index 2
2024-03-25 19:43:40,106 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 2
2024-03-25 19:43:40,106 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29: applyIndex: 2
2024-03-25 19:43:40,108 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-03-25 19:43:40,108 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-03-25 19:43:40,117 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-03-25 19:43:40,122 [grpc-default-executor-6] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: Completed APPEND_ENTRIES, lastRequest: null
2024-03-25 19:43:40,117 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-25 19:43:40,123 [grpc-default-executor-6] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "a6fb26e7-f548-473f-8cf0-48fafe70504d"
  replyId: "6e65d581-b1bc-41f2-b39b-16d8508d6618"
  raftGroupId {
    id: "\215_}^\003\022I\026\2622\023\351\347>m)"
  }
  success: true
}
term: 2
nextIndex: 1
matchIndex: 18446744073709551615
isHearbeat: true

2024-03-25 19:43:40,122 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: Completed APPEND_ENTRIES, lastRequest: a6fb26e7-f548-473f-8cf0-48fafe70504d->6e65d581-b1bc-41f2-b39b-16d8508d6618#2-t2,previous=(t:2, i:1),leaderCommit=1,initializing? false,entries: size=1, first=(t:2, i:2), METADATAENTRY(c:1)
2024-03-25 19:43:40,124 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: Completed APPEND_ENTRIES, lastReply: null
2024-03-25 19:43:40,125 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29->6e65d581-b1bc-41f2-b39b-16d8508d6618-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-25 19:43:40,127 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29->6e65d581-b1bc-41f2-b39b-16d8508d6618-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-03-25 19:43:40,129 [8de788e1-2c95-4c74-b4ac-29ea2448e86a-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/meta/datanode.id
2024-03-25 19:43:40,193 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(412)) - Stopping the Mini Ozone Cluster
2024-03-25 19:43:40,193 [main] INFO  om.OzoneManager (OzoneManager.java:stop(2238)) - om1[localhost:15004]: Stopping Ozone Manager
2024-03-25 19:43:40,193 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15004
2024-03-25 19:43:40,195 [IPC Server listener on 15004] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15004
2024-03-25 19:43:40,195 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-03-25 19:43:40,196 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:stop(594)) - Stopping org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer@45791d5d at port 15007
2024-03-25 19:43:40,196 [main] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(416)) - om1: close
2024-03-25 19:43:40,196 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - om1: shutdown server GrpcServerProtocolService now
2024-03-25 19:43:40,197 [om1-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - om1@group-C5BA1605619E: shutdown
2024-03-25 19:43:40,197 [om1-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2024-03-25 19:43:40,197 [om1-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - om1: shutdown om1@group-C5BA1605619E-LeaderStateImpl
2024-03-25 19:43:40,197 [om1-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - om1@group-C5BA1605619E-PendingRequests: sendNotLeaderResponses
2024-03-25 19:43:40,197 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - om1: shutdown server GrpcServerProtocolService successfully
2024-03-25 19:43:40,201 [om1-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - om1@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 12
2024-03-25 19:43:40,201 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshotImpl(481)) -  applied = (t:1, i:11)
2024-03-25 19:43:40,201 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshotImpl(482)) -  skipped = 11
2024-03-25 19:43:40,201 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshotImpl(483)) - notified = (t:1, i:12)
2024-03-25 19:43:40,201 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshotImpl(484)) - snapshot = (t:1, i:12)
2024-03-25 19:43:40,209 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - om1@group-C5BA1605619E-StateMachineUpdater: Took a snapshot at index 12
2024-03-25 19:43:40,209 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - om1@group-C5BA1605619E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 12
2024-03-25 19:43:40,210 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(527)) - Stopping OzoneManagerStateMachine:om1:group-C5BA1605619E.
2024-03-25 19:43:40,210 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(517)) - Stopping OMDoubleBuffer flush thread
2024-03-25 19:43:40,210 [om1-OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:canFlush(581)) - OMDoubleBuffer flush thread om1-OMDoubleBufferFlushThread is interrupted and will exit.
2024-03-25 19:43:40,211 [om1-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(427)) - om1@group-C5BA1605619E: applyIndex: 11
2024-03-25 19:43:40,211 [om1@group-C5BA1605619E-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - om1@group-C5BA1605619E-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-25 19:43:40,404 [UnderReplicatedProcessor] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:chooseNodeInternal(669)) - No available node in (scope="/" excludedScope="[/default-rack/a6fb26e7-f548-473f-8cf0-48fafe70504d, /default-rack/a568c6b4-1a28-494a-b080-2324592b3a72]" excludedNodes="[a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27)]"  ancestorGen="1").
2024-03-25 19:43:40,404 [UnderReplicatedProcessor] WARN  algorithms.SCMContainerPlacementRackAware (SCMContainerPlacementRackAware.java:chooseNode(485)) - Failed to find the datanode for container. excludedNodes:[a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27), a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27)], affinityNode:
2024-03-25 19:43:40,404 [UnderReplicatedProcessor] INFO  scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:isValidNode(518)) - Datanode f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27) is not chosen. Required metadata size is 0 and required data size is 5368709120 and NodeStatus is OperationalState: DECOMMISSIONED Health: HEALTHY OperationStateExpiry: 0
2024-03-25 19:43:40,405 [UnderReplicatedProcessor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [replicateContainerCommand: containerId=1, replicaIndex=0, targetNode=6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27), priority=NORMAL] for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-03-25T19:42:41.453Z, pipelineID=PipelineID=37d82d77-2193-41cd-938d-dc6410947516, owner=omServiceIdDefault} to a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27) with datanode deadline 1711396390405 and scm deadline 1711396420405
2024-03-25 19:43:40,405 [UnderReplicatedProcessor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(138)) - Processed 1 containers with health state counts {UNDER_REPLICATED=1}, failed processing 0, deferred due to load 0
2024-03-25 19:43:40,416 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-03-25 19:43:40,474 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 is not found
2024-03-25 19:43:40,475 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29. Trying to get from SCM.
2024-03-25 19:43:40,475 [IPC Server handler 4 on default port 15000] INFO  ipc.Server (Server.java:logException(3109)) - IPC Server handler 4 on default port 15000, call Call#913 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from fv-az1540-867:33866 / 10.1.0.27:33866
org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 not found
	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:158)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManagerImpl.getPipeline(PipelineStateManagerImpl.java:138)
	at sun.reflect.GeneratedMethodAccessor26.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeLocal(SCMHAInvocationHandler.java:92)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:75)
	at com.sun.proxy.$Proxy28.getPipeline(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.getPipeline(PipelineManagerImpl.java:335)
	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:761)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:960)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:607)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:89)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:232)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-03-25 19:43:40,477 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] ERROR scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(79)) - Could not find pipeline PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29 at SCM.
2024-03-25 19:43:40,477 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] ERROR pipeline.PipelineReportHandler (PipelineReportHandler.java:onMessage(98)) - Could not find pipeline id: "8d5f7d5e-0312-4916-b232-13e9e73e6d29"
uuid128 {
  mostSigBits: -8259745348842272490
  leastSigBits: -5606396690794910423
}

2024-03-25 19:43:40,514 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29-SegmentedRaftLogWorker close()
2024-03-25 19:43:40,515 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29
2024-03-25 19:43:40,516 [a6fb26e7-f548-473f-8cf0-48fafe70504d-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=8d5f7d5e-0312-4916-b232-13e9e73e6d29
org.apache.ratis.protocol.exceptions.GroupMismatchException: a6fb26e7-f548-473f-8cf0-48fafe70504d: group-13E9E73E6D29 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-25 19:43:40,663 [om1-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker close()
2024-03-25 19:43:40,669 [JvmPauseMonitor1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-om1: Stopped
2024-03-25 19:43:40,670 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service KeyDeletingService
2024-03-25 19:43:40,670 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service DirectoryDeletingService
2024-03-25 19:43:40,670 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service OpenKeyCleanupService
2024-03-25 19:43:40,670 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SstFilteringService
2024-03-25 19:43:40,670 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SnapshotDeletingService
2024-03-25 19:43:40,671 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service MultipartUploadCleanupService
2024-03-25 19:43:40,671 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SnapshotDirectoryCleaningService
2024-03-25 19:43:40,672 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@2e4dbcd0{ozoneManager,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2024-03-25 19:43:40,672 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@4bfbc57a{HTTP/1.1, (http/1.1)}{0.0.0.0:15005}
2024-03-25 19:43:40,672 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-03-25 19:43:40,673 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@66f4c5cb{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2024-03-25 19:43:40,673 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5ec357e4{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-03-25 19:43:40,674 [main] INFO  rocksdiff.RocksDBCheckpointDiffer (RocksDBCheckpointDiffer.java:close(310)) - Shutting down CompactionDagPruningService.
2024-03-25 19:43:40,676 [main] INFO  snapshot.SnapshotDiffManager (SnapshotDiffManager.java:closeExecutorService(1657)) - Shutting down executorService: 'SnapDiffExecutor'
2024-03-25 19:43:40,676 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SnapshotDiffCleanupService
2024-03-25 19:43:40,677 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(471)) - Stopping the HddsDatanodes
2024-03-25 19:43:40,683 [ForkJoinPool.commonPool-worker-3] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-03-25 19:43:40,684 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-03-25 19:43:40,684 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-03-25 19:43:40,685 [ForkJoinPool.commonPool-worker-3] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/data-0/hdds) is shutting down. 
2024-03-25 19:43:40,685 [ForkJoinPool.commonPool-worker-2] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-03-25 19:43:40,685 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-03-25 19:43:40,685 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-03-25 19:43:40,686 [ForkJoinPool.commonPool-worker-2] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-803237d0-c9dc-4fed-b0b2-099c5dbec3f7/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-71af8759-bfa1-4ad0-bcf2-b488489b099b/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-e828a9d5-04d1-4ff4-9efb-57eb4f509c93/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-a11ce00a-a8e8-4457-9c04-884d2480a314/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-96cefe10-55c8-478c-92f7-334af2b965c5/container.db]
2024-03-25 19:43:40,685 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/data-0/hdds, DS-803237d0-c9dc-4fed-b0b2-099c5dbec3f7) exiting.
2024-03-25 19:43:40,686 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-03-25 19:43:40,686 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-03-25 19:43:40,689 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-03-25 19:43:40,689 [ForkJoinPool.commonPool-worker-3] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(416)) - a568c6b4-1a28-494a-b080-2324592b3a72: close
2024-03-25 19:43:40,689 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-03-25 19:43:40,689 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-03-25 19:43:40,690 [main] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/data-0/hdds) is shutting down. 
2024-03-25 19:43:40,689 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/data-0/hdds) is shutting down. 
2024-03-25 19:43:40,690 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-03-25 19:43:40,690 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/data-0/hdds, DS-e828a9d5-04d1-4ff4-9efb-57eb4f509c93) exiting.
2024-03-25 19:43:40,690 [ForkJoinPool.commonPool-worker-2] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-96cefe10-55c8-478c-92f7-334af2b965c5/container.db from cache
2024-03-25 19:43:40,691 [ForkJoinPool.commonPool-worker-2] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(451)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-5/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-96cefe10-55c8-478c-92f7-334af2b965c5/container.db for volume DS-96cefe10-55c8-478c-92f7-334af2b965c5
2024-03-25 19:43:40,690 [a568c6b4-1a28-494a-b080-2324592b3a72-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563: shutdown
2024-03-25 19:43:40,689 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - a568c6b4-1a28-494a-b080-2324592b3a72: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-03-25 19:43:40,691 [main] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(416)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: close
2024-03-25 19:43:40,693 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-03-25 19:43:40,690 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-03-25 19:43:40,696 [Thread-1084] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83 Close channels
2024-03-25 19:43:40,696 [Thread-1086] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - a6fb26e7-f548-473f-8cf0-48fafe70504d Close channels
2024-03-25 19:43:40,693 [ForkJoinPool.commonPool-worker-2] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-03-25 19:43:40,692 [a568c6b4-1a28-494a-b080-2324592b3a72-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-739850C3A563,id=a568c6b4-1a28-494a-b080-2324592b3a72
2024-03-25 19:43:40,697 [a568c6b4-1a28-494a-b080-2324592b3a72-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - a568c6b4-1a28-494a-b080-2324592b3a72: shutdown a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-LeaderStateImpl
2024-03-25 19:43:40,697 [a568c6b4-1a28-494a-b080-2324592b3a72-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-PendingRequests: sendNotLeaderResponses
2024-03-25 19:43:40,697 [ForkJoinPool.commonPool-worker-2] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-03-25 19:43:40,697 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/data-0/hdds, DS-71af8759-bfa1-4ad0-bcf2-b488489b099b) exiting.
2024-03-25 19:43:40,698 [a568c6b4-1a28-494a-b080-2324592b3a72-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-StateMachineUpdater: set stopIndex = 0
2024-03-25 19:43:40,698 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-739850C3A563: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/9fcebae3-2819-4af1-b2d2-739850c3a563/sm/snapshot.1_0
2024-03-25 19:43:40,698 [Thread-1090] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618 Close channels
2024-03-25 19:43:40,698 [Thread-1091] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a Close channels
2024-03-25 19:43:40,701 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-739850C3A563: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/ratis/9fcebae3-2819-4af1-b2d2-739850c3a563/sm/snapshot.1_0 took: 4 ms
2024-03-25 19:43:40,701 [ForkJoinPool.commonPool-worker-2] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(638)) - Ozone container server stopped.
2024-03-25 19:43:40,703 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-StateMachineUpdater: Took a snapshot at index 0
2024-03-25 19:43:40,703 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-03-25 19:43:40,702 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(416)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: close
2024-03-25 19:43:40,702 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - a568c6b4-1a28-494a-b080-2324592b3a72: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-03-25 19:43:40,706 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: shutdown server GrpcServerProtocolService now
2024-03-25 19:43:40,706 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@7135c05{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-03-25 19:43:40,705 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-25 19:43:40,706 [a6fb26e7-f548-473f-8cf0-48fafe70504d-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986: shutdown
2024-03-25 19:43:40,707 [a568c6b4-1a28-494a-b080-2324592b3a72-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(427)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563: applyIndex: 0
2024-03-25 19:43:40,706 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-03-25 19:43:40,706 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - a568c6b4-1a28-494a-b080-2324592b3a72: shutdown server GrpcServerProtocolService now
2024-03-25 19:43:40,707 [a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-25 19:43:40,707 [a6fb26e7-f548-473f-8cf0-48fafe70504d-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-837C047AC986,id=a6fb26e7-f548-473f-8cf0-48fafe70504d
2024-03-25 19:43:40,707 [a6fb26e7-f548-473f-8cf0-48fafe70504d-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: shutdown a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-LeaderStateImpl
2024-03-25 19:43:40,707 [a6fb26e7-f548-473f-8cf0-48fafe70504d-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-PendingRequests: sendNotLeaderResponses
2024-03-25 19:43:40,708 [a6fb26e7-f548-473f-8cf0-48fafe70504d-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-StateMachineUpdater: set stopIndex = 0
2024-03-25 19:43:40,708 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-837C047AC986: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/f8263715-53d5-4884-b6a7-837c047ac986/sm/snapshot.1_0
2024-03-25 19:43:40,708 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-837C047AC986: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/ratis/f8263715-53d5-4884-b6a7-837c047ac986/sm/snapshot.1_0 took: 0 ms
2024-03-25 19:43:40,708 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-StateMachineUpdater: Took a snapshot at index 0
2024-03-25 19:43:40,708 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-25 19:43:40,709 [a6fb26e7-f548-473f-8cf0-48fafe70504d-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(427)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986: applyIndex: 0
2024-03-25 19:43:40,709 [a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-25 19:43:40,710 [ForkJoinPool.commonPool-worker-2] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@12eb66a6{HTTP/1.1, (http/1.1)}{0.0.0.0:15047}
2024-03-25 19:43:40,710 [ForkJoinPool.commonPool-worker-2] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-03-25 19:43:40,710 [Thread-1094] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - a568c6b4-1a28-494a-b080-2324592b3a72 Close channels
2024-03-25 19:43:40,713 [Thread-1100] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83 Close channels
2024-03-25 19:43:40,725 [Thread-1105] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 8de788e1-2c95-4c74-b4ac-29ea2448e86a Close channels
2024-03-25 19:43:40,725 [Thread-1104] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618 Close channels
2024-03-25 19:43:40,726 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@e2b05e8{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2024-03-25 19:43:40,727 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - a568c6b4-1a28-494a-b080-2324592b3a72: shutdown server GrpcServerProtocolService successfully
2024-03-25 19:43:40,728 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - a568c6b4-1a28-494a-b080-2324592b3a72: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-03-25 19:43:40,726 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: shutdown server GrpcServerProtocolService successfully
2024-03-25 19:43:40,728 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-03-25 19:43:40,729 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@32c8b088{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-03-25 19:43:40,734 [ForkJoinPool.commonPool-worker-2] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-03-25 19:43:40,750 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-03-25 19:43:40,750 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: shutdown server GrpcServerProtocolService now
2024-03-25 19:43:40,750 [ForkJoinPool.commonPool-worker-2] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15048
2024-03-25 19:43:40,753 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - a568c6b4-1a28-494a-b080-2324592b3a72: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-03-25 19:43:40,753 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - f8c0ec26-9898-49d2-a0ea-132d14d0dc83: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-03-25 19:43:40,755 [IPC Server listener on 15048] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15048
2024-03-25 19:43:40,757 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-03-25 19:43:40,761 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x27663235, L:/0.0.0.0:15035] CLOSE
2024-03-25 19:43:40,761 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x27663235, L:/0.0.0.0:15035] INACTIVE
2024-03-25 19:43:40,762 [f8c0ec26-9898-49d2-a0ea-132d14d0dc83-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x27663235, L:/0.0.0.0:15035] UNREGISTERED
2024-03-25 19:43:40,767 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: shutdown server GrpcServerProtocolService successfully
2024-03-25 19:43:40,768 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-03-25 19:43:40,770 [JvmPauseMonitor5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-f8c0ec26-9898-49d2-a0ea-132d14d0dc83: Stopped
2024-03-25 19:43:40,786 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - a6fb26e7-f548-473f-8cf0-48fafe70504d: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-03-25 19:43:40,790 [a568c6b4-1a28-494a-b080-2324592b3a72-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x5a82eb56, L:/0.0.0.0:15017] CLOSE
2024-03-25 19:43:40,791 [a568c6b4-1a28-494a-b080-2324592b3a72-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x5a82eb56, L:/0.0.0.0:15017] INACTIVE
2024-03-25 19:43:40,791 [a568c6b4-1a28-494a-b080-2324592b3a72-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x5a82eb56, L:/0.0.0.0:15017] UNREGISTERED
2024-03-25 19:43:40,792 [ForkJoinPool.commonPool-worker-2] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-03-25 19:43:40,794 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-03-25 19:43:40,794 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-03-25 19:43:40,794 [ForkJoinPool.commonPool-worker-2] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/data-0/hdds) is shutting down. 
2024-03-25 19:43:40,805 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-03-25 19:43:40,805 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/data-0/hdds, DS-a11ce00a-a8e8-4457-9c04-884d2480a314) exiting.
2024-03-25 19:43:40,805 [ForkJoinPool.commonPool-worker-2] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(416)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: close
2024-03-25 19:43:40,805 [a6fb26e7-f548-473f-8cf0-48fafe70504d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x26e8580d, L:/0.0.0.0:15026] CLOSE
2024-03-25 19:43:40,805 [a6fb26e7-f548-473f-8cf0-48fafe70504d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x26e8580d, L:/0.0.0.0:15026] INACTIVE
2024-03-25 19:43:40,805 [a6fb26e7-f548-473f-8cf0-48fafe70504d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x26e8580d, L:/0.0.0.0:15026] UNREGISTERED
2024-03-25 19:43:40,806 [6e65d581-b1bc-41f2-b39b-16d8508d6618-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29: shutdown
2024-03-25 19:43:40,806 [6e65d581-b1bc-41f2-b39b-16d8508d6618-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-13E9E73E6D29,id=6e65d581-b1bc-41f2-b39b-16d8508d6618
2024-03-25 19:43:40,806 [6e65d581-b1bc-41f2-b39b-16d8508d6618-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: shutdown 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-FollowerState
2024-03-25 19:43:40,807 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-03-25 19:43:40,807 [6e65d581-b1bc-41f2-b39b-16d8508d6618-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6: shutdown
2024-03-25 19:43:40,807 [6e65d581-b1bc-41f2-b39b-16d8508d6618-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-7CBE81B705E6,id=6e65d581-b1bc-41f2-b39b-16d8508d6618
2024-03-25 19:43:40,807 [6e65d581-b1bc-41f2-b39b-16d8508d6618-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: shutdown 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-LeaderStateImpl
2024-03-25 19:43:40,807 [6e65d581-b1bc-41f2-b39b-16d8508d6618-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-PendingRequests: sendNotLeaderResponses
2024-03-25 19:43:40,807 [6e65d581-b1bc-41f2-b39b-16d8508d6618-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-StateMachineUpdater: set stopIndex = 0
2024-03-25 19:43:40,808 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-7CBE81B705E6: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/1c6daf81-1115-4d9e-8b57-7cbe81b705e6/sm/snapshot.1_0
2024-03-25 19:43:40,808 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-FollowerState was interrupted
2024-03-25 19:43:40,811 [6e65d581-b1bc-41f2-b39b-16d8508d6618-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-StateMachineUpdater: set stopIndex = 1
2024-03-25 19:43:40,811 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-7CBE81B705E6: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/1c6daf81-1115-4d9e-8b57-7cbe81b705e6/sm/snapshot.1_0 took: 3 ms
2024-03-25 19:43:40,811 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-StateMachineUpdater: Took a snapshot at index 0
2024-03-25 19:43:40,811 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-25 19:43:40,811 [6e65d581-b1bc-41f2-b39b-16d8508d6618-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6: applyIndex: 0
2024-03-25 19:43:40,811 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-25 19:43:40,811 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-13E9E73E6D29: Taking a snapshot at:(t:2, i:1) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29/sm/snapshot.2_1
2024-03-25 19:43:40,812 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-13E9E73E6D29: Finished taking a snapshot at:(t:2, i:1) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/ratis/8d5f7d5e-0312-4916-b232-13e9e73e6d29/sm/snapshot.2_1 took: 3 ms
2024-03-25 19:43:40,812 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-StateMachineUpdater: Took a snapshot at index 1
2024-03-25 19:43:40,812 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 1
2024-03-25 19:43:40,812 [6e65d581-b1bc-41f2-b39b-16d8508d6618-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29: applyIndex: 1
2024-03-25 19:43:40,812 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-03-25 19:43:40,812 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: shutdown server GrpcServerProtocolService now
2024-03-25 19:43:40,812 [6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-25 19:43:40,814 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: shutdown server GrpcServerProtocolService successfully
2024-03-25 19:43:40,814 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-03-25 19:43:40,818 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-03-25 19:43:40,821 [6e65d581-b1bc-41f2-b39b-16d8508d6618-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x81c3c182, L:/0.0.0.0:15044] CLOSE
2024-03-25 19:43:40,821 [6e65d581-b1bc-41f2-b39b-16d8508d6618-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x81c3c182, L:/0.0.0.0:15044] INACTIVE
2024-03-25 19:43:40,821 [6e65d581-b1bc-41f2-b39b-16d8508d6618-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x81c3c182, L:/0.0.0.0:15044] UNREGISTERED
2024-03-25 19:43:41,107 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 3 milliseconds to process 2 existing database records.
2024-03-25 19:43:41,109 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 2 containers.
2024-03-25 19:43:41,109 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:41,109 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:41,109 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:41,109 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:41,109 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:41,109 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:41,109 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:41,127 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-03-25 19:43:41,127 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-03-25 19:43:41,127 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-03-25 19:43:41,130 [Recon-SyncOM-2] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(422)) - com.google.protobuf.ServiceException: java.io.EOFException: End of File Exception between local host is: "fv-az1540-867/10.1.0.27"; destination host is: "localhost":15004; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException, while invoking $Proxy77.submitRequest over nodeId=null,nodeAddress=localhost:15004. Trying to failover after sleeping for 2000ms. Current retry count: 0.
2024-03-25 19:43:41,417 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-03-25 19:43:41,516 [6e65d581-b1bc-41f2-b39b-16d8508d6618-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-13E9E73E6D29-SegmentedRaftLogWorker close()
2024-03-25 19:43:41,617 [a568c6b4-1a28-494a-b080-2324592b3a72-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - a568c6b4-1a28-494a-b080-2324592b3a72@group-739850C3A563-SegmentedRaftLogWorker close()
2024-03-25 19:43:41,617 [JvmPauseMonitor3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-a568c6b4-1a28-494a-b080-2324592b3a72: Stopped
2024-03-25 19:43:41,686 [a6fb26e7-f548-473f-8cf0-48fafe70504d-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-837C047AC986-SegmentedRaftLogWorker close()
2024-03-25 19:43:41,686 [JvmPauseMonitor4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-a6fb26e7-f548-473f-8cf0-48fafe70504d: Stopped
2024-03-25 19:43:41,804 [6e65d581-b1bc-41f2-b39b-16d8508d6618-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 6e65d581-b1bc-41f2-b39b-16d8508d6618@group-7CBE81B705E6-SegmentedRaftLogWorker close()
2024-03-25 19:43:41,805 [JvmPauseMonitor6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-6e65d581-b1bc-41f2-b39b-16d8508d6618: Stopped
2024-03-25 19:43:42,114 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 4 milliseconds to process 2 existing database records.
2024-03-25 19:43:42,115 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 2 containers.
2024-03-25 19:43:42,115 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:42,115 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:42,115 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:42,115 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:42,116 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:42,116 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:42,116 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:42,417 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-03-25 19:43:42,794 [main] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-803237d0-c9dc-4fed-b0b2-099c5dbec3f7/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-71af8759-bfa1-4ad0-bcf2-b488489b099b/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-e828a9d5-04d1-4ff4-9efb-57eb4f509c93/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-a11ce00a-a8e8-4457-9c04-884d2480a314/container.db]
2024-03-25 19:43:42,795 [main] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-e828a9d5-04d1-4ff4-9efb-57eb4f509c93/container.db from cache
2024-03-25 19:43:42,796 [main] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(451)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-3/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-e828a9d5-04d1-4ff4-9efb-57eb4f509c93/container.db for volume DS-e828a9d5-04d1-4ff4-9efb-57eb4f509c93
2024-03-25 19:43:42,796 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-03-25 19:43:42,796 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-03-25 19:43:42,797 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(638)) - Ozone container server stopped.
2024-03-25 19:43:42,797 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@f0cf7a4{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-03-25 19:43:42,798 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@7b11904c{HTTP/1.1, (http/1.1)}{0.0.0.0:15029}
2024-03-25 19:43:42,798 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-03-25 19:43:42,798 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@3c602531{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2024-03-25 19:43:42,799 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@1769fe0d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-03-25 19:43:42,800 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-03-25 19:43:42,800 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15030
2024-03-25 19:43:42,801 [IPC Server listener on 15030] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15030
2024-03-25 19:43:42,801 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-03-25 19:43:42,894 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27) moved to stale state. Finalizing its pipelines [PipelineID=1c6daf81-1115-4d9e-8b57-7cbe81b705e6]
2024-03-25 19:43:42,895 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=1c6daf81-1115-4d9e-8b57-7cbe81b705e6 moved to CLOSED state
2024-03-25 19:43:43,119 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 3 milliseconds to process 2 existing database records.
2024-03-25 19:43:43,120 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 2 containers.
2024-03-25 19:43:43,120 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:43,120 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:43,120 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-03-25 19:43:43,120 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-03-25 19:43:43,120 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-03-25 19:43:43,120 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-03-25 19:43:43,120 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-03-25 19:43:43,131 [Recon-SyncOM-2] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(422)) - com.google.protobuf.ServiceException: java.net.ConnectException: Call From fv-az1540-867/10.1.0.27 to localhost:15004 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy77.submitRequest over nodeId=null,nodeAddress=localhost:15004 after 1 failover attempts. Trying to failover after sleeping for 4000ms. Current retry count: 1.
2024-03-25 19:43:43,195 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 6e65d581-b1bc-41f2-b39b-16d8508d6618(fv-az1540-867/10.1.0.27) moved to stale state. Finalizing its pipelines [PipelineID=1c6daf81-1115-4d9e-8b57-7cbe81b705e6]
2024-03-25 19:43:43,196 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=1c6daf81-1115-4d9e-8b57-7cbe81b705e6 moved to CLOSED state
2024-03-25 19:43:43,197 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 3 pipelines in house.
2024-03-25 19:43:43,199 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 3 milliseconds.
2024-03-25 19:43:43,418 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-03-25 19:43:43,483 [timer1] WARN  server.GrpcLogAppender (LogUtils.java:warn(121)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29->8de788e1-2c95-4c74-b4ac-29ea2448e86a-AppendLogResponseHandler: Failed appendEntries (Repeated 8 times in the last 5.001s): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-03-25 19:43:43,491 [timer4] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(217)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29->8de788e1-2c95-4c74-b4ac-29ea2448e86a-GrpcLogAppender: Follower failed (request=null, errorCount=2); keep nextIndex (1) unchanged and retry. (Repeated 2 times in the last 5.000s)
2024-03-25 19:43:43,495 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27) moved to stale state. Finalizing its pipelines []
2024-03-25 19:43:43,495 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27) moved to stale state. Finalizing its pipelines [PipelineID=f8263715-53d5-4884-b6a7-837c047ac986]
2024-03-25 19:43:43,495 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode f8c0ec26-9898-49d2-a0ea-132d14d0dc83(fv-az1540-867/10.1.0.27) moved to stale state. Finalizing its pipelines []
2024-03-25 19:43:43,495 [timer6] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(217)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29->8de788e1-2c95-4c74-b4ac-29ea2448e86a-GrpcLogAppender: Follower failed (request=null, errorCount=4); keep nextIndex (2) unchanged and retry. (Repeated 2 times in the last 5.000s)
2024-03-25 19:43:43,496 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=f8263715-53d5-4884-b6a7-837c047ac986 moved to CLOSED state
2024-03-25 19:43:43,497 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 3 pipelines in house.
2024-03-25 19:43:43,498 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 3 milliseconds.
2024-03-25 19:43:43,500 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode a6fb26e7-f548-473f-8cf0-48fafe70504d(fv-az1540-867/10.1.0.27) moved to stale state. Finalizing its pipelines [PipelineID=f8263715-53d5-4884-b6a7-837c047ac986]
2024-03-25 19:43:43,501 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 3 pipelines in house.
2024-03-25 19:43:43,503 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 3 milliseconds.
2024-03-25 19:43:43,514 [timer1] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(217)) - a6fb26e7-f548-473f-8cf0-48fafe70504d@group-13E9E73E6D29->8de788e1-2c95-4c74-b4ac-29ea2448e86a-GrpcLogAppender: Follower failed (request=null, errorCount=8); keep nextIndex (3) unchanged and retry. (Repeated 4 times in the last 4.999s)
2024-03-25 19:43:43,619 [ForkJoinPool.commonPool-worker-3] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-803237d0-c9dc-4fed-b0b2-099c5dbec3f7/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-71af8759-bfa1-4ad0-bcf2-b488489b099b/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-a11ce00a-a8e8-4457-9c04-884d2480a314/container.db]
2024-03-25 19:43:43,623 [ForkJoinPool.commonPool-worker-3] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-803237d0-c9dc-4fed-b0b2-099c5dbec3f7/container.db from cache
2024-03-25 19:43:43,623 [ForkJoinPool.commonPool-worker-3] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(451)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-1/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-803237d0-c9dc-4fed-b0b2-099c5dbec3f7/container.db for volume DS-803237d0-c9dc-4fed-b0b2-099c5dbec3f7
2024-03-25 19:43:43,623 [ForkJoinPool.commonPool-worker-3] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-03-25 19:43:43,624 [ForkJoinPool.commonPool-worker-3] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-03-25 19:43:43,624 [ForkJoinPool.commonPool-worker-3] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(638)) - Ozone container server stopped.
2024-03-25 19:43:43,626 [ForkJoinPool.commonPool-worker-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@3a55f8c7{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-03-25 19:43:43,627 [ForkJoinPool.commonPool-worker-3] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@3e21253f{HTTP/1.1, (http/1.1)}{0.0.0.0:15011}
2024-03-25 19:43:43,627 [ForkJoinPool.commonPool-worker-3] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-03-25 19:43:43,628 [ForkJoinPool.commonPool-worker-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5eb645c8{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2024-03-25 19:43:43,628 [ForkJoinPool.commonPool-worker-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2f730434{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-03-25 19:43:43,629 [ForkJoinPool.commonPool-worker-3] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-03-25 19:43:43,630 [ForkJoinPool.commonPool-worker-3] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15012
2024-03-25 19:43:43,630 [IPC Server listener on 15012] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15012
2024-03-25 19:43:43,631 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-03-25 19:43:43,689 [ForkJoinPool.commonPool-worker-1] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-71af8759-bfa1-4ad0-bcf2-b488489b099b/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-a11ce00a-a8e8-4457-9c04-884d2480a314/container.db]
2024-03-25 19:43:43,690 [ForkJoinPool.commonPool-worker-1] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-71af8759-bfa1-4ad0-bcf2-b488489b099b/container.db from cache
2024-03-25 19:43:43,691 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(451)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-2/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-71af8759-bfa1-4ad0-bcf2-b488489b099b/container.db for volume DS-71af8759-bfa1-4ad0-bcf2-b488489b099b
2024-03-25 19:43:43,691 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-03-25 19:43:43,692 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-03-25 19:43:43,692 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(638)) - Ozone container server stopped.
2024-03-25 19:43:43,694 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@99daa14{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-03-25 19:43:43,694 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@3823c031{HTTP/1.1, (http/1.1)}{0.0.0.0:15020}
2024-03-25 19:43:43,695 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-03-25 19:43:43,695 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7aaefbf8{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2024-03-25 19:43:43,695 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27) moved to stale state. Finalizing its pipelines [PipelineID=9fcebae3-2819-4af1-b2d2-739850c3a563]
2024-03-25 19:43:43,697 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=9fcebae3-2819-4af1-b2d2-739850c3a563 moved to CLOSED state
2024-03-25 19:43:43,695 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode a568c6b4-1a28-494a-b080-2324592b3a72(fv-az1540-867/10.1.0.27) moved to stale state. Finalizing its pipelines [PipelineID=9fcebae3-2819-4af1-b2d2-739850c3a563]
2024-03-25 19:43:43,696 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@4747a860{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-03-25 19:43:43,698 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=9fcebae3-2819-4af1-b2d2-739850c3a563 moved to CLOSED state
2024-03-25 19:43:43,698 [ForkJoinPool.commonPool-worker-1] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-03-25 19:43:43,699 [ForkJoinPool.commonPool-worker-1] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15021
2024-03-25 19:43:43,699 [IPC Server listener on 15021] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15021
2024-03-25 19:43:43,699 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-03-25 19:43:43,700 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 3 pipelines in house.
2024-03-25 19:43:43,701 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 4 milliseconds.
2024-03-25 19:43:43,808 [ForkJoinPool.commonPool-worker-2] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-a11ce00a-a8e8-4457-9c04-884d2480a314/container.db]
2024-03-25 19:43:43,810 [ForkJoinPool.commonPool-worker-2] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-a11ce00a-a8e8-4457-9c04-884d2480a314/container.db from cache
2024-03-25 19:43:43,810 [ForkJoinPool.commonPool-worker-2] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(451)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-6a4a2262-318d-47a5-8347-82ea62ef3dc4/ozone-meta/datanode-4/data-0/hdds/6a4a2262-318d-47a5-8347-82ea62ef3dc4/DS-a11ce00a-a8e8-4457-9c04-884d2480a314/container.db for volume DS-a11ce00a-a8e8-4457-9c04-884d2480a314
2024-03-25 19:43:43,810 [ForkJoinPool.commonPool-worker-2] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-03-25 19:43:43,811 [ForkJoinPool.commonPool-worker-2] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-03-25 19:43:43,812 [ForkJoinPool.commonPool-worker-2] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(638)) - Ozone container server stopped.
2024-03-25 19:43:43,819 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@1469a956{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2024-03-25 19:43:43,820 [ForkJoinPool.commonPool-worker-2] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@69fbbcf6{HTTP/1.1, (http/1.1)}{0.0.0.0:15038}
2024-03-25 19:43:43,821 [ForkJoinPool.commonPool-worker-2] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-03-25 19:43:43,821 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7fb342f8{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.5.0-SNAPSHOT/hdds-container-service-1.5.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2024-03-25 19:43:43,822 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@41e537cb{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-03-25 19:43:43,823 [ForkJoinPool.commonPool-worker-2] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-03-25 19:43:43,824 [ForkJoinPool.commonPool-worker-2] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15039
2024-03-25 19:43:43,825 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-03-25 19:43:43,825 [IPC Server listener on 15039] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15039
2024-03-25 19:43:43,826 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(486)) - Stopping the StorageContainerManager
2024-03-25 19:43:43,826 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1653)) - Container Balancer is not running.
2024-03-25 19:43:43,826 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stopReplicationManager(1786)) - Stopping Replication Manager Service.
2024-03-25 19:43:43,826 [main] INFO  replication.ReplicationManager (ReplicationManager.java:stop(328)) - Stopping Replication Monitor Thread.
2024-03-25 19:43:43,827 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1662)) - Stopping the Datanode Admin Monitor.
2024-03-25 19:43:43,827 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(935)) - Replication Monitor Thread is stopped
2024-03-25 19:43:43,827 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1669)) - Stopping datanode service RPC server
2024-03-25 19:43:43,827 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(425)) - Stopping the RPC server for DataNodes
2024-03-25 19:43:43,827 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15002
2024-03-25 19:43:43,827 [UnderReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(180)) - UnderReplicatedProcessor interrupted. Exiting...
2024-03-25 19:43:43,827 [OverReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(180)) - OverReplicatedProcessor interrupted. Exiting...
2024-03-25 19:43:43,833 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-03-25 19:43:43,833 [IPC Server listener on 15002] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15002
2024-03-25 19:43:43,896 [SCMHeartbeatProcessor-0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(878)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2024-03-25 19:43:43,896 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1677)) - Stopping block service RPC server
2024-03-25 19:43:43,896 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(171)) - Stopping the RPC server for Block Protocol
2024-03-25 19:43:43,896 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15001
2024-03-25 19:43:43,899 [IPC Server listener on 15001] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15001
2024-03-25 19:43:43,900 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-03-25 19:43:43,900 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1684)) - Stopping the StorageContainerLocationProtocol RPC server
2024-03-25 19:43:43,900 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(213)) - Stopping the RPC server for Client Protocol
2024-03-25 19:43:43,900 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15000
2024-03-25 19:43:43,904 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-03-25 19:43:43,904 [IPC Server listener on 15000] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15000
2024-03-25 19:43:43,904 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1691)) - Stopping Storage Container Manager HTTP server.
2024-03-25 19:43:43,905 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@4d484961{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2024-03-25 19:43:43,906 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@bf70ce5{HTTP/1.1, (http/1.1)}{0.0.0.0:15003}
2024-03-25 19:43:43,907 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-03-25 19:43:43,907 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@1f9af742{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2024-03-25 19:43:43,907 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@749ebc39{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-03-25 19:43:43,909 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1699)) - Stopping SCM LayoutVersionManager Service.
2024-03-25 19:43:43,909 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1711)) - Stopping Block Manager Service.
2024-03-25 19:43:43,909 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SCMBlockDeletingService
2024-03-25 19:43:43,910 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SCMBlockDeletingService
2024-03-25 19:43:43,920 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1731)) - Stopping SCM Event Queue.
2024-03-25 19:43:43,923 [JvmPauseMonitor0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-9c2d3f76-8b57-48c2-b1f2-06f080cfbafd: Stopped
2024-03-25 19:43:43,923 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1742)) - Stopping SCM HA services.
2024-03-25 19:43:43,923 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(152)) - Stopping RatisPipelineUtilsThread.
2024-03-25 19:43:43,923 [RatisPipelineUtilsThread-0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(183)) - RatisPipelineUtilsThread is interrupted.
2024-03-25 19:43:43,924 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(128)) - Stopping BackgroundPipelineScrubber Service.
2024-03-25 19:43:43,924 [BackgroundPipelineScrubber] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(112)) - BackgroundPipelineScrubber is interrupted, exit
2024-03-25 19:43:43,925 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2024-03-25 19:43:43,945 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2024-03-25 19:43:43,946 [main] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(148)) - RatisPipelineUtilsThread is not running, just ignore.
2024-03-25 19:43:43,946 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(123)) - BackgroundPipelineScrubber Service is not running, skip stop.
2024-03-25 19:43:43,946 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(128)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2024-03-25 19:43:43,946 [ExpiredContainerReplicaOpScrubber] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(112)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2024-03-25 19:43:43,946 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SCMBlockDeletingService
2024-03-25 19:43:43,946 [main] INFO  replication.ReplicationManager (ReplicationManager.java:stop(338)) - Replication Monitor Thread is not running.
2024-03-25 19:43:43,947 [main] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(327)) - Cannot stop Container Balancer because it's not running or stopping
2024-03-25 19:43:43,947 [LeaseManager#LeaseMonitor] WARN  lease.LeaseManager (LeaseManager.java:run(287)) - Lease manager is interrupted. Shutting down...
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1039)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1328)
	at java.util.concurrent.Semaphore.tryAcquire(Semaphore.java:409)
	at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:285)
	at java.lang.Thread.run(Thread.java:750)
2024-03-25 19:43:43,947 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1777)) - Stopping SCM MetadataStore.
2024-03-25 19:43:43,948 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopRecon(501)) - Stopping Recon
2024-03-25 19:43:43,948 [main] INFO  recon.ReconServer (ReconServer.java:stop(235)) - Stopping Recon server
2024-03-25 19:43:43,957 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@46c820f4{recon,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.5.0-SNAPSHOT/ozone-recon-1.5.0-SNAPSHOT.jar!/webapps/recon}
2024-03-25 19:43:43,958 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@47bd0384{HTTP/1.1, (http/1.1)}{0.0.0.0:15008}
2024-03-25 19:43:43,958 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-03-25 19:43:43,959 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@6b71002{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.5.0-SNAPSHOT/ozone-recon-1.5.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2024-03-25 19:43:43,959 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7aba0b5a{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-03-25 19:43:43,959 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(425)) - Stopping the RPC server for DataNodes
2024-03-25 19:43:43,960 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15009
2024-03-25 19:43:43,962 [IPC Server listener on 15009] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15009
2024-03-25 19:43:43,962 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-03-25 19:43:43,996 [SCMHeartbeatProcessor-0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(878)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2024-03-25 19:43:43,996 [main] INFO  scm.ReconScmTask (ReconScmTask.java:stop(72)) - Stopping ContainerSizeCountTask Thread.
2024-03-25 19:43:43,996 [main] INFO  scm.ReconScmTask (ReconScmTask.java:stop(72)) - Stopping ContainerHealthTask Thread.
2024-03-25 19:43:43,996 [main] INFO  scm.ReconScmTask (ReconScmTask.java:stop(72)) - Stopping PipelineSyncTask Thread.
2024-03-25 19:43:43,996 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:stop(462)) - Stopping SCM Event Queue.
2024-03-25 19:43:43,997 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:stop(470)) - Flushing container replica history to DB.
2024-03-25 19:43:43,999 [ContainerSizeCountTask] INFO  tasks.ContainerSizeCountTask (ContainerSizeCountTask.java:process(200)) - Completed a 'process' run of ContainerSizeCountTask.
2024-03-25 19:43:43,999 [ContainerSizeCountTask] INFO  tasks.ContainerSizeCountTask (ContainerSizeCountTask.java:run(114)) - Elapsed Time in milliseconds for Process() execution: 2
2024-03-25 19:43:43,999 [main] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:stop(303)) - Stopping Ozone Manager Service Provider.
2024-03-25 19:43:44,000 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:stop(230)) - Stopping Recon Task Controller.
2024-03-25 19:43:44,001 [main] INFO  recon.ReconServer (ReconServer.java:stop(260)) - Closing Recon Container Key DB.
2024-03-25 19:43:44,001 [Recon-SyncOM-2] WARN  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(528)) - Unable to get and apply delta updates from OM.
2024-03-25 19:43:44,001 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(537)) - Obtaining full snapshot from Ozone Manager
2024-03-25 19:43:44,002 [JvmPauseMonitor2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-Recon: Stopped
2024-03-25 19:43:44,002 [Recon-SyncOM-2] ERROR impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getOzoneManagerDBSnapshot(373)) - Unable to obtain Ozone Manager DB Snapshot. 
java.nio.channels.ClosedByInterruptException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:658)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:191)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:600)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:652)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:773)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:347)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1632)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1410)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:250)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:132)
	at com.sun.proxy.$Proxy77.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor101.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:433)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:166)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:158)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:96)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:362)
	at com.sun.proxy.$Proxy77.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransport.submitRequest(Hadoop3OmTransport.java:80)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:345)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceList(OzoneManagerProtocolClientSideTranslatorPB.java:1801)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerSnapshotUrl(OzoneManagerServiceProviderImpl.java:322)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:357)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:551)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:531)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:355)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:387)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:539)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$startSyncDataFromOM$0(OzoneManagerServiceProviderImpl.java:267)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-03-25 19:43:44,002 [Recon-SyncOM-2] ERROR impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:updateReconOmDBWithNewSnapshot(400)) - Null snapshot location got from OM.
2024-03-25 19:43:44,160 [shutdown-hook-0] INFO  recon.ReconServer (StringUtils.java:lambda$startupShutdownMessage$0(144)) - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ReconServer at fv-az1540-867/10.1.0.27
************************************************************/
