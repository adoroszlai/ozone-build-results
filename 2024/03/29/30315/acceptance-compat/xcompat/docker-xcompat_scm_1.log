No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
2024-03-29 17:31:19,620 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = d067c450f10e/172.19.0.14
STARTUP_MSG:   args = [--init]
STARTUP_MSG:   version = 1.5.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.14.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.15.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.16.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.16.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.16.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.5.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.0.1.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk18on-1.77.jar:/opt/hadoop/share/ozone/lib/bcutil-jdk18on-1.77.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.8.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.15.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.8.1.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.22.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.26.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.9.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.9.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.12.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-1.2.2.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.14.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/commons-net-3.10.0.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/ozone/lib/re2j-1.7.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.2.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.37.2.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.10.5.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.25.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-2.0.12.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.10.1.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.16.0.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.4.0.jar:/opt/hadoop/share/ozone/lib/jheaps-0.11.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.4.0.jar:/opt/hadoop/share/ozone/lib/jgraphx-3.9.8.1.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk18on-1.77.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/slf4j-api-2.0.12.jar:/opt/hadoop/share/ozone/lib/commons-text-1.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/okhttp-4.12.0.jar:/opt/hadoop/share/ozone/lib/okio-3.6.0.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.6.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.9.22.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.9.22.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.9.22.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.16.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.5.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/cb5d51983d044734a714f32a32255dc9604eb701 ; compiled by 'runner' on 2024-03-29T16:59Z
STARTUP_MSG:   java = 17.0.2
STARTUP_MSG:   conf = {hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=false, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.chunk.write.sync=false, hdds.container.close.threshold=0.9f, hdds.container.ipc.port=9859, hdds.container.ipc.random.port=false, hdds.container.ratis.admin.port=9857, hdds.container.ratis.datastream.enabled=false, hdds.container.ratis.datastream.port=9855, hdds.container.ratis.datastream.random.port=false, hdds.container.ratis.enabled=false, hdds.container.ratis.ipc.port=9858, hdds.container.ratis.ipc.random.port=false, hdds.container.ratis.leader.pending.bytes.limit=1GB, hdds.container.ratis.log.appender.queue.byte-limit=32MB, hdds.container.ratis.log.appender.queue.num-elements=1, hdds.container.ratis.log.purge.gap=1000000, hdds.container.ratis.log.queue.byte-limit=4GB, hdds.container.ratis.log.queue.num-elements=1024, hdds.container.ratis.num.container.op.executors=10, hdds.container.ratis.num.write.chunk.threads.per.volume=10, hdds.container.ratis.replication.level=MAJORITY, hdds.container.ratis.rpc.type=GRPC, hdds.container.ratis.segment.preallocated.size=4MB, hdds.container.ratis.segment.size=64MB, hdds.container.ratis.server.port=9856, hdds.container.ratis.statemachine.max.pending.apply-transactions=10000, hdds.container.ratis.statemachinedata.sync.timeout=10s, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=true, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=false, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.datanode.http.auth.type=simple, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.replication.zerocopy.enabled=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.slow.op.warning.threshold=500ms, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=false, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.leader.election.minimum.timeout.duration=5s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.ratis.server.retry-cache.timeout.duration=600000ms, hdds.ratis.snapshot.threshold=10000, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.scm.http.auth.type=simple, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/SCM.keytab, hdds.scm.kerberos.principal=SCM/_HOST@REALM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=3, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneAccessAuthorizer, ozone.acl.enabled=false, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.reconstruct.stripe.write.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.max.retries=3, ozone.client.read.retry.interval=1, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.default.bucket.layout=LEGACY, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.http.policy=HTTP_ONLY, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=om, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=om:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.om.http.auth.type=simple, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.kerberos.keytab.file=/etc/security/keytabs/OM.keytab, ozone.om.kerberos.principal=OM/_HOST@REALM, ozone.om.kerberos.principal.pattern=*, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.network.topology.refresh.duration=1h, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=true, ozone.path.deleting.limit.per.task=6000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.recon.http.auth.type=simple, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=10m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.s3g.http.auth.type=simple, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/_HOST@REALM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.metrics.percentiles.intervals.seconds=60, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=false, ozone.s3g.volume.name=s3v, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.handler.count.key=100, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.handler.count.key=100, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=150s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.handler.count.key=100, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.names=scm, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=120s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=false, ozone.security.http.kerberos.enabled=false, ozone.security.reconfigure.protocol.acl=*, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.xceiver.client.metrics.percentiles.intervals.seconds=60, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, recon.om.snapshot.task.interval.delay=1m, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2024-03-29 17:31:19,653 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2024-03-29 17:31:19,961 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:31:20,734 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2024-03-29 17:31:20,825 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2024-03-29 17:31:21,784 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2024-03-29 17:31:22,038 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-03-29 17:31:22,057 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2024-03-29 17:31:22,058 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-03-29 17:31:22,060 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2024-03-29 17:31:22,060 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2024-03-29 17:31:22,060 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2024-03-29 17:31:22,061 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2024-03-29 17:31:22,080 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:31:22,081 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2024-03-29 17:31:22,088 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2024-03-29 17:31:22,102 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2024-03-29 17:31:22,125 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-03-29 17:31:22,140 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-03-29 17:31:23,452 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2024-03-29 17:31:23,456 [main] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-29 17:31:23,457 [main] INFO server.RaftServerConfigKeys: raft.server.close.threshold = 60s (default)
2024-03-29 17:31:23,457 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-29 17:31:23,541 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2024-03-29 17:31:23,544 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2024-03-29 17:31:23,545 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2024-03-29 17:31:23,580 [main] INFO server.RaftServer: 7e6300f4-431e-434b-a906-4a062bd22839: addNew group-FC8F27CF4CBC:[7e6300f4-431e-434b-a906-4a062bd22839|d067c450f10e:9894] returns group-FC8F27CF4CBC:java.util.concurrent.CompletableFuture@1cb7936c[Not completed]
2024-03-29 17:31:23,631 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServer$Division: 7e6300f4-431e-434b-a906-4a062bd22839: new RaftServerImpl for group-FC8F27CF4CBC:[7e6300f4-431e-434b-a906-4a062bd22839|d067c450f10e:9894] with SCMStateMachine:uninitialized
2024-03-29 17:31:23,633 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2024-03-29 17:31:23,639 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-29 17:31:23,639 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2024-03-29 17:31:23,641 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2024-03-29 17:31:23,641 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-29 17:31:23,642 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.member.majority-add = false (default)
2024-03-29 17:31:23,642 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-29 17:31:23,672 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServer$Division: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC: ConfigurationManager, init=-1: peers:[7e6300f4-431e-434b-a906-4a062bd22839|d067c450f10e:9894]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-29 17:31:23,693 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2024-03-29 17:31:23,699 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2024-03-29 17:31:23,717 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2024-03-29 17:31:23,737 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-29 17:31:23,745 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2024-03-29 17:31:23,756 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-29 17:31:23,785 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.dropwizard3.Dm3MetricRegistriesImpl
2024-03-29 17:31:24,430 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2024-03-29 17:31:24,488 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-29 17:31:24,500 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2024-03-29 17:31:24,507 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2024-03-29 17:31:24,508 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2024-03-29 17:31:24,511 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2024-03-29 17:31:24,541 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-29 17:31:24,541 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-29 17:31:24,542 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2024-03-29 17:31:24,562 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/9c09a99f-571f-4bb7-b6cf-fc8f27cf4cbc does not exist. Creating ...
2024-03-29 17:31:24,627 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/9c09a99f-571f-4bb7-b6cf-fc8f27cf4cbc/in_use.lock acquired by nodename 12@d067c450f10e
2024-03-29 17:31:24,646 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/9c09a99f-571f-4bb7-b6cf-fc8f27cf4cbc has been successfully formatted.
2024-03-29 17:31:24,656 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] WARN util.FileUtils: Failed to Files.newInputStream /data/metadata/scm-ha/9c09a99f-571f-4bb7-b6cf-fc8f27cf4cbc/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /data/metadata/scm-ha/9c09a99f-571f-4bb7-b6cf-fc8f27cf4cbc/current/raft-meta.conf
2024-03-29 17:31:24,666 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2024-03-29 17:31:24,709 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2024-03-29 17:31:24,715 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:31:24,719 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-29 17:31:24,759 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-29 17:31:24,764 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2024-03-29 17:31:24,817 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-29 17:31:24,844 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-29 17:31:24,844 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:31:24,847 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO util.AwaitToRun: Thread[7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-cacheEviction-AwaitToRun,5,main] started
2024-03-29 17:31:24,850 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/9c09a99f-571f-4bb7-b6cf-fc8f27cf4cbc
2024-03-29 17:31:24,851 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2024-03-29 17:31:24,852 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2024-03-29 17:31:24,853 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2024-03-29 17:31:24,853 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2024-03-29 17:31:24,856 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2024-03-29 17:31:24,857 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2024-03-29 17:31:24,857 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-29 17:31:24,868 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2024-03-29 17:31:24,879 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554440 (custom)
2024-03-29 17:31:24,893 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:31:24,894 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2024-03-29 17:31:24,894 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2024-03-29 17:31:24,912 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2024-03-29 17:31:24,938 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-29 17:31:24,938 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-29 17:31:24,949 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServer$Division: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC: start as a follower, conf=-1: peers:[7e6300f4-431e-434b-a906-4a062bd22839|d067c450f10e:9894]|listeners:[], old=null
2024-03-29 17:31:24,964 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServer$Division: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-29 17:31:24,965 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO impl.RoleInfo: 7e6300f4-431e-434b-a906-4a062bd22839: start 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-FollowerState
2024-03-29 17:31:24,990 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FC8F27CF4CBC,id=7e6300f4-431e-434b-a906-4a062bd22839
2024-03-29 17:31:25,021 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-29 17:31:25,080 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-29 17:31:25,022 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2024-03-29 17:31:25,080 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2024-03-29 17:31:25,080 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-29 17:31:25,080 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2024-03-29 17:31:25,081 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-29 17:31:25,088 [main] INFO server.RaftServer: 7e6300f4-431e-434b-a906-4a062bd22839: start RPC server
2024-03-29 17:31:25,236 [main] INFO server.GrpcService: 7e6300f4-431e-434b-a906-4a062bd22839: GrpcService started, listening on 9894
2024-03-29 17:31:25,259 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-7e6300f4-431e-434b-a906-4a062bd22839: Started
2024-03-29 17:31:30,161 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-FollowerState] INFO impl.FollowerState: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5196507802ns, electionTimeout:5080ms
2024-03-29 17:31:30,161 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-FollowerState] INFO impl.RoleInfo: 7e6300f4-431e-434b-a906-4a062bd22839: shutdown 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-FollowerState
2024-03-29 17:31:30,162 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-FollowerState] INFO server.RaftServer$Division: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-29 17:31:30,164 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
2024-03-29 17:31:30,164 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-FollowerState] INFO impl.RoleInfo: 7e6300f4-431e-434b-a906-4a062bd22839: start 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1
2024-03-29 17:31:30,168 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO impl.LeaderElection: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[7e6300f4-431e-434b-a906-4a062bd22839|d067c450f10e:9894]|listeners:[], old=null
2024-03-29 17:31:30,169 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO impl.LeaderElection: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1 PRE_VOTE round 0: result PASSED (term=0)
2024-03-29 17:31:30,179 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO impl.LeaderElection: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[7e6300f4-431e-434b-a906-4a062bd22839|d067c450f10e:9894]|listeners:[], old=null
2024-03-29 17:31:30,179 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO impl.LeaderElection: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1 ELECTION round 0: result PASSED (term=1)
2024-03-29 17:31:30,179 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO impl.RoleInfo: 7e6300f4-431e-434b-a906-4a062bd22839: shutdown 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1
2024-03-29 17:31:30,180 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServer$Division: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-29 17:31:30,184 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2024-03-29 17:31:30,196 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2024-03-29 17:31:30,197 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2024-03-29 17:31:30,200 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2024-03-29 17:31:30,203 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2024-03-29 17:31:30,204 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2024-03-29 17:31:30,221 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.enabled = false (default)
2024-03-29 17:31:30,223 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-29 17:31:30,226 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2024-03-29 17:31:30,226 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2024-03-29 17:31:30,226 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-29 17:31:30,228 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO impl.RoleInfo: 7e6300f4-431e-434b-a906-4a062bd22839: start 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderStateImpl
2024-03-29 17:31:30,231 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServer$Division: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC: set firstElectionSinceStartup to false for becomeLeader
2024-03-29 17:31:30,231 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServer$Division: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC: change Leader from null to 7e6300f4-431e-434b-a906-4a062bd22839 at term 1 for becomeLeader, leader elected after 6538ms
2024-03-29 17:31:30,292 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-29 17:31:30,384 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-SegmentedRaftLogWorker] INFO segmented.BufferedWriteChannel: open log_inprogress_0 at position 0
2024-03-29 17:31:30,389 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServer$Division: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC: set configuration 0: peers:[7e6300f4-431e-434b-a906-4a062bd22839|d067c450f10e:9894]|listeners:[], old=null
2024-03-29 17:31:30,418 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/9c09a99f-571f-4bb7-b6cf-fc8f27cf4cbc/current/log_inprogress_0
2024-03-29 17:31:30,480 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-StateMachineUpdater] INFO server.RaftServer$Division: leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-29 17:31:31,256 [main] INFO server.RaftServer: 7e6300f4-431e-434b-a906-4a062bd22839: close
2024-03-29 17:31:31,257 [main] INFO server.GrpcService: 7e6300f4-431e-434b-a906-4a062bd22839: shutdown server GrpcServerProtocolService now
2024-03-29 17:31:31,258 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServer$Division: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC: shutdown
2024-03-29 17:31:31,260 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-FC8F27CF4CBC,id=7e6300f4-431e-434b-a906-4a062bd22839
2024-03-29 17:31:31,260 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO impl.RoleInfo: 7e6300f4-431e-434b-a906-4a062bd22839: shutdown 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderStateImpl
2024-03-29 17:31:31,278 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO impl.PendingRequests: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-PendingRequests: sendNotLeaderResponses
2024-03-29 17:31:31,291 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-StateMachineUpdater] INFO impl.StateMachineUpdater: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-StateMachineUpdater: Took a snapshot at index 0
2024-03-29 17:31:31,293 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-StateMachineUpdater] INFO impl.StateMachineUpdater: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-29 17:31:31,302 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO impl.StateMachineUpdater: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-StateMachineUpdater: set stopIndex = 0
2024-03-29 17:31:31,303 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServer$Division: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC: applyIndex: 0
2024-03-29 17:31:31,314 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-cacheEviction-AwaitToRun] INFO util.AwaitToRun: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-29 17:31:31,315 [main] INFO server.GrpcService: 7e6300f4-431e-434b-a906-4a062bd22839: shutdown server GrpcServerProtocolService successfully
2024-03-29 17:31:31,457 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-SegmentedRaftLogWorker close()
2024-03-29 17:31:31,459 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-7e6300f4-431e-434b-a906-4a062bd22839: Stopped
2024-03-29 17:31:31,459 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:31:31,466 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-9c09a99f-571f-4bb7-b6cf-fc8f27cf4cbc; layoutVersion=7; scmId=7e6300f4-431e-434b-a906-4a062bd22839
2024-03-29 17:31:31,503 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at d067c450f10e/172.19.0.14
************************************************************/
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
2024-03-29 17:31:36,159 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = d067c450f10e/172.19.0.14
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.5.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.14.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.15.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.16.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.16.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.16.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.5.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.0.1.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk18on-1.77.jar:/opt/hadoop/share/ozone/lib/bcutil-jdk18on-1.77.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.8.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.15.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.8.1.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.22.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.26.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.9.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.9.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.12.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-1.2.2.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.14.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/commons-net-3.10.0.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/ozone/lib/re2j-1.7.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.2.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.37.2.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.10.5.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.25.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-2.0.12.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.10.1.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.16.0.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.4.0.jar:/opt/hadoop/share/ozone/lib/jheaps-0.11.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.4.0.jar:/opt/hadoop/share/ozone/lib/jgraphx-3.9.8.1.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk18on-1.77.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/slf4j-api-2.0.12.jar:/opt/hadoop/share/ozone/lib/commons-text-1.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/okhttp-4.12.0.jar:/opt/hadoop/share/ozone/lib/okio-3.6.0.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.6.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.9.22.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.9.22.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.9.22.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.16.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.5.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/cb5d51983d044734a714f32a32255dc9604eb701 ; compiled by 'runner' on 2024-03-29T16:59Z
STARTUP_MSG:   java = 17.0.2
STARTUP_MSG:   conf = {hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=false, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.chunk.write.sync=false, hdds.container.close.threshold=0.9f, hdds.container.ipc.port=9859, hdds.container.ipc.random.port=false, hdds.container.ratis.admin.port=9857, hdds.container.ratis.datastream.enabled=false, hdds.container.ratis.datastream.port=9855, hdds.container.ratis.datastream.random.port=false, hdds.container.ratis.enabled=false, hdds.container.ratis.ipc.port=9858, hdds.container.ratis.ipc.random.port=false, hdds.container.ratis.leader.pending.bytes.limit=1GB, hdds.container.ratis.log.appender.queue.byte-limit=32MB, hdds.container.ratis.log.appender.queue.num-elements=1, hdds.container.ratis.log.purge.gap=1000000, hdds.container.ratis.log.queue.byte-limit=4GB, hdds.container.ratis.log.queue.num-elements=1024, hdds.container.ratis.num.container.op.executors=10, hdds.container.ratis.num.write.chunk.threads.per.volume=10, hdds.container.ratis.replication.level=MAJORITY, hdds.container.ratis.rpc.type=GRPC, hdds.container.ratis.segment.preallocated.size=4MB, hdds.container.ratis.segment.size=64MB, hdds.container.ratis.server.port=9856, hdds.container.ratis.statemachine.max.pending.apply-transactions=10000, hdds.container.ratis.statemachinedata.sync.timeout=10s, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=true, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=false, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.datanode.http.auth.type=simple, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.replication.zerocopy.enabled=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.slow.op.warning.threshold=500ms, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=false, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.leader.election.minimum.timeout.duration=5s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.ratis.server.retry-cache.timeout.duration=600000ms, hdds.ratis.snapshot.threshold=10000, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.scm.http.auth.type=simple, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/SCM.keytab, hdds.scm.kerberos.principal=SCM/_HOST@REALM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=3, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneAccessAuthorizer, ozone.acl.enabled=false, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.reconstruct.stripe.write.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.max.retries=3, ozone.client.read.retry.interval=1, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.default.bucket.layout=LEGACY, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.http.policy=HTTP_ONLY, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=om, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=om:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.om.http.auth.type=simple, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.kerberos.keytab.file=/etc/security/keytabs/OM.keytab, ozone.om.kerberos.principal=OM/_HOST@REALM, ozone.om.kerberos.principal.pattern=*, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.network.topology.refresh.duration=1h, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=true, ozone.path.deleting.limit.per.task=6000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.recon.http.auth.type=simple, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=10m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.s3g.http.auth.type=simple, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/_HOST@REALM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.metrics.percentiles.intervals.seconds=60, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=false, ozone.s3g.volume.name=s3v, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.handler.count.key=100, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.handler.count.key=100, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=150s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.handler.count.key=100, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.names=scm, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=120s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=false, ozone.security.http.kerberos.enabled=false, ozone.security.reconfigure.protocol.acl=*, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.xceiver.client.metrics.percentiles.intervals.seconds=60, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, recon.om.snapshot.task.interval.delay=1m, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2024-03-29 17:31:36,175 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2024-03-29 17:31:36,268 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:31:36,695 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2024-03-29 17:31:36,702 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2024-03-29 17:31:37,926 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:31:38,237 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:31:38,254 [main] INFO utils.LeakDetector: Starting leak detector thread ManagedRocksObject0.
2024-03-29 17:31:38,627 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.5.0-SNAPSHOT.jar!/network-topology-default.xml]
2024-03-29 17:31:38,637 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
2024-03-29 17:31:38,707 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.dropwizard3.Dm3MetricRegistriesImpl
2024-03-29 17:31:38,933 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:7e6300f4-431e-434b-a906-4a062bd22839
2024-03-29 17:31:39,026 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2024-03-29 17:31:39,043 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-03-29 17:31:39,044 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2024-03-29 17:31:39,045 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-03-29 17:31:39,045 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2024-03-29 17:31:39,045 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2024-03-29 17:31:39,045 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2024-03-29 17:31:39,046 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2024-03-29 17:31:39,059 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:31:39,059 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2024-03-29 17:31:39,060 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2024-03-29 17:31:39,091 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2024-03-29 17:31:39,097 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-03-29 17:31:39,098 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-03-29 17:31:39,422 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2024-03-29 17:31:39,424 [main] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-29 17:31:39,424 [main] INFO server.RaftServerConfigKeys: raft.server.close.threshold = 60s (default)
2024-03-29 17:31:39,424 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-29 17:31:39,430 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2024-03-29 17:31:39,431 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2024-03-29 17:31:39,432 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2024-03-29 17:31:39,435 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServer: 7e6300f4-431e-434b-a906-4a062bd22839: found a subdirectory /data/metadata/scm-ha/9c09a99f-571f-4bb7-b6cf-fc8f27cf4cbc
2024-03-29 17:31:39,443 [main] INFO server.RaftServer: 7e6300f4-431e-434b-a906-4a062bd22839: addNew group-FC8F27CF4CBC:[] returns group-FC8F27CF4CBC:java.util.concurrent.CompletableFuture@73e776b7[Not completed]
2024-03-29 17:31:39,459 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServer$Division: 7e6300f4-431e-434b-a906-4a062bd22839: new RaftServerImpl for group-FC8F27CF4CBC:[] with SCMStateMachine:uninitialized
2024-03-29 17:31:39,460 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2024-03-29 17:31:39,460 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-29 17:31:39,461 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2024-03-29 17:31:39,461 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2024-03-29 17:31:39,461 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-29 17:31:39,462 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.member.majority-add = false (default)
2024-03-29 17:31:39,462 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-29 17:31:39,469 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServer$Division: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-29 17:31:39,475 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2024-03-29 17:31:39,480 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2024-03-29 17:31:39,483 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2024-03-29 17:31:39,484 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-29 17:31:39,487 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2024-03-29 17:31:39,488 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-29 17:31:39,661 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2024-03-29 17:31:39,670 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-29 17:31:39,675 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2024-03-29 17:31:39,676 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2024-03-29 17:31:39,677 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2024-03-29 17:31:39,678 [7e6300f4-431e-434b-a906-4a062bd22839-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2024-03-29 17:31:39,685 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
2024-03-29 17:31:39,685 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2024-03-29 17:31:39,685 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
2024-03-29 17:31:39,742 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-03-29 17:31:39,840 [main] INFO ha.SequenceIdGenerator: upgrade localId to 113750153625600000
2024-03-29 17:31:39,841 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
2024-03-29 17:31:39,849 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
2024-03-29 17:31:39,885 [main] INFO ha.SequenceIdGenerator: upgrade CertificateId to 2
2024-03-29 17:31:39,890 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
2024-03-29 17:31:40,023 [main] INFO node.SCMNodeManager: Entering startup safe mode.
2024-03-29 17:31:40,061 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2024-03-29 17:31:40,068 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2024-03-29 17:31:40,088 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
2024-03-29 17:31:40,120 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2024-03-29 17:31:40,122 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2024-03-29 17:31:40,136 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
2024-03-29 17:31:40,136 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
2024-03-29 17:31:40,142 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
2024-03-29 17:31:40,150 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
2024-03-29 17:31:40,157 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
2024-03-29 17:31:40,157 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
2024-03-29 17:31:40,196 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-03-29 17:31:40,197 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-03-29 17:31:40,241 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
2024-03-29 17:31:40,334 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
2024-03-29 17:31:40,351 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
2024-03-29 17:31:40,353 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
2024-03-29 17:31:40,372 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
2024-03-29 17:31:40,378 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:31:40,380 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2024-03-29 17:31:40,430 [main] INFO server.StorageContainerManager: SCM start with adminUsers: [hadoop]
2024-03-29 17:31:41,237 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2024-03-29 17:31:41,304 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-29 17:31:41,348 [main] INFO ipc.Server: Listener at 0.0.0.0:9861
2024-03-29 17:31:41,351 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
2024-03-29 17:31:41,385 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2024-03-29 17:31:41,392 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-29 17:31:41,392 [main] INFO ipc.Server: Listener at 0.0.0.0:9863
2024-03-29 17:31:41,392 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
2024-03-29 17:31:41,449 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2024-03-29 17:31:41,495 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-29 17:31:41,496 [main] INFO ipc.Server: Listener at 0.0.0.0:9860
2024-03-29 17:31:41,504 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
2024-03-29 17:31:41,711 [main] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
2024-03-29 17:31:41,711 [main] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2024-03-29 17:31:41,718 [main] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
2024-03-29 17:31:41,723 [main] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
2024-03-29 17:31:41,727 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-29 17:31:41,727 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-29 17:31:41,728 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2024-03-29 17:31:41,747 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/9c09a99f-571f-4bb7-b6cf-fc8f27cf4cbc/in_use.lock acquired by nodename 6@d067c450f10e
2024-03-29 17:31:41,752 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=7e6300f4-431e-434b-a906-4a062bd22839} from /data/metadata/scm-ha/9c09a99f-571f-4bb7-b6cf-fc8f27cf4cbc/current/raft-meta
2024-03-29 17:31:41,828 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServer$Division: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC: set configuration 0: peers:[7e6300f4-431e-434b-a906-4a062bd22839|d067c450f10e:9894]|listeners:[], old=null
2024-03-29 17:31:41,831 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2024-03-29 17:31:41,838 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2024-03-29 17:31:41,839 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:31:41,840 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-29 17:31:41,840 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-29 17:31:41,850 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2024-03-29 17:31:41,857 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-29 17:31:41,858 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-29 17:31:41,858 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:31:41,861 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO util.AwaitToRun: Thread[7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-cacheEviction-AwaitToRun,5,main] started
2024-03-29 17:31:41,864 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/9c09a99f-571f-4bb7-b6cf-fc8f27cf4cbc
2024-03-29 17:31:41,864 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2024-03-29 17:31:41,865 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2024-03-29 17:31:41,866 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2024-03-29 17:31:41,866 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2024-03-29 17:31:41,867 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2024-03-29 17:31:41,868 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2024-03-29 17:31:41,868 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-29 17:31:41,868 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2024-03-29 17:31:41,872 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554440 (custom)
2024-03-29 17:31:41,877 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:31:41,878 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2024-03-29 17:31:41,878 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2024-03-29 17:31:41,878 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2024-03-29 17:31:41,902 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServer$Division: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC: set configuration 0: peers:[7e6300f4-431e-434b-a906-4a062bd22839|d067c450f10e:9894]|listeners:[], old=null
2024-03-29 17:31:41,903 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/9c09a99f-571f-4bb7-b6cf-fc8f27cf4cbc/current/log_inprogress_0
2024-03-29 17:31:41,905 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-29 17:31:41,919 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO segmented.BufferedWriteChannel: open log_inprogress_0 (append) at position 78
2024-03-29 17:31:41,920 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServer$Division: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC: start as a follower, conf=0: peers:[7e6300f4-431e-434b-a906-4a062bd22839|d067c450f10e:9894]|listeners:[], old=null
2024-03-29 17:31:41,920 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServer$Division: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC: changes role from      null to FOLLOWER at term 1 for startAsFollower
2024-03-29 17:31:41,921 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO impl.RoleInfo: 7e6300f4-431e-434b-a906-4a062bd22839: start 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-FollowerState
2024-03-29 17:31:41,922 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2024-03-29 17:31:41,923 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-29 17:31:41,923 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FC8F27CF4CBC,id=7e6300f4-431e-434b-a906-4a062bd22839
2024-03-29 17:31:41,925 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-29 17:31:41,927 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-29 17:31:41,927 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2024-03-29 17:31:41,928 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2024-03-29 17:31:41,928 [7e6300f4-431e-434b-a906-4a062bd22839-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-29 17:31:41,936 [main] INFO server.RaftServer: 7e6300f4-431e-434b-a906-4a062bd22839: start RPC server
2024-03-29 17:31:41,970 [main] INFO server.GrpcService: 7e6300f4-431e-434b-a906-4a062bd22839: GrpcService started, listening on 9894
2024-03-29 17:31:41,982 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-7e6300f4-431e-434b-a906-4a062bd22839: Started
2024-03-29 17:31:41,986 [main] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [7e6300f4-431e-434b-a906-4a062bd22839|d067c450f10e:9894]
2024-03-29 17:31:41,986 [main] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
2024-03-29 17:31:41,988 [main] INFO SCMHATransactionMonitor: Starting SCMHATransactionMonitor Service.
2024-03-29 17:31:41,995 [main] INFO ha.SCMServiceManager: Registering service SCMHATransactionMonitor.
2024-03-29 17:31:41,995 [main] INFO SCMHATransactionMonitor: SCMHATransactionMonitor Service is already running, skip start.
2024-03-29 17:31:42,089 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2024-03-29 17:31:42,099 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-03-29 17:31:42,099 [main] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
2024-03-29 17:31:42,384 [main] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
2024-03-29 17:31:42,388 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-03-29 17:31:42,393 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
2024-03-29 17:31:42,636 [main] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
2024-03-29 17:31:42,637 [main] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
2024-03-29 17:31:42,640 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-03-29 17:31:42,645 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
2024-03-29 17:31:42,875 [main] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
2024-03-29 17:31:42,875 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-29 17:31:42,904 [main] INFO util.log: Logging initialized @10436ms to org.eclipse.jetty.util.log.Slf4jLog
2024-03-29 17:31:43,012 [main] WARN server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /opt/hadoop/hadoop-http-auth-signature-secret
2024-03-29 17:31:43,017 [main] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
2024-03-29 17:31:43,023 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-29 17:31:43,025 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2024-03-29 17:31:43,025 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-29 17:31:43,025 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-29 17:31:43,054 [main] INFO http.BaseHttpServer: HTTP server of scm uses base directory /data/metadata/webserver
2024-03-29 17:31:43,055 [main] INFO http.HttpServer2: Jetty bound to port 9876
2024-03-29 17:31:43,056 [main] INFO server.Server: jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 17.0.2+8-86
2024-03-29 17:31:43,096 [main] INFO server.session: DefaultSessionIdManager workerName=node0
2024-03-29 17:31:43,096 [main] INFO server.session: No SessionScavenger set, using defaults
2024-03-29 17:31:43,097 [main] INFO server.session: node0 Scavenging every 660000ms
2024-03-29 17:31:43,107 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4f5bfbca{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
2024-03-29 17:31:43,107 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@53c9541c{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-03-29 17:31:43,214 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@34588991{scm,/,file:///data/metadata/webserver/jetty-0_0_0_0-9876-hdds-server-scm-1_5_0-SNAPSHOT_jar-_-any-5962536926713346049/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.5.0-SNAPSHOT.jar!/webapps/scm}
2024-03-29 17:31:43,224 [main] INFO server.AbstractConnector: Started ServerConnector@5c13534a{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
2024-03-29 17:31:43,224 [main] INFO server.Server: Started @10756ms
2024-03-29 17:31:43,229 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
2024-03-29 17:31:43,230 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
2024-03-29 17:31:43,233 [main] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
2024-03-29 17:31:47,041 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-FollowerState] INFO impl.FollowerState: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5120656777ns, electionTimeout:5118ms
2024-03-29 17:31:47,042 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-FollowerState] INFO impl.RoleInfo: 7e6300f4-431e-434b-a906-4a062bd22839: shutdown 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-FollowerState
2024-03-29 17:31:47,042 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-FollowerState] INFO server.RaftServer$Division: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2024-03-29 17:31:47,044 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
2024-03-29 17:31:47,044 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-FollowerState] INFO impl.RoleInfo: 7e6300f4-431e-434b-a906-4a062bd22839: start 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1
2024-03-29 17:31:47,045 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO impl.LeaderElection: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 1 for 0: peers:[7e6300f4-431e-434b-a906-4a062bd22839|d067c450f10e:9894]|listeners:[], old=null
2024-03-29 17:31:47,046 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO impl.LeaderElection: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1 PRE_VOTE round 0: result PASSED (term=1)
2024-03-29 17:31:47,057 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO impl.LeaderElection: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: peers:[7e6300f4-431e-434b-a906-4a062bd22839|d067c450f10e:9894]|listeners:[], old=null
2024-03-29 17:31:47,058 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO impl.LeaderElection: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1 ELECTION round 0: result PASSED (term=2)
2024-03-29 17:31:47,058 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO impl.RoleInfo: 7e6300f4-431e-434b-a906-4a062bd22839: shutdown 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1
2024-03-29 17:31:47,058 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServer$Division: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2024-03-29 17:31:47,062 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2024-03-29 17:31:47,065 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2024-03-29 17:31:47,067 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2024-03-29 17:31:47,071 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2024-03-29 17:31:47,072 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2024-03-29 17:31:47,072 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2024-03-29 17:31:47,075 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.enabled = false (default)
2024-03-29 17:31:47,077 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-29 17:31:47,077 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2024-03-29 17:31:47,077 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2024-03-29 17:31:47,077 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-29 17:31:47,079 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO impl.RoleInfo: 7e6300f4-431e-434b-a906-4a062bd22839: start 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderStateImpl
2024-03-29 17:31:47,079 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServer$Division: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC: set firstElectionSinceStartup to false for becomeLeader
2024-03-29 17:31:47,079 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
2024-03-29 17:31:47,079 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
2024-03-29 17:31:47,081 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServer$Division: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC: change Leader from null to 7e6300f4-431e-434b-a906-4a062bd22839 at term 2 for becomeLeader, leader elected after 7604ms
2024-03-29 17:31:47,086 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2024-03-29 17:31:47,087 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/9c09a99f-571f-4bb7-b6cf-fc8f27cf4cbc/current/log_inprogress_0 to /data/metadata/scm-ha/9c09a99f-571f-4bb7-b6cf-fc8f27cf4cbc/current/log_0-0
2024-03-29 17:31:47,088 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-LeaderElection1] INFO server.RaftServer$Division: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC: set configuration 1: peers:[7e6300f4-431e-434b-a906-4a062bd22839|d067c450f10e:9894]|listeners:[], old=null
2024-03-29 17:31:47,090 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-SegmentedRaftLogWorker] INFO segmented.BufferedWriteChannel: open log_inprogress_1 at position 0
2024-03-29 17:31:47,100 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/9c09a99f-571f-4bb7-b6cf-fc8f27cf4cbc/current/log_inprogress_1
2024-03-29 17:31:47,106 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-StateMachineUpdater] INFO server.RaftServer$Division: leader is ready since appliedIndex == 1 >= startIndex == 1
2024-03-29 17:31:47,106 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
2024-03-29 17:31:47,107 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
2024-03-29 17:31:47,108 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:31:47,108 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
2024-03-29 17:31:47,108 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2024-03-29 17:31:47,108 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
2024-03-29 17:31:47,109 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-03-29 17:31:47,109 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
2024-03-29 17:31:47,182 [IPC Server handler 1 on default port 9861] WARN ipc.Server: IPC Server handler 1 on default port 9861, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from xcompat_datanode_2.xcompat_default:58772 / 172.19.0.5:58772: output error
2024-03-29 17:31:47,183 [IPC Server handler 1 on default port 9861] INFO ipc.Server: IPC Server handler 1 on default port 9861 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:215)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:527)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3743)
	at org.apache.hadoop.ipc.Server.access$1800(Server.java:148)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1722)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1792)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2919)
	at org.apache.hadoop.ipc.Server$Connection.access$400(Server.java:1864)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1176)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:954)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:940)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1111)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-03-29 17:31:47,185 [IPC Server handler 0 on default port 9861] WARN ipc.Server: IPC Server handler 0 on default port 9861, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from xcompat_datanode_1.xcompat_default:39458 / 172.19.0.8:39458: output error
2024-03-29 17:31:47,185 [IPC Server handler 0 on default port 9861] INFO ipc.Server: IPC Server handler 0 on default port 9861 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:215)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:527)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3743)
	at org.apache.hadoop.ipc.Server.access$1800(Server.java:148)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1722)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1792)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2919)
	at org.apache.hadoop.ipc.Server$Connection.access$400(Server.java:1864)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1176)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:954)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:940)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1111)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-03-29 17:31:47,183 [IPC Server handler 2 on default port 9861] WARN ipc.Server: IPC Server handler 2 on default port 9861, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from xcompat_datanode_3.xcompat_default:46764 / 172.19.0.4:46764: output error
2024-03-29 17:31:47,186 [IPC Server handler 2 on default port 9861] INFO ipc.Server: IPC Server handler 2 on default port 9861 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:215)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:527)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3743)
	at org.apache.hadoop.ipc.Server.access$1800(Server.java:148)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1722)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1792)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2919)
	at org.apache.hadoop.ipc.Server$Connection.access$400(Server.java:1864)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1176)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:954)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:940)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1111)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-03-29 17:31:48,210 [IPC Server handler 20 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/085c729d-4292-40e9-9036-f47ff270bf64
2024-03-29 17:31:48,240 [IPC Server handler 20 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 085c729d-4292-40e9-9036-f47ff270bf64{ip: 172.19.0.4, host: xcompat_datanode_3.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:31:48,254 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:31:48,264 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
2024-03-29 17:31:48,274 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2024-03-29 17:31:48,288 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:31:48,293 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=39348e77-0049-4b6e-99bc-3de2b312400a to datanode:085c729d-4292-40e9-9036-f47ff270bf64
2024-03-29 17:31:48,571 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:31:48,587 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 39348e77-0049-4b6e-99bc-3de2b312400a, Nodes: 085c729d-4292-40e9-9036-f47ff270bf64(xcompat_datanode_3.xcompat_default/172.19.0.4), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:31:48.290787083Z[UTC]]
2024-03-29 17:31:49,076 [IPC Server handler 3 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/e7e36316-6c16-4f77-9b1f-b7af0f3cb70c
2024-03-29 17:31:49,076 [IPC Server handler 3 on default port 9861] INFO node.SCMNodeManager: Registered datanode: e7e36316-6c16-4f77-9b1f-b7af0f3cb70c{ip: 172.19.0.5, host: xcompat_datanode_2.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:31:49,077 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:31:49,077 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
2024-03-29 17:31:49,078 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=c20c9233-a622-46ad-80c1-e12c1231009b to datanode:e7e36316-6c16-4f77-9b1f-b7af0f3cb70c
2024-03-29 17:31:49,084 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:31:49,084 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: c20c9233-a622-46ad-80c1-e12c1231009b, Nodes: e7e36316-6c16-4f77-9b1f-b7af0f3cb70c(xcompat_datanode_2.xcompat_default/172.19.0.5), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:31:49.078707600Z[UTC]]
2024-03-29 17:31:49,723 [IPC Server handler 3 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/b845044c-574d-4d12-9c3c-9db488af7668
2024-03-29 17:31:49,723 [IPC Server handler 3 on default port 9861] INFO node.SCMNodeManager: Registered datanode: b845044c-574d-4d12-9c3c-9db488af7668{ip: 172.19.0.8, host: xcompat_datanode_1.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:31:49,725 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
2024-03-29 17:31:49,725 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
2024-03-29 17:31:49,725 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
2024-03-29 17:31:49,725 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2024-03-29 17:31:49,725 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:31:49,726 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:31:49,726 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=02250c53-38d6-4fe9-af80-7bff2d5a5a5c to datanode:b845044c-574d-4d12-9c3c-9db488af7668
2024-03-29 17:31:49,730 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:31:49,731 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 02250c53-38d6-4fe9-af80-7bff2d5a5a5c, Nodes: b845044c-574d-4d12-9c3c-9db488af7668(xcompat_datanode_1.xcompat_default/172.19.0.8), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:31:49.726723638Z[UTC]]
2024-03-29 17:31:49,739 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=c352fc0e-042a-42aa-82f2-7d8f014c9069 to datanode:e7e36316-6c16-4f77-9b1f-b7af0f3cb70c
2024-03-29 17:31:49,739 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=c352fc0e-042a-42aa-82f2-7d8f014c9069 to datanode:b845044c-574d-4d12-9c3c-9db488af7668
2024-03-29 17:31:49,740 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=c352fc0e-042a-42aa-82f2-7d8f014c9069 to datanode:085c729d-4292-40e9-9036-f47ff270bf64
2024-03-29 17:31:49,749 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:31:49,750 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: c352fc0e-042a-42aa-82f2-7d8f014c9069, Nodes: e7e36316-6c16-4f77-9b1f-b7af0f3cb70c(xcompat_datanode_2.xcompat_default/172.19.0.5)b845044c-574d-4d12-9c3c-9db488af7668(xcompat_datanode_1.xcompat_default/172.19.0.8)085c729d-4292-40e9-9036-f47ff270bf64(xcompat_datanode_3.xcompat_default/172.19.0.4), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:31:49.739590659Z[UTC]]
2024-03-29 17:31:49,753 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=deb3d444-8fd6-411c-baee-5ffc383ea46f to datanode:b845044c-574d-4d12-9c3c-9db488af7668
2024-03-29 17:31:49,753 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=deb3d444-8fd6-411c-baee-5ffc383ea46f to datanode:e7e36316-6c16-4f77-9b1f-b7af0f3cb70c
2024-03-29 17:31:49,754 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=deb3d444-8fd6-411c-baee-5ffc383ea46f to datanode:085c729d-4292-40e9-9036-f47ff270bf64
2024-03-29 17:31:49,763 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:31:49,766 [RatisPipelineUtilsThread-0] INFO pipeline.PipelineManagerImpl: Pipeline: PipelineID=deb3d444-8fd6-411c-baee-5ffc383ea46f contains same datanodes as previous pipelines: PipelineID=c352fc0e-042a-42aa-82f2-7d8f014c9069 nodeIds: b845044c-574d-4d12-9c3c-9db488af7668, e7e36316-6c16-4f77-9b1f-b7af0f3cb70c, 085c729d-4292-40e9-9036-f47ff270bf64
2024-03-29 17:31:49,766 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: deb3d444-8fd6-411c-baee-5ffc383ea46f, Nodes: b845044c-574d-4d12-9c3c-9db488af7668(xcompat_datanode_1.xcompat_default/172.19.0.8)e7e36316-6c16-4f77-9b1f-b7af0f3cb70c(xcompat_datanode_2.xcompat_default/172.19.0.5)085c729d-4292-40e9-9036-f47ff270bf64(xcompat_datanode_3.xcompat_default/172.19.0.4), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:31:49.753643890Z[UTC]]
2024-03-29 17:31:51,319 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:31:51,319 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=39348e77-0049-4b6e-99bc-3de2b312400a
2024-03-29 17:31:51,320 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:31:51,491 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:31:52,541 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:31:52,542 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=c20c9233-a622-46ad-80c1-e12c1231009b
2024-03-29 17:31:52,542 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:31:52,635 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:31:52,792 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:31:53,124 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:31:53,125 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=02250c53-38d6-4fe9-af80-7bff2d5a5a5c
2024-03-29 17:31:53,125 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:31:53,314 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:31:53,467 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:31:53,556 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:31:56,499 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:31:57,640 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:31:57,806 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
2024-03-29 17:31:57,807 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=c352fc0e-042a-42aa-82f2-7d8f014c9069
2024-03-29 17:31:57,807 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2024-03-29 17:31:57,807 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
2024-03-29 17:31:57,807 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
2024-03-29 17:31:57,807 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
2024-03-29 17:31:57,808 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2024-03-29 17:31:57,808 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
2024-03-29 17:31:57,808 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2024-03-29 17:31:57,808 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO block.SCMBlockDeletingService: notifyStatusChanged:RUNNING
2024-03-29 17:31:57,808 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
2024-03-29 17:31:57,821 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2024-03-29 17:31:57,821 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO SCMHATransactionMonitor: Service SCMHATransactionMonitor transitions to RUNNING.
2024-03-29 17:31:58,736 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=deb3d444-8fd6-411c-baee-5ffc383ea46f
2024-03-29 17:32:02,030 [IPC Server handler 0 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
2024-03-29 17:32:02,043 [7e6300f4-431e-434b-a906-4a062bd22839@group-FC8F27CF4CBC-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 113750153625600000.
2024-03-29 17:32:02,046 [IPC Server handler 0 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 113750153625600000 to 113750153625601000.
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2024-03-29 17:36:17 INFO  StorageContainerManagerStarter:112 - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = ec33b2ee6906/172.20.0.7
STARTUP_MSG:   args = [--init]
STARTUP_MSG:   version = 1.0.0
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.0.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.5.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.0.0-tests.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.0.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.0.0.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/28d372ca903b4741131bace09e0339e9161257bb ; compiled by 'sammi' on 2020-08-25T13:04Z
STARTUP_MSG:   java = 11.0.3
************************************************************/
2024-03-29 17:36:17 INFO  StorageContainerManagerStarter:90 - registered UNIX signal handlers for [TERM, HUP, INT]
2024-03-29 17:36:18 WARN  ServerUtils:148 - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:36:18 INFO  StorageContainerManager:644 - SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-f8dabfd9-0f5b-4766-9353-9a9f1f3aa3a5;layoutVersion=0
2024-03-29 17:36:18 INFO  StorageContainerManagerStarter:124 - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at ec33b2ee6906/172.20.0.7
************************************************************/
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the HADOOP_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2024-03-29 17:36:21 INFO  StorageContainerManagerStarter:112 - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = ec33b2ee6906/172.20.0.7
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.0.0
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/hadoop/common/*:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.10.3.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/ozone/lib/jaxb-impl-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.3.50.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.0.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-1.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-netty-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.11.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.5.0.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-1.0.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.10.3.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.0.0-tests.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.60.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.0.0.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.1.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.2.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.0.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.11.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.3.50.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.10.3.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.16.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.26.v20200117.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/picocli-3.9.6.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-all-4.1.48.Final.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jettison-1.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-1.0.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.10.3.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jersey-json-1.19.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-1.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.4.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.0.0.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop-ozone.git/28d372ca903b4741131bace09e0339e9161257bb ; compiled by 'sammi' on 2020-08-25T13:04Z
STARTUP_MSG:   java = 11.0.3
************************************************************/
2024-03-29 17:36:21 INFO  StorageContainerManagerStarter:90 - registered UNIX signal handlers for [TERM, HUP, INT]
2024-03-29 17:36:22 WARN  ServerUtils:148 - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:36:22 WARN  DBStoreBuilder:277 - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:36:23 INFO  NodeSchemaLoader:126 - Loading file from java.lang.CompoundEnumeration@7b4c50bc
2024-03-29 17:36:23 INFO  NodeSchemaLoader:172 - Loading network topology layer schema file
2024-03-29 17:36:23 INFO  SCMNodeManager:116 - Entering startup safe mode.
2024-03-29 17:36:23 INFO  ContainerPlacementPolicyFactory:60 - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2024-03-29 17:36:23 INFO  SCMPipelineManager:161 - No pipeline exists in current db
2024-03-29 17:36:24 INFO  HealthyPipelineSafeModeRule:89 - Total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:36:24 INFO  OneReplicaPipelineSafeModeRule:79 - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2024-03-29 17:36:24 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2024-03-29 17:36:25 INFO  CallQueueManager:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-29 17:36:25 INFO  Server:1219 - Starting Socket Reader #1 for port 9861
2024-03-29 17:36:25 INFO  CallQueueManager:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-29 17:36:25 INFO  Server:1219 - Starting Socket Reader #1 for port 9863
2024-03-29 17:36:25 INFO  CallQueueManager:84 - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-29 17:36:25 INFO  Server:1219 - Starting Socket Reader #1 for port 9860
2024-03-29 17:36:25 INFO  BaseHttpServer:207 - Starting Web-server for scm at: http://0.0.0.0:9876
2024-03-29 17:36:25 INFO  BaseHttpServer:106 - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-29 17:36:26 INFO  log:169 - Logging initialized @7307ms to org.eclipse.jetty.util.log.Slf4jLog
2024-03-29 17:36:26 INFO  AuthenticationFilter:240 - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-03-29 17:36:26 INFO  HttpRequestLog:86 - Http request log for http.requests.scm is not defined
2024-03-29 17:36:26 INFO  HttpServer2:1019 - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-29 17:36:26 INFO  HttpServer2:995 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2024-03-29 17:36:26 INFO  HttpServer2:1003 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-29 17:36:26 INFO  HttpServer2:1003 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-29 17:36:26 INFO  StorageContainerManager:784 - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
2024-03-29 17:36:27 INFO  MetricsConfig:118 - Loaded properties from hadoop-metrics2.properties
2024-03-29 17:36:27 INFO  MetricsSystemImpl:374 - Scheduled Metric snapshot period at 10 second(s).
2024-03-29 17:36:27 INFO  MetricsSystemImpl:191 - StorageContainerManager metrics system started
2024-03-29 17:36:28 INFO  SCMClientProtocolServer:156 - RPC server for Client  is listening at /0.0.0.0:9860
2024-03-29 17:36:28 INFO  Server:1460 - IPC Server Responder: starting
2024-03-29 17:36:28 INFO  Server:1298 - IPC Server listener on 9860: starting
2024-03-29 17:36:28 INFO  StorageContainerManager:796 - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
2024-03-29 17:36:28 INFO  SCMBlockProtocolServer:149 - RPC server for Block Protocol is listening at /0.0.0.0:9863
2024-03-29 17:36:28 INFO  Server:1460 - IPC Server Responder: starting
2024-03-29 17:36:28 INFO  Server:1298 - IPC Server listener on 9863: starting
2024-03-29 17:36:28 INFO  StorageContainerManager:802 - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
2024-03-29 17:36:28 INFO  SCMDatanodeProtocolServer:172 - RPC server for DataNodes is listening at /0.0.0.0:9861
2024-03-29 17:36:28 INFO  Server:1460 - IPC Server Responder: starting
2024-03-29 17:36:28 INFO  Server:1298 - IPC Server listener on 9861: starting
2024-03-29 17:36:28 INFO  HttpServer2:1237 - Jetty bound to port 9876
2024-03-29 17:36:28 INFO  Server:359 - jetty-9.4.26.v20200117; built: 2020-01-17T12:35:33.676Z; git: 7b38981d25d14afb4a12ff1f2596756144edf695; jvm 11.0.3+7-LTS
2024-03-29 17:36:28 INFO  session:333 - DefaultSessionIdManager workerName=node0
2024-03-29 17:36:28 INFO  session:338 - No SessionScavenger set, using defaults
2024-03-29 17:36:28 INFO  session:140 - node0 Scavenging every 600000ms
2024-03-29 17:36:29 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@66ba7e45{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
2024-03-29 17:36:29 INFO  ContextHandler:825 - Started o.e.j.s.ServletContextHandler@7573e12f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.0.0.jar!/webapps/static,AVAILABLE}
2024-03-29 17:36:29 INFO  ContextHandler:825 - Started o.e.j.w.WebAppContext@e9ef5b6{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-1_0_0_jar-_-any-12035079446680652640.dir/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.0.0.jar!/webapps/scm}
2024-03-29 17:36:29 INFO  AbstractConnector:330 - Started ServerConnector@5f80fa43{HTTP/1.1,[http/1.1]}{0.0.0.0:9876}
2024-03-29 17:36:29 INFO  Server:399 - Started @10672ms
2024-03-29 17:36:29 INFO  MetricsSinkAdapter:204 - Sink prometheus started
2024-03-29 17:36:29 INFO  MetricsSystemImpl:301 - Registered sink prometheus
2024-03-29 17:36:29 INFO  BaseHttpServer:327 - HTTP server of scm listening at http://0.0.0.0:9876
2024-03-29 17:36:29 INFO  JvmPauseMonitor:188 - Starting JVM pause monitor
2024-03-29 17:36:31 INFO  NetworkTopology:111 - Added a new node: /default-rack/c99d089e-3cf3-479b-a4b4-a5a005520f92
2024-03-29 17:36:31 INFO  SCMNodeManager:273 - Registered Data node : c99d089e-3cf3-479b-a4b4-a5a005520f92{ip: 172.20.0.9, host: xcompat_datanode_1.xcompat_default, networkLocation: /default-rack, certSerialId: null}
2024-03-29 17:36:31 INFO  SCMSafeModeManager:214 - ContainerSafeModeRule rule is successfully validated
2024-03-29 17:36:31 INFO  SCMSafeModeManager:71 - SCM in safe mode. 1 DataNodes registered, 3 required.
2024-03-29 17:36:31 INFO  RatisPipelineProvider:138 - Sending CreatePipelineCommand for pipeline:PipelineID=cfbe7bff-ddef-4c1b-8d9c-da5a68687a6b to datanode:c99d089e-3cf3-479b-a4b4-a5a005520f92
2024-03-29 17:36:31 INFO  PipelineStateManager:54 - Created pipeline Pipeline[ Id: cfbe7bff-ddef-4c1b-8d9c-da5a68687a6b, Nodes: c99d089e-3cf3-479b-a4b4-a5a005520f92{ip: 172.20.0.9, host: xcompat_datanode_1.xcompat_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:36:31.604702Z]
2024-03-29 17:36:31 INFO  NetworkTopology:111 - Added a new node: /default-rack/0b1cfbed-bbbc-4767-b7a9-50be2d32af5e
2024-03-29 17:36:31 INFO  SCMNodeManager:273 - Registered Data node : 0b1cfbed-bbbc-4767-b7a9-50be2d32af5e{ip: 172.20.0.13, host: xcompat_datanode_2.xcompat_default, networkLocation: /default-rack, certSerialId: null}
2024-03-29 17:36:31 INFO  SCMSafeModeManager:71 - SCM in safe mode. 2 DataNodes registered, 3 required.
2024-03-29 17:36:31 INFO  SCMSafeModeManager:214 - ContainerSafeModeRule rule is successfully validated
2024-03-29 17:36:31 INFO  RatisPipelineProvider:138 - Sending CreatePipelineCommand for pipeline:PipelineID=f1ac8fd7-d688-45d3-8007-7e5ecc9e92bf to datanode:0b1cfbed-bbbc-4767-b7a9-50be2d32af5e
2024-03-29 17:36:31 INFO  PipelineStateManager:54 - Created pipeline Pipeline[ Id: f1ac8fd7-d688-45d3-8007-7e5ecc9e92bf, Nodes: 0b1cfbed-bbbc-4767-b7a9-50be2d32af5e{ip: 172.20.0.13, host: xcompat_datanode_2.xcompat_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:36:31.978732Z]
2024-03-29 17:36:31 INFO  NetworkTopology:111 - Added a new node: /default-rack/6f52a04a-83f8-4970-b8a1-92836a10bfb2
2024-03-29 17:36:31 INFO  SCMNodeManager:273 - Registered Data node : 6f52a04a-83f8-4970-b8a1-92836a10bfb2{ip: 172.20.0.12, host: xcompat_datanode_3.xcompat_default, networkLocation: /default-rack, certSerialId: null}
2024-03-29 17:36:31 INFO  SCMSafeModeManager:71 - SCM in safe mode. 3 DataNodes registered, 3 required.
2024-03-29 17:36:31 INFO  SCMSafeModeManager:214 - ContainerSafeModeRule rule is successfully validated
2024-03-29 17:36:31 INFO  SCMSafeModeManager:214 - DataNodeSafeModeRule rule is successfully validated
2024-03-29 17:36:31 INFO  SCMSafeModeManager:242 - All SCM safe mode pre check rules have passed
2024-03-29 17:36:31 INFO  RatisPipelineProvider:138 - Sending CreatePipelineCommand for pipeline:PipelineID=0c8d1be4-7f4b-4109-a647-a75a783c97c6 to datanode:6f52a04a-83f8-4970-b8a1-92836a10bfb2
2024-03-29 17:36:31 INFO  PipelineStateManager:54 - Created pipeline Pipeline[ Id: 0c8d1be4-7f4b-4109-a647-a75a783c97c6, Nodes: 6f52a04a-83f8-4970-b8a1-92836a10bfb2{ip: 172.20.0.12, host: xcompat_datanode_3.xcompat_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:36:31.995645Z]
2024-03-29 17:36:32 INFO  RatisPipelineProvider:138 - Sending CreatePipelineCommand for pipeline:PipelineID=0b6516f9-ec5b-410b-9b7e-deb6282a4404 to datanode:6f52a04a-83f8-4970-b8a1-92836a10bfb2
2024-03-29 17:36:32 INFO  RatisPipelineProvider:138 - Sending CreatePipelineCommand for pipeline:PipelineID=0b6516f9-ec5b-410b-9b7e-deb6282a4404 to datanode:0b1cfbed-bbbc-4767-b7a9-50be2d32af5e
2024-03-29 17:36:32 INFO  RatisPipelineProvider:138 - Sending CreatePipelineCommand for pipeline:PipelineID=0b6516f9-ec5b-410b-9b7e-deb6282a4404 to datanode:c99d089e-3cf3-479b-a4b4-a5a005520f92
2024-03-29 17:36:32 INFO  PipelineStateManager:54 - Created pipeline Pipeline[ Id: 0b6516f9-ec5b-410b-9b7e-deb6282a4404, Nodes: 6f52a04a-83f8-4970-b8a1-92836a10bfb2{ip: 172.20.0.12, host: xcompat_datanode_3.xcompat_default, networkLocation: /default-rack, certSerialId: null}0b1cfbed-bbbc-4767-b7a9-50be2d32af5e{ip: 172.20.0.13, host: xcompat_datanode_2.xcompat_default, networkLocation: /default-rack, certSerialId: null}c99d089e-3cf3-479b-a4b4-a5a005520f92{ip: 172.20.0.9, host: xcompat_datanode_1.xcompat_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:36:32.035310Z]
2024-03-29 17:37:34 INFO  PipelineStateManager:131 - Pipeline Pipeline[ Id: cfbe7bff-ddef-4c1b-8d9c-da5a68687a6b, Nodes: c99d089e-3cf3-479b-a4b4-a5a005520f92{ip: 172.20.0.9, host: xcompat_datanode_1.xcompat_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:c99d089e-3cf3-479b-a4b4-a5a005520f92, CreationTimestamp2024-03-29T17:36:31.604702Z] moved to OPEN state
2024-03-29 17:37:34 INFO  SCMSafeModeManager:129 - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:37:34 INFO  SCMSafeModeManager:214 - AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:37:34 INFO  PipelineStateManager:131 - Pipeline Pipeline[ Id: 0c8d1be4-7f4b-4109-a647-a75a783c97c6, Nodes: 6f52a04a-83f8-4970-b8a1-92836a10bfb2{ip: 172.20.0.12, host: xcompat_datanode_3.xcompat_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:6f52a04a-83f8-4970-b8a1-92836a10bfb2, CreationTimestamp2024-03-29T17:36:31.995645Z] moved to OPEN state
2024-03-29 17:37:34 INFO  SCMSafeModeManager:214 - AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:37:34 INFO  SCMSafeModeManager:129 - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:37:35 INFO  PipelineStateManager:131 - Pipeline Pipeline[ Id: f1ac8fd7-d688-45d3-8007-7e5ecc9e92bf, Nodes: 0b1cfbed-bbbc-4767-b7a9-50be2d32af5e{ip: 172.20.0.13, host: xcompat_datanode_2.xcompat_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:0b1cfbed-bbbc-4767-b7a9-50be2d32af5e, CreationTimestamp2024-03-29T17:36:31.978732Z] moved to OPEN state
2024-03-29 17:37:35 INFO  SCMSafeModeManager:214 - AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:37:35 INFO  SCMSafeModeManager:129 - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:37:39 INFO  PipelineStateManager:131 - Pipeline Pipeline[ Id: 0b6516f9-ec5b-410b-9b7e-deb6282a4404, Nodes: 6f52a04a-83f8-4970-b8a1-92836a10bfb2{ip: 172.20.0.12, host: xcompat_datanode_3.xcompat_default, networkLocation: /default-rack, certSerialId: null}0b1cfbed-bbbc-4767-b7a9-50be2d32af5e{ip: 172.20.0.13, host: xcompat_datanode_2.xcompat_default, networkLocation: /default-rack, certSerialId: null}c99d089e-3cf3-479b-a4b4-a5a005520f92{ip: 172.20.0.9, host: xcompat_datanode_1.xcompat_default, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:c99d089e-3cf3-479b-a4b4-a5a005520f92, CreationTimestamp2024-03-29T17:36:32.035310Z] moved to OPEN state
2024-03-29 17:37:39 INFO  SCMSafeModeManager:214 - AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:37:39 INFO  SCMSafeModeManager:129 - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2024-03-29 17:37:39 INFO  SCMSafeModeManager:214 - HealthyPipelineSafeModeRule rule is successfully validated
2024-03-29 17:37:39 INFO  SCMSafeModeManager:228 - ScmSafeModeManager, all rules are successfully validated
2024-03-29 17:37:39 INFO  SCMSafeModeManager:257 - SCM exiting safe mode.
2024-03-29 17:38:01 WARN  SCMNodeManager:653 - Cannot find node for address 172.20.0.14
2024-03-29 17:38:08 WARN  SCMNodeManager:653 - Cannot find node for address 172.20.0.14
2024-03-29 17:38:39 WARN  SCMNodeManager:653 - Cannot find node for address 172.20.0.14
2024-03-29 17:38:45 WARN  SCMNodeManager:653 - Cannot find node for address 172.20.0.14
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2024-03-29 17:38:57,369 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = c30552985a1c/172.21.0.7
STARTUP_MSG:   args = [--init]
STARTUP_MSG:   version = 1.1.0
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.0.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.0.0.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.0.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.0.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.0.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0.jar
STARTUP_MSG:   build = https://github.com/apache/ozone.git/f2406c4b4eb2b1295d06ec379cfe684ed9a16637 ; compiled by 'ppogde' on 2021-04-09T04:10Z
STARTUP_MSG:   java = 11.0.10
************************************************************/
2024-03-29 17:38:57,401 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2024-03-29 17:38:57,850 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:38:57,994 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm;cid=CID-15f2ffc1-5f5b-4941-b652-8312205ea083;layoutVersion=0
2024-03-29 17:38:58,005 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at c30552985a1c/172.21.0.7
************************************************************/
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2024-03-29 17:39:01,903 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = c30552985a1c/172.21.0.7
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.1.0
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.2.2.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.13.3.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-server-1.1.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.0.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/picocli-4.4.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.2.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-container-service-1.1.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.2.0.jar:/opt/hadoop/share/ozone/lib/javax.activation-api-1.2.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-admin-1.1.0.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.0.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.2.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-hadoop-dependency-client-1.1.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.0.0.jar:/opt/hadoop/share/ozone/lib/okio-2.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/guava-28.2-jre.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/xz-1.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/libthrift-0.13.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.13.3.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-client-1.1.0.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.0.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.8.1.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.0.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-config-1.1.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-client-1.1.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.2.2.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.0.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-framework-1.1.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.5.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-interface-server-1.1.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/checker-qual-2.10.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.0.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.2.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.35.v20201120.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0.jar
STARTUP_MSG:   build = https://github.com/apache/ozone.git/f2406c4b4eb2b1295d06ec379cfe684ed9a16637 ; compiled by 'ppogde' on 2021-04-09T04:10Z
STARTUP_MSG:   java = 11.0.10
************************************************************/
2024-03-29 17:39:01,933 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2024-03-29 17:39:02,283 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:39:02,916 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:39:03,209 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-common-1.1.0.jar!/network-topology-default.xml]
2024-03-29 17:39:03,219 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
2024-03-29 17:39:03,576 [main] INFO node.SCMNodeManager: Entering startup safe mode.
2024-03-29 17:39:04,165 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2024-03-29 17:39:04,267 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2024-03-29 17:39:04,276 [main] INFO pipeline.SCMPipelineManager: No pipeline exists in current db
2024-03-29 17:39:04,470 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-03-29 17:39:04,665 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:39:04,668 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2024-03-29 17:39:07,244 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-29 17:39:07,301 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
2024-03-29 17:39:07,333 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-29 17:39:07,333 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
2024-03-29 17:39:07,352 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-29 17:39:07,353 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
2024-03-29 17:39:07,380 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
2024-03-29 17:39:07,536 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2024-03-29 17:39:07,556 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-03-29 17:39:07,557 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
2024-03-29 17:39:08,613 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
2024-03-29 17:39:08,613 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-03-29 17:39:08,614 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
2024-03-29 17:39:08,626 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
2024-03-29 17:39:08,725 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
2024-03-29 17:39:08,730 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-03-29 17:39:08,733 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
2024-03-29 17:39:08,979 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
2024-03-29 17:39:08,986 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
2024-03-29 17:39:09,180 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-03-29 17:39:09,180 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
2024-03-29 17:39:09,644 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1d540566] INFO util.JvmPauseMonitor: Starting JVM pause monitor
2024-03-29 17:39:09,668 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
2024-03-29 17:39:09,669 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-29 17:39:09,743 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @11323ms to org.eclipse.jetty.util.log.Slf4jLog
2024-03-29 17:39:10,027 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-03-29 17:39:10,030 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
2024-03-29 17:39:10,042 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-29 17:39:10,044 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2024-03-29 17:39:10,044 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-29 17:39:10,044 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-29 17:39:10,104 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
2024-03-29 17:39:10,106 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.35.v20201120; built: 2020-11-20T21:17:03.964Z; git: bdc54f03a5e0a7e280fab27f55c3c75ee8da89fb; jvm 11.0.10+9-LTS
2024-03-29 17:39:10,168 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
2024-03-29 17:39:10,178 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
2024-03-29 17:39:10,181 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
2024-03-29 17:39:10,205 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5d5c04f9{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
2024-03-29 17:39:10,208 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@61cd1c71{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0.jar!/webapps/static,AVAILABLE}
2024-03-29 17:39:10,617 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@37b52340{scm,/,file:///tmp/jetty-0_0_0_0-9876-hadoop-hdds-server-scm-1_1_0_jar-_-any-3339307819526624864/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hadoop-hdds-server-scm-1.1.0.jar!/webapps/scm}
2024-03-29 17:39:10,636 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@6981f8f3{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
2024-03-29 17:39:10,637 [Listener at 0.0.0.0/9860] INFO server.Server: Started @12225ms
2024-03-29 17:39:10,639 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
2024-03-29 17:39:10,639 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
2024-03-29 17:39:10,640 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
2024-03-29 17:39:12,980 [IPC Server handler 1 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/6a08f208-0e0d-4c17-9eb8-5f41db3b2dd6
2024-03-29 17:39:12,983 [IPC Server handler 1 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 6a08f208-0e0d-4c17-9eb8-5f41db3b2dd6{ip: 172.21.0.3, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:39:13,030 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2024-03-29 17:39:13,037 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
2024-03-29 17:39:13,084 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:39:13,097 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=90265dd6-6c84-40fa-b052-4a390ca8c603 to datanode:6a08f208-0e0d-4c17-9eb8-5f41db3b2dd6
2024-03-29 17:39:13,133 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 90265dd6-6c84-40fa-b052-4a390ca8c603, Nodes: 6a08f208-0e0d-4c17-9eb8-5f41db3b2dd6{ip: 172.21.0.3, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:39:13.095150Z]
2024-03-29 17:39:13,651 [IPC Server handler 0 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/1ce3b2da-58f0-4b5c-8179-efdea0297235
2024-03-29 17:39:13,659 [IPC Server handler 0 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 1ce3b2da-58f0-4b5c-8179-efdea0297235{ip: 172.21.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:39:13,661 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
2024-03-29 17:39:13,661 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:39:13,662 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2024-03-29 17:39:13,663 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=cc62fcca-7131-4bd5-922a-b998e62fd768 to datanode:1ce3b2da-58f0-4b5c-8179-efdea0297235
2024-03-29 17:39:13,664 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: cc62fcca-7131-4bd5-922a-b998e62fd768, Nodes: 1ce3b2da-58f0-4b5c-8179-efdea0297235{ip: 172.21.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:39:13.663345Z]
2024-03-29 17:39:14,035 [IPC Server handler 1 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/c50ef9ac-d7c9-44d9-8702-f9b4ba5b7aaf
2024-03-29 17:39:14,035 [IPC Server handler 1 on default port 9861] INFO node.SCMNodeManager: Registered Data node : c50ef9ac-d7c9-44d9-8702-f9b4ba5b7aaf{ip: 172.21.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:39:14,038 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2024-03-29 17:39:14,039 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:39:14,037 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=72b151e3-4ce9-468c-8d9f-f9df5397a854 to datanode:c50ef9ac-d7c9-44d9-8702-f9b4ba5b7aaf
2024-03-29 17:39:14,040 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 72b151e3-4ce9-468c-8d9f-f9df5397a854, Nodes: c50ef9ac-d7c9-44d9-8702-f9b4ba5b7aaf{ip: 172.21.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:39:14.037494Z]
2024-03-29 17:39:14,038 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
2024-03-29 17:39:14,042 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
2024-03-29 17:39:14,043 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
2024-03-29 17:39:14,051 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=f8ecd567-d94c-4d5b-b234-147a8b00f5d7 to datanode:c50ef9ac-d7c9-44d9-8702-f9b4ba5b7aaf
2024-03-29 17:39:14,051 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=f8ecd567-d94c-4d5b-b234-147a8b00f5d7 to datanode:6a08f208-0e0d-4c17-9eb8-5f41db3b2dd6
2024-03-29 17:39:14,052 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=f8ecd567-d94c-4d5b-b234-147a8b00f5d7 to datanode:1ce3b2da-58f0-4b5c-8179-efdea0297235
2024-03-29 17:39:14,052 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: f8ecd567-d94c-4d5b-b234-147a8b00f5d7, Nodes: c50ef9ac-d7c9-44d9-8702-f9b4ba5b7aaf{ip: 172.21.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}6a08f208-0e0d-4c17-9eb8-5f41db3b2dd6{ip: 172.21.0.3, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ce3b2da-58f0-4b5c-8179-efdea0297235{ip: 172.21.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:39:14.051247Z]
2024-03-29 17:39:14,054 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=20b7ef4f-a71a-4bbe-8161-64e09775bc88 to datanode:c50ef9ac-d7c9-44d9-8702-f9b4ba5b7aaf
2024-03-29 17:39:14,054 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=20b7ef4f-a71a-4bbe-8161-64e09775bc88 to datanode:6a08f208-0e0d-4c17-9eb8-5f41db3b2dd6
2024-03-29 17:39:14,055 [RatisPipelineUtilsThread] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=20b7ef4f-a71a-4bbe-8161-64e09775bc88 to datanode:1ce3b2da-58f0-4b5c-8179-efdea0297235
2024-03-29 17:39:14,056 [RatisPipelineUtilsThread] INFO pipeline.PipelineStateManager: Created pipeline Pipeline[ Id: 20b7ef4f-a71a-4bbe-8161-64e09775bc88, Nodes: c50ef9ac-d7c9-44d9-8702-f9b4ba5b7aaf{ip: 172.21.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}6a08f208-0e0d-4c17-9eb8-5f41db3b2dd6{ip: 172.21.0.3, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ce3b2da-58f0-4b5c-8179-efdea0297235{ip: 172.21.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:39:14.054099Z]
2024-03-29 17:39:14,057 [RatisPipelineUtilsThread] INFO pipeline.SCMPipelineManager: Pipeline: PipelineID=20b7ef4f-a71a-4bbe-8161-64e09775bc88 contains same datanodes as previous pipelines: PipelineID=f8ecd567-d94c-4d5b-b234-147a8b00f5d7 nodeIds: c50ef9ac-d7c9-44d9-8702-f9b4ba5b7aaf, 6a08f208-0e0d-4c17-9eb8-5f41db3b2dd6, 1ce3b2da-58f0-4b5c-8179-efdea0297235
2024-03-29 17:39:15,996 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:39:16,002 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 90265dd6-6c84-40fa-b052-4a390ca8c603, Nodes: 6a08f208-0e0d-4c17-9eb8-5f41db3b2dd6{ip: 172.21.0.3, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:6a08f208-0e0d-4c17-9eb8-5f41db3b2dd6, CreationTimestamp2024-03-29T17:39:13.095150Z] moved to OPEN state
2024-03-29 17:39:16,005 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:39:16,131 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:39:16,135 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:39:16,680 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:39:16,681 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: cc62fcca-7131-4bd5-922a-b998e62fd768, Nodes: 1ce3b2da-58f0-4b5c-8179-efdea0297235{ip: 172.21.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:1ce3b2da-58f0-4b5c-8179-efdea0297235, CreationTimestamp2024-03-29T17:39:13.663345Z] moved to OPEN state
2024-03-29 17:39:16,682 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:39:16,699 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:39:16,800 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:39:16,800 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:39:17,013 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:39:17,013 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 72b151e3-4ce9-468c-8d9f-f9df5397a854, Nodes: c50ef9ac-d7c9-44d9-8702-f9b4ba5b7aaf{ip: 172.21.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:ONE, State:ALLOCATED, leaderId:c50ef9ac-d7c9-44d9-8702-f9b4ba5b7aaf, CreationTimestamp2024-03-29T17:39:14.037494Z] moved to OPEN state
2024-03-29 17:39:17,016 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:39:17,058 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:39:17,060 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:39:17,211 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:39:17,213 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:39:17,349 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:39:17,350 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:39:21,176 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:39:21,177 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:39:21,930 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:39:21,930 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:39:22,115 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:39:22,116 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:39:26,334 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:39:26,334 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: f8ecd567-d94c-4d5b-b234-147a8b00f5d7, Nodes: c50ef9ac-d7c9-44d9-8702-f9b4ba5b7aaf{ip: 172.21.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}6a08f208-0e0d-4c17-9eb8-5f41db3b2dd6{ip: 172.21.0.3, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ce3b2da-58f0-4b5c-8179-efdea0297235{ip: 172.21.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:c50ef9ac-d7c9-44d9-8702-f9b4ba5b7aaf, CreationTimestamp2024-03-29T17:39:14.051247Z] moved to OPEN state
2024-03-29 17:39:26,334 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:39:26,335 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2024-03-29 17:39:26,335 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
2024-03-29 17:39:26,335 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
2024-03-29 17:39:26,335 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
2024-03-29 17:39:27,344 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineStateManager: Pipeline Pipeline[ Id: 20b7ef4f-a71a-4bbe-8161-64e09775bc88, Nodes: c50ef9ac-d7c9-44d9-8702-f9b4ba5b7aaf{ip: 172.21.0.9, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}6a08f208-0e0d-4c17-9eb8-5f41db3b2dd6{ip: 172.21.0.3, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}1ce3b2da-58f0-4b5c-8179-efdea0297235{ip: 172.21.0.6, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, Type:RATIS, Factor:THREE, State:ALLOCATED, leaderId:6a08f208-0e0d-4c17-9eb8-5f41db3b2dd6, CreationTimestamp2024-03-29T17:39:14.054099Z] moved to OPEN state
2024-03-29 17:39:48,455 [IPC Server handler 11 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.21.0.5
2024-03-29 17:39:55,147 [IPC Server handler 99 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.21.0.5
2024-03-29 17:40:26,625 [IPC Server handler 17 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.21.0.5
2024-03-29 17:40:33,164 [IPC Server handler 2 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.21.0.5
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2024-03-29 17:40:46,192 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = f705cddfa2c4/172.22.0.12
STARTUP_MSG:   args = [--init]
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.16.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.16.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.1.jar
STARTUP_MSG:   build = https://github.com/apache/ozone.git/76aa27e7c05196ae00cba540efce4bb7529e5d15 ; compiled by 'ethanrose' on 2021-12-15T22:27Z
STARTUP_MSG:   java = 11.0.13
************************************************************/
2024-03-29 17:40:46,222 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2024-03-29 17:40:46,485 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:40:46,685 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2024-03-29 17:40:46,685 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2024-03-29 17:40:47,057 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-62444857-83fa-40c1-95c9-0f13e06a4291; layoutVersion=2; scmId=1f063bfd-4fe9-45f8-9f35-7996f1109f57
2024-03-29 17:40:47,100 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at f705cddfa2c4/172.22.0.12
************************************************************/
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2024-03-29 17:40:50,921 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = f705cddfa2c4/172.22.0.12
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.2.1
STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/ozone/lib/jackson-annotations-2.12.1.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-log4j12-1.7.30.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-6.20.3.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/ozone/lib/commons-io-2.8.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.31.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.8.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.2.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.16.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.12.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.26.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-30.1.1-jre.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.12.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.2.0.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.1.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.12.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.1.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.2.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.2.0.jar:/opt/hadoop/share/ozone/lib/json-smart-2.3.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-1.2.17.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-1.2.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.2.1.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.30.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.1.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/gson-2.2.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.43.v20210629.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.63.Final.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.4.31.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.16.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.2.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.2.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.2.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.2.1.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.2.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.1.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.20.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.2.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.1.jar
STARTUP_MSG:   build = https://github.com/apache/ozone.git/76aa27e7c05196ae00cba540efce4bb7529e5d15 ; compiled by 'ethanrose' on 2021-12-15T22:27Z
STARTUP_MSG:   java = 11.0.13
************************************************************/
2024-03-29 17:40:50,930 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2024-03-29 17:40:51,088 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2024-03-29 17:40:51,088 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2024-03-29 17:40:51,374 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:40:51,472 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = SCM_HA (version = 2), software layout = SCM_HA (version = 2)
2024-03-29 17:40:52,372 [main] INFO reflections.Reflections: Reflections took 583 ms to scan 3 urls, producing 103 keys and 211 values 
2024-03-29 17:40:54,587 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:40:55,337 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:40:55,748 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/opt/hadoop/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.2.1.jar!/network-topology-default.xml]
2024-03-29 17:40:55,750 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
2024-03-29 17:40:55,908 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2024-03-29 17:40:55,939 [main] INFO ha.SequenceIdGenerator: upgrade localId to 113750153625600000
2024-03-29 17:40:55,939 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
2024-03-29 17:40:55,941 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
2024-03-29 17:40:55,943 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
2024-03-29 17:40:56,044 [main] INFO node.SCMNodeManager: Entering startup safe mode.
2024-03-29 17:40:56,059 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2024-03-29 17:40:56,083 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
2024-03-29 17:40:56,346 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2024-03-29 17:40:56,371 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
2024-03-29 17:40:56,371 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
2024-03-29 17:40:56,515 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-03-29 17:40:56,601 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
2024-03-29 17:40:56,648 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
2024-03-29 17:40:56,650 [main] INFO container.ReplicationManager: Starting Replication Monitor Thread.
2024-03-29 17:40:56,680 [ReplicationMonitor] INFO container.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2024-03-29 17:40:56,681 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
2024-03-29 17:40:56,689 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:40:56,707 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2024-03-29 17:40:59,200 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-29 17:40:59,281 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
2024-03-29 17:40:59,334 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-29 17:40:59,340 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
2024-03-29 17:40:59,356 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-29 17:40:59,357 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
2024-03-29 17:40:59,570 [Listener at 0.0.0.0/9860] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2024-03-29 17:40:59,598 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          0.1
Max Datanodes to Involve per Iteration(ratio)      0.2
Max Size to Move per Iteration                     32212254720B

2024-03-29 17:40:59,598 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2024-03-29 17:40:59,603 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2024-03-29 17:40:59,622 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
2024-03-29 17:40:59,823 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2024-03-29 17:40:59,858 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-03-29 17:40:59,858 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
2024-03-29 17:41:00,353 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
2024-03-29 17:41:00,353 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-03-29 17:41:00,354 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
2024-03-29 17:41:00,450 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
2024-03-29 17:41:00,452 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
2024-03-29 17:41:00,475 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-03-29 17:41:00,476 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
2024-03-29 17:41:00,574 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmDatanodeProtocl RPC server is listening at /0.0.0.0:9861
2024-03-29 17:41:00,574 [Listener at 0.0.0.0/9860] INFO server.SCMDatanodeProtocolServer: RPC server for DataNodes is listening at /0.0.0.0:9861
2024-03-29 17:41:00,575 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-03-29 17:41:00,575 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
2024-03-29 17:41:00,757 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@de81be1] INFO util.JvmPauseMonitor: Starting JVM pause monitor
2024-03-29 17:41:00,798 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
2024-03-29 17:41:00,798 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-29 17:41:00,834 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @13177ms to org.eclipse.jetty.util.log.Slf4jLog
2024-03-29 17:41:01,065 [Listener at 0.0.0.0/9860] INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2024-03-29 17:41:01,079 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
2024-03-29 17:41:01,084 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-29 17:41:01,085 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2024-03-29 17:41:01,086 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-29 17:41:01,086 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-29 17:41:01,125 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
2024-03-29 17:41:01,133 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.13+8-LTS
2024-03-29 17:41:01,196 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
2024-03-29 17:41:01,196 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
2024-03-29 17:41:01,198 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
2024-03-29 17:41:01,214 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@606a1bc4{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
2024-03-29 17:41:01,215 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@e29f4f6{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.1.jar!/webapps/static,AVAILABLE}
2024-03-29 17:41:02,103 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@10a18e3e{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_2_1_jar-_-any-12096002826560817543/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.2.1.jar!/webapps/scm}
2024-03-29 17:41:02,157 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@59fc6d05{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
2024-03-29 17:41:02,163 [Listener at 0.0.0.0/9860] INFO server.Server: Started @14500ms
2024-03-29 17:41:02,187 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
2024-03-29 17:41:02,187 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
2024-03-29 17:41:02,189 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
2024-03-29 17:41:03,408 [IPC Server handler 2 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/2d395e8c-fc1c-4d47-970f-0a77fc5d9ff8
2024-03-29 17:41:03,413 [IPC Server handler 2 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 2d395e8c-fc1c-4d47-970f-0a77fc5d9ff8{ip: 172.22.0.11, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:41:03,449 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2024-03-29 17:41:03,438 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:41:03,464 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
2024-03-29 17:41:03,471 [IPC Server handler 5 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/e42f26de-20f3-485c-a587-114dae8c221d
2024-03-29 17:41:03,484 [IPC Server handler 5 on default port 9861] INFO node.SCMNodeManager: Registered Data node : e42f26de-20f3-485c-a587-114dae8c221d{ip: 172.22.0.6, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:41:03,485 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:41:03,493 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
2024-03-29 17:41:03,493 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:41:03,518 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=8b4187b0-3f88-4146-a202-44cd5a37fb51 to datanode:2d395e8c-fc1c-4d47-970f-0a77fc5d9ff8
2024-03-29 17:41:03,525 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 8b4187b0-3f88-4146-a202-44cd5a37fb51, Nodes: 2d395e8c-fc1c-4d47-970f-0a77fc5d9ff8{ip: 172.22.0.11, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:41:03.516Z[UTC]].
2024-03-29 17:41:03,536 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=be498f16-5ba0-474b-8b8d-9b8314a2a6be to datanode:e42f26de-20f3-485c-a587-114dae8c221d
2024-03-29 17:41:03,545 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: be498f16-5ba0-474b-8b8d-9b8314a2a6be, Nodes: e42f26de-20f3-485c-a587-114dae8c221d{ip: 172.22.0.6, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:41:03.536Z[UTC]].
2024-03-29 17:41:03,949 [IPC Server handler 1 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/c5af30d5-73d2-46d0-b6bf-17f465ded466
2024-03-29 17:41:03,950 [IPC Server handler 1 on default port 9861] INFO node.SCMNodeManager: Registered Data node : c5af30d5-73d2-46d0-b6bf-17f465ded466{ip: 172.22.0.9, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:41:03,950 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:41:03,952 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
2024-03-29 17:41:03,953 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
2024-03-29 17:41:03,953 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
2024-03-29 17:41:03,953 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2024-03-29 17:41:03,959 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2024-03-29 17:41:03,966 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:41:03,967 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ed9b66ac-4095-4c2f-81d2-5ae936faa243 to datanode:c5af30d5-73d2-46d0-b6bf-17f465ded466
2024-03-29 17:41:03,968 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: ed9b66ac-4095-4c2f-81d2-5ae936faa243, Nodes: c5af30d5-73d2-46d0-b6bf-17f465ded466{ip: 172.22.0.9, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:41:03.967Z[UTC]].
2024-03-29 17:41:03,991 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=077d24f5-cdbf-4ff8-8059-c3d223249571 to datanode:2d395e8c-fc1c-4d47-970f-0a77fc5d9ff8
2024-03-29 17:41:03,991 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=077d24f5-cdbf-4ff8-8059-c3d223249571 to datanode:c5af30d5-73d2-46d0-b6bf-17f465ded466
2024-03-29 17:41:03,992 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=077d24f5-cdbf-4ff8-8059-c3d223249571 to datanode:e42f26de-20f3-485c-a587-114dae8c221d
2024-03-29 17:41:03,993 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 077d24f5-cdbf-4ff8-8059-c3d223249571, Nodes: 2d395e8c-fc1c-4d47-970f-0a77fc5d9ff8{ip: 172.22.0.11, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c5af30d5-73d2-46d0-b6bf-17f465ded466{ip: 172.22.0.9, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e42f26de-20f3-485c-a587-114dae8c221d{ip: 172.22.0.6, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:41:03.991Z[UTC]].
2024-03-29 17:41:03,999 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=141a871f-779b-432c-9c5f-ca6894a13144 to datanode:e42f26de-20f3-485c-a587-114dae8c221d
2024-03-29 17:41:04,002 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=141a871f-779b-432c-9c5f-ca6894a13144 to datanode:c5af30d5-73d2-46d0-b6bf-17f465ded466
2024-03-29 17:41:04,005 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=141a871f-779b-432c-9c5f-ca6894a13144 to datanode:2d395e8c-fc1c-4d47-970f-0a77fc5d9ff8
2024-03-29 17:41:04,009 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 141a871f-779b-432c-9c5f-ca6894a13144, Nodes: e42f26de-20f3-485c-a587-114dae8c221d{ip: 172.22.0.6, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c5af30d5-73d2-46d0-b6bf-17f465ded466{ip: 172.22.0.9, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2d395e8c-fc1c-4d47-970f-0a77fc5d9ff8{ip: 172.22.0.11, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:41:03.999Z[UTC]].
2024-03-29 17:41:04,009 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineManagerImpl: Pipeline: PipelineID=141a871f-779b-432c-9c5f-ca6894a13144 contains same datanodes as previous pipelines: PipelineID=077d24f5-cdbf-4ff8-8059-c3d223249571 nodeIds: e42f26de-20f3-485c-a587-114dae8c221d, c5af30d5-73d2-46d0-b6bf-17f465ded466, 2d395e8c-fc1c-4d47-970f-0a77fc5d9ff8
2024-03-29 17:41:06,438 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 8b4187b0-3f88-4146-a202-44cd5a37fb51, Nodes: 2d395e8c-fc1c-4d47-970f-0a77fc5d9ff8{ip: 172.22.0.11, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:2d395e8c-fc1c-4d47-970f-0a77fc5d9ff8, CreationTimestamp2024-03-29T17:41:03.516Z[UTC]] moved to OPEN state
2024-03-29 17:41:06,446 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:41:06,530 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: be498f16-5ba0-474b-8b8d-9b8314a2a6be, Nodes: e42f26de-20f3-485c-a587-114dae8c221d{ip: 172.22.0.6, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:e42f26de-20f3-485c-a587-114dae8c221d, CreationTimestamp2024-03-29T17:41:03.536Z[UTC]] moved to OPEN state
2024-03-29 17:41:06,532 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:41:06,660 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:41:06,729 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:41:07,056 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: ed9b66ac-4095-4c2f-81d2-5ae936faa243, Nodes: c5af30d5-73d2-46d0-b6bf-17f465ded466{ip: 172.22.0.9, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:c5af30d5-73d2-46d0-b6bf-17f465ded466, CreationTimestamp2024-03-29T17:41:03.967Z[UTC]] moved to OPEN state
2024-03-29 17:41:07,060 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:41:07,409 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:41:07,714 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:41:07,849 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:41:07,961 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:41:11,704 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:41:11,768 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:41:12,407 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:41:12,941 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 141a871f-779b-432c-9c5f-ca6894a13144, Nodes: e42f26de-20f3-485c-a587-114dae8c221d{ip: 172.22.0.6, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c5af30d5-73d2-46d0-b6bf-17f465ded466{ip: 172.22.0.9, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}2d395e8c-fc1c-4d47-970f-0a77fc5d9ff8{ip: 172.22.0.11, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:e42f26de-20f3-485c-a587-114dae8c221d, CreationTimestamp2024-03-29T17:41:03.999Z[UTC]] moved to OPEN state
2024-03-29 17:41:12,942 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2024-03-29 17:41:12,942 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
2024-03-29 17:41:12,942 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
2024-03-29 17:41:12,942 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
2024-03-29 17:41:12,942 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2024-03-29 17:41:12,943 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2024-03-29 17:41:12,943 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
2024-03-29 17:41:12,943 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO container.ReplicationManager: Service ReplicationManager transitions to RUNNING.
2024-03-29 17:41:15,893 [IPC Server handler 2 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
2024-03-29 17:41:15,904 [IPC Server handler 2 on default port 9863] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 113750153625600000.
2024-03-29 17:41:15,905 [IPC Server handler 2 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 113750153625600000 to 113750153625601000.
2024-03-29 17:41:22,108 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 077d24f5-cdbf-4ff8-8059-c3d223249571, Nodes: 2d395e8c-fc1c-4d47-970f-0a77fc5d9ff8{ip: 172.22.0.11, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}c5af30d5-73d2-46d0-b6bf-17f465ded466{ip: 172.22.0.9, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e42f26de-20f3-485c-a587-114dae8c221d{ip: 172.22.0.6, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:2d395e8c-fc1c-4d47-970f-0a77fc5d9ff8, CreationTimestamp2024-03-29T17:41:03.991Z[UTC]] moved to OPEN state
2024-03-29 17:41:35,653 [IPC Server handler 2 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.22.0.8
2024-03-29 17:41:42,296 [IPC Server handler 5 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.22.0.8
2024-03-29 17:42:16,558 [IPC Server handler 97 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.22.0.8
2024-03-29 17:42:23,072 [IPC Server handler 3 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.22.0.8
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2024-03-29 17:42:38,644 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = 293f326d8bab/172.23.0.2
STARTUP_MSG:   args = [--init]
STARTUP_MSG:   version = 1.3.0
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.2.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.0.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.0.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.32.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.0.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0.jar
STARTUP_MSG:   build = https://github.com/apache/ozone.git/d0d18a3bff64b90f5f0755edb6003301049ffb32 ; compiled by 'micahzhao' on 2022-12-10T13:23Z
STARTUP_MSG:   java = 11.0.14.1
************************************************************/
2024-03-29 17:42:38,673 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2024-03-29 17:42:38,949 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:42:39,138 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2024-03-29 17:42:39,202 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2024-03-29 17:42:39,882 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2024-03-29 17:42:40,086 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-03-29 17:42:40,087 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2024-03-29 17:42:40,089 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-03-29 17:42:40,090 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2024-03-29 17:42:40,090 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2024-03-29 17:42:40,090 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2024-03-29 17:42:40,091 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2024-03-29 17:42:40,098 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:42:40,099 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2024-03-29 17:42:40,099 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2024-03-29 17:42:40,124 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2024-03-29 17:42:40,129 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-03-29 17:42:40,133 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-03-29 17:42:41,149 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2024-03-29 17:42:41,152 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2024-03-29 17:42:41,153 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2024-03-29 17:42:41,160 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2024-03-29 17:42:41,160 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-29 17:42:41,178 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2024-03-29 17:42:41,201 [main] INFO server.RaftServer: aa66c5ad-5081-4c78-b06e-86b7cfb78902: addNew group-DF02C1146A00:[aa66c5ad-5081-4c78-b06e-86b7cfb78902|rpc:293f326d8bab:9894|priority:0|startupRole:FOLLOWER] returns group-DF02C1146A00:java.util.concurrent.CompletableFuture@43b4fe19[Not completed]
2024-03-29 17:42:41,266 [pool-2-thread-1] INFO server.RaftServer$Division: aa66c5ad-5081-4c78-b06e-86b7cfb78902: new RaftServerImpl for group-DF02C1146A00:[aa66c5ad-5081-4c78-b06e-86b7cfb78902|rpc:293f326d8bab:9894|priority:0|startupRole:FOLLOWER] with SCMStateMachine:uninitialized
2024-03-29 17:42:41,269 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2024-03-29 17:42:41,270 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-29 17:42:41,273 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2024-03-29 17:42:41,274 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2024-03-29 17:42:41,274 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-29 17:42:41,275 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-29 17:42:41,303 [pool-2-thread-1] INFO server.RaftServer$Division: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00: ConfigurationManager, init=-1: peers:[aa66c5ad-5081-4c78-b06e-86b7cfb78902|rpc:293f326d8bab:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-29 17:42:41,303 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2024-03-29 17:42:41,327 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-29 17:42:41,328 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-29 17:42:41,355 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2024-03-29 17:42:41,362 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2024-03-29 17:42:41,362 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
2024-03-29 17:42:41,471 [pool-2-thread-1] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2024-03-29 17:42:41,868 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-29 17:42:41,869 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2024-03-29 17:42:41,888 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2024-03-29 17:42:41,888 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2024-03-29 17:42:41,889 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2024-03-29 17:42:41,890 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/1927025a-e656-49a1-a5bf-df02c1146a00 does not exist. Creating ...
2024-03-29 17:42:41,919 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/1927025a-e656-49a1-a5bf-df02c1146a00/in_use.lock acquired by nodename 13@293f326d8bab
2024-03-29 17:42:41,935 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/1927025a-e656-49a1-a5bf-df02c1146a00 has been successfully formatted.
2024-03-29 17:42:41,969 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2024-03-29 17:42:41,999 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2024-03-29 17:42:42,002 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:42:42,019 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-29 17:42:42,022 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-29 17:42:42,024 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2024-03-29 17:42:42,056 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-29 17:42:42,059 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-29 17:42:42,070 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/1927025a-e656-49a1-a5bf-df02c1146a00
2024-03-29 17:42:42,079 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2024-03-29 17:42:42,080 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2024-03-29 17:42:42,081 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2024-03-29 17:42:42,081 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2024-03-29 17:42:42,082 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2024-03-29 17:42:42,083 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2024-03-29 17:42:42,084 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-29 17:42:42,084 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2024-03-29 17:42:42,105 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
2024-03-29 17:42:42,106 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2024-03-29 17:42:42,111 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2024-03-29 17:42:42,112 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2024-03-29 17:42:42,134 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO segmented.SegmentedRaftLogWorker: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-29 17:42:42,135 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO segmented.SegmentedRaftLogWorker: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-29 17:42:42,148 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServer$Division: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00: start as a follower, conf=-1: peers:[aa66c5ad-5081-4c78-b06e-86b7cfb78902|rpc:293f326d8bab:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2024-03-29 17:42:42,151 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServer$Division: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-29 17:42:42,153 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO impl.RoleInfo: aa66c5ad-5081-4c78-b06e-86b7cfb78902: start aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-FollowerState
2024-03-29 17:42:42,161 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2024-03-29 17:42:42,162 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-29 17:42:42,165 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DF02C1146A00,id=aa66c5ad-5081-4c78-b06e-86b7cfb78902
2024-03-29 17:42:42,167 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-29 17:42:42,168 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2024-03-29 17:42:42,168 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2024-03-29 17:42:42,169 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-29 17:42:42,212 [main] INFO server.RaftServer: aa66c5ad-5081-4c78-b06e-86b7cfb78902: start RPC server
2024-03-29 17:42:42,404 [main] INFO server.GrpcService: aa66c5ad-5081-4c78-b06e-86b7cfb78902: GrpcService started, listening on 9894
2024-03-29 17:42:42,407 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-aa66c5ad-5081-4c78-b06e-86b7cfb78902: Started
2024-03-29 17:42:47,244 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-FollowerState] INFO impl.FollowerState: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5091373907ns, electionTimeout:5073ms
2024-03-29 17:42:47,256 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-FollowerState] INFO impl.RoleInfo: aa66c5ad-5081-4c78-b06e-86b7cfb78902: shutdown aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-FollowerState
2024-03-29 17:42:47,256 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-FollowerState] INFO server.RaftServer$Division: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-29 17:42:47,259 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
2024-03-29 17:42:47,259 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-FollowerState] INFO impl.RoleInfo: aa66c5ad-5081-4c78-b06e-86b7cfb78902: start aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1
2024-03-29 17:42:47,281 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO impl.LeaderElection: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[aa66c5ad-5081-4c78-b06e-86b7cfb78902|rpc:293f326d8bab:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2024-03-29 17:42:47,282 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO impl.LeaderElection: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1 ELECTION round 0: result PASSED (term=1)
2024-03-29 17:42:47,283 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO impl.RoleInfo: aa66c5ad-5081-4c78-b06e-86b7cfb78902: shutdown aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1
2024-03-29 17:42:47,283 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO server.RaftServer$Division: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-29 17:42:47,283 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO server.RaftServer$Division: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00: change Leader from null to aa66c5ad-5081-4c78-b06e-86b7cfb78902 at term 1 for becomeLeader, leader elected after 5929ms
2024-03-29 17:42:47,295 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2024-03-29 17:42:47,299 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2024-03-29 17:42:47,304 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2024-03-29 17:42:47,309 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2024-03-29 17:42:47,313 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2024-03-29 17:42:47,314 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2024-03-29 17:42:47,325 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2024-03-29 17:42:47,368 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-29 17:42:47,385 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO impl.RoleInfo: aa66c5ad-5081-4c78-b06e-86b7cfb78902: start aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderStateImpl
2024-03-29 17:42:47,524 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-29 17:42:47,801 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO server.RaftServer$Division: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00: set configuration 0: peers:[aa66c5ad-5081-4c78-b06e-86b7cfb78902|rpc:293f326d8bab:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2024-03-29 17:42:48,016 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/1927025a-e656-49a1-a5bf-df02c1146a00/current/log_inprogress_0
2024-03-29 17:42:48,410 [main] INFO server.RaftServer: aa66c5ad-5081-4c78-b06e-86b7cfb78902: close
2024-03-29 17:42:48,411 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServer$Division: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00: shutdown
2024-03-29 17:42:48,411 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DF02C1146A00,id=aa66c5ad-5081-4c78-b06e-86b7cfb78902
2024-03-29 17:42:48,411 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO impl.RoleInfo: aa66c5ad-5081-4c78-b06e-86b7cfb78902: shutdown aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderStateImpl
2024-03-29 17:42:48,411 [main] INFO server.GrpcService: aa66c5ad-5081-4c78-b06e-86b7cfb78902: shutdown server GrpcServerProtocolService now
2024-03-29 17:42:48,421 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO impl.PendingRequests: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-PendingRequests: sendNotLeaderResponses
2024-03-29 17:42:48,430 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO impl.StateMachineUpdater: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater: set stopIndex = 0
2024-03-29 17:42:48,430 [main] INFO server.GrpcService: aa66c5ad-5081-4c78-b06e-86b7cfb78902: shutdown server GrpcServerProtocolService successfully
2024-03-29 17:42:48,435 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater] INFO impl.StateMachineUpdater: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater: Took a snapshot at index 0
2024-03-29 17:42:48,439 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater] INFO impl.StateMachineUpdater: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-29 17:42:48,499 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServer$Division: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00: closes. applyIndex: 0
2024-03-29 17:42:48,508 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2024-03-29 17:42:48,529 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO segmented.SegmentedRaftLogWorker: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-SegmentedRaftLogWorker close()
2024-03-29 17:42:48,536 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-aa66c5ad-5081-4c78-b06e-86b7cfb78902: Stopped
2024-03-29 17:42:48,543 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:42:48,550 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-1927025a-e656-49a1-a5bf-df02c1146a00; layoutVersion=4; scmId=aa66c5ad-5081-4c78-b06e-86b7cfb78902
2024-03-29 17:42:48,587 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at 293f326d8bab/172.23.0.2
************************************************************/
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2024-03-29 17:42:52,869 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = 293f326d8bab/172.23.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.3.0
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.2.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.3.0.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.0.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.0.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-net-3.6.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.3.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.0.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.32.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.4.5.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.3.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.3.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.0.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.0.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.3.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-7.9.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.11.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.3.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.79.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.3.0.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.3.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0.jar
STARTUP_MSG:   build = https://github.com/apache/ozone.git/d0d18a3bff64b90f5f0755edb6003301049ffb32 ; compiled by 'micahzhao' on 2022-12-10T13:23Z
STARTUP_MSG:   java = 11.0.14.1
************************************************************/
2024-03-29 17:42:52,893 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2024-03-29 17:42:52,986 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:42:53,070 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2024-03-29 17:42:53,095 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2024-03-29 17:42:54,626 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:42:54,784 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:42:54,987 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.3.0.jar!/network-topology-default.xml]
2024-03-29 17:42:54,989 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
2024-03-29 17:42:55,066 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2024-03-29 17:42:55,084 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:aa66c5ad-5081-4c78-b06e-86b7cfb78902
2024-03-29 17:42:55,187 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2024-03-29 17:42:55,262 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-03-29 17:42:55,265 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2024-03-29 17:42:55,266 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-03-29 17:42:55,268 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2024-03-29 17:42:55,268 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2024-03-29 17:42:55,268 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2024-03-29 17:42:55,269 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2024-03-29 17:42:55,271 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:42:55,274 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2024-03-29 17:42:55,275 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2024-03-29 17:42:55,285 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2024-03-29 17:42:55,289 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-03-29 17:42:55,290 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-03-29 17:42:55,606 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2024-03-29 17:42:55,622 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2024-03-29 17:42:55,636 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2024-03-29 17:42:55,636 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2024-03-29 17:42:55,637 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-29 17:42:55,643 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2024-03-29 17:42:55,651 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServer: aa66c5ad-5081-4c78-b06e-86b7cfb78902: found a subdirectory /data/metadata/scm-ha/1927025a-e656-49a1-a5bf-df02c1146a00
2024-03-29 17:42:55,668 [main] INFO server.RaftServer: aa66c5ad-5081-4c78-b06e-86b7cfb78902: addNew group-DF02C1146A00:[] returns group-DF02C1146A00:java.util.concurrent.CompletableFuture@2b8bd14b[Not completed]
2024-03-29 17:42:55,714 [pool-16-thread-1] INFO server.RaftServer$Division: aa66c5ad-5081-4c78-b06e-86b7cfb78902: new RaftServerImpl for group-DF02C1146A00:[] with SCMStateMachine:uninitialized
2024-03-29 17:42:55,715 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2024-03-29 17:42:55,719 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-29 17:42:55,719 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2024-03-29 17:42:55,720 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2024-03-29 17:42:55,720 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-29 17:42:55,720 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-29 17:42:55,726 [pool-16-thread-1] INFO server.RaftServer$Division: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-29 17:42:55,727 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2024-03-29 17:42:55,730 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-29 17:42:55,730 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-29 17:42:55,742 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2024-03-29 17:42:55,745 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2024-03-29 17:42:55,745 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
2024-03-29 17:42:55,940 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-29 17:42:55,941 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2024-03-29 17:42:55,941 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2024-03-29 17:42:55,941 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2024-03-29 17:42:55,942 [pool-16-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2024-03-29 17:42:55,956 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
2024-03-29 17:42:55,956 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2024-03-29 17:42:55,957 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
2024-03-29 17:42:56,005 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2024-03-29 17:42:56,323 [main] INFO reflections.Reflections: Reflections took 236 ms to scan 3 urls, producing 112 keys and 252 values 
2024-03-29 17:42:56,408 [main] INFO ha.SequenceIdGenerator: upgrade localId to 113750153625600000
2024-03-29 17:42:56,409 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
2024-03-29 17:42:56,411 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
2024-03-29 17:42:56,412 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
2024-03-29 17:42:56,440 [main] INFO node.SCMNodeManager: Entering startup safe mode.
2024-03-29 17:42:56,451 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2024-03-29 17:42:56,452 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2024-03-29 17:42:56,457 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
2024-03-29 17:42:56,481 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2024-03-29 17:42:56,481 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2024-03-29 17:42:56,487 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
2024-03-29 17:42:56,488 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
2024-03-29 17:42:56,492 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
2024-03-29 17:42:56,492 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
2024-03-29 17:42:56,503 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
2024-03-29 17:42:56,504 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
2024-03-29 17:42:56,564 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-03-29 17:42:56,623 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
2024-03-29 17:42:56,653 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
2024-03-29 17:42:56,663 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
2024-03-29 17:42:56,664 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
2024-03-29 17:42:56,670 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
2024-03-29 17:42:56,672 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:42:56,673 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2024-03-29 17:42:57,095 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2024-03-29 17:42:57,115 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-29 17:42:57,350 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
2024-03-29 17:42:57,476 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2024-03-29 17:42:57,480 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-29 17:42:57,487 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
2024-03-29 17:42:57,530 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2024-03-29 17:42:57,543 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-29 17:42:57,544 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
2024-03-29 17:42:57,610 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
2024-03-29 17:42:57,611 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
Container Balancer status:
Key                            Value
Running                        true
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2024-03-29 17:42:57,611 [Listener at 0.0.0.0/9860] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2024-03-29 17:42:57,611 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2024-03-29 17:42:57,621 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
2024-03-29 17:42:57,624 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
2024-03-29 17:42:57,635 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/1927025a-e656-49a1-a5bf-df02c1146a00/in_use.lock acquired by nodename 7@293f326d8bab
2024-03-29 17:42:57,639 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=aa66c5ad-5081-4c78-b06e-86b7cfb78902} from /data/metadata/scm-ha/1927025a-e656-49a1-a5bf-df02c1146a00/current/raft-meta
2024-03-29 17:42:57,684 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServer$Division: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00: set configuration 0: peers:[aa66c5ad-5081-4c78-b06e-86b7cfb78902|rpc:293f326d8bab:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2024-03-29 17:42:57,694 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2024-03-29 17:42:57,701 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2024-03-29 17:42:57,701 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:42:57,708 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-29 17:42:57,710 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-29 17:42:57,718 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2024-03-29 17:42:57,726 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-29 17:42:57,728 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-29 17:42:57,733 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/1927025a-e656-49a1-a5bf-df02c1146a00
2024-03-29 17:42:57,734 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2024-03-29 17:42:57,734 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2024-03-29 17:42:57,739 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2024-03-29 17:42:57,740 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2024-03-29 17:42:57,742 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2024-03-29 17:42:57,749 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2024-03-29 17:42:57,749 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-29 17:42:57,753 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2024-03-29 17:42:57,767 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
2024-03-29 17:42:57,768 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2024-03-29 17:42:57,768 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2024-03-29 17:42:57,768 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2024-03-29 17:42:57,823 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServer$Division: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00: set configuration 0: peers:[aa66c5ad-5081-4c78-b06e-86b7cfb78902|rpc:293f326d8bab:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2024-03-29 17:42:57,823 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/1927025a-e656-49a1-a5bf-df02c1146a00/current/log_inprogress_0
2024-03-29 17:42:57,830 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO segmented.SegmentedRaftLogWorker: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
2024-03-29 17:42:57,830 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO segmented.SegmentedRaftLogWorker: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-29 17:42:57,928 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServer$Division: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00: start as a follower, conf=0: peers:[aa66c5ad-5081-4c78-b06e-86b7cfb78902|rpc:293f326d8bab:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2024-03-29 17:42:57,929 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServer$Division: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00: changes role from      null to FOLLOWER at term 1 for startAsFollower
2024-03-29 17:42:57,930 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO impl.RoleInfo: aa66c5ad-5081-4c78-b06e-86b7cfb78902: start aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-FollowerState
2024-03-29 17:42:57,932 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2024-03-29 17:42:57,932 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-29 17:42:57,933 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DF02C1146A00,id=aa66c5ad-5081-4c78-b06e-86b7cfb78902
2024-03-29 17:42:57,936 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-29 17:42:57,936 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2024-03-29 17:42:57,937 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2024-03-29 17:42:57,937 [aa66c5ad-5081-4c78-b06e-86b7cfb78902-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-29 17:42:57,959 [Listener at 0.0.0.0/9860] INFO server.RaftServer: aa66c5ad-5081-4c78-b06e-86b7cfb78902: start RPC server
2024-03-29 17:42:58,032 [Listener at 0.0.0.0/9860] INFO server.GrpcService: aa66c5ad-5081-4c78-b06e-86b7cfb78902: GrpcService started, listening on 9894
2024-03-29 17:42:58,041 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [aa66c5ad-5081-4c78-b06e-86b7cfb78902|rpc:293f326d8bab:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]
2024-03-29 17:42:58,041 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
2024-03-29 17:42:58,041 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-aa66c5ad-5081-4c78-b06e-86b7cfb78902: Started
2024-03-29 17:42:58,138 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2024-03-29 17:42:58,149 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-03-29 17:42:58,149 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
2024-03-29 17:42:58,368 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
2024-03-29 17:42:58,369 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-03-29 17:42:58,372 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
2024-03-29 17:42:58,452 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
2024-03-29 17:42:58,453 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
2024-03-29 17:42:58,455 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-03-29 17:42:58,467 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
2024-03-29 17:42:58,475 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@39652a30] INFO util.JvmPauseMonitor: Starting JVM pause monitor
2024-03-29 17:42:58,486 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
2024-03-29 17:42:58,487 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-29 17:42:58,511 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @8903ms to org.eclipse.jetty.util.log.Slf4jLog
2024-03-29 17:42:58,687 [Listener at 0.0.0.0/9860] WARN server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /opt/hadoop/hadoop-http-auth-signature-secret
2024-03-29 17:42:58,701 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
2024-03-29 17:42:58,706 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-29 17:42:58,710 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2024-03-29 17:42:58,710 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-29 17:42:58,711 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-29 17:42:58,749 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
2024-03-29 17:42:58,750 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
2024-03-29 17:42:58,788 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
2024-03-29 17:42:58,788 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
2024-03-29 17:42:58,789 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
2024-03-29 17:42:58,801 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@66020d69{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
2024-03-29 17:42:58,802 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@2b44605c{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0.jar!/webapps/static,AVAILABLE}
2024-03-29 17:42:59,069 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4eeb14e0{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_3_0_jar-_-any-15710689431904150758/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.3.0.jar!/webapps/scm}
2024-03-29 17:42:59,075 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@4628a02b{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
2024-03-29 17:42:59,076 [Listener at 0.0.0.0/9860] INFO server.Server: Started @9469ms
2024-03-29 17:42:59,078 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
2024-03-29 17:42:59,078 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
2024-03-29 17:42:59,079 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
2024-03-29 17:43:03,077 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-FollowerState] INFO impl.FollowerState: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5147548964ns, electionTimeout:5144ms
2024-03-29 17:43:03,078 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-FollowerState] INFO impl.RoleInfo: aa66c5ad-5081-4c78-b06e-86b7cfb78902: shutdown aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-FollowerState
2024-03-29 17:43:03,078 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-FollowerState] INFO server.RaftServer$Division: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2024-03-29 17:43:03,081 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
2024-03-29 17:43:03,081 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-FollowerState] INFO impl.RoleInfo: aa66c5ad-5081-4c78-b06e-86b7cfb78902: start aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1
2024-03-29 17:43:03,095 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO impl.LeaderElection: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: peers:[aa66c5ad-5081-4c78-b06e-86b7cfb78902|rpc:293f326d8bab:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2024-03-29 17:43:03,095 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO impl.LeaderElection: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1 ELECTION round 0: result PASSED (term=2)
2024-03-29 17:43:03,096 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO impl.RoleInfo: aa66c5ad-5081-4c78-b06e-86b7cfb78902: shutdown aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1
2024-03-29 17:43:03,096 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO server.RaftServer$Division: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2024-03-29 17:43:03,096 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
2024-03-29 17:43:03,096 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
2024-03-29 17:43:03,097 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO server.RaftServer$Division: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00: change Leader from null to aa66c5ad-5081-4c78-b06e-86b7cfb78902 at term 2 for becomeLeader, leader elected after 7354ms
2024-03-29 17:43:03,101 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2024-03-29 17:43:03,104 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2024-03-29 17:43:03,104 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2024-03-29 17:43:03,107 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2024-03-29 17:43:03,107 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2024-03-29 17:43:03,108 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2024-03-29 17:43:03,111 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2024-03-29 17:43:03,112 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-29 17:43:03,113 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO impl.RoleInfo: aa66c5ad-5081-4c78-b06e-86b7cfb78902: start aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderStateImpl
2024-03-29 17:43:03,117 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2024-03-29 17:43:03,120 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/1927025a-e656-49a1-a5bf-df02c1146a00/current/log_inprogress_0 to /data/metadata/scm-ha/1927025a-e656-49a1-a5bf-df02c1146a00/current/log_0-0
2024-03-29 17:43:03,120 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-LeaderElection1] INFO server.RaftServer$Division: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00: set configuration 1: peers:[aa66c5ad-5081-4c78-b06e-86b7cfb78902|rpc:293f326d8bab:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2024-03-29 17:43:03,131 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/1927025a-e656-49a1-a5bf-df02c1146a00/current/log_inprogress_1
2024-03-29 17:43:03,135 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
2024-03-29 17:43:03,135 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
2024-03-29 17:43:03,136 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:43:03,137 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
2024-03-29 17:43:03,137 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2024-03-29 17:43:03,137 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
2024-03-29 17:43:03,143 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-03-29 17:43:03,143 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
2024-03-29 17:43:03,194 [IPC Server handler 3 on default port 9861] WARN ipc.Server: IPC Server handler 3 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.23.0.10:48476: output error
2024-03-29 17:43:03,195 [IPC Server handler 3 on default port 9861] INFO ipc.Server: IPC Server handler 3 on default port 9861 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2024-03-29 17:43:03,201 [IPC Server handler 0 on default port 9861] WARN ipc.Server: IPC Server handler 0 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.23.0.3:41660: output error
2024-03-29 17:43:03,201 [IPC Server handler 0 on default port 9861] INFO ipc.Server: IPC Server handler 0 on default port 9861 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2024-03-29 17:43:03,201 [IPC Server handler 5 on default port 9861] WARN ipc.Server: IPC Server handler 5 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from 172.23.0.9:40950: output error
2024-03-29 17:43:03,202 [IPC Server handler 5 on default port 9861] INFO ipc.Server: IPC Server handler 5 on default port 9861 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3619)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:144)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1672)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1742)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2847)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1814)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1125)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:917)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:903)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1060)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
2024-03-29 17:43:03,576 [IPC Server handler 6 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/3c404993-6ad5-462e-b7b3-ca6e8ed0e89d
2024-03-29 17:43:03,578 [IPC Server handler 6 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 3c404993-6ad5-462e-b7b3-ca6e8ed0e89d{ip: 172.23.0.3, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:43:03,580 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:43:03,584 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
2024-03-29 17:43:03,595 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ed17a046-0a1a-4467-b3bf-ebcb5a9cf180 to datanode:3c404993-6ad5-462e-b7b3-ca6e8ed0e89d
2024-03-29 17:43:03,590 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2024-03-29 17:43:03,603 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:43:03,654 [IPC Server handler 7 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/7d006827-e707-46b3-ab4b-ba7b4972b69a
2024-03-29 17:43:03,654 [IPC Server handler 7 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 7d006827-e707-46b3-ab4b-ba7b4972b69a{ip: 172.23.0.10, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:43:03,655 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:43:03,656 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
2024-03-29 17:43:03,673 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: ed17a046-0a1a-4467-b3bf-ebcb5a9cf180, Nodes: 3c404993-6ad5-462e-b7b3-ca6e8ed0e89d{ip: 172.23.0.3, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:43:03.594Z[UTC]].
2024-03-29 17:43:03,675 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:43:03,685 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=08f7432a-d6e5-44ae-b15e-251247e5d124 to datanode:7d006827-e707-46b3-ab4b-ba7b4972b69a
2024-03-29 17:43:03,690 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 08f7432a-d6e5-44ae-b15e-251247e5d124, Nodes: 7d006827-e707-46b3-ab4b-ba7b4972b69a{ip: 172.23.0.10, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:43:03.685Z[UTC]].
2024-03-29 17:43:03,690 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:43:03,991 [IPC Server handler 8 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/6a48a643-4073-450c-97e2-fa4e35a77243
2024-03-29 17:43:03,992 [IPC Server handler 8 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 6a48a643-4073-450c-97e2-fa4e35a77243{ip: 172.23.0.9, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:43:03,993 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:43:03,996 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
2024-03-29 17:43:04,002 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
2024-03-29 17:43:04,002 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
2024-03-29 17:43:04,002 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=24eae68c-e83a-4b1b-a004-be6186742f09 to datanode:6a48a643-4073-450c-97e2-fa4e35a77243
2024-03-29 17:43:04,004 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2024-03-29 17:43:04,012 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2024-03-29 17:43:04,015 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:43:04,016 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 24eae68c-e83a-4b1b-a004-be6186742f09, Nodes: 6a48a643-4073-450c-97e2-fa4e35a77243{ip: 172.23.0.9, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:43:04.002Z[UTC]].
2024-03-29 17:43:04,017 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:43:04,021 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=65820a46-690f-4b4b-b63e-92bc573ecf7d to datanode:7d006827-e707-46b3-ab4b-ba7b4972b69a
2024-03-29 17:43:04,022 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=65820a46-690f-4b4b-b63e-92bc573ecf7d to datanode:3c404993-6ad5-462e-b7b3-ca6e8ed0e89d
2024-03-29 17:43:04,022 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=65820a46-690f-4b4b-b63e-92bc573ecf7d to datanode:6a48a643-4073-450c-97e2-fa4e35a77243
2024-03-29 17:43:04,028 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 65820a46-690f-4b4b-b63e-92bc573ecf7d, Nodes: 7d006827-e707-46b3-ab4b-ba7b4972b69a{ip: 172.23.0.10, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c404993-6ad5-462e-b7b3-ca6e8ed0e89d{ip: 172.23.0.3, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}6a48a643-4073-450c-97e2-fa4e35a77243{ip: 172.23.0.9, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:43:04.021Z[UTC]].
2024-03-29 17:43:04,028 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:43:04,036 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=bba07f8b-1e65-47ec-81ef-18390d7a5c88 to datanode:6a48a643-4073-450c-97e2-fa4e35a77243
2024-03-29 17:43:04,037 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=bba07f8b-1e65-47ec-81ef-18390d7a5c88 to datanode:3c404993-6ad5-462e-b7b3-ca6e8ed0e89d
2024-03-29 17:43:04,037 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=bba07f8b-1e65-47ec-81ef-18390d7a5c88 to datanode:7d006827-e707-46b3-ab4b-ba7b4972b69a
2024-03-29 17:43:04,040 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: bba07f8b-1e65-47ec-81ef-18390d7a5c88, Nodes: 6a48a643-4073-450c-97e2-fa4e35a77243{ip: 172.23.0.9, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c404993-6ad5-462e-b7b3-ca6e8ed0e89d{ip: 172.23.0.3, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}7d006827-e707-46b3-ab4b-ba7b4972b69a{ip: 172.23.0.10, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:43:04.036Z[UTC]].
2024-03-29 17:43:04,040 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:43:04,043 [RatisPipelineUtilsThread - 0] INFO pipeline.PipelineManagerImpl: Pipeline: PipelineID=bba07f8b-1e65-47ec-81ef-18390d7a5c88 contains same datanodes as previous pipelines: PipelineID=65820a46-690f-4b4b-b63e-92bc573ecf7d nodeIds: 6a48a643-4073-450c-97e2-fa4e35a77243, 3c404993-6ad5-462e-b7b3-ca6e8ed0e89d, 7d006827-e707-46b3-ab4b-ba7b4972b69a
2024-03-29 17:43:06,765 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: ed17a046-0a1a-4467-b3bf-ebcb5a9cf180, Nodes: 3c404993-6ad5-462e-b7b3-ca6e8ed0e89d{ip: 172.23.0.3, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:3c404993-6ad5-462e-b7b3-ca6e8ed0e89d, CreationTimestamp2024-03-29T17:43:03.594Z[UTC]] moved to OPEN state
2024-03-29 17:43:06,769 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:43:06,770 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:43:06,909 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 08f7432a-d6e5-44ae-b15e-251247e5d124, Nodes: 7d006827-e707-46b3-ab4b-ba7b4972b69a{ip: 172.23.0.10, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:7d006827-e707-46b3-ab4b-ba7b4972b69a, CreationTimestamp2024-03-29T17:43:03.685Z[UTC]] moved to OPEN state
2024-03-29 17:43:06,911 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:43:06,912 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:43:06,975 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:43:07,085 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:43:07,319 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 24eae68c-e83a-4b1b-a004-be6186742f09, Nodes: 6a48a643-4073-450c-97e2-fa4e35a77243{ip: 172.23.0.9, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:6a48a643-4073-450c-97e2-fa4e35a77243, CreationTimestamp2024-03-29T17:43:04.002Z[UTC]] moved to OPEN state
2024-03-29 17:43:07,323 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:43:07,324 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:43:07,472 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:43:08,353 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:43:08,373 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:43:08,482 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:43:11,955 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:43:12,081 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:43:12,222 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 65820a46-690f-4b4b-b63e-92bc573ecf7d, Nodes: 7d006827-e707-46b3-ab4b-ba7b4972b69a{ip: 172.23.0.10, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c404993-6ad5-462e-b7b3-ca6e8ed0e89d{ip: 172.23.0.3, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}6a48a643-4073-450c-97e2-fa4e35a77243{ip: 172.23.0.9, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:3c404993-6ad5-462e-b7b3-ca6e8ed0e89d, CreationTimestamp2024-03-29T17:43:04.021Z[UTC]] moved to OPEN state
2024-03-29 17:43:12,226 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
2024-03-29 17:43:12,227 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2024-03-29 17:43:12,227 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
2024-03-29 17:43:12,227 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
2024-03-29 17:43:12,228 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
2024-03-29 17:43:12,228 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN events.EventQueue: No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='Safe mode status'}
2024-03-29 17:43:12,228 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2024-03-29 17:43:12,228 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
2024-03-29 17:43:12,229 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2024-03-29 17:43:12,232 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
2024-03-29 17:43:12,234 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2024-03-29 17:43:13,513 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: bba07f8b-1e65-47ec-81ef-18390d7a5c88, Nodes: 6a48a643-4073-450c-97e2-fa4e35a77243{ip: 172.23.0.9, host: xcompat_datanode_3.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3c404993-6ad5-462e-b7b3-ca6e8ed0e89d{ip: 172.23.0.3, host: xcompat_datanode_1.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}7d006827-e707-46b3-ab4b-ba7b4972b69a{ip: 172.23.0.10, host: xcompat_datanode_2.xcompat_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:7d006827-e707-46b3-ab4b-ba7b4972b69a, CreationTimestamp2024-03-29T17:43:04.036Z[UTC]] moved to OPEN state
2024-03-29 17:43:15,737 [IPC Server handler 12 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
2024-03-29 17:43:15,756 [aa66c5ad-5081-4c78-b06e-86b7cfb78902@group-DF02C1146A00-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 113750153625600000.
2024-03-29 17:43:15,761 [IPC Server handler 12 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 113750153625600000 to 113750153625601000.
2024-03-29 17:43:35,381 [IPC Server handler 9 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.23.0.14
2024-03-29 17:43:42,150 [IPC Server handler 9 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.23.0.14
2024-03-29 17:44:17,587 [IPC Server handler 12 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.23.0.14
2024-03-29 17:44:24,260 [IPC Server handler 16 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.23.0.14
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2024-03-29 17:44:47,070 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = 03bbc0f826a7/172.24.0.6
STARTUP_MSG:   args = [--init]
STARTUP_MSG:   version = 1.4.0
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jgraphx-2.0.0.1.jar:/opt/hadoop/share/ozone/lib/commons-net-3.10.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.12.0.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.9.21.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.21.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.6.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-text-1.10.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.6.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.0.1.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/okio-3.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.5.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.9.21.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.4.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/jgraph-5.13.0.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/antlr4-runtime-4.5.3.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.9.21.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.0.1.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0.jar
STARTUP_MSG:   build = https://github.com/apache/ozone.git/e4b6007c8e9f79d1432cf6f128d6f83e733f8e9b ; compiled by 'ozone' on 2024-01-10T15:30Z
STARTUP_MSG:   java = 11.0.19
STARTUP_MSG:   conf = {dfs.container.chunk.write.sync=false, dfs.container.ipc=9859, dfs.container.ipc.random.port=false, dfs.container.ratis.admin.port=9857, dfs.container.ratis.datastream.enabled=false, dfs.container.ratis.datastream.port=9855, dfs.container.ratis.datastream.random.port=false, dfs.container.ratis.enabled=false, dfs.container.ratis.ipc=9858, dfs.container.ratis.ipc.random.port=false, dfs.container.ratis.leader.pending.bytes.limit=1GB, dfs.container.ratis.log.appender.queue.byte-limit=32MB, dfs.container.ratis.log.appender.queue.num-elements=1, dfs.container.ratis.log.purge.gap=1000000, dfs.container.ratis.log.queue.byte-limit=4GB, dfs.container.ratis.log.queue.num-elements=1024, dfs.container.ratis.num.container.op.executors=10, dfs.container.ratis.num.write.chunk.threads.per.volume=10, dfs.container.ratis.replication.level=MAJORITY, dfs.container.ratis.rpc.type=GRPC, dfs.container.ratis.segment.preallocated.size=4MB, dfs.container.ratis.segment.size=64MB, dfs.container.ratis.server.port=9856, dfs.container.ratis.statemachine.max.pending.apply-transactions=10000, dfs.container.ratis.statemachinedata.sync.timeout=10s, dfs.ratis.leader.election.minimum.timeout.duration=5s, dfs.ratis.server.retry-cache.timeout.duration=600000ms, dfs.ratis.snapshot.threshold=10000, hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=false, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.close.threshold=0.9f, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=false, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=false, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.datanode.http.auth.type=simple, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=false, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.scm.http.auth.type=simple, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/SCM.keytab, hdds.scm.kerberos.principal=SCM/_HOST@REALM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=3, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneAccessAuthorizer, ozone.acl.enabled=false, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.default.bucket.layout=LEGACY, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.http.policy=HTTP_ONLY, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=om, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=om:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.om.http.auth.type=simple, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.kerberos.keytab.file=/etc/security/keytabs/OM.keytab, ozone.om.kerberos.principal=OM/_HOST@REALM, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.sst_dumptool.buffer.size=8KB, ozone.om.snapshot.sst_dumptool.pool.size=1, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=true, ozone.path.deleting.limit.per.task=6000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.recon.http.auth.type=simple, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=10m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.s3g.http.auth.type=simple, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/_HOST@REALM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=false, ozone.s3g.volume.name=s3v, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=150s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.names=scm, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=120s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=false, ozone.security.http.kerberos.enabled=false, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.trace.enabled=false, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, recon.om.snapshot.task.interval.delay=1m, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2024-03-29 17:44:47,137 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2024-03-29 17:44:47,350 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:44:48,265 [main] INFO reflections.Reflections: Reflections took 644 ms to scan 3 urls, producing 134 keys and 291 values 
2024-03-29 17:44:48,486 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2024-03-29 17:44:48,512 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2024-03-29 17:44:49,428 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2024-03-29 17:44:49,719 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-03-29 17:44:49,720 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2024-03-29 17:44:49,720 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-03-29 17:44:49,721 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2024-03-29 17:44:49,721 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2024-03-29 17:44:49,721 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2024-03-29 17:44:49,722 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2024-03-29 17:44:49,748 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:44:49,749 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2024-03-29 17:44:49,750 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2024-03-29 17:44:49,779 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2024-03-29 17:44:49,792 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-03-29 17:44:49,808 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-03-29 17:44:50,684 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2024-03-29 17:44:50,703 [main] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-29 17:44:50,703 [main] INFO server.RaftServerConfigKeys: raft.server.close.threshold = 60s (default)
2024-03-29 17:44:50,703 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-29 17:44:50,712 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2024-03-29 17:44:50,713 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2024-03-29 17:44:50,713 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2024-03-29 17:44:50,721 [main] INFO server.RaftServer: 4fd50358-f617-4fef-b43e-6e61c9cf84a5: addNew group-3543F8E510A5:[4fd50358-f617-4fef-b43e-6e61c9cf84a5|03bbc0f826a7:9894] returns group-3543F8E510A5:java.util.concurrent.CompletableFuture@36bc415e[Not completed]
2024-03-29 17:44:50,743 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServer$Division: 4fd50358-f617-4fef-b43e-6e61c9cf84a5: new RaftServerImpl for group-3543F8E510A5:[4fd50358-f617-4fef-b43e-6e61c9cf84a5|03bbc0f826a7:9894] with SCMStateMachine:uninitialized
2024-03-29 17:44:50,746 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2024-03-29 17:44:50,746 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-29 17:44:50,746 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2024-03-29 17:44:50,746 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2024-03-29 17:44:50,747 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-29 17:44:50,759 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.member.majority-add = false (default)
2024-03-29 17:44:50,760 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-29 17:44:50,782 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServer$Division: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5: ConfigurationManager, init=-1: peers:[4fd50358-f617-4fef-b43e-6e61c9cf84a5|03bbc0f826a7:9894]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-29 17:44:50,793 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2024-03-29 17:44:50,808 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2024-03-29 17:44:50,836 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2024-03-29 17:44:50,837 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-29 17:44:50,848 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2024-03-29 17:44:50,857 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-29 17:44:50,905 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.dropwizard3.Dm3MetricRegistriesImpl
2024-03-29 17:44:51,547 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2024-03-29 17:44:51,550 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-29 17:44:51,551 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2024-03-29 17:44:51,551 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2024-03-29 17:44:51,552 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2024-03-29 17:44:51,552 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2024-03-29 17:44:51,560 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-29 17:44:51,563 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-29 17:44:51,564 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2024-03-29 17:44:51,604 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/e4179187-75bc-4062-bff5-3543f8e510a5 does not exist. Creating ...
2024-03-29 17:44:51,648 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/e4179187-75bc-4062-bff5-3543f8e510a5/in_use.lock acquired by nodename 13@03bbc0f826a7
2024-03-29 17:44:51,693 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/e4179187-75bc-4062-bff5-3543f8e510a5 has been successfully formatted.
2024-03-29 17:44:51,694 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] WARN util.FileUtils: Failed to Files.newInputStream /data/metadata/scm-ha/e4179187-75bc-4062-bff5-3543f8e510a5/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /data/metadata/scm-ha/e4179187-75bc-4062-bff5-3543f8e510a5/current/raft-meta.conf
2024-03-29 17:44:51,716 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2024-03-29 17:44:51,767 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2024-03-29 17:44:51,767 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:44:51,769 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-29 17:44:51,769 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-29 17:44:51,783 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2024-03-29 17:44:51,787 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-29 17:44:51,813 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-29 17:44:51,813 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:44:51,829 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO util.AwaitToRun: Thread[4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-cacheEviction-AwaitToRun,5,main] started
2024-03-29 17:44:51,839 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/e4179187-75bc-4062-bff5-3543f8e510a5
2024-03-29 17:44:51,840 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2024-03-29 17:44:51,844 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2024-03-29 17:44:51,845 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2024-03-29 17:44:51,848 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2024-03-29 17:44:51,848 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2024-03-29 17:44:51,849 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2024-03-29 17:44:51,849 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-29 17:44:51,850 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2024-03-29 17:44:51,852 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554440 (custom)
2024-03-29 17:44:51,869 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:44:51,884 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2024-03-29 17:44:51,884 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2024-03-29 17:44:51,884 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2024-03-29 17:44:51,895 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-29 17:44:51,895 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-29 17:44:51,898 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServer$Division: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5: start as a follower, conf=-1: peers:[4fd50358-f617-4fef-b43e-6e61c9cf84a5|03bbc0f826a7:9894]|listeners:[], old=null
2024-03-29 17:44:51,899 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServer$Division: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-29 17:44:51,900 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO impl.RoleInfo: 4fd50358-f617-4fef-b43e-6e61c9cf84a5: start 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-FollowerState
2024-03-29 17:44:51,906 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2024-03-29 17:44:51,907 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-29 17:44:51,910 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3543F8E510A5,id=4fd50358-f617-4fef-b43e-6e61c9cf84a5
2024-03-29 17:44:51,930 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-29 17:44:51,931 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-29 17:44:51,935 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2024-03-29 17:44:51,936 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2024-03-29 17:44:51,937 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-29 17:44:51,956 [main] INFO server.RaftServer: 4fd50358-f617-4fef-b43e-6e61c9cf84a5: start RPC server
2024-03-29 17:44:52,093 [main] INFO server.GrpcService: 4fd50358-f617-4fef-b43e-6e61c9cf84a5: GrpcService started, listening on 9894
2024-03-29 17:44:52,119 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-4fd50358-f617-4fef-b43e-6e61c9cf84a5: Started
2024-03-29 17:44:57,008 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-FollowerState] INFO impl.FollowerState: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5108078655ns, electionTimeout:5090ms
2024-03-29 17:44:57,008 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-FollowerState] INFO impl.RoleInfo: 4fd50358-f617-4fef-b43e-6e61c9cf84a5: shutdown 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-FollowerState
2024-03-29 17:44:57,008 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-FollowerState] INFO server.RaftServer$Division: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-29 17:44:57,015 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
2024-03-29 17:44:57,016 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-FollowerState] INFO impl.RoleInfo: 4fd50358-f617-4fef-b43e-6e61c9cf84a5: start 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1
2024-03-29 17:44:57,019 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO impl.LeaderElection: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[4fd50358-f617-4fef-b43e-6e61c9cf84a5|03bbc0f826a7:9894]|listeners:[], old=null
2024-03-29 17:44:57,020 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO impl.LeaderElection: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1 PRE_VOTE round 0: result PASSED (term=0)
2024-03-29 17:44:57,029 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO impl.LeaderElection: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[4fd50358-f617-4fef-b43e-6e61c9cf84a5|03bbc0f826a7:9894]|listeners:[], old=null
2024-03-29 17:44:57,029 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO impl.LeaderElection: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1 ELECTION round 0: result PASSED (term=1)
2024-03-29 17:44:57,029 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO impl.RoleInfo: 4fd50358-f617-4fef-b43e-6e61c9cf84a5: shutdown 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1
2024-03-29 17:44:57,029 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServer$Division: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-29 17:44:57,037 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2024-03-29 17:44:57,086 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2024-03-29 17:44:57,087 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2024-03-29 17:44:57,090 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2024-03-29 17:44:57,090 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2024-03-29 17:44:57,091 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2024-03-29 17:44:57,168 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.enabled = false (default)
2024-03-29 17:44:57,170 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-29 17:44:57,180 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2024-03-29 17:44:57,187 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2024-03-29 17:44:57,188 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-29 17:44:57,190 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO impl.RoleInfo: 4fd50358-f617-4fef-b43e-6e61c9cf84a5: start 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderStateImpl
2024-03-29 17:44:57,207 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServer$Division: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5: set firstElectionSinceStartup to false for becomeLeader
2024-03-29 17:44:57,207 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServer$Division: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5: change Leader from null to 4fd50358-f617-4fef-b43e-6e61c9cf84a5 at term 1 for becomeLeader, leader elected after 6414ms
2024-03-29 17:44:57,299 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-29 17:44:57,416 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-SegmentedRaftLogWorker] INFO segmented.BufferedWriteChannel: open log_inprogress_0 at position 0
2024-03-29 17:44:57,464 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/e4179187-75bc-4062-bff5-3543f8e510a5/current/log_inprogress_0
2024-03-29 17:44:57,508 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServer$Division: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5: set configuration 0: peers:[4fd50358-f617-4fef-b43e-6e61c9cf84a5|03bbc0f826a7:9894]|listeners:[], old=null
2024-03-29 17:44:57,556 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-StateMachineUpdater] INFO server.RaftServer$Division: leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-29 17:44:58,117 [main] INFO server.RaftServer: 4fd50358-f617-4fef-b43e-6e61c9cf84a5: close
2024-03-29 17:44:58,119 [main] INFO server.GrpcService: 4fd50358-f617-4fef-b43e-6e61c9cf84a5: shutdown server GrpcServerProtocolService now
2024-03-29 17:44:58,119 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServer$Division: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5: shutdown
2024-03-29 17:44:58,122 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-3543F8E510A5,id=4fd50358-f617-4fef-b43e-6e61c9cf84a5
2024-03-29 17:44:58,122 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO impl.RoleInfo: 4fd50358-f617-4fef-b43e-6e61c9cf84a5: shutdown 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderStateImpl
2024-03-29 17:44:58,126 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO impl.PendingRequests: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-PendingRequests: sendNotLeaderResponses
2024-03-29 17:44:58,165 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO impl.StateMachineUpdater: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-StateMachineUpdater: set stopIndex = 0
2024-03-29 17:44:58,166 [main] INFO server.GrpcService: 4fd50358-f617-4fef-b43e-6e61c9cf84a5: shutdown server GrpcServerProtocolService successfully
2024-03-29 17:44:58,171 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-StateMachineUpdater] INFO impl.StateMachineUpdater: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-StateMachineUpdater: Took a snapshot at index 0
2024-03-29 17:44:58,172 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-StateMachineUpdater] INFO impl.StateMachineUpdater: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-29 17:44:58,183 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServer$Division: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5: applyIndex: 0
2024-03-29 17:44:58,184 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-cacheEviction-AwaitToRun] INFO util.AwaitToRun: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-29 17:44:58,487 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-SegmentedRaftLogWorker close()
2024-03-29 17:44:58,489 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-4fd50358-f617-4fef-b43e-6e61c9cf84a5: Stopped
2024-03-29 17:44:58,489 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:44:58,496 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-e4179187-75bc-4062-bff5-3543f8e510a5; layoutVersion=7; scmId=4fd50358-f617-4fef-b43e-6e61c9cf84a5
2024-03-29 17:44:58,503 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at 03bbc0f826a7/172.24.0.6
************************************************************/
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2024-03-29 17:45:01,898 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = 03bbc0f826a7/172.24.0.6
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.4.0
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jgraphx-2.0.0.1.jar:/opt/hadoop/share/ozone/lib/commons-net-3.10.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/okhttp-4.12.0.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.9.21.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.21.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.6.0.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-text-1.10.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.6.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.0.1.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/okio-3.6.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.0.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.5.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.9.21.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.4.0.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/jgraph-5.13.0.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/antlr4-runtime-4.5.3.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.9.21.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.0.1.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0.jar
STARTUP_MSG:   build = https://github.com/apache/ozone.git/e4b6007c8e9f79d1432cf6f128d6f83e733f8e9b ; compiled by 'ozone' on 2024-01-10T15:30Z
STARTUP_MSG:   java = 11.0.19
STARTUP_MSG:   conf = {dfs.container.chunk.write.sync=false, dfs.container.ipc=9859, dfs.container.ipc.random.port=false, dfs.container.ratis.admin.port=9857, dfs.container.ratis.datastream.enabled=false, dfs.container.ratis.datastream.port=9855, dfs.container.ratis.datastream.random.port=false, dfs.container.ratis.enabled=false, dfs.container.ratis.ipc=9858, dfs.container.ratis.ipc.random.port=false, dfs.container.ratis.leader.pending.bytes.limit=1GB, dfs.container.ratis.log.appender.queue.byte-limit=32MB, dfs.container.ratis.log.appender.queue.num-elements=1, dfs.container.ratis.log.purge.gap=1000000, dfs.container.ratis.log.queue.byte-limit=4GB, dfs.container.ratis.log.queue.num-elements=1024, dfs.container.ratis.num.container.op.executors=10, dfs.container.ratis.num.write.chunk.threads.per.volume=10, dfs.container.ratis.replication.level=MAJORITY, dfs.container.ratis.rpc.type=GRPC, dfs.container.ratis.segment.preallocated.size=4MB, dfs.container.ratis.segment.size=64MB, dfs.container.ratis.server.port=9856, dfs.container.ratis.statemachine.max.pending.apply-transactions=10000, dfs.container.ratis.statemachinedata.sync.timeout=10s, dfs.ratis.leader.election.minimum.timeout.duration=5s, dfs.ratis.server.retry-cache.timeout.duration=600000ms, dfs.ratis.snapshot.threshold=10000, hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=false, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.close.threshold=0.9f, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=false, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=false, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.datanode.http.auth.type=simple, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=false, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.scm.http.auth.type=simple, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/SCM.keytab, hdds.scm.kerberos.principal=SCM/_HOST@REALM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=3, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneAccessAuthorizer, ozone.acl.enabled=false, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.default.bucket.layout=LEGACY, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.http.policy=HTTP_ONLY, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=om, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=om:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.om.http.auth.type=simple, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.kerberos.keytab.file=/etc/security/keytabs/OM.keytab, ozone.om.kerberos.principal=OM/_HOST@REALM, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.sst_dumptool.buffer.size=8KB, ozone.om.snapshot.sst_dumptool.pool.size=1, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=true, ozone.path.deleting.limit.per.task=6000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.recon.http.auth.type=simple, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=10m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.s3g.http.auth.type=simple, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/_HOST@REALM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=false, ozone.s3g.volume.name=s3v, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=150s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.names=scm, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=120s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=false, ozone.security.http.kerberos.enabled=false, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.trace.enabled=false, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, recon.om.snapshot.task.interval.delay=1m, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2024-03-29 17:45:01,912 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2024-03-29 17:45:01,966 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:45:02,301 [main] INFO reflections.Reflections: Reflections took 217 ms to scan 3 urls, producing 134 keys and 291 values 
2024-03-29 17:45:02,396 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2024-03-29 17:45:02,402 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2024-03-29 17:45:02,999 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:45:03,189 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:45:03,488 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0.jar!/network-topology-default.xml]
2024-03-29 17:45:03,491 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
2024-03-29 17:45:03,564 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.dropwizard3.Dm3MetricRegistriesImpl
2024-03-29 17:45:03,735 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:4fd50358-f617-4fef-b43e-6e61c9cf84a5
2024-03-29 17:45:03,803 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2024-03-29 17:45:03,814 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-03-29 17:45:03,815 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2024-03-29 17:45:03,815 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-03-29 17:45:03,816 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2024-03-29 17:45:03,816 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2024-03-29 17:45:03,816 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2024-03-29 17:45:03,816 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2024-03-29 17:45:03,817 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:45:03,818 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2024-03-29 17:45:03,818 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2024-03-29 17:45:03,826 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2024-03-29 17:45:03,829 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-03-29 17:45:03,829 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-03-29 17:45:03,980 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2024-03-29 17:45:03,982 [main] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-29 17:45:03,983 [main] INFO server.RaftServerConfigKeys: raft.server.close.threshold = 60s (default)
2024-03-29 17:45:03,983 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-29 17:45:03,987 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2024-03-29 17:45:03,988 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2024-03-29 17:45:03,988 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2024-03-29 17:45:03,992 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServer: 4fd50358-f617-4fef-b43e-6e61c9cf84a5: found a subdirectory /data/metadata/scm-ha/e4179187-75bc-4062-bff5-3543f8e510a5
2024-03-29 17:45:03,999 [main] INFO server.RaftServer: 4fd50358-f617-4fef-b43e-6e61c9cf84a5: addNew group-3543F8E510A5:[] returns group-3543F8E510A5:java.util.concurrent.CompletableFuture@fd9ebde[Not completed]
2024-03-29 17:45:04,018 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServer$Division: 4fd50358-f617-4fef-b43e-6e61c9cf84a5: new RaftServerImpl for group-3543F8E510A5:[] with SCMStateMachine:uninitialized
2024-03-29 17:45:04,019 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2024-03-29 17:45:04,020 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-29 17:45:04,020 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2024-03-29 17:45:04,020 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2024-03-29 17:45:04,020 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-29 17:45:04,021 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.member.majority-add = false (default)
2024-03-29 17:45:04,021 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-29 17:45:04,028 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServer$Division: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-29 17:45:04,033 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2024-03-29 17:45:04,036 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2024-03-29 17:45:04,039 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2024-03-29 17:45:04,040 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-29 17:45:04,044 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2024-03-29 17:45:04,045 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-29 17:45:04,148 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2024-03-29 17:45:04,150 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-29 17:45:04,150 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2024-03-29 17:45:04,151 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2024-03-29 17:45:04,151 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2024-03-29 17:45:04,151 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2024-03-29 17:45:04,162 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
2024-03-29 17:45:04,162 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2024-03-29 17:45:04,162 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
2024-03-29 17:45:04,181 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-03-29 17:45:04,247 [main] INFO ha.SequenceIdGenerator: upgrade localId to 113750153625600000
2024-03-29 17:45:04,248 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
2024-03-29 17:45:04,261 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
2024-03-29 17:45:04,264 [main] INFO ha.SequenceIdGenerator: upgrade CertificateId to 2
2024-03-29 17:45:04,266 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
2024-03-29 17:45:04,333 [main] INFO node.SCMNodeManager: Entering startup safe mode.
2024-03-29 17:45:04,352 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2024-03-29 17:45:04,357 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2024-03-29 17:45:04,382 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
2024-03-29 17:45:04,394 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2024-03-29 17:45:04,394 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2024-03-29 17:45:04,399 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
2024-03-29 17:45:04,399 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
2024-03-29 17:45:04,402 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
2024-03-29 17:45:04,402 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
2024-03-29 17:45:04,408 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
2024-03-29 17:45:04,411 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
2024-03-29 17:45:04,447 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-03-29 17:45:04,448 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-03-29 17:45:04,461 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
2024-03-29 17:45:04,550 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
2024-03-29 17:45:04,553 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
2024-03-29 17:45:04,572 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.hadoop.hdds.utils.MetricsUtil (file:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0.jar) to method java.lang.Class.annotationData()
WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.hdds.utils.MetricsUtil
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
2024-03-29 17:45:04,586 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
2024-03-29 17:45:04,588 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:45:04,591 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2024-03-29 17:45:04,645 [main] INFO server.StorageContainerManager: SCM start with adminUsers: [hadoop]
2024-03-29 17:45:05,210 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2024-03-29 17:45:05,227 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-29 17:45:05,254 [main] INFO ipc.Server: Listener at 0.0.0.0:9861
2024-03-29 17:45:05,256 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
2024-03-29 17:45:05,296 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2024-03-29 17:45:05,299 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-29 17:45:05,299 [main] INFO ipc.Server: Listener at 0.0.0.0:9863
2024-03-29 17:45:05,300 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
2024-03-29 17:45:05,318 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2024-03-29 17:45:05,323 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-29 17:45:05,324 [main] INFO ipc.Server: Listener at 0.0.0.0:9860
2024-03-29 17:45:05,324 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
2024-03-29 17:45:05,357 [main] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
2024-03-29 17:45:05,358 [main] INFO server.StorageContainerManager: 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB
Number of Iterations                               10
Time Limit for Single Container's Movement         65min
Time Limit for Single Container's Replication      50min
Interval between each Iteration                    70min
Whether to Enable Network Topology                 false
Whether to Trigger Refresh Datanode Usage Info     false
Container IDs to Exclude from Balancing            None
Datanodes Specified to be Balanced                 None
Datanodes Excluded from Balancing                  None

2024-03-29 17:45:05,358 [main] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2024-03-29 17:45:05,362 [main] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
2024-03-29 17:45:05,375 [main] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
2024-03-29 17:45:05,380 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-29 17:45:05,381 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-29 17:45:05,381 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2024-03-29 17:45:05,410 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/e4179187-75bc-4062-bff5-3543f8e510a5/in_use.lock acquired by nodename 7@03bbc0f826a7
2024-03-29 17:45:05,422 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=4fd50358-f617-4fef-b43e-6e61c9cf84a5} from /data/metadata/scm-ha/e4179187-75bc-4062-bff5-3543f8e510a5/current/raft-meta
2024-03-29 17:45:05,465 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServer$Division: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5: set configuration 0: peers:[4fd50358-f617-4fef-b43e-6e61c9cf84a5|03bbc0f826a7:9894]|listeners:[], old=null
2024-03-29 17:45:05,469 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2024-03-29 17:45:05,480 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2024-03-29 17:45:05,481 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:45:05,482 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-29 17:45:05,482 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-29 17:45:05,498 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2024-03-29 17:45:05,503 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-29 17:45:05,504 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-29 17:45:05,504 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:45:05,506 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO util.AwaitToRun: Thread[4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-cacheEviction-AwaitToRun,5,main] started
2024-03-29 17:45:05,563 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/e4179187-75bc-4062-bff5-3543f8e510a5
2024-03-29 17:45:05,563 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2024-03-29 17:45:05,564 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2024-03-29 17:45:05,566 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2024-03-29 17:45:05,566 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2024-03-29 17:45:05,567 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2024-03-29 17:45:05,567 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2024-03-29 17:45:05,567 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-29 17:45:05,570 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2024-03-29 17:45:05,572 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554440 (custom)
2024-03-29 17:45:05,579 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:45:05,579 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2024-03-29 17:45:05,580 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2024-03-29 17:45:05,580 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2024-03-29 17:45:05,602 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServer$Division: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5: set configuration 0: peers:[4fd50358-f617-4fef-b43e-6e61c9cf84a5|03bbc0f826a7:9894]|listeners:[], old=null
2024-03-29 17:45:05,602 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/e4179187-75bc-4062-bff5-3543f8e510a5/current/log_inprogress_0
2024-03-29 17:45:05,604 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-29 17:45:05,615 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO segmented.BufferedWriteChannel: open log_inprogress_0 (append) at position 78
2024-03-29 17:45:05,616 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServer$Division: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5: start as a follower, conf=0: peers:[4fd50358-f617-4fef-b43e-6e61c9cf84a5|03bbc0f826a7:9894]|listeners:[], old=null
2024-03-29 17:45:05,616 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServer$Division: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5: changes role from      null to FOLLOWER at term 1 for startAsFollower
2024-03-29 17:45:05,617 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO impl.RoleInfo: 4fd50358-f617-4fef-b43e-6e61c9cf84a5: start 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-FollowerState
2024-03-29 17:45:05,618 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3543F8E510A5,id=4fd50358-f617-4fef-b43e-6e61c9cf84a5
2024-03-29 17:45:05,620 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-29 17:45:05,620 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-29 17:45:05,620 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2024-03-29 17:45:05,620 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2024-03-29 17:45:05,621 [4fd50358-f617-4fef-b43e-6e61c9cf84a5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-29 17:45:05,622 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2024-03-29 17:45:05,622 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-29 17:45:05,625 [main] INFO server.RaftServer: 4fd50358-f617-4fef-b43e-6e61c9cf84a5: start RPC server
2024-03-29 17:45:05,657 [main] INFO server.GrpcService: 4fd50358-f617-4fef-b43e-6e61c9cf84a5: GrpcService started, listening on 9894
2024-03-29 17:45:05,658 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-4fd50358-f617-4fef-b43e-6e61c9cf84a5: Started
2024-03-29 17:45:05,664 [main] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [4fd50358-f617-4fef-b43e-6e61c9cf84a5|03bbc0f826a7:9894]
2024-03-29 17:45:05,664 [main] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
2024-03-29 17:45:05,666 [main] INFO SCMHATransactionMonitor: Starting SCMHATransactionMonitor Service.
2024-03-29 17:45:05,666 [main] INFO ha.SCMServiceManager: Registering service SCMHATransactionMonitor.
2024-03-29 17:45:05,666 [main] INFO SCMHATransactionMonitor: SCMHATransactionMonitor Service is already running, skip start.
2024-03-29 17:45:05,741 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2024-03-29 17:45:05,754 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-03-29 17:45:05,754 [main] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
2024-03-29 17:45:06,000 [main] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
2024-03-29 17:45:06,001 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-03-29 17:45:06,002 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
2024-03-29 17:45:06,071 [main] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
2024-03-29 17:45:06,071 [main] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
2024-03-29 17:45:06,075 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-03-29 17:45:06,078 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
2024-03-29 17:45:06,151 [main] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
2024-03-29 17:45:06,151 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-29 17:45:06,188 [main] INFO util.log: Logging initialized @6725ms to org.eclipse.jetty.util.log.Slf4jLog
2024-03-29 17:45:06,353 [main] WARN server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /opt/hadoop/hadoop-http-auth-signature-secret
2024-03-29 17:45:06,358 [main] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
2024-03-29 17:45:06,367 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-29 17:45:06,369 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2024-03-29 17:45:06,370 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-29 17:45:06,370 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-29 17:45:06,413 [main] INFO http.BaseHttpServer: HTTP server of scm uses base directory /data/metadata/webserver
2024-03-29 17:45:06,415 [main] INFO http.HttpServer2: Jetty bound to port 9876
2024-03-29 17:45:06,416 [main] INFO server.Server: jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 11.0.19+7-LTS
2024-03-29 17:45:06,454 [main] INFO server.session: DefaultSessionIdManager workerName=node0
2024-03-29 17:45:06,454 [main] INFO server.session: No SessionScavenger set, using defaults
2024-03-29 17:45:06,455 [main] INFO server.session: node0 Scavenging every 600000ms
2024-03-29 17:45:06,466 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@20b54cfe{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
2024-03-29 17:45:06,468 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7185e611{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0.jar!/webapps/static,AVAILABLE}
2024-03-29 17:45:06,727 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@6ba060af{scm,/,file:///data/metadata/webserver/jetty-0_0_0_0-9876-hdds-server-scm-1_4_0_jar-_-any-2073704642121732743/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0.jar!/webapps/scm}
2024-03-29 17:45:06,737 [main] INFO server.AbstractConnector: Started ServerConnector@75839695{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
2024-03-29 17:45:06,737 [main] INFO server.Server: Started @7277ms
2024-03-29 17:45:06,741 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
2024-03-29 17:45:06,741 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
2024-03-29 17:45:06,743 [main] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
2024-03-29 17:45:10,812 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-FollowerState] INFO impl.FollowerState: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5194859214ns, electionTimeout:5189ms
2024-03-29 17:45:10,812 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-FollowerState] INFO impl.RoleInfo: 4fd50358-f617-4fef-b43e-6e61c9cf84a5: shutdown 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-FollowerState
2024-03-29 17:45:10,812 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-FollowerState] INFO server.RaftServer$Division: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2024-03-29 17:45:10,815 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
2024-03-29 17:45:10,815 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-FollowerState] INFO impl.RoleInfo: 4fd50358-f617-4fef-b43e-6e61c9cf84a5: start 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1
2024-03-29 17:45:10,817 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO impl.LeaderElection: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 1 for 0: peers:[4fd50358-f617-4fef-b43e-6e61c9cf84a5|03bbc0f826a7:9894]|listeners:[], old=null
2024-03-29 17:45:10,818 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO impl.LeaderElection: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1 PRE_VOTE round 0: result PASSED (term=1)
2024-03-29 17:45:10,830 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO impl.LeaderElection: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: peers:[4fd50358-f617-4fef-b43e-6e61c9cf84a5|03bbc0f826a7:9894]|listeners:[], old=null
2024-03-29 17:45:10,830 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO impl.LeaderElection: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1 ELECTION round 0: result PASSED (term=2)
2024-03-29 17:45:10,830 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO impl.RoleInfo: 4fd50358-f617-4fef-b43e-6e61c9cf84a5: shutdown 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1
2024-03-29 17:45:10,831 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServer$Division: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2024-03-29 17:45:10,835 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2024-03-29 17:45:10,838 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2024-03-29 17:45:10,839 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2024-03-29 17:45:10,841 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2024-03-29 17:45:10,841 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2024-03-29 17:45:10,842 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2024-03-29 17:45:10,846 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.enabled = false (default)
2024-03-29 17:45:10,848 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-29 17:45:10,848 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2024-03-29 17:45:10,848 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2024-03-29 17:45:10,848 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-29 17:45:10,850 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO impl.RoleInfo: 4fd50358-f617-4fef-b43e-6e61c9cf84a5: start 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderStateImpl
2024-03-29 17:45:10,850 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServer$Division: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5: set firstElectionSinceStartup to false for becomeLeader
2024-03-29 17:45:10,851 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
2024-03-29 17:45:10,851 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
2024-03-29 17:45:10,861 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServer$Division: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5: change Leader from null to 4fd50358-f617-4fef-b43e-6e61c9cf84a5 at term 2 for becomeLeader, leader elected after 6816ms
2024-03-29 17:45:10,868 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2024-03-29 17:45:10,870 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/e4179187-75bc-4062-bff5-3543f8e510a5/current/log_inprogress_0 to /data/metadata/scm-ha/e4179187-75bc-4062-bff5-3543f8e510a5/current/log_0-0
2024-03-29 17:45:10,874 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-SegmentedRaftLogWorker] INFO segmented.BufferedWriteChannel: open log_inprogress_1 at position 0
2024-03-29 17:45:10,880 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-LeaderElection1] INFO server.RaftServer$Division: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5: set configuration 1: peers:[4fd50358-f617-4fef-b43e-6e61c9cf84a5|03bbc0f826a7:9894]|listeners:[], old=null
2024-03-29 17:45:10,882 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/e4179187-75bc-4062-bff5-3543f8e510a5/current/log_inprogress_1
2024-03-29 17:45:10,892 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-StateMachineUpdater] INFO server.RaftServer$Division: leader is ready since appliedIndex == 1 >= startIndex == 1
2024-03-29 17:45:10,892 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
2024-03-29 17:45:10,892 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
2024-03-29 17:45:10,893 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:45:10,894 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
2024-03-29 17:45:10,894 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2024-03-29 17:45:10,894 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
2024-03-29 17:45:10,896 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-03-29 17:45:10,896 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
2024-03-29 17:45:10,989 [IPC Server handler 95 on default port 9861] WARN ipc.Server: IPC Server handler 95 on default port 9861, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from xcompat_datanode_3.xcompat_default:44762 / 172.24.0.11:44762: output error
2024-03-29 17:45:10,990 [IPC Server handler 95 on default port 9861] INFO ipc.Server: IPC Server handler 95 on default port 9861 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3743)
	at org.apache.hadoop.ipc.Server.access$1800(Server.java:148)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1722)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1792)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2919)
	at org.apache.hadoop.ipc.Server$Connection.access$400(Server.java:1864)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1176)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:954)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:940)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1111)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-03-29 17:45:10,992 [IPC Server handler 3 on default port 9861] WARN ipc.Server: IPC Server handler 3 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from xcompat_datanode_2.xcompat_default:55426 / 172.24.0.7:55426: output error
2024-03-29 17:45:10,993 [IPC Server handler 3 on default port 9861] INFO ipc.Server: IPC Server handler 3 on default port 9861 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:180)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:452)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3743)
	at org.apache.hadoop.ipc.Server.access$1800(Server.java:148)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1722)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1792)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2919)
	at org.apache.hadoop.ipc.Server$Connection.access$400(Server.java:1864)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1176)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:954)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:940)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1111)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-03-29 17:45:11,644 [IPC Server handler 5 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/0ae9ff18-ee67-47ef-97c6-95a186ff9c4b
2024-03-29 17:45:11,647 [IPC Server handler 5 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 0ae9ff18-ee67-47ef-97c6-95a186ff9c4b{ip: 172.24.0.7, host: xcompat_datanode_2.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:45:11,650 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:45:11,652 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
2024-03-29 17:45:11,654 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2024-03-29 17:45:11,659 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=3ec3dfc1-5532-4d89-8986-7167ae9c7870 to datanode:0ae9ff18-ee67-47ef-97c6-95a186ff9c4b
2024-03-29 17:45:11,684 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:45:11,721 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:45:11,729 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 3ec3dfc1-5532-4d89-8986-7167ae9c7870, Nodes: 0ae9ff18-ee67-47ef-97c6-95a186ff9c4b(xcompat_datanode_2.xcompat_default/172.24.0.7), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:45:11.658545Z[UTC]]
2024-03-29 17:45:12,031 [IPC Server handler 5 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/7408b79d-005a-4738-96d0-624852937dbe
2024-03-29 17:45:12,032 [IPC Server handler 5 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 7408b79d-005a-4738-96d0-624852937dbe{ip: 172.24.0.10, host: xcompat_datanode_1.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:45:12,036 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:45:12,036 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
2024-03-29 17:45:12,038 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b5f43ccd-fb71-47c1-a8af-2f482b06ff9e to datanode:7408b79d-005a-4738-96d0-624852937dbe
2024-03-29 17:45:12,044 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:45:12,044 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: b5f43ccd-fb71-47c1-a8af-2f482b06ff9e, Nodes: 7408b79d-005a-4738-96d0-624852937dbe(xcompat_datanode_1.xcompat_default/172.24.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:45:12.038212Z[UTC]]
2024-03-29 17:45:12,284 [IPC Server handler 1 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/0079dda5-1d86-4268-b93f-d5e252550dd2
2024-03-29 17:45:12,285 [IPC Server handler 1 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 0079dda5-1d86-4268-b93f-d5e252550dd2{ip: 172.24.0.11, host: xcompat_datanode_3.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:45:12,285 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
2024-03-29 17:45:12,285 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
2024-03-29 17:45:12,286 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
2024-03-29 17:45:12,286 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2024-03-29 17:45:12,286 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:45:12,286 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:45:12,288 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=fbcf97d7-1e50-4e1b-bf82-091e4749396c to datanode:0079dda5-1d86-4268-b93f-d5e252550dd2
2024-03-29 17:45:12,291 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:45:12,292 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: fbcf97d7-1e50-4e1b-bf82-091e4749396c, Nodes: 0079dda5-1d86-4268-b93f-d5e252550dd2(xcompat_datanode_3.xcompat_default/172.24.0.11), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:45:12.288824Z[UTC]]
2024-03-29 17:45:12,300 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=11e2b16c-18c0-4019-a23a-dea13fb811e5 to datanode:0ae9ff18-ee67-47ef-97c6-95a186ff9c4b
2024-03-29 17:45:12,300 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=11e2b16c-18c0-4019-a23a-dea13fb811e5 to datanode:0079dda5-1d86-4268-b93f-d5e252550dd2
2024-03-29 17:45:12,300 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=11e2b16c-18c0-4019-a23a-dea13fb811e5 to datanode:7408b79d-005a-4738-96d0-624852937dbe
2024-03-29 17:45:12,304 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:45:12,305 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 11e2b16c-18c0-4019-a23a-dea13fb811e5, Nodes: 0ae9ff18-ee67-47ef-97c6-95a186ff9c4b(xcompat_datanode_2.xcompat_default/172.24.0.7)0079dda5-1d86-4268-b93f-d5e252550dd2(xcompat_datanode_3.xcompat_default/172.24.0.11)7408b79d-005a-4738-96d0-624852937dbe(xcompat_datanode_1.xcompat_default/172.24.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:45:12.300139Z[UTC]]
2024-03-29 17:45:12,307 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=2ac5fb11-61ca-44d7-8bbf-67b123a685ce to datanode:0ae9ff18-ee67-47ef-97c6-95a186ff9c4b
2024-03-29 17:45:12,307 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=2ac5fb11-61ca-44d7-8bbf-67b123a685ce to datanode:0079dda5-1d86-4268-b93f-d5e252550dd2
2024-03-29 17:45:12,307 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=2ac5fb11-61ca-44d7-8bbf-67b123a685ce to datanode:7408b79d-005a-4738-96d0-624852937dbe
2024-03-29 17:45:12,310 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:45:12,311 [RatisPipelineUtilsThread-0] INFO pipeline.PipelineManagerImpl: Pipeline: PipelineID=2ac5fb11-61ca-44d7-8bbf-67b123a685ce contains same datanodes as previous pipelines: PipelineID=11e2b16c-18c0-4019-a23a-dea13fb811e5 nodeIds: 0ae9ff18-ee67-47ef-97c6-95a186ff9c4b, 0079dda5-1d86-4268-b93f-d5e252550dd2, 7408b79d-005a-4738-96d0-624852937dbe
2024-03-29 17:45:12,311 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 2ac5fb11-61ca-44d7-8bbf-67b123a685ce, Nodes: 0ae9ff18-ee67-47ef-97c6-95a186ff9c4b(xcompat_datanode_2.xcompat_default/172.24.0.7)0079dda5-1d86-4268-b93f-d5e252550dd2(xcompat_datanode_3.xcompat_default/172.24.0.11)7408b79d-005a-4738-96d0-624852937dbe(xcompat_datanode_1.xcompat_default/172.24.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:45:12.307140Z[UTC]]
2024-03-29 17:45:14,770 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:45:14,771 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=3ec3dfc1-5532-4d89-8986-7167ae9c7870
2024-03-29 17:45:14,773 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:45:14,920 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:45:15,342 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:45:15,347 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=b5f43ccd-fb71-47c1-a8af-2f482b06ff9e
2024-03-29 17:45:15,348 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:45:15,563 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:45:15,768 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:45:15,768 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=fbcf97d7-1e50-4e1b-bf82-091e4749396c
2024-03-29 17:45:15,769 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:45:16,026 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:45:16,483 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:45:16,632 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:45:16,698 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:45:19,994 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:45:20,551 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:45:20,803 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
2024-03-29 17:45:20,803 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=11e2b16c-18c0-4019-a23a-dea13fb811e5
2024-03-29 17:45:20,803 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2024-03-29 17:45:20,803 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
2024-03-29 17:45:20,803 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
2024-03-29 17:45:20,803 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
2024-03-29 17:45:20,803 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2024-03-29 17:45:20,804 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
2024-03-29 17:45:20,804 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2024-03-29 17:45:20,805 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
2024-03-29 17:45:20,807 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2024-03-29 17:45:20,807 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO SCMHATransactionMonitor: Service SCMHATransactionMonitor transitions to RUNNING.
2024-03-29 17:45:21,806 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=2ac5fb11-61ca-44d7-8bbf-67b123a685ce
2024-03-29 17:45:26,180 [IPC Server handler 0 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
2024-03-29 17:45:26,204 [4fd50358-f617-4fef-b43e-6e61c9cf84a5@group-3543F8E510A5-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 113750153625600000.
2024-03-29 17:45:26,207 [IPC Server handler 0 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 113750153625600000 to 113750153625601000.
2024-03-29 17:45:47,069 [IPC Server handler 6 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.24.0.3
2024-03-29 17:45:53,961 [IPC Server handler 6 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.24.0.3
2024-03-29 17:46:11,522 [IPC Server handler 7 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.24.0.12
2024-03-29 17:46:17,192 [IPC Server handler 0 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.24.0.12
2024-03-29 17:46:22,580 [IPC Server handler 9 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.24.0.12
2024-03-29 17:46:28,027 [IPC Server handler 10 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.24.0.12
2024-03-29 17:46:34,207 [IPC Server handler 1 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.24.0.3
2024-03-29 17:46:41,534 [IPC Server handler 9 on default port 9863] WARN node.SCMNodeManager: Cannot find node for address 172.24.0.3
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
2024-03-29 17:47:07,313 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = 5d1473b286f4/172.25.0.13
STARTUP_MSG:   args = [--init]
STARTUP_MSG:   version = 1.5.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.14.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.15.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.16.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.16.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.16.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.5.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.0.1.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk18on-1.77.jar:/opt/hadoop/share/ozone/lib/bcutil-jdk18on-1.77.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.8.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.15.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.8.1.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.22.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.26.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.9.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.9.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.12.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-1.2.2.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.14.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/commons-net-3.10.0.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/ozone/lib/re2j-1.7.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.2.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.37.2.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.10.5.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.25.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-2.0.12.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.10.1.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.16.0.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.4.0.jar:/opt/hadoop/share/ozone/lib/jheaps-0.11.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.4.0.jar:/opt/hadoop/share/ozone/lib/jgraphx-3.9.8.1.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk18on-1.77.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/slf4j-api-2.0.12.jar:/opt/hadoop/share/ozone/lib/commons-text-1.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/okhttp-4.12.0.jar:/opt/hadoop/share/ozone/lib/okio-3.6.0.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.6.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.9.22.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.9.22.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.9.22.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.16.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.5.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/cb5d51983d044734a714f32a32255dc9604eb701 ; compiled by 'runner' on 2024-03-29T16:59Z
STARTUP_MSG:   java = 17.0.2
STARTUP_MSG:   conf = {hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=false, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.chunk.write.sync=false, hdds.container.close.threshold=0.9f, hdds.container.ipc.port=9859, hdds.container.ipc.random.port=false, hdds.container.ratis.admin.port=9857, hdds.container.ratis.datastream.enabled=false, hdds.container.ratis.datastream.port=9855, hdds.container.ratis.datastream.random.port=false, hdds.container.ratis.enabled=false, hdds.container.ratis.ipc.port=9858, hdds.container.ratis.ipc.random.port=false, hdds.container.ratis.leader.pending.bytes.limit=1GB, hdds.container.ratis.log.appender.queue.byte-limit=32MB, hdds.container.ratis.log.appender.queue.num-elements=1, hdds.container.ratis.log.purge.gap=1000000, hdds.container.ratis.log.queue.byte-limit=4GB, hdds.container.ratis.log.queue.num-elements=1024, hdds.container.ratis.num.container.op.executors=10, hdds.container.ratis.num.write.chunk.threads.per.volume=10, hdds.container.ratis.replication.level=MAJORITY, hdds.container.ratis.rpc.type=GRPC, hdds.container.ratis.segment.preallocated.size=4MB, hdds.container.ratis.segment.size=64MB, hdds.container.ratis.server.port=9856, hdds.container.ratis.statemachine.max.pending.apply-transactions=10000, hdds.container.ratis.statemachinedata.sync.timeout=10s, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=true, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=false, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.datanode.http.auth.type=simple, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.replication.zerocopy.enabled=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.slow.op.warning.threshold=500ms, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=false, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.leader.election.minimum.timeout.duration=5s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.ratis.server.retry-cache.timeout.duration=600000ms, hdds.ratis.snapshot.threshold=10000, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.scm.http.auth.type=simple, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/SCM.keytab, hdds.scm.kerberos.principal=SCM/_HOST@REALM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=3, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneAccessAuthorizer, ozone.acl.enabled=false, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.reconstruct.stripe.write.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.max.retries=3, ozone.client.read.retry.interval=1, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.default.bucket.layout=LEGACY, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.http.policy=HTTP_ONLY, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=om, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=om:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.om.http.auth.type=simple, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.kerberos.keytab.file=/etc/security/keytabs/OM.keytab, ozone.om.kerberos.principal=OM/_HOST@REALM, ozone.om.kerberos.principal.pattern=*, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.network.topology.refresh.duration=1h, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=true, ozone.path.deleting.limit.per.task=6000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.recon.http.auth.type=simple, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=10m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.s3g.http.auth.type=simple, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/_HOST@REALM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.metrics.percentiles.intervals.seconds=60, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=false, ozone.s3g.volume.name=s3v, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.handler.count.key=100, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.handler.count.key=100, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=150s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.handler.count.key=100, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.names=scm, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=120s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=false, ozone.security.http.kerberos.enabled=false, ozone.security.reconfigure.protocol.acl=*, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.xceiver.client.metrics.percentiles.intervals.seconds=60, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, recon.om.snapshot.task.interval.delay=1m, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2024-03-29 17:47:07,407 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2024-03-29 17:47:08,020 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:47:09,940 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2024-03-29 17:47:10,002 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2024-03-29 17:47:10,966 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2024-03-29 17:47:11,384 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-03-29 17:47:11,392 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2024-03-29 17:47:11,413 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-03-29 17:47:11,413 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2024-03-29 17:47:11,419 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2024-03-29 17:47:11,423 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2024-03-29 17:47:11,425 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2024-03-29 17:47:11,428 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:47:11,465 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2024-03-29 17:47:11,466 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2024-03-29 17:47:11,474 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2024-03-29 17:47:11,492 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-03-29 17:47:11,536 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-03-29 17:47:12,719 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2024-03-29 17:47:12,735 [main] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-29 17:47:12,735 [main] INFO server.RaftServerConfigKeys: raft.server.close.threshold = 60s (default)
2024-03-29 17:47:12,739 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-29 17:47:12,760 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2024-03-29 17:47:12,761 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2024-03-29 17:47:12,781 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2024-03-29 17:47:12,832 [main] INFO server.RaftServer: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: addNew group-E82F96A4C8AD:[8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf|5d1473b286f4:9894] returns group-E82F96A4C8AD:java.util.concurrent.CompletableFuture@1cb7936c[Not completed]
2024-03-29 17:47:12,879 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServer$Division: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: new RaftServerImpl for group-E82F96A4C8AD:[8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf|5d1473b286f4:9894] with SCMStateMachine:uninitialized
2024-03-29 17:47:12,925 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2024-03-29 17:47:12,925 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-29 17:47:12,926 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2024-03-29 17:47:12,926 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2024-03-29 17:47:12,926 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-29 17:47:12,927 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.member.majority-add = false (default)
2024-03-29 17:47:12,935 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-29 17:47:12,960 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServer$Division: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD: ConfigurationManager, init=-1: peers:[8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf|5d1473b286f4:9894]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-29 17:47:12,989 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2024-03-29 17:47:12,992 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2024-03-29 17:47:13,007 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2024-03-29 17:47:13,015 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-29 17:47:13,027 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2024-03-29 17:47:13,040 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-29 17:47:13,050 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.dropwizard3.Dm3MetricRegistriesImpl
2024-03-29 17:47:13,833 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2024-03-29 17:47:13,909 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-29 17:47:13,911 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2024-03-29 17:47:13,915 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2024-03-29 17:47:13,927 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2024-03-29 17:47:13,936 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2024-03-29 17:47:13,939 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-29 17:47:13,947 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-29 17:47:13,948 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2024-03-29 17:47:13,960 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/f1e2ddde-13b8-4857-81d8-e82f96a4c8ad does not exist. Creating ...
2024-03-29 17:47:13,974 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/f1e2ddde-13b8-4857-81d8-e82f96a4c8ad/in_use.lock acquired by nodename 13@5d1473b286f4
2024-03-29 17:47:14,018 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/f1e2ddde-13b8-4857-81d8-e82f96a4c8ad has been successfully formatted.
2024-03-29 17:47:14,019 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] WARN util.FileUtils: Failed to Files.newInputStream /data/metadata/scm-ha/f1e2ddde-13b8-4857-81d8-e82f96a4c8ad/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /data/metadata/scm-ha/f1e2ddde-13b8-4857-81d8-e82f96a4c8ad/current/raft-meta.conf
2024-03-29 17:47:14,025 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2024-03-29 17:47:14,042 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2024-03-29 17:47:14,042 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:47:14,043 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-29 17:47:14,043 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-29 17:47:14,063 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2024-03-29 17:47:14,079 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-29 17:47:14,079 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-29 17:47:14,079 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:47:14,083 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO util.AwaitToRun: Thread[8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-cacheEviction-AwaitToRun,5,main] started
2024-03-29 17:47:14,086 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/f1e2ddde-13b8-4857-81d8-e82f96a4c8ad
2024-03-29 17:47:14,088 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2024-03-29 17:47:14,088 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2024-03-29 17:47:14,089 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2024-03-29 17:47:14,091 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2024-03-29 17:47:14,093 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2024-03-29 17:47:14,093 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2024-03-29 17:47:14,093 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-29 17:47:14,096 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2024-03-29 17:47:14,112 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554440 (custom)
2024-03-29 17:47:14,129 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:47:14,153 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2024-03-29 17:47:14,160 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2024-03-29 17:47:14,163 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2024-03-29 17:47:14,172 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-29 17:47:14,172 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-29 17:47:14,200 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServer$Division: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD: start as a follower, conf=-1: peers:[8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf|5d1473b286f4:9894]|listeners:[], old=null
2024-03-29 17:47:14,200 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServer$Division: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-29 17:47:14,201 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO impl.RoleInfo: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: start 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-FollowerState
2024-03-29 17:47:14,202 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2024-03-29 17:47:14,207 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-29 17:47:14,212 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E82F96A4C8AD,id=8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf
2024-03-29 17:47:14,242 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-29 17:47:14,251 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-29 17:47:14,252 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2024-03-29 17:47:14,252 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2024-03-29 17:47:14,253 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-29 17:47:14,265 [main] INFO server.RaftServer: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: start RPC server
2024-03-29 17:47:14,406 [main] INFO server.GrpcService: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: GrpcService started, listening on 9894
2024-03-29 17:47:14,420 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: Started
2024-03-29 17:47:19,294 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-FollowerState] INFO impl.FollowerState: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5092754653ns, electionTimeout:5085ms
2024-03-29 17:47:19,294 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-FollowerState] INFO impl.RoleInfo: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: shutdown 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-FollowerState
2024-03-29 17:47:19,294 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-FollowerState] INFO server.RaftServer$Division: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-29 17:47:19,296 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
2024-03-29 17:47:19,296 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-FollowerState] INFO impl.RoleInfo: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: start 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1
2024-03-29 17:47:19,302 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO impl.LeaderElection: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf|5d1473b286f4:9894]|listeners:[], old=null
2024-03-29 17:47:19,302 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO impl.LeaderElection: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1 PRE_VOTE round 0: result PASSED (term=0)
2024-03-29 17:47:19,305 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO impl.LeaderElection: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf|5d1473b286f4:9894]|listeners:[], old=null
2024-03-29 17:47:19,306 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO impl.LeaderElection: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1 ELECTION round 0: result PASSED (term=1)
2024-03-29 17:47:19,306 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO impl.RoleInfo: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: shutdown 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1
2024-03-29 17:47:19,306 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServer$Division: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-29 17:47:19,310 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2024-03-29 17:47:19,312 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2024-03-29 17:47:19,313 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2024-03-29 17:47:19,329 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2024-03-29 17:47:19,329 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2024-03-29 17:47:19,330 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2024-03-29 17:47:19,348 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.enabled = false (default)
2024-03-29 17:47:19,357 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-29 17:47:19,363 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2024-03-29 17:47:19,364 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2024-03-29 17:47:19,364 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-29 17:47:19,372 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO impl.RoleInfo: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: start 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderStateImpl
2024-03-29 17:47:19,375 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServer$Division: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD: set firstElectionSinceStartup to false for becomeLeader
2024-03-29 17:47:19,375 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServer$Division: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD: change Leader from null to 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf at term 1 for becomeLeader, leader elected after 6386ms
2024-03-29 17:47:19,471 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-29 17:47:19,644 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-SegmentedRaftLogWorker] INFO segmented.BufferedWriteChannel: open log_inprogress_0 at position 0
2024-03-29 17:47:19,647 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServer$Division: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD: set configuration 0: peers:[8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf|5d1473b286f4:9894]|listeners:[], old=null
2024-03-29 17:47:19,665 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/f1e2ddde-13b8-4857-81d8-e82f96a4c8ad/current/log_inprogress_0
2024-03-29 17:47:19,769 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater] INFO server.RaftServer$Division: leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-29 17:47:20,421 [main] INFO server.RaftServer: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: close
2024-03-29 17:47:20,423 [main] INFO server.GrpcService: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: shutdown server GrpcServerProtocolService now
2024-03-29 17:47:20,425 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServer$Division: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD: shutdown
2024-03-29 17:47:20,425 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-E82F96A4C8AD,id=8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf
2024-03-29 17:47:20,426 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO impl.RoleInfo: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: shutdown 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderStateImpl
2024-03-29 17:47:20,437 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO impl.PendingRequests: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-PendingRequests: sendNotLeaderResponses
2024-03-29 17:47:20,458 [main] INFO server.GrpcService: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: shutdown server GrpcServerProtocolService successfully
2024-03-29 17:47:20,476 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater] INFO impl.StateMachineUpdater: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater: Took a snapshot at index 0
2024-03-29 17:47:20,477 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater] INFO impl.StateMachineUpdater: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-29 17:47:20,491 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO impl.StateMachineUpdater: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater: set stopIndex = 0
2024-03-29 17:47:20,499 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServer$Division: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD: applyIndex: 0
2024-03-29 17:47:20,504 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-cacheEviction-AwaitToRun] INFO util.AwaitToRun: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-29 17:47:20,776 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-SegmentedRaftLogWorker close()
2024-03-29 17:47:20,777 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: Stopped
2024-03-29 17:47:20,778 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:47:20,780 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-f1e2ddde-13b8-4857-81d8-e82f96a4c8ad; layoutVersion=7; scmId=8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf
2024-03-29 17:47:20,787 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at 5d1473b286f4/172.25.0.13
************************************************************/
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
2024-03-29 17:47:27,812 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = 5d1473b286f4/172.25.0.13
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.5.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.14.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.15.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.16.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.16.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.16.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.5.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.0.1.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk18on-1.77.jar:/opt/hadoop/share/ozone/lib/bcutil-jdk18on-1.77.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.8.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.15.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.8.1.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.22.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.26.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.9.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.9.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.12.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-1.2.2.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.14.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/commons-net-3.10.0.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/ozone/lib/re2j-1.7.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.2.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.37.2.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.10.5.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.25.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-2.0.12.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.10.1.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.16.0.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.4.0.jar:/opt/hadoop/share/ozone/lib/jheaps-0.11.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.4.0.jar:/opt/hadoop/share/ozone/lib/jgraphx-3.9.8.1.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk18on-1.77.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/slf4j-api-2.0.12.jar:/opt/hadoop/share/ozone/lib/commons-text-1.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/okhttp-4.12.0.jar:/opt/hadoop/share/ozone/lib/okio-3.6.0.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.6.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.9.22.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.9.22.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.9.22.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.16.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.5.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/cb5d51983d044734a714f32a32255dc9604eb701 ; compiled by 'runner' on 2024-03-29T16:59Z
STARTUP_MSG:   java = 17.0.2
STARTUP_MSG:   conf = {hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=false, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.chunk.write.sync=false, hdds.container.close.threshold=0.9f, hdds.container.ipc.port=9859, hdds.container.ipc.random.port=false, hdds.container.ratis.admin.port=9857, hdds.container.ratis.datastream.enabled=false, hdds.container.ratis.datastream.port=9855, hdds.container.ratis.datastream.random.port=false, hdds.container.ratis.enabled=false, hdds.container.ratis.ipc.port=9858, hdds.container.ratis.ipc.random.port=false, hdds.container.ratis.leader.pending.bytes.limit=1GB, hdds.container.ratis.log.appender.queue.byte-limit=32MB, hdds.container.ratis.log.appender.queue.num-elements=1, hdds.container.ratis.log.purge.gap=1000000, hdds.container.ratis.log.queue.byte-limit=4GB, hdds.container.ratis.log.queue.num-elements=1024, hdds.container.ratis.num.container.op.executors=10, hdds.container.ratis.num.write.chunk.threads.per.volume=10, hdds.container.ratis.replication.level=MAJORITY, hdds.container.ratis.rpc.type=GRPC, hdds.container.ratis.segment.preallocated.size=4MB, hdds.container.ratis.segment.size=64MB, hdds.container.ratis.server.port=9856, hdds.container.ratis.statemachine.max.pending.apply-transactions=10000, hdds.container.ratis.statemachinedata.sync.timeout=10s, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=true, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=false, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.datanode.http.auth.type=simple, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.replication.zerocopy.enabled=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.slow.op.warning.threshold=500ms, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=false, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.leader.election.minimum.timeout.duration=5s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.ratis.server.retry-cache.timeout.duration=600000ms, hdds.ratis.snapshot.threshold=10000, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.scm.http.auth.type=simple, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/SCM.keytab, hdds.scm.kerberos.principal=SCM/_HOST@REALM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=3, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneAccessAuthorizer, ozone.acl.enabled=false, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.reconstruct.stripe.write.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.max.retries=3, ozone.client.read.retry.interval=1, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.default.bucket.layout=LEGACY, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.http.policy=HTTP_ONLY, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=om, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=om:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.om.http.auth.type=simple, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.kerberos.keytab.file=/etc/security/keytabs/OM.keytab, ozone.om.kerberos.principal=OM/_HOST@REALM, ozone.om.kerberos.principal.pattern=*, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.network.topology.refresh.duration=1h, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=true, ozone.path.deleting.limit.per.task=6000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.recon.http.auth.type=simple, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=10m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.s3g.http.auth.type=simple, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/_HOST@REALM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.metrics.percentiles.intervals.seconds=60, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=false, ozone.s3g.volume.name=s3v, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.handler.count.key=100, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.handler.count.key=100, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=150s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.handler.count.key=100, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.names=scm, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=120s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=false, ozone.security.http.kerberos.enabled=false, ozone.security.reconfigure.protocol.acl=*, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.xceiver.client.metrics.percentiles.intervals.seconds=60, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, recon.om.snapshot.task.interval.delay=1m, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2024-03-29 17:47:27,863 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2024-03-29 17:47:28,275 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:47:29,621 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2024-03-29 17:47:29,639 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2024-03-29 17:47:32,180 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:47:32,510 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:47:32,524 [main] INFO utils.LeakDetector: Starting leak detector thread ManagedRocksObject0.
2024-03-29 17:47:32,883 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.5.0-SNAPSHOT.jar!/network-topology-default.xml]
2024-03-29 17:47:32,884 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
2024-03-29 17:47:32,932 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.dropwizard3.Dm3MetricRegistriesImpl
2024-03-29 17:47:33,100 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf
2024-03-29 17:47:33,180 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2024-03-29 17:47:33,198 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-03-29 17:47:33,199 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2024-03-29 17:47:33,199 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-03-29 17:47:33,203 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2024-03-29 17:47:33,203 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2024-03-29 17:47:33,203 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2024-03-29 17:47:33,204 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2024-03-29 17:47:33,205 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:47:33,206 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2024-03-29 17:47:33,206 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2024-03-29 17:47:33,212 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2024-03-29 17:47:33,216 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-03-29 17:47:33,219 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-03-29 17:47:33,429 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2024-03-29 17:47:33,433 [main] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-29 17:47:33,433 [main] INFO server.RaftServerConfigKeys: raft.server.close.threshold = 60s (default)
2024-03-29 17:47:33,433 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-29 17:47:33,439 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2024-03-29 17:47:33,440 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2024-03-29 17:47:33,441 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2024-03-29 17:47:33,466 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServer: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: found a subdirectory /data/metadata/scm-ha/f1e2ddde-13b8-4857-81d8-e82f96a4c8ad
2024-03-29 17:47:33,494 [main] INFO server.RaftServer: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: addNew group-E82F96A4C8AD:[] returns group-E82F96A4C8AD:java.util.concurrent.CompletableFuture@73e776b7[Not completed]
2024-03-29 17:47:33,531 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServer$Division: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: new RaftServerImpl for group-E82F96A4C8AD:[] with SCMStateMachine:uninitialized
2024-03-29 17:47:33,533 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2024-03-29 17:47:33,533 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-29 17:47:33,533 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2024-03-29 17:47:33,533 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2024-03-29 17:47:33,533 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-29 17:47:33,534 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.member.majority-add = false (default)
2024-03-29 17:47:33,534 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-29 17:47:33,546 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServer$Division: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-29 17:47:33,564 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2024-03-29 17:47:33,567 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2024-03-29 17:47:33,571 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2024-03-29 17:47:33,571 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-29 17:47:33,574 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2024-03-29 17:47:33,575 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-29 17:47:33,757 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2024-03-29 17:47:33,760 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-29 17:47:33,761 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2024-03-29 17:47:33,761 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2024-03-29 17:47:33,764 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2024-03-29 17:47:33,770 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2024-03-29 17:47:33,772 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
2024-03-29 17:47:33,772 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2024-03-29 17:47:33,772 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
2024-03-29 17:47:33,822 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-03-29 17:47:33,985 [main] INFO ha.SequenceIdGenerator: upgrade localId to 113750153625600000
2024-03-29 17:47:33,989 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
2024-03-29 17:47:34,012 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
2024-03-29 17:47:34,036 [main] INFO ha.SequenceIdGenerator: upgrade CertificateId to 2
2024-03-29 17:47:34,039 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
2024-03-29 17:47:34,110 [main] INFO node.SCMNodeManager: Entering startup safe mode.
2024-03-29 17:47:34,133 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2024-03-29 17:47:34,138 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2024-03-29 17:47:34,150 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
2024-03-29 17:47:34,166 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2024-03-29 17:47:34,167 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2024-03-29 17:47:34,176 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
2024-03-29 17:47:34,177 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
2024-03-29 17:47:34,180 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
2024-03-29 17:47:34,182 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
2024-03-29 17:47:34,190 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
2024-03-29 17:47:34,210 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
2024-03-29 17:47:34,250 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-03-29 17:47:34,251 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-03-29 17:47:34,297 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
2024-03-29 17:47:34,427 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
2024-03-29 17:47:34,435 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
2024-03-29 17:47:34,444 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
2024-03-29 17:47:34,461 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
2024-03-29 17:47:34,472 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:47:34,476 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2024-03-29 17:47:34,612 [main] INFO server.StorageContainerManager: SCM start with adminUsers: [hadoop]
2024-03-29 17:47:35,280 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2024-03-29 17:47:35,308 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-29 17:47:35,341 [main] INFO ipc.Server: Listener at 0.0.0.0:9861
2024-03-29 17:47:35,343 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
2024-03-29 17:47:35,393 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2024-03-29 17:47:35,401 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-29 17:47:35,401 [main] INFO ipc.Server: Listener at 0.0.0.0:9863
2024-03-29 17:47:35,409 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
2024-03-29 17:47:35,470 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2024-03-29 17:47:35,483 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-29 17:47:35,484 [main] INFO ipc.Server: Listener at 0.0.0.0:9860
2024-03-29 17:47:35,492 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
2024-03-29 17:47:35,573 [main] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
2024-03-29 17:47:35,573 [main] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2024-03-29 17:47:35,576 [main] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
2024-03-29 17:47:35,580 [main] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
2024-03-29 17:47:35,583 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-29 17:47:35,583 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-29 17:47:35,583 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2024-03-29 17:47:35,598 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/f1e2ddde-13b8-4857-81d8-e82f96a4c8ad/in_use.lock acquired by nodename 7@5d1473b286f4
2024-03-29 17:47:35,602 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf} from /data/metadata/scm-ha/f1e2ddde-13b8-4857-81d8-e82f96a4c8ad/current/raft-meta
2024-03-29 17:47:35,620 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServer$Division: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD: set configuration 0: peers:[8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf|5d1473b286f4:9894]|listeners:[], old=null
2024-03-29 17:47:35,623 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2024-03-29 17:47:35,644 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2024-03-29 17:47:35,644 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:47:35,646 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-29 17:47:35,646 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-29 17:47:35,654 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2024-03-29 17:47:35,664 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-29 17:47:35,664 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-29 17:47:35,665 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:47:35,673 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO util.AwaitToRun: Thread[8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-cacheEviction-AwaitToRun,5,main] started
2024-03-29 17:47:35,676 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/f1e2ddde-13b8-4857-81d8-e82f96a4c8ad
2024-03-29 17:47:35,677 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2024-03-29 17:47:35,679 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2024-03-29 17:47:35,686 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2024-03-29 17:47:35,686 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2024-03-29 17:47:35,686 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2024-03-29 17:47:35,688 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2024-03-29 17:47:35,688 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-29 17:47:35,688 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2024-03-29 17:47:35,691 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554440 (custom)
2024-03-29 17:47:35,696 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:47:35,697 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2024-03-29 17:47:35,697 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2024-03-29 17:47:35,697 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2024-03-29 17:47:35,734 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServer$Division: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD: set configuration 0: peers:[8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf|5d1473b286f4:9894]|listeners:[], old=null
2024-03-29 17:47:35,749 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/f1e2ddde-13b8-4857-81d8-e82f96a4c8ad/current/log_inprogress_0
2024-03-29 17:47:35,753 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-29 17:47:35,801 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO segmented.BufferedWriteChannel: open log_inprogress_0 (append) at position 78
2024-03-29 17:47:35,803 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServer$Division: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD: start as a follower, conf=0: peers:[8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf|5d1473b286f4:9894]|listeners:[], old=null
2024-03-29 17:47:35,803 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServer$Division: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD: changes role from      null to FOLLOWER at term 1 for startAsFollower
2024-03-29 17:47:35,804 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO impl.RoleInfo: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: start 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-FollowerState
2024-03-29 17:47:35,807 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E82F96A4C8AD,id=8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf
2024-03-29 17:47:35,808 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-29 17:47:35,809 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-29 17:47:35,809 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2024-03-29 17:47:35,809 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2024-03-29 17:47:35,809 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-29 17:47:35,817 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2024-03-29 17:47:35,818 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-29 17:47:35,840 [main] INFO server.RaftServer: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: start RPC server
2024-03-29 17:47:35,902 [main] INFO server.GrpcService: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: GrpcService started, listening on 9894
2024-03-29 17:47:35,918 [main] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf|5d1473b286f4:9894]
2024-03-29 17:47:35,919 [main] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
2024-03-29 17:47:35,921 [main] INFO SCMHATransactionMonitor: Starting SCMHATransactionMonitor Service.
2024-03-29 17:47:35,921 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: Started
2024-03-29 17:47:35,923 [main] INFO ha.SCMServiceManager: Registering service SCMHATransactionMonitor.
2024-03-29 17:47:35,923 [main] INFO SCMHATransactionMonitor: SCMHATransactionMonitor Service is already running, skip start.
2024-03-29 17:47:36,024 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2024-03-29 17:47:36,043 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-03-29 17:47:36,044 [main] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
2024-03-29 17:47:36,394 [main] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
2024-03-29 17:47:36,399 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-03-29 17:47:36,405 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
2024-03-29 17:47:36,657 [main] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
2024-03-29 17:47:36,658 [main] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
2024-03-29 17:47:36,658 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-03-29 17:47:36,658 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
2024-03-29 17:47:36,922 [main] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
2024-03-29 17:47:36,923 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-29 17:47:36,993 [main] INFO util.log: Logging initialized @15179ms to org.eclipse.jetty.util.log.Slf4jLog
2024-03-29 17:47:37,088 [main] WARN server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /opt/hadoop/hadoop-http-auth-signature-secret
2024-03-29 17:47:37,105 [main] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
2024-03-29 17:47:37,113 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-29 17:47:37,115 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2024-03-29 17:47:37,115 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-29 17:47:37,115 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-29 17:47:37,174 [main] INFO http.BaseHttpServer: HTTP server of scm uses base directory /data/metadata/webserver
2024-03-29 17:47:37,178 [main] INFO http.HttpServer2: Jetty bound to port 9876
2024-03-29 17:47:37,179 [main] INFO server.Server: jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 17.0.2+8-86
2024-03-29 17:47:37,262 [main] INFO server.session: DefaultSessionIdManager workerName=node0
2024-03-29 17:47:37,262 [main] INFO server.session: No SessionScavenger set, using defaults
2024-03-29 17:47:37,263 [main] INFO server.session: node0 Scavenging every 600000ms
2024-03-29 17:47:37,279 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4f5bfbca{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
2024-03-29 17:47:37,279 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@53c9541c{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-03-29 17:47:37,375 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@34588991{scm,/,file:///data/metadata/webserver/jetty-0_0_0_0-9876-hdds-server-scm-1_5_0-SNAPSHOT_jar-_-any-1575533690252179675/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.5.0-SNAPSHOT.jar!/webapps/scm}
2024-03-29 17:47:37,381 [main] INFO server.AbstractConnector: Started ServerConnector@5c13534a{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
2024-03-29 17:47:37,382 [main] INFO server.Server: Started @15568ms
2024-03-29 17:47:37,383 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
2024-03-29 17:47:37,383 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
2024-03-29 17:47:37,384 [main] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
2024-03-29 17:47:40,971 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-FollowerState] INFO impl.FollowerState: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5167564519ns, electionTimeout:5153ms
2024-03-29 17:47:40,972 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-FollowerState] INFO impl.RoleInfo: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: shutdown 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-FollowerState
2024-03-29 17:47:40,972 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-FollowerState] INFO server.RaftServer$Division: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2024-03-29 17:47:40,974 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
2024-03-29 17:47:40,974 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-FollowerState] INFO impl.RoleInfo: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: start 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1
2024-03-29 17:47:40,975 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO impl.LeaderElection: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 1 for 0: peers:[8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf|5d1473b286f4:9894]|listeners:[], old=null
2024-03-29 17:47:40,975 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO impl.LeaderElection: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1 PRE_VOTE round 0: result PASSED (term=1)
2024-03-29 17:47:40,988 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO impl.LeaderElection: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: peers:[8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf|5d1473b286f4:9894]|listeners:[], old=null
2024-03-29 17:47:40,988 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO impl.LeaderElection: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1 ELECTION round 0: result PASSED (term=2)
2024-03-29 17:47:40,988 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO impl.RoleInfo: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: shutdown 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1
2024-03-29 17:47:40,989 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServer$Division: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2024-03-29 17:47:40,993 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2024-03-29 17:47:40,995 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2024-03-29 17:47:40,995 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2024-03-29 17:47:40,998 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2024-03-29 17:47:40,998 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2024-03-29 17:47:40,998 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2024-03-29 17:47:41,002 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.enabled = false (default)
2024-03-29 17:47:41,003 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-29 17:47:41,004 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2024-03-29 17:47:41,004 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2024-03-29 17:47:41,004 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-29 17:47:41,005 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO impl.RoleInfo: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf: start 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderStateImpl
2024-03-29 17:47:41,006 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServer$Division: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD: set firstElectionSinceStartup to false for becomeLeader
2024-03-29 17:47:41,006 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
2024-03-29 17:47:41,006 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
2024-03-29 17:47:41,008 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServer$Division: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD: change Leader from null to 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf at term 2 for becomeLeader, leader elected after 7442ms
2024-03-29 17:47:41,013 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2024-03-29 17:47:41,014 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/f1e2ddde-13b8-4857-81d8-e82f96a4c8ad/current/log_inprogress_0 to /data/metadata/scm-ha/f1e2ddde-13b8-4857-81d8-e82f96a4c8ad/current/log_0-0
2024-03-29 17:47:41,017 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-LeaderElection1] INFO server.RaftServer$Division: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD: set configuration 1: peers:[8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf|5d1473b286f4:9894]|listeners:[], old=null
2024-03-29 17:47:41,017 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-SegmentedRaftLogWorker] INFO segmented.BufferedWriteChannel: open log_inprogress_1 at position 0
2024-03-29 17:47:41,027 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/f1e2ddde-13b8-4857-81d8-e82f96a4c8ad/current/log_inprogress_1
2024-03-29 17:47:41,035 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater] INFO server.RaftServer$Division: leader is ready since appliedIndex == 1 >= startIndex == 1
2024-03-29 17:47:41,035 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
2024-03-29 17:47:41,036 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
2024-03-29 17:47:41,037 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:47:41,037 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
2024-03-29 17:47:41,037 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2024-03-29 17:47:41,037 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
2024-03-29 17:47:41,038 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-03-29 17:47:41,040 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
2024-03-29 17:47:41,043 [IPC Server handler 0 on default port 9861] INFO ipc.Server: IPC Server handler 0 on default port 9861: skipped Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from xcompat_datanode_5.xcompat_default:45220 / 172.25.0.14:45220
2024-03-29 17:47:41,043 [IPC Server handler 0 on default port 9861] INFO ipc.Server: IPC Server handler 0 on default port 9861: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from xcompat_datanode_4.xcompat_default:41326 / 172.25.0.9:41326
2024-03-29 17:47:41,043 [IPC Server handler 0 on default port 9861] INFO ipc.Server: IPC Server handler 0 on default port 9861: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from xcompat_datanode_3.xcompat_default:60750 / 172.25.0.11:60750
2024-03-29 17:47:41,136 [IPC Server handler 0 on default port 9861] WARN ipc.Server: IPC Server handler 0 on default port 9861, call Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from xcompat_datanode_1.xcompat_default:54438 / 172.25.0.8:54438: output error
2024-03-29 17:47:41,137 [IPC Server handler 0 on default port 9861] INFO ipc.Server: IPC Server handler 0 on default port 9861 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:215)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:527)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3743)
	at org.apache.hadoop.ipc.Server.access$1800(Server.java:148)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1722)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1792)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2919)
	at org.apache.hadoop.ipc.Server$Connection.access$400(Server.java:1864)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1176)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:954)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:940)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1111)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-03-29 17:47:42,491 [IPC Server handler 43 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/fc2885e4-1e8d-4382-87e4-30ef6b7bd14d
2024-03-29 17:47:42,509 [IPC Server handler 43 on default port 9861] INFO node.SCMNodeManager: Registered datanode: fc2885e4-1e8d-4382-87e4-30ef6b7bd14d{ip: 172.25.0.14, host: xcompat_datanode_5.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:47:42,529 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:47:42,550 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
2024-03-29 17:47:42,555 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=81d26f51-e2cb-4637-a978-0ce0230073a6 to datanode:fc2885e4-1e8d-4382-87e4-30ef6b7bd14d
2024-03-29 17:47:42,559 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2024-03-29 17:47:42,607 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:47:42,709 [IPC Server handler 69 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/20edbe0a-a2af-4e4b-be05-fb2b83efbef7
2024-03-29 17:47:42,709 [IPC Server handler 69 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 20edbe0a-a2af-4e4b-be05-fb2b83efbef7{ip: 172.25.0.11, host: xcompat_datanode_3.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:47:42,710 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:47:42,710 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
2024-03-29 17:47:42,816 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:47:42,832 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 81d26f51-e2cb-4637-a978-0ce0230073a6, Nodes: fc2885e4-1e8d-4382-87e4-30ef6b7bd14d(xcompat_datanode_5.xcompat_default/172.25.0.14), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:47:42.554764016Z[UTC]]
2024-03-29 17:47:42,838 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=3262b5a5-44d3-41a3-9870-1f5adab17066 to datanode:20edbe0a-a2af-4e4b-be05-fb2b83efbef7
2024-03-29 17:47:42,843 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:47:42,844 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 3262b5a5-44d3-41a3-9870-1f5adab17066, Nodes: 20edbe0a-a2af-4e4b-be05-fb2b83efbef7(xcompat_datanode_3.xcompat_default/172.25.0.11), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:47:42.838174349Z[UTC]]
2024-03-29 17:47:43,176 [IPC Server handler 18 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/e4cae0de-d6c9-44ef-981a-7d75e272ab30
2024-03-29 17:47:43,176 [IPC Server handler 18 on default port 9861] INFO node.SCMNodeManager: Registered datanode: e4cae0de-d6c9-44ef-981a-7d75e272ab30{ip: 172.25.0.10, host: xcompat_datanode_2.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:47:43,178 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:47:43,178 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
2024-03-29 17:47:43,178 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
2024-03-29 17:47:43,178 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
2024-03-29 17:47:43,178 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2024-03-29 17:47:43,178 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:47:43,178 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=2b7a1ed2-ab65-434b-94d5-db88edd50b83 to datanode:e4cae0de-d6c9-44ef-981a-7d75e272ab30
2024-03-29 17:47:43,181 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:47:43,181 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 2b7a1ed2-ab65-434b-94d5-db88edd50b83, Nodes: e4cae0de-d6c9-44ef-981a-7d75e272ab30(xcompat_datanode_2.xcompat_default/172.25.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:47:43.178539692Z[UTC]]
2024-03-29 17:47:43,186 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=7edcf99a-809f-478c-896f-736556795f88 to datanode:fc2885e4-1e8d-4382-87e4-30ef6b7bd14d
2024-03-29 17:47:43,186 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=7edcf99a-809f-478c-896f-736556795f88 to datanode:20edbe0a-a2af-4e4b-be05-fb2b83efbef7
2024-03-29 17:47:43,186 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=7edcf99a-809f-478c-896f-736556795f88 to datanode:e4cae0de-d6c9-44ef-981a-7d75e272ab30
2024-03-29 17:47:43,189 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:47:43,190 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 7edcf99a-809f-478c-896f-736556795f88, Nodes: fc2885e4-1e8d-4382-87e4-30ef6b7bd14d(xcompat_datanode_5.xcompat_default/172.25.0.14)20edbe0a-a2af-4e4b-be05-fb2b83efbef7(xcompat_datanode_3.xcompat_default/172.25.0.11)e4cae0de-d6c9-44ef-981a-7d75e272ab30(xcompat_datanode_2.xcompat_default/172.25.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:47:43.186019778Z[UTC]]
2024-03-29 17:47:43,191 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=625249d9-a6e8-49cd-bf40-8c63e4864072 to datanode:e4cae0de-d6c9-44ef-981a-7d75e272ab30
2024-03-29 17:47:43,192 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=625249d9-a6e8-49cd-bf40-8c63e4864072 to datanode:fc2885e4-1e8d-4382-87e4-30ef6b7bd14d
2024-03-29 17:47:43,192 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=625249d9-a6e8-49cd-bf40-8c63e4864072 to datanode:20edbe0a-a2af-4e4b-be05-fb2b83efbef7
2024-03-29 17:47:43,196 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:47:43,197 [RatisPipelineUtilsThread-0] INFO pipeline.PipelineManagerImpl: Pipeline: PipelineID=625249d9-a6e8-49cd-bf40-8c63e4864072 contains same datanodes as previous pipelines: PipelineID=7edcf99a-809f-478c-896f-736556795f88 nodeIds: e4cae0de-d6c9-44ef-981a-7d75e272ab30, fc2885e4-1e8d-4382-87e4-30ef6b7bd14d, 20edbe0a-a2af-4e4b-be05-fb2b83efbef7
2024-03-29 17:47:43,197 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 625249d9-a6e8-49cd-bf40-8c63e4864072, Nodes: e4cae0de-d6c9-44ef-981a-7d75e272ab30(xcompat_datanode_2.xcompat_default/172.25.0.10)fc2885e4-1e8d-4382-87e4-30ef6b7bd14d(xcompat_datanode_5.xcompat_default/172.25.0.14)20edbe0a-a2af-4e4b-be05-fb2b83efbef7(xcompat_datanode_3.xcompat_default/172.25.0.11), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:47:43.191896031Z[UTC]]
2024-03-29 17:47:43,586 [IPC Server handler 53 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/f730dd9f-e9a6-4648-91b1-bfa3f7ccfb32
2024-03-29 17:47:43,586 [IPC Server handler 53 on default port 9861] INFO node.SCMNodeManager: Registered datanode: f730dd9f-e9a6-4648-91b1-bfa3f7ccfb32{ip: 172.25.0.9, host: xcompat_datanode_4.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:47:43,587 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:47:43,588 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=80084acc-07e0-4f3f-ab07-568b7dff0901 to datanode:f730dd9f-e9a6-4648-91b1-bfa3f7ccfb32
2024-03-29 17:47:43,592 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:47:43,593 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 80084acc-07e0-4f3f-ab07-568b7dff0901, Nodes: f730dd9f-e9a6-4648-91b1-bfa3f7ccfb32(xcompat_datanode_4.xcompat_default/172.25.0.9), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:47:43.588458479Z[UTC]]
2024-03-29 17:47:43,824 [IPC Server handler 81 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/004e63ce-585f-4c8b-b576-3fd7ee884e81
2024-03-29 17:47:43,825 [IPC Server handler 81 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 004e63ce-585f-4c8b-b576-3fd7ee884e81{ip: 172.25.0.8, host: xcompat_datanode_1.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:47:43,825 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:47:43,827 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=110c8953-3b4a-4d54-91e8-20780a056406 to datanode:004e63ce-585f-4c8b-b576-3fd7ee884e81
2024-03-29 17:47:43,835 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:47:43,838 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 110c8953-3b4a-4d54-91e8-20780a056406, Nodes: 004e63ce-585f-4c8b-b576-3fd7ee884e81(xcompat_datanode_1.xcompat_default/172.25.0.8), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:47:43.826963347Z[UTC]]
2024-03-29 17:47:45,702 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:47:45,718 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=81d26f51-e2cb-4637-a978-0ce0230073a6
2024-03-29 17:47:45,718 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:47:45,925 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:47:46,115 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:47:46,115 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=3262b5a5-44d3-41a3-9870-1f5adab17066
2024-03-29 17:47:46,115 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:47:46,315 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:47:46,966 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:47:46,967 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=2b7a1ed2-ab65-434b-94d5-db88edd50b83
2024-03-29 17:47:46,967 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:47:47,184 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:47:47,185 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=80084acc-07e0-4f3f-ab07-568b7dff0901
2024-03-29 17:47:47,186 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:47:47,266 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:47:47,305 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:47:47,305 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=110c8953-3b4a-4d54-91e8-20780a056406
2024-03-29 17:47:47,306 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:47:48,550 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:47:48,551 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:47:48,690 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:47:51,088 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:47:51,440 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:47:51,573 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:47:51,579 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
2024-03-29 17:47:51,579 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=7edcf99a-809f-478c-896f-736556795f88
2024-03-29 17:47:51,579 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2024-03-29 17:47:51,579 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
2024-03-29 17:47:51,580 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
2024-03-29 17:47:51,580 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
2024-03-29 17:47:51,580 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2024-03-29 17:47:51,580 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
2024-03-29 17:47:51,580 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2024-03-29 17:47:51,580 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO block.SCMBlockDeletingService: notifyStatusChanged:RUNNING
2024-03-29 17:47:51,580 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
2024-03-29 17:47:51,587 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2024-03-29 17:47:51,588 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO SCMHATransactionMonitor: Service SCMHATransactionMonitor transitions to RUNNING.
2024-03-29 17:47:53,763 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=625249d9-a6e8-49cd-bf40-8c63e4864072
2024-03-29 17:48:09,719 [IPC Server handler 9 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
2024-03-29 17:48:09,760 [8a66ec7c-25f8-4f73-9432-d4fe59bd1eaf@group-E82F96A4C8AD-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 113750153625600000.
2024-03-29 17:48:09,766 [IPC Server handler 9 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 113750153625600000 to 113750153625601000.
2024-03-29 17:48:19,327 [IPC Server handler 6 on default port 9863] INFO algorithms.SCMContainerPlacementRackScatter: Chosen nodes: [004e63ce-585f-4c8b-b576-3fd7ee884e81(xcompat_datanode_1.xcompat_default/172.25.0.8), fc2885e4-1e8d-4382-87e4-30ef6b7bd14d(xcompat_datanode_5.xcompat_default/172.25.0.14), 20edbe0a-a2af-4e4b-be05-fb2b83efbef7(xcompat_datanode_3.xcompat_default/172.25.0.11), f730dd9f-e9a6-4648-91b1-bfa3f7ccfb32(xcompat_datanode_4.xcompat_default/172.25.0.9), e4cae0de-d6c9-44ef-981a-7d75e272ab30(xcompat_datanode_2.xcompat_default/172.25.0.10)]. isPolicySatisfied: true.
2024-03-29 17:48:19,345 [IPC Server handler 6 on default port 9863] INFO pipeline.WritableECContainerProvider: Created and opened new pipeline Pipeline[ Id: 1cefd782-402c-4c9a-b471-f1d8407ebed2, Nodes: 004e63ce-585f-4c8b-b576-3fd7ee884e81(xcompat_datanode_1.xcompat_default/172.25.0.8)fc2885e4-1e8d-4382-87e4-30ef6b7bd14d(xcompat_datanode_5.xcompat_default/172.25.0.14)20edbe0a-a2af-4e4b-be05-fb2b83efbef7(xcompat_datanode_3.xcompat_default/172.25.0.11)f730dd9f-e9a6-4648-91b1-bfa3f7ccfb32(xcompat_datanode_4.xcompat_default/172.25.0.9)e4cae0de-d6c9-44ef-981a-7d75e272ab30(xcompat_datanode_2.xcompat_default/172.25.0.10), ReplicationConfig: EC{rs-3-2-1024k}, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:48:19.327816266Z[UTC]]
2024-03-29 17:49:53,105 [IPC Server handler 6 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
2024-03-29 17:52:43,863 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = 95fdf36a174b/172.26.0.7
STARTUP_MSG:   args = [--init]
STARTUP_MSG:   version = 1.5.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.14.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.15.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.16.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.16.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.16.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.5.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.0.1.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk18on-1.77.jar:/opt/hadoop/share/ozone/lib/bcutil-jdk18on-1.77.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.8.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.15.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.8.1.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.22.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.26.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.9.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.9.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.12.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-1.2.2.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.14.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/commons-net-3.10.0.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/ozone/lib/re2j-1.7.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.2.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.37.2.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.10.5.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.25.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-2.0.12.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.10.1.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.16.0.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.4.0.jar:/opt/hadoop/share/ozone/lib/jheaps-0.11.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.4.0.jar:/opt/hadoop/share/ozone/lib/jgraphx-3.9.8.1.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk18on-1.77.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/slf4j-api-2.0.12.jar:/opt/hadoop/share/ozone/lib/commons-text-1.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/okhttp-4.12.0.jar:/opt/hadoop/share/ozone/lib/okio-3.6.0.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.6.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.9.22.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.9.22.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.9.22.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.16.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.5.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/cb5d51983d044734a714f32a32255dc9604eb701 ; compiled by 'runner' on 2024-03-29T16:59Z
STARTUP_MSG:   java = 17.0.2
STARTUP_MSG:   conf = {hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=false, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.chunk.write.sync=false, hdds.container.close.threshold=0.9f, hdds.container.ipc.port=9859, hdds.container.ipc.random.port=false, hdds.container.ratis.admin.port=9857, hdds.container.ratis.datastream.enabled=false, hdds.container.ratis.datastream.port=9855, hdds.container.ratis.datastream.random.port=false, hdds.container.ratis.enabled=false, hdds.container.ratis.ipc.port=9858, hdds.container.ratis.ipc.random.port=false, hdds.container.ratis.leader.pending.bytes.limit=1GB, hdds.container.ratis.log.appender.queue.byte-limit=32MB, hdds.container.ratis.log.appender.queue.num-elements=1, hdds.container.ratis.log.purge.gap=1000000, hdds.container.ratis.log.queue.byte-limit=4GB, hdds.container.ratis.log.queue.num-elements=1024, hdds.container.ratis.num.container.op.executors=10, hdds.container.ratis.num.write.chunk.threads.per.volume=10, hdds.container.ratis.replication.level=MAJORITY, hdds.container.ratis.rpc.type=GRPC, hdds.container.ratis.segment.preallocated.size=4MB, hdds.container.ratis.segment.size=64MB, hdds.container.ratis.server.port=9856, hdds.container.ratis.statemachine.max.pending.apply-transactions=10000, hdds.container.ratis.statemachinedata.sync.timeout=10s, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=true, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=false, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.datanode.http.auth.type=simple, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.replication.zerocopy.enabled=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.slow.op.warning.threshold=500ms, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=false, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.leader.election.minimum.timeout.duration=5s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.ratis.server.retry-cache.timeout.duration=600000ms, hdds.ratis.snapshot.threshold=10000, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.scm.http.auth.type=simple, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/SCM.keytab, hdds.scm.kerberos.principal=SCM/_HOST@REALM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=3, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneAccessAuthorizer, ozone.acl.enabled=false, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.reconstruct.stripe.write.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.max.retries=3, ozone.client.read.retry.interval=1, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.default.bucket.layout=LEGACY, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.http.policy=HTTP_ONLY, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=om, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=om:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.om.http.auth.type=simple, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.kerberos.keytab.file=/etc/security/keytabs/OM.keytab, ozone.om.kerberos.principal=OM/_HOST@REALM, ozone.om.kerberos.principal.pattern=*, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.network.topology.refresh.duration=1h, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=true, ozone.path.deleting.limit.per.task=6000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.recon.http.auth.type=simple, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=10m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.s3g.http.auth.type=simple, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/_HOST@REALM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.metrics.percentiles.intervals.seconds=60, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=false, ozone.s3g.volume.name=s3v, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.handler.count.key=100, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.handler.count.key=100, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=150s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.handler.count.key=100, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.names=scm, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=120s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=false, ozone.security.http.kerberos.enabled=false, ozone.security.reconfigure.protocol.acl=*, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.xceiver.client.metrics.percentiles.intervals.seconds=60, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, recon.om.snapshot.task.interval.delay=1m, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2024-03-29 17:52:43,962 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2024-03-29 17:52:44,518 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:52:46,419 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2024-03-29 17:52:46,492 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2024-03-29 17:52:47,607 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2024-03-29 17:52:47,946 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-03-29 17:52:47,954 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2024-03-29 17:52:47,963 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-03-29 17:52:47,967 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2024-03-29 17:52:47,967 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2024-03-29 17:52:47,967 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2024-03-29 17:52:47,970 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2024-03-29 17:52:47,986 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:52:47,992 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2024-03-29 17:52:47,994 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2024-03-29 17:52:48,077 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2024-03-29 17:52:48,094 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-03-29 17:52:48,141 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-03-29 17:52:49,587 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2024-03-29 17:52:49,625 [main] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-29 17:52:49,627 [main] INFO server.RaftServerConfigKeys: raft.server.close.threshold = 60s (default)
2024-03-29 17:52:49,627 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-29 17:52:49,634 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2024-03-29 17:52:49,671 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2024-03-29 17:52:49,692 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2024-03-29 17:52:49,786 [main] INFO server.RaftServer: aa678345-8a5e-4c7e-9814-4ef57b2706b8: addNew group-519610457742:[aa678345-8a5e-4c7e-9814-4ef57b2706b8|95fdf36a174b:9894] returns group-519610457742:java.util.concurrent.CompletableFuture@1cb7936c[Not completed]
2024-03-29 17:52:49,969 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServer$Division: aa678345-8a5e-4c7e-9814-4ef57b2706b8: new RaftServerImpl for group-519610457742:[aa678345-8a5e-4c7e-9814-4ef57b2706b8|95fdf36a174b:9894] with SCMStateMachine:uninitialized
2024-03-29 17:52:49,976 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2024-03-29 17:52:49,987 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-29 17:52:49,988 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2024-03-29 17:52:49,988 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2024-03-29 17:52:49,991 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-29 17:52:49,992 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.member.majority-add = false (default)
2024-03-29 17:52:49,995 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-29 17:52:50,025 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServer$Division: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742: ConfigurationManager, init=-1: peers:[aa678345-8a5e-4c7e-9814-4ef57b2706b8|95fdf36a174b:9894]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-29 17:52:50,065 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2024-03-29 17:52:50,094 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2024-03-29 17:52:50,139 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2024-03-29 17:52:50,183 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-29 17:52:50,221 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2024-03-29 17:52:50,240 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-29 17:52:50,302 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.dropwizard3.Dm3MetricRegistriesImpl
2024-03-29 17:52:51,209 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2024-03-29 17:52:51,213 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-29 17:52:51,256 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2024-03-29 17:52:51,258 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2024-03-29 17:52:51,267 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2024-03-29 17:52:51,275 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2024-03-29 17:52:51,320 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-29 17:52:51,321 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-29 17:52:51,330 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2024-03-29 17:52:51,353 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/b971e942-ed47-4c80-90d8-519610457742 does not exist. Creating ...
2024-03-29 17:52:51,404 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/b971e942-ed47-4c80-90d8-519610457742/in_use.lock acquired by nodename 13@95fdf36a174b
2024-03-29 17:52:51,438 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/b971e942-ed47-4c80-90d8-519610457742 has been successfully formatted.
2024-03-29 17:52:51,444 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] WARN util.FileUtils: Failed to Files.newInputStream /data/metadata/scm-ha/b971e942-ed47-4c80-90d8-519610457742/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /data/metadata/scm-ha/b971e942-ed47-4c80-90d8-519610457742/current/raft-meta.conf
2024-03-29 17:52:51,465 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2024-03-29 17:52:51,500 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2024-03-29 17:52:51,516 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:52:51,524 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-29 17:52:51,525 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-29 17:52:51,536 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2024-03-29 17:52:51,571 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-29 17:52:51,572 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-29 17:52:51,573 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:52:51,576 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO util.AwaitToRun: Thread[aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-cacheEviction-AwaitToRun,5,main] started
2024-03-29 17:52:51,585 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/b971e942-ed47-4c80-90d8-519610457742
2024-03-29 17:52:51,592 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2024-03-29 17:52:51,594 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2024-03-29 17:52:51,595 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2024-03-29 17:52:51,598 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2024-03-29 17:52:51,605 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2024-03-29 17:52:51,606 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2024-03-29 17:52:51,611 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-29 17:52:51,612 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2024-03-29 17:52:51,625 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554440 (custom)
2024-03-29 17:52:51,630 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:52:51,645 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2024-03-29 17:52:51,647 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2024-03-29 17:52:51,649 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2024-03-29 17:52:51,655 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO segmented.SegmentedRaftLogWorker: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-03-29 17:52:51,667 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO segmented.SegmentedRaftLogWorker: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-29 17:52:51,676 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServer$Division: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742: start as a follower, conf=-1: peers:[aa678345-8a5e-4c7e-9814-4ef57b2706b8|95fdf36a174b:9894]|listeners:[], old=null
2024-03-29 17:52:51,677 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServer$Division: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-03-29 17:52:51,678 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO impl.RoleInfo: aa678345-8a5e-4c7e-9814-4ef57b2706b8: start aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-FollowerState
2024-03-29 17:52:51,692 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-519610457742,id=aa678345-8a5e-4c7e-9814-4ef57b2706b8
2024-03-29 17:52:51,699 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-29 17:52:51,712 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-29 17:52:51,712 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2024-03-29 17:52:51,717 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2024-03-29 17:52:51,724 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-29 17:52:51,711 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2024-03-29 17:52:51,731 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-29 17:52:51,735 [main] INFO server.RaftServer: aa678345-8a5e-4c7e-9814-4ef57b2706b8: start RPC server
2024-03-29 17:52:51,931 [main] INFO server.GrpcService: aa678345-8a5e-4c7e-9814-4ef57b2706b8: GrpcService started, listening on 9894
2024-03-29 17:52:51,971 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-aa678345-8a5e-4c7e-9814-4ef57b2706b8: Started
2024-03-29 17:52:56,875 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-FollowerState] INFO impl.FollowerState: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5197372221ns, electionTimeout:5143ms
2024-03-29 17:52:56,876 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-FollowerState] INFO impl.RoleInfo: aa678345-8a5e-4c7e-9814-4ef57b2706b8: shutdown aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-FollowerState
2024-03-29 17:52:56,876 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-FollowerState] INFO server.RaftServer$Division: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-03-29 17:52:56,878 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
2024-03-29 17:52:56,878 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-FollowerState] INFO impl.RoleInfo: aa678345-8a5e-4c7e-9814-4ef57b2706b8: start aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1
2024-03-29 17:52:56,889 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO impl.LeaderElection: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[aa678345-8a5e-4c7e-9814-4ef57b2706b8|95fdf36a174b:9894]|listeners:[], old=null
2024-03-29 17:52:56,891 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO impl.LeaderElection: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1 PRE_VOTE round 0: result PASSED (term=0)
2024-03-29 17:52:56,898 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO impl.LeaderElection: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[aa678345-8a5e-4c7e-9814-4ef57b2706b8|95fdf36a174b:9894]|listeners:[], old=null
2024-03-29 17:52:56,899 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO impl.LeaderElection: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1 ELECTION round 0: result PASSED (term=1)
2024-03-29 17:52:56,899 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO impl.RoleInfo: aa678345-8a5e-4c7e-9814-4ef57b2706b8: shutdown aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1
2024-03-29 17:52:56,899 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServer$Division: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-03-29 17:52:56,927 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2024-03-29 17:52:56,934 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2024-03-29 17:52:56,960 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2024-03-29 17:52:56,973 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2024-03-29 17:52:56,976 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2024-03-29 17:52:56,980 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2024-03-29 17:52:57,012 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.enabled = false (default)
2024-03-29 17:52:57,020 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-29 17:52:57,023 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2024-03-29 17:52:57,025 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2024-03-29 17:52:57,026 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-29 17:52:57,028 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO impl.RoleInfo: aa678345-8a5e-4c7e-9814-4ef57b2706b8: start aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderStateImpl
2024-03-29 17:52:57,036 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServer$Division: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742: set firstElectionSinceStartup to false for becomeLeader
2024-03-29 17:52:57,041 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServer$Division: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742: change Leader from null to aa678345-8a5e-4c7e-9814-4ef57b2706b8 at term 1 for becomeLeader, leader elected after 6971ms
2024-03-29 17:52:57,135 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-SegmentedRaftLogWorker: Starting segment from index:0
2024-03-29 17:52:57,236 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServer$Division: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742: set configuration 0: peers:[aa678345-8a5e-4c7e-9814-4ef57b2706b8|95fdf36a174b:9894]|listeners:[], old=null
2024-03-29 17:52:57,462 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-SegmentedRaftLogWorker] INFO segmented.BufferedWriteChannel: open log_inprogress_0 at position 0
2024-03-29 17:52:57,500 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/b971e942-ed47-4c80-90d8-519610457742/current/log_inprogress_0
2024-03-29 17:52:57,581 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater] INFO server.RaftServer$Division: leader is ready since appliedIndex == 0 >= startIndex == 0
2024-03-29 17:52:57,972 [main] INFO server.RaftServer: aa678345-8a5e-4c7e-9814-4ef57b2706b8: close
2024-03-29 17:52:57,973 [main] INFO server.GrpcService: aa678345-8a5e-4c7e-9814-4ef57b2706b8: shutdown server GrpcServerProtocolService now
2024-03-29 17:52:57,996 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServer$Division: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742: shutdown
2024-03-29 17:52:57,996 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-519610457742,id=aa678345-8a5e-4c7e-9814-4ef57b2706b8
2024-03-29 17:52:57,996 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO impl.RoleInfo: aa678345-8a5e-4c7e-9814-4ef57b2706b8: shutdown aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderStateImpl
2024-03-29 17:52:58,004 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO impl.PendingRequests: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-PendingRequests: sendNotLeaderResponses
2024-03-29 17:52:58,028 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO impl.StateMachineUpdater: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater: set stopIndex = 0
2024-03-29 17:52:58,030 [main] INFO server.GrpcService: aa678345-8a5e-4c7e-9814-4ef57b2706b8: shutdown server GrpcServerProtocolService successfully
2024-03-29 17:52:58,031 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater] INFO impl.StateMachineUpdater: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater: Took a snapshot at index 0
2024-03-29 17:52:58,034 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater] INFO impl.StateMachineUpdater: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-03-29 17:52:58,044 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServer$Division: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742: applyIndex: 0
2024-03-29 17:52:58,045 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-cacheEviction-AwaitToRun] INFO util.AwaitToRun: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-03-29 17:52:58,546 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO segmented.SegmentedRaftLogWorker: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-SegmentedRaftLogWorker close()
2024-03-29 17:52:58,555 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-aa678345-8a5e-4c7e-9814-4ef57b2706b8: Stopped
2024-03-29 17:52:58,555 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:52:58,558 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-b971e942-ed47-4c80-90d8-519610457742; layoutVersion=7; scmId=aa678345-8a5e-4c7e-9814-4ef57b2706b8
2024-03-29 17:52:58,590 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at 95fdf36a174b/172.26.0.7
************************************************************/
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8' to the OZONE_OPTS
2024-03-29 17:53:05,562 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = 95fdf36a174b/172.26.0.7
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.5.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/picocli-4.7.5.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.14.0.jar:/opt/hadoop/share/ozone/lib/commons-io-2.15.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.16.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.16.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.16.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.3.2.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-2.1.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.5.jar:/opt/hadoop/share/ozone/lib/ratis-proto-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-common-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-client-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-api-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-dropwizard3-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-3.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-3.0.1.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk18on-1.77.jar:/opt/hadoop/share/ozone/lib/bcutil-jdk18on-1.77.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.8.1.jar:/opt/hadoop/share/ozone/lib/libthrift-0.15.0.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.8.1.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.9.22.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.58.0.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.26.0.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.9.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.9.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.12.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-1.2.2.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.14.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.16.jar:/opt/hadoop/share/ozone/lib/commons-net-3.10.0.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/ozone/lib/re2j-1.7.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.2.0.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.37.2.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.10.5.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.25.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-2.0.12.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.10.1.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.4.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.16.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.16.0.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.5.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.4.0.jar:/opt/hadoop/share/ozone/lib/jheaps-0.11.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.4.0.jar:/opt/hadoop/share/ozone/lib/jgraphx-3.9.8.1.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk18on-1.77.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/slf4j-api-2.0.12.jar:/opt/hadoop/share/ozone/lib/commons-text-1.11.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/okhttp-4.12.0.jar:/opt/hadoop/share/ozone/lib/okio-3.6.0.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.6.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.9.22.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.9.22.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.9.22.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.16.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.5.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/cb5d51983d044734a714f32a32255dc9604eb701 ; compiled by 'runner' on 2024-03-29T16:59Z
STARTUP_MSG:   java = 17.0.2
STARTUP_MSG:   conf = {hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=false, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.chunk.write.sync=false, hdds.container.close.threshold=0.9f, hdds.container.ipc.port=9859, hdds.container.ipc.random.port=false, hdds.container.ratis.admin.port=9857, hdds.container.ratis.datastream.enabled=false, hdds.container.ratis.datastream.port=9855, hdds.container.ratis.datastream.random.port=false, hdds.container.ratis.enabled=false, hdds.container.ratis.ipc.port=9858, hdds.container.ratis.ipc.random.port=false, hdds.container.ratis.leader.pending.bytes.limit=1GB, hdds.container.ratis.log.appender.queue.byte-limit=32MB, hdds.container.ratis.log.appender.queue.num-elements=1, hdds.container.ratis.log.purge.gap=1000000, hdds.container.ratis.log.queue.byte-limit=4GB, hdds.container.ratis.log.queue.num-elements=1024, hdds.container.ratis.num.container.op.executors=10, hdds.container.ratis.num.write.chunk.threads.per.volume=10, hdds.container.ratis.replication.level=MAJORITY, hdds.container.ratis.rpc.type=GRPC, hdds.container.ratis.segment.preallocated.size=4MB, hdds.container.ratis.segment.size=64MB, hdds.container.ratis.server.port=9856, hdds.container.ratis.statemachine.max.pending.apply-transactions=10000, hdds.container.ratis.statemachinedata.sync.timeout=10s, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=true, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=false, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.datanode.http.auth.type=simple, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.replication.zerocopy.enabled=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.slow.op.warning.threshold=500ms, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=false, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.leader.election.minimum.timeout.duration=5s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.ratis.server.retry-cache.timeout.duration=600000ms, hdds.ratis.snapshot.threshold=10000, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.scm.http.auth.type=simple, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/SCM.keytab, hdds.scm.kerberos.principal=SCM/_HOST@REALM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=3, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneAccessAuthorizer, ozone.acl.enabled=false, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.reconstruct.stripe.write.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.max.retries=3, ozone.client.read.retry.interval=1, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.default.bucket.layout=LEGACY, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.http.policy=HTTP_ONLY, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=om, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=om:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.om.http.auth.type=simple, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.kerberos.keytab.file=/etc/security/keytabs/OM.keytab, ozone.om.kerberos.principal=OM/_HOST@REALM, ozone.om.kerberos.principal.pattern=*, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.network.topology.refresh.duration=1h, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=true, ozone.path.deleting.limit.per.task=6000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.recon.http.auth.type=simple, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=10m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.s3g.http.auth.type=simple, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/_HOST@REALM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.metrics.percentiles.intervals.seconds=60, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=false, ozone.s3g.volume.name=s3v, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.handler.count.key=100, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.handler.count.key=100, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=150s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.handler.count.key=100, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.names=scm, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=120s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=false, ozone.security.http.kerberos.enabled=false, ozone.security.reconfigure.protocol.acl=*, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.xceiver.client.metrics.percentiles.intervals.seconds=60, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, recon.om.snapshot.task.interval.delay=1m, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2024-03-29 17:53:05,632 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2024-03-29 17:53:05,868 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:53:06,904 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2024-03-29 17:53:06,923 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2024-03-29 17:53:08,761 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:53:09,136 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-03-29 17:53:09,160 [main] INFO utils.LeakDetector: Starting leak detector thread ManagedRocksObject0.
2024-03-29 17:53:09,503 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.5.0-SNAPSHOT.jar!/network-topology-default.xml]
2024-03-29 17:53:09,505 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
2024-03-29 17:53:09,587 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.dropwizard3.Dm3MetricRegistriesImpl
2024-03-29 17:53:09,858 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:aa678345-8a5e-4c7e-9814-4ef57b2706b8
2024-03-29 17:53:09,945 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2024-03-29 17:53:09,952 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-03-29 17:53:09,953 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2024-03-29 17:53:09,953 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-03-29 17:53:09,954 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2024-03-29 17:53:09,954 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2024-03-29 17:53:09,954 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2024-03-29 17:53:09,955 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2024-03-29 17:53:09,957 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:53:09,957 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2024-03-29 17:53:09,960 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2024-03-29 17:53:09,966 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2024-03-29 17:53:09,972 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-03-29 17:53:09,972 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-03-29 17:53:10,194 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2024-03-29 17:53:10,202 [main] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-29 17:53:10,203 [main] INFO server.RaftServerConfigKeys: raft.server.close.threshold = 60s (default)
2024-03-29 17:53:10,207 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-29 17:53:10,218 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2024-03-29 17:53:10,219 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2024-03-29 17:53:10,220 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2024-03-29 17:53:10,231 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServer: aa678345-8a5e-4c7e-9814-4ef57b2706b8: found a subdirectory /data/metadata/scm-ha/b971e942-ed47-4c80-90d8-519610457742
2024-03-29 17:53:10,239 [main] INFO server.RaftServer: aa678345-8a5e-4c7e-9814-4ef57b2706b8: addNew group-519610457742:[] returns group-519610457742:java.util.concurrent.CompletableFuture@16ee9aa7[Not completed]
2024-03-29 17:53:10,273 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServer$Division: aa678345-8a5e-4c7e-9814-4ef57b2706b8: new RaftServerImpl for group-519610457742:[] with SCMStateMachine:uninitialized
2024-03-29 17:53:10,278 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2024-03-29 17:53:10,278 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2024-03-29 17:53:10,278 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2024-03-29 17:53:10,278 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2024-03-29 17:53:10,279 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-03-29 17:53:10,279 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.member.majority-add = false (default)
2024-03-29 17:53:10,279 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2024-03-29 17:53:10,285 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServer$Division: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-03-29 17:53:10,291 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2024-03-29 17:53:10,293 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2024-03-29 17:53:10,296 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2024-03-29 17:53:10,297 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-03-29 17:53:10,300 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2024-03-29 17:53:10,300 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-03-29 17:53:10,457 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2024-03-29 17:53:10,459 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-03-29 17:53:10,461 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2024-03-29 17:53:10,461 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2024-03-29 17:53:10,462 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2024-03-29 17:53:10,463 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2024-03-29 17:53:10,465 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
2024-03-29 17:53:10,465 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2024-03-29 17:53:10,466 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
2024-03-29 17:53:10,557 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-03-29 17:53:10,655 [main] INFO ha.SequenceIdGenerator: upgrade localId to 113750153625600000
2024-03-29 17:53:10,656 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
2024-03-29 17:53:10,679 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
2024-03-29 17:53:10,682 [main] INFO ha.SequenceIdGenerator: upgrade CertificateId to 2
2024-03-29 17:53:10,686 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
2024-03-29 17:53:10,795 [main] INFO node.SCMNodeManager: Entering startup safe mode.
2024-03-29 17:53:10,821 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2024-03-29 17:53:10,825 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2024-03-29 17:53:10,834 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
2024-03-29 17:53:10,850 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2024-03-29 17:53:10,850 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2024-03-29 17:53:10,873 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
2024-03-29 17:53:10,873 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
2024-03-29 17:53:10,878 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
2024-03-29 17:53:10,883 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
2024-03-29 17:53:10,898 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
2024-03-29 17:53:10,908 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
2024-03-29 17:53:10,991 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-03-29 17:53:10,991 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-03-29 17:53:11,040 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
2024-03-29 17:53:11,130 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
2024-03-29 17:53:11,135 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
2024-03-29 17:53:11,139 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
2024-03-29 17:53:11,154 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
2024-03-29 17:53:11,163 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:53:11,166 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2024-03-29 17:53:11,222 [main] INFO server.StorageContainerManager: SCM start with adminUsers: [hadoop]
2024-03-29 17:53:11,786 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2024-03-29 17:53:11,834 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-29 17:53:11,915 [main] INFO ipc.Server: Listener at 0.0.0.0:9861
2024-03-29 17:53:11,924 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
2024-03-29 17:53:11,969 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2024-03-29 17:53:11,993 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-29 17:53:11,994 [main] INFO ipc.Server: Listener at 0.0.0.0:9863
2024-03-29 17:53:11,999 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
2024-03-29 17:53:12,049 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2024-03-29 17:53:12,069 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-03-29 17:53:12,069 [main] INFO ipc.Server: Listener at 0.0.0.0:9860
2024-03-29 17:53:12,078 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
2024-03-29 17:53:12,197 [main] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
2024-03-29 17:53:12,197 [main] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2024-03-29 17:53:12,203 [main] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
2024-03-29 17:53:12,208 [main] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
2024-03-29 17:53:12,211 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2024-03-29 17:53:12,211 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2024-03-29 17:53:12,212 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2024-03-29 17:53:12,234 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/b971e942-ed47-4c80-90d8-519610457742/in_use.lock acquired by nodename 7@95fdf36a174b
2024-03-29 17:53:12,247 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=aa678345-8a5e-4c7e-9814-4ef57b2706b8} from /data/metadata/scm-ha/b971e942-ed47-4c80-90d8-519610457742/current/raft-meta
2024-03-29 17:53:12,324 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServer$Division: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742: set configuration 0: peers:[aa678345-8a5e-4c7e-9814-4ef57b2706b8|95fdf36a174b:9894]|listeners:[], old=null
2024-03-29 17:53:12,331 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2024-03-29 17:53:12,358 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2024-03-29 17:53:12,358 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:53:12,360 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-03-29 17:53:12,361 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2024-03-29 17:53:12,371 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2024-03-29 17:53:12,375 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2024-03-29 17:53:12,376 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-03-29 17:53:12,376 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:53:12,377 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO util.AwaitToRun: Thread[aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-cacheEviction-AwaitToRun,5,main] started
2024-03-29 17:53:12,380 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/b971e942-ed47-4c80-90d8-519610457742
2024-03-29 17:53:12,381 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2024-03-29 17:53:12,381 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2024-03-29 17:53:12,382 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2024-03-29 17:53:12,382 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2024-03-29 17:53:12,383 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2024-03-29 17:53:12,383 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2024-03-29 17:53:12,383 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-03-29 17:53:12,384 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2024-03-29 17:53:12,386 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 33554440 (custom)
2024-03-29 17:53:12,396 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2024-03-29 17:53:12,396 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2024-03-29 17:53:12,397 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2024-03-29 17:53:12,397 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2024-03-29 17:53:12,430 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServer$Division: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742: set configuration 0: peers:[aa678345-8a5e-4c7e-9814-4ef57b2706b8|95fdf36a174b:9894]|listeners:[], old=null
2024-03-29 17:53:12,431 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/b971e942-ed47-4c80-90d8-519610457742/current/log_inprogress_0
2024-03-29 17:53:12,432 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO segmented.SegmentedRaftLogWorker: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-03-29 17:53:12,490 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO segmented.BufferedWriteChannel: open log_inprogress_0 (append) at position 78
2024-03-29 17:53:12,497 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServer$Division: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742: start as a follower, conf=0: peers:[aa678345-8a5e-4c7e-9814-4ef57b2706b8|95fdf36a174b:9894]|listeners:[], old=null
2024-03-29 17:53:12,497 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServer$Division: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742: changes role from      null to FOLLOWER at term 1 for startAsFollower
2024-03-29 17:53:12,498 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO impl.RoleInfo: aa678345-8a5e-4c7e-9814-4ef57b2706b8: start aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-FollowerState
2024-03-29 17:53:12,507 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-519610457742,id=aa678345-8a5e-4c7e-9814-4ef57b2706b8
2024-03-29 17:53:12,512 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-03-29 17:53:12,513 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-03-29 17:53:12,513 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2024-03-29 17:53:12,514 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2024-03-29 17:53:12,515 [aa678345-8a5e-4c7e-9814-4ef57b2706b8-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2024-03-29 17:53:12,518 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2024-03-29 17:53:12,519 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-03-29 17:53:12,531 [main] INFO server.RaftServer: aa678345-8a5e-4c7e-9814-4ef57b2706b8: start RPC server
2024-03-29 17:53:12,625 [main] INFO server.GrpcService: aa678345-8a5e-4c7e-9814-4ef57b2706b8: GrpcService started, listening on 9894
2024-03-29 17:53:12,637 [main] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [aa678345-8a5e-4c7e-9814-4ef57b2706b8|95fdf36a174b:9894]
2024-03-29 17:53:12,637 [main] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
2024-03-29 17:53:12,638 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-aa678345-8a5e-4c7e-9814-4ef57b2706b8: Started
2024-03-29 17:53:12,643 [main] INFO SCMHATransactionMonitor: Starting SCMHATransactionMonitor Service.
2024-03-29 17:53:12,651 [main] INFO ha.SCMServiceManager: Registering service SCMHATransactionMonitor.
2024-03-29 17:53:12,651 [main] INFO SCMHATransactionMonitor: SCMHATransactionMonitor Service is already running, skip start.
2024-03-29 17:53:12,865 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2024-03-29 17:53:12,907 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2024-03-29 17:53:12,907 [main] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
2024-03-29 17:53:13,307 [main] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
2024-03-29 17:53:13,316 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-03-29 17:53:13,323 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
2024-03-29 17:53:13,418 [main] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
2024-03-29 17:53:13,419 [main] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
2024-03-29 17:53:13,420 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
2024-03-29 17:53:13,421 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-03-29 17:53:13,796 [main] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
2024-03-29 17:53:13,796 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-03-29 17:53:13,820 [main] INFO util.log: Logging initialized @14174ms to org.eclipse.jetty.util.log.Slf4jLog
2024-03-29 17:53:13,897 [main] WARN server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /opt/hadoop/hadoop-http-auth-signature-secret
2024-03-29 17:53:13,902 [main] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
2024-03-29 17:53:13,908 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-03-29 17:53:13,909 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2024-03-29 17:53:13,909 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-03-29 17:53:13,909 [main] INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-03-29 17:53:13,936 [main] INFO http.BaseHttpServer: HTTP server of scm uses base directory /data/metadata/webserver
2024-03-29 17:53:13,936 [main] INFO http.HttpServer2: Jetty bound to port 9876
2024-03-29 17:53:13,937 [main] INFO server.Server: jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 17.0.2+8-86
2024-03-29 17:53:13,961 [main] INFO server.session: DefaultSessionIdManager workerName=node0
2024-03-29 17:53:13,961 [main] INFO server.session: No SessionScavenger set, using defaults
2024-03-29 17:53:13,962 [main] INFO server.session: node0 Scavenging every 600000ms
2024-03-29 17:53:13,972 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@49c947f7{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
2024-03-29 17:53:13,972 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5b72b13a{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.5.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2024-03-29 17:53:14,078 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@1db5de29{scm,/,file:///data/metadata/webserver/jetty-0_0_0_0-9876-hdds-server-scm-1_5_0-SNAPSHOT_jar-_-any-1879285679584174811/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.5.0-SNAPSHOT.jar!/webapps/scm}
2024-03-29 17:53:14,088 [main] INFO server.AbstractConnector: Started ServerConnector@205b73d8{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
2024-03-29 17:53:14,089 [main] INFO server.Server: Started @14442ms
2024-03-29 17:53:14,091 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
2024-03-29 17:53:14,091 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
2024-03-29 17:53:14,092 [main] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
2024-03-29 17:53:17,717 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-FollowerState] INFO impl.FollowerState: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5219136877ns, electionTimeout:5198ms
2024-03-29 17:53:17,718 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-FollowerState] INFO impl.RoleInfo: aa678345-8a5e-4c7e-9814-4ef57b2706b8: shutdown aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-FollowerState
2024-03-29 17:53:17,718 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-FollowerState] INFO server.RaftServer$Division: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2024-03-29 17:53:17,720 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = true (default)
2024-03-29 17:53:17,720 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-FollowerState] INFO impl.RoleInfo: aa678345-8a5e-4c7e-9814-4ef57b2706b8: start aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1
2024-03-29 17:53:17,721 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO impl.LeaderElection: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 1 for 0: peers:[aa678345-8a5e-4c7e-9814-4ef57b2706b8|95fdf36a174b:9894]|listeners:[], old=null
2024-03-29 17:53:17,721 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO impl.LeaderElection: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1 PRE_VOTE round 0: result PASSED (term=1)
2024-03-29 17:53:17,731 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO impl.LeaderElection: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: peers:[aa678345-8a5e-4c7e-9814-4ef57b2706b8|95fdf36a174b:9894]|listeners:[], old=null
2024-03-29 17:53:17,732 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO impl.LeaderElection: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1 ELECTION round 0: result PASSED (term=2)
2024-03-29 17:53:17,732 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO impl.RoleInfo: aa678345-8a5e-4c7e-9814-4ef57b2706b8: shutdown aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1
2024-03-29 17:53:17,732 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServer$Division: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2024-03-29 17:53:17,735 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2024-03-29 17:53:17,737 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2024-03-29 17:53:17,738 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2024-03-29 17:53:17,741 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2024-03-29 17:53:17,741 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2024-03-29 17:53:17,741 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2024-03-29 17:53:17,745 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.enabled = false (default)
2024-03-29 17:53:17,747 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-03-29 17:53:17,747 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2024-03-29 17:53:17,747 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2024-03-29 17:53:17,747 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-03-29 17:53:17,749 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO impl.RoleInfo: aa678345-8a5e-4c7e-9814-4ef57b2706b8: start aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderStateImpl
2024-03-29 17:53:17,749 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServer$Division: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742: set firstElectionSinceStartup to false for becomeLeader
2024-03-29 17:53:17,749 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
2024-03-29 17:53:17,749 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
2024-03-29 17:53:17,750 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServer$Division: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742: change Leader from null to aa678345-8a5e-4c7e-9814-4ef57b2706b8 at term 2 for becomeLeader, leader elected after 7457ms
2024-03-29 17:53:17,754 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2024-03-29 17:53:17,756 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/b971e942-ed47-4c80-90d8-519610457742/current/log_inprogress_0 to /data/metadata/scm-ha/b971e942-ed47-4c80-90d8-519610457742/current/log_0-0
2024-03-29 17:53:17,759 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-SegmentedRaftLogWorker] INFO segmented.BufferedWriteChannel: open log_inprogress_1 at position 0
2024-03-29 17:53:17,762 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-LeaderElection1] INFO server.RaftServer$Division: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742: set configuration 1: peers:[aa678345-8a5e-4c7e-9814-4ef57b2706b8|95fdf36a174b:9894]|listeners:[], old=null
2024-03-29 17:53:17,769 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/b971e942-ed47-4c80-90d8-519610457742/current/log_inprogress_1
2024-03-29 17:53:17,778 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater] INFO server.RaftServer$Division: leader is ready since appliedIndex == 1 >= startIndex == 1
2024-03-29 17:53:17,778 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
2024-03-29 17:53:17,778 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
2024-03-29 17:53:17,783 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:53:17,784 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
2024-03-29 17:53:17,784 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2024-03-29 17:53:17,784 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
2024-03-29 17:53:17,785 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2024-03-29 17:53:17,799 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
2024-03-29 17:53:17,804 [IPC Server handler 1 on default port 9861] INFO ipc.Server: IPC Server handler 1 on default port 9861: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from xcompat_datanode_3.xcompat_default:51830 / 172.26.0.10:51830
2024-03-29 17:53:17,804 [IPC Server handler 2 on default port 9861] INFO ipc.Server: IPC Server handler 2 on default port 9861: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from xcompat_datanode_5.xcompat_default:36574 / 172.26.0.5:36574
2024-03-29 17:53:17,804 [IPC Server handler 1 on default port 9861] INFO ipc.Server: IPC Server handler 1 on default port 9861: skipped Call#0 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from xcompat_datanode_4.xcompat_default:59902 / 172.26.0.4:59902
2024-03-29 17:53:17,804 [IPC Server handler 2 on default port 9861] INFO ipc.Server: IPC Server handler 2 on default port 9861: skipped Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from xcompat_datanode_1.xcompat_default:41266 / 172.26.0.6:41266
2024-03-29 17:53:17,890 [IPC Server handler 0 on default port 9861] WARN ipc.Server: IPC Server handler 0 on default port 9861, call Call#1 Retry#0 org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol.submitRequest from xcompat_datanode_2.xcompat_default:48800 / 172.26.0.2:48800: output error
2024-03-29 17:53:17,891 [IPC Server handler 0 on default port 9861] INFO ipc.Server: IPC Server handler 0 on default port 9861 caught an exception
java.nio.channels.ClosedChannelException
	at java.base/sun.nio.ch.SocketChannelImpl.ensureOpenAndConnected(SocketChannelImpl.java:215)
	at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:527)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3743)
	at org.apache.hadoop.ipc.Server.access$1800(Server.java:148)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1722)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1792)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2919)
	at org.apache.hadoop.ipc.Server$Connection.access$400(Server.java:1864)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1176)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:954)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:940)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1111)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-03-29 17:53:19,124 [IPC Server handler 5 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/ed0f7660-5cac-415d-b837-d8f0b4973b4e
2024-03-29 17:53:19,146 [IPC Server handler 5 on default port 9861] INFO node.SCMNodeManager: Registered datanode: ed0f7660-5cac-415d-b837-d8f0b4973b4e{ip: 172.26.0.10, host: xcompat_datanode_3.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:53:19,163 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2024-03-29 17:53:19,163 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:53:19,171 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
2024-03-29 17:53:19,173 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=539f08e6-9b7c-4dbd-ac6d-d94c526ddcad to datanode:ed0f7660-5cac-415d-b837-d8f0b4973b4e
2024-03-29 17:53:19,200 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2024-03-29 17:53:19,276 [IPC Server handler 7 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/415eeceb-c817-4304-9754-585a9d26e93b
2024-03-29 17:53:19,279 [IPC Server handler 7 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 415eeceb-c817-4304-9754-585a9d26e93b{ip: 172.26.0.5, host: xcompat_datanode_5.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:53:19,280 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:53:19,280 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
2024-03-29 17:53:19,351 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:53:19,365 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 539f08e6-9b7c-4dbd-ac6d-d94c526ddcad, Nodes: ed0f7660-5cac-415d-b837-d8f0b4973b4e(xcompat_datanode_3.xcompat_default/172.26.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:53:19.172298020Z[UTC]]
2024-03-29 17:53:19,367 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=402852e4-b3a2-4fa7-8b5c-7e89e1c7ea09 to datanode:415eeceb-c817-4304-9754-585a9d26e93b
2024-03-29 17:53:19,376 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:53:19,377 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 402852e4-b3a2-4fa7-8b5c-7e89e1c7ea09, Nodes: 415eeceb-c817-4304-9754-585a9d26e93b(xcompat_datanode_5.xcompat_default/172.26.0.5), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:53:19.367570488Z[UTC]]
2024-03-29 17:53:19,506 [IPC Server handler 8 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/d7ce4d0f-8b20-4194-a8ad-b44119347170
2024-03-29 17:53:19,506 [IPC Server handler 8 on default port 9861] INFO node.SCMNodeManager: Registered datanode: d7ce4d0f-8b20-4194-a8ad-b44119347170{ip: 172.26.0.4, host: xcompat_datanode_4.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:53:19,507 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:53:19,507 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
2024-03-29 17:53:19,507 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
2024-03-29 17:53:19,507 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
2024-03-29 17:53:19,507 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2024-03-29 17:53:19,508 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:53:19,508 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=eb565655-d139-4c65-9c93-c5017456f10a to datanode:d7ce4d0f-8b20-4194-a8ad-b44119347170
2024-03-29 17:53:19,514 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:53:19,515 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: eb565655-d139-4c65-9c93-c5017456f10a, Nodes: d7ce4d0f-8b20-4194-a8ad-b44119347170(xcompat_datanode_4.xcompat_default/172.26.0.4), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:53:19.508567554Z[UTC]]
2024-03-29 17:53:19,522 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a07d486e-5240-48a3-84bb-07cc1c89901b to datanode:ed0f7660-5cac-415d-b837-d8f0b4973b4e
2024-03-29 17:53:19,522 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a07d486e-5240-48a3-84bb-07cc1c89901b to datanode:d7ce4d0f-8b20-4194-a8ad-b44119347170
2024-03-29 17:53:19,522 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=a07d486e-5240-48a3-84bb-07cc1c89901b to datanode:415eeceb-c817-4304-9754-585a9d26e93b
2024-03-29 17:53:19,527 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:53:19,528 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: a07d486e-5240-48a3-84bb-07cc1c89901b, Nodes: ed0f7660-5cac-415d-b837-d8f0b4973b4e(xcompat_datanode_3.xcompat_default/172.26.0.10)d7ce4d0f-8b20-4194-a8ad-b44119347170(xcompat_datanode_4.xcompat_default/172.26.0.4)415eeceb-c817-4304-9754-585a9d26e93b(xcompat_datanode_5.xcompat_default/172.26.0.5), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:53:19.522237270Z[UTC]]
2024-03-29 17:53:19,532 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=9c852ec1-ea9e-4082-9fa0-edb6fedcf377 to datanode:415eeceb-c817-4304-9754-585a9d26e93b
2024-03-29 17:53:19,532 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=9c852ec1-ea9e-4082-9fa0-edb6fedcf377 to datanode:d7ce4d0f-8b20-4194-a8ad-b44119347170
2024-03-29 17:53:19,532 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=9c852ec1-ea9e-4082-9fa0-edb6fedcf377 to datanode:ed0f7660-5cac-415d-b837-d8f0b4973b4e
2024-03-29 17:53:19,536 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:53:19,539 [RatisPipelineUtilsThread-0] INFO pipeline.PipelineManagerImpl: Pipeline: PipelineID=9c852ec1-ea9e-4082-9fa0-edb6fedcf377 contains same datanodes as previous pipelines: PipelineID=a07d486e-5240-48a3-84bb-07cc1c89901b nodeIds: 415eeceb-c817-4304-9754-585a9d26e93b, d7ce4d0f-8b20-4194-a8ad-b44119347170, ed0f7660-5cac-415d-b837-d8f0b4973b4e
2024-03-29 17:53:19,539 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 9c852ec1-ea9e-4082-9fa0-edb6fedcf377, Nodes: 415eeceb-c817-4304-9754-585a9d26e93b(xcompat_datanode_5.xcompat_default/172.26.0.5)d7ce4d0f-8b20-4194-a8ad-b44119347170(xcompat_datanode_4.xcompat_default/172.26.0.4)ed0f7660-5cac-415d-b837-d8f0b4973b4e(xcompat_datanode_3.xcompat_default/172.26.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:53:19.531194402Z[UTC]]
2024-03-29 17:53:19,950 [IPC Server handler 78 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/c02a8598-c71a-4fa5-9ce5-6754a1ec9bb8
2024-03-29 17:53:19,955 [IPC Server handler 78 on default port 9861] INFO node.SCMNodeManager: Registered datanode: c02a8598-c71a-4fa5-9ce5-6754a1ec9bb8{ip: 172.26.0.2, host: xcompat_datanode_2.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:53:19,956 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:53:19,958 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=6d6b0c86-e781-4327-aa95-0c79a4735791 to datanode:c02a8598-c71a-4fa5-9ce5-6754a1ec9bb8
2024-03-29 17:53:19,964 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:53:19,965 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 6d6b0c86-e781-4327-aa95-0c79a4735791, Nodes: c02a8598-c71a-4fa5-9ce5-6754a1ec9bb8(xcompat_datanode_2.xcompat_default/172.26.0.2), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:53:19.958645174Z[UTC]]
2024-03-29 17:53:20,542 [IPC Server handler 9 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/5a61586a-b497-4359-89e1-9e8f5ecd7955
2024-03-29 17:53:20,543 [IPC Server handler 9 on default port 9861] INFO node.SCMNodeManager: Registered datanode: 5a61586a-b497-4359-89e1-9e8f5ecd7955{ip: 172.26.0.6, host: xcompat_datanode_1.xcompat_default, ports: [HTTP=9882, CLIENT_RPC=19864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, STANDALONE=9859], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-03-29 17:53:20,544 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
2024-03-29 17:53:20,544 [RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=588b961f-fb2b-4d39-ba40-c0d8c0b3542b to datanode:5a61586a-b497-4359-89e1-9e8f5ecd7955
2024-03-29 17:53:20,548 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:53:20,549 [RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 588b961f-fb2b-4d39-ba40-c0d8c0b3542b, Nodes: 5a61586a-b497-4359-89e1-9e8f5ecd7955(xcompat_datanode_1.xcompat_default/172.26.0.6), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:53:20.544881022Z[UTC]]
2024-03-29 17:53:22,299 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:53:22,299 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=539f08e6-9b7c-4dbd-ac6d-d94c526ddcad
2024-03-29 17:53:22,300 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:53:22,450 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:53:22,740 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:53:22,741 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=402852e4-b3a2-4fa7-8b5c-7e89e1c7ea09
2024-03-29 17:53:22,742 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:53:23,023 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:53:23,110 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:53:23,110 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=eb565655-d139-4c65-9c93-c5017456f10a
2024-03-29 17:53:23,110 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:53:23,309 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:53:23,472 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:53:23,473 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=6d6b0c86-e781-4327-aa95-0c79a4735791
2024-03-29 17:53:23,473 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:53:24,092 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
2024-03-29 17:53:24,093 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=588b961f-fb2b-4d39-ba40-c0d8c0b3542b
2024-03-29 17:53:24,094 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:53:24,462 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:53:24,678 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:53:24,724 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:53:27,411 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-03-29 17:53:27,741 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
2024-03-29 17:53:27,742 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=a07d486e-5240-48a3-84bb-07cc1c89901b
2024-03-29 17:53:27,742 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2024-03-29 17:53:27,742 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
2024-03-29 17:53:27,742 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
2024-03-29 17:53:27,742 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
2024-03-29 17:53:27,742 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2024-03-29 17:53:27,742 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
2024-03-29 17:53:27,742 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2024-03-29 17:53:27,743 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO block.SCMBlockDeletingService: notifyStatusChanged:RUNNING
2024-03-29 17:53:27,743 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
2024-03-29 17:53:27,747 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2024-03-29 17:53:27,749 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO SCMHATransactionMonitor: Service SCMHATransactionMonitor transitions to RUNNING.
2024-03-29 17:53:29,892 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineReportHandler: Opened pipeline PipelineID=9c852ec1-ea9e-4082-9fa0-edb6fedcf377
2024-03-29 17:53:48,061 [IPC Server handler 4 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
2024-03-29 17:53:48,073 [aa678345-8a5e-4c7e-9814-4ef57b2706b8@group-519610457742-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 113750153625600000.
2024-03-29 17:53:48,084 [IPC Server handler 4 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 113750153625600000 to 113750153625601000.
2024-03-29 17:53:58,779 [IPC Server handler 88 on default port 9863] INFO algorithms.SCMContainerPlacementRackScatter: Chosen nodes: [5a61586a-b497-4359-89e1-9e8f5ecd7955(xcompat_datanode_1.xcompat_default/172.26.0.6), 415eeceb-c817-4304-9754-585a9d26e93b(xcompat_datanode_5.xcompat_default/172.26.0.5), ed0f7660-5cac-415d-b837-d8f0b4973b4e(xcompat_datanode_3.xcompat_default/172.26.0.10), c02a8598-c71a-4fa5-9ce5-6754a1ec9bb8(xcompat_datanode_2.xcompat_default/172.26.0.2), d7ce4d0f-8b20-4194-a8ad-b44119347170(xcompat_datanode_4.xcompat_default/172.26.0.4)]. isPolicySatisfied: true.
2024-03-29 17:53:58,794 [IPC Server handler 88 on default port 9863] INFO pipeline.WritableECContainerProvider: Created and opened new pipeline Pipeline[ Id: 3638e036-54ff-4801-b8c2-c3086334da54, Nodes: 5a61586a-b497-4359-89e1-9e8f5ecd7955(xcompat_datanode_1.xcompat_default/172.26.0.6)415eeceb-c817-4304-9754-585a9d26e93b(xcompat_datanode_5.xcompat_default/172.26.0.5)ed0f7660-5cac-415d-b837-d8f0b4973b4e(xcompat_datanode_3.xcompat_default/172.26.0.10)c02a8598-c71a-4fa5-9ce5-6754a1ec9bb8(xcompat_datanode_2.xcompat_default/172.26.0.2)d7ce4d0f-8b20-4194-a8ad-b44119347170(xcompat_datanode_4.xcompat_default/172.26.0.4), ReplicationConfig: EC{rs-3-2-1024k}, State:ALLOCATED, leaderId:, CreationTimestamp2024-03-29T17:53:58.779641756Z[UTC]]
2024-03-29 17:55:30,158 [IPC Server handler 0 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
