2024-04-06 10:33:13,801 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(143)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-04-06 10:33:13,979 [main] INFO  reflections.Reflections (Reflections.java:scan(219)) - Reflections took 150 ms to scan 7 urls, producing 158 keys and 372 values
2024-04-06 10:33:14,166 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(143)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-04-06 10:33:14,171 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(207)) - ServiceID for StorageContainerManager is null
2024-04-06 10:33:14,181 [main] WARN  ha.SCMHANodeDetails (SCMHANodeDetails.java:validateSCMHAConfig(180)) - Default/Configured value of config ozone.scm.ratis.enable conflicts with the expected value. Default/Configured: true. Expected: false. Falling back to the expected value. Current State of SCM: SCM is running without Ratis. Ratis SCM -> Non Ratis SCM is not supported.
2024-04-06 10:33:14,182 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(212)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2024-04-06 10:33:14,754 [main] WARN  utils.HAUtils (HAUtils.java:getMetaDir(339)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-04-06 10:33:14,856 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(171)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-04-06 10:33:14,865 [main] INFO  utils.LeakDetector (LeakDetector.java:start(73)) - Starting leak detector thread ManagedRocksObject0.
2024-04-06 10:33:15,071 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [file:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/classes/network-topology-default.xml]
2024-04-06 10:33:15,073 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2024-04-06 10:33:15,117 [main] INFO  metrics.MetricRegistries (MetricRegistriesLoader.java:load(64)) - Loaded MetricRegistries class org.apache.ratis.metrics.dropwizard3.Dm3MetricRegistriesImpl
2024-04-06 10:33:15,131 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-04-06 10:33:15,286 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(370)) - upgrade localId to 113750153625600000
2024-04-06 10:33:15,288 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(380)) - upgrade delTxnId to 0
2024-04-06 10:33:15,295 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(397)) - upgrade containerId to 0
2024-04-06 10:33:15,299 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToCertificateSequenceId(444)) - upgrade CertificateId to 2
2024-04-06 10:33:15,302 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(241)) - Init the HA SequenceIdGenerator.
2024-04-06 10:33:15,355 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(177)) - Entering startup safe mode.
2024-04-06 10:33:15,366 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2024-04-06 10:33:15,368 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2024-04-06 10:33:15,396 [main] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2024-04-06 10:33:15,408 [main] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2024-04-06 10:33:15,409 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2024-04-06 10:33:15,414 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2024-04-06 10:33:15,415 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(127)) - Starting RatisPipelineUtilsThread.
2024-04-06 10:33:15,418 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(65)) - Starting BackgroundPipelineScrubber Service.
2024-04-06 10:33:15,419 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2024-04-06 10:33:15,425 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(65)) - Starting ExpiredContainerReplicaOpScrubber Service.
2024-04-06 10:33:15,426 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2024-04-06 10:33:15,446 [main] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(80)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-04-06 10:33:15,447 [main] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(80)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2024-04-06 10:33:15,478 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2024-04-06 10:33:15,595 [main] INFO  replication.ReplicationManager (ReplicationManager.java:start(295)) - Starting Replication Monitor Thread.
2024-04-06 10:33:15,597 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2024-04-06 10:33:15,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:15,608 [main] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(91)) - containers with one replica threshold count 0
2024-04-06 10:33:15,612 [main] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(176)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2024-04-06 10:33:15,615 [main] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(193)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2024-04-06 10:33:15,660 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(440)) - SCM start with adminUsers: [runner]
2024-04-06 10:33:15,883 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for SCMAudit to [].
2024-04-06 10:33:15,912 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-04-06 10:33:15,943 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15002
2024-04-06 10:33:15,945 [Socket Reader #1 for port 15002] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15002
2024-04-06 10:33:15,990 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for SCMAudit to [].
2024-04-06 10:33:15,994 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-04-06 10:33:15,995 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15001
2024-04-06 10:33:15,996 [Socket Reader #1 for port 15001] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15001
2024-04-06 10:33:16,018 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for SCMAudit to [].
2024-04-06 10:33:16,027 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-04-06 10:33:16,027 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15000
2024-04-06 10:33:16,028 [Socket Reader #1 for port 15000] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15000
2024-04-06 10:33:16,066 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2024-04-06 10:33:16,067 [main] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(225)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2024-04-06 10:33:16,069 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1545)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:15000
2024-04-06 10:33:16,129 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(136)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2024-04-06 10:33:16,140 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2024-04-06 10:33:16,141 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2024-04-06 10:33:16,371 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(204)) - RPC server for Client  is listening at /0.0.0.0:15000
2024-04-06 10:33:16,371 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-04-06 10:33:16,372 [IPC Server listener on 15000] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15000: starting
2024-04-06 10:33:16,405 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1558)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:15001
2024-04-06 10:33:16,406 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(162)) - RPC server for Block Protocol is listening at /0.0.0.0:15001
2024-04-06 10:33:16,407 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-04-06 10:33:16,407 [IPC Server listener on 15001] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15001: starting
2024-04-06 10:33:16,416 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(194)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:15002
2024-04-06 10:33:16,417 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-04-06 10:33:16,418 [IPC Server listener on 15002] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15002: starting
2024-04-06 10:33:16,430 [JvmPauseMonitor0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-81d466ec-566f-42e5-9a02-20848490241e: Started
2024-04-06 10:33:16,439 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for scm at: http://0.0.0.0:15003
2024-04-06 10:33:16,440 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-04-06 10:33:16,458 [main] INFO  util.log (Log.java:initialized(170)) - Logging initialized @4258ms to org.eclipse.jetty.util.log.Slf4jLog
2024-04-06 10:33:16,552 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-04-06 10:33:16,557 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.scm is not defined
2024-04-06 10:33:16,561 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-04-06 10:33:16,563 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2024-04-06 10:33:16,563 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-04-06 10:33:16,564 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-04-06 10:33:16,590 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of scm uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/webserver
2024-04-06 10:33:16,590 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15003
2024-04-06 10:33:16,591 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-04-06 10:33:16,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:16,611 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-04-06 10:33:16,612 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-04-06 10:33:16,613 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2024-04-06 10:33:16,622 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@4c43c37d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-04-06 10:33:16,623 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@28f5a003{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2024-04-06 10:33:16,654 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@16a4e4c9{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2024-04-06 10:33:16,659 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@6517bc6b{HTTP/1.1, (http/1.1)}{0.0.0.0:15003}
2024-04-06 10:33:16,659 [main] INFO  server.Server (Server.java:doStart(415)) - Started @4459ms
2024-04-06 10:33:16,662 [main] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2024-04-06 10:33:16,662 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2024-04-06 10:33:16,663 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of scm listening at http://0.0.0.0:15003
2024-04-06 10:33:16,665 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-04-06 10:33:16,721 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for OMAudit to [].
2024-04-06 10:33:16,787 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(115)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2024-04-06 10:33:16,790 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(226)) - Configuration does not have ozone.om.address set. Falling back to the default OM address /127.0.0.1:15004
2024-04-06 10:33:16,790 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(254)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2024-04-06 10:33:16,791 [main] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(261)) - OM Node ID is not set. Setting it to the default ID: om1
2024-04-06 10:33:16,794 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-04-06 10:33:16,798 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = QUOTA (version = 6), software layout = QUOTA (version = 6)
2024-04-06 10:33:16,859 [main] INFO  reflections.Reflections (Reflections.java:scan(219)) - Reflections took 60 ms to scan 2 urls, producing 187 keys and 543 values
2024-04-06 10:33:16,862 [main] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(113)) - Skipping Upgrade Action QuotaRepairUpgradeAction since it has been finalized.
2024-04-06 10:33:16,863 [main] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(113)) - Skipping Upgrade Action MockOmUpgradeAction since it has been finalized.
2024-04-06 10:33:16,865 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-04-06 10:33:16,984 [main] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(115)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:15001]
2024-04-06 10:33:17,009 [main] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(115)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:15001]
2024-04-06 10:33:17,177 [main] INFO  om.OzoneManager (OzoneManager.java:<init>(677)) - OM start with adminUsers: [runner]
2024-04-06 10:33:17,206 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-04-06 10:33:17,225 [main] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(71)) - OmKeyInfo.getCodec ignorePipeline = true
2024-04-06 10:33:17,447 [main] INFO  om.OzoneManager (OzoneManager.java:instantiateServices(811)) - S3 Multi-Tenancy is disabled
2024-04-06 10:33:17,469 [main] INFO  om.OmSnapshotManager (OmSnapshotManager.java:<init>(177)) - Ozone filesystem snapshot feature is enabled.
2024-04-06 10:33:17,475 [main] WARN  server.ServerUtils (ServerUtils.java:getDBPath(299)) - ozone.om.snapshot.diff.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2024-04-06 10:33:17,504 [main] INFO  utils.NativeLibraryLoader (NativeLibraryLoader.java:loadLibrary(108)) - Loading Library: ozone_rocksdb_tools
2024-04-06 10:33:17,505 [main] ERROR snapshot.SnapshotDiffManager (SnapshotDiffManager.java:initNativeLibraryForEfficientDiff(287)) - Native Library for raw sst file reading loading failed.
org.apache.hadoop.hdds.utils.NativeLibraryNotLoadedException: Unable to load library ozone_rocksdb_tools from both java.library.path & resource file libozone_rocksdb_tools.so from jar.
	at org.apache.hadoop.hdds.utils.db.managed.ManagedRawSSTFileReader.loadLibrary(ManagedRawSSTFileReader.java:38)
	at org.apache.hadoop.ozone.om.snapshot.SnapshotDiffManager.initNativeLibraryForEfficientDiff(SnapshotDiffManager.java:285)
	at org.apache.hadoop.ozone.om.snapshot.SnapshotDiffManager.<init>(SnapshotDiffManager.java:259)
	at org.apache.hadoop.ozone.om.OmSnapshotManager.<init>(OmSnapshotManager.java:279)
	at org.apache.hadoop.ozone.om.OzoneManager.instantiateServices(OzoneManager.java:863)
	at org.apache.hadoop.ozone.om.OzoneManager.<init>(OzoneManager.java:687)
	at org.apache.hadoop.ozone.om.OzoneManager.createOm(OzoneManager.java:774)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.createOM(MiniOzoneClusterImpl.java:689)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.createAndStartSingleOM(MiniOzoneClusterImpl.java:673)
	at org.apache.hadoop.ozone.MiniOzoneClusterImpl$Builder.build(MiniOzoneClusterImpl.java:535)
	at org.apache.hadoop.ozone.recon.TestReconAndAdminContainerCLI.init(TestReconAndAdminContainerCLI.java:134)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:728)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:156)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptLifecycleMethod(TimeoutExtension.java:128)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptBeforeAllMethod(TimeoutExtension.java:70)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(InterceptingExecutableInvoker.java:103)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:93)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:92)
	at org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:86)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.lambda$invokeBeforeAllMethods$13(ClassBasedTestDescriptor.java:412)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.invokeBeforeAllMethods(ClassBasedTestDescriptor.java:410)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:216)
	at org.junit.jupiter.engine.descriptor.ClassBasedTestDescriptor.before(ClassBasedTestDescriptor.java:85)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:148)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:198)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:169)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:93)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:58)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:141)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:57)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:103)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:85)
	at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:63)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2024-04-06 10:33:17,554 [main] INFO  om.OzoneManager (OzoneManager.java:addS3GVolumeToDB(4463)) - Created Volume s3v With Owner runner required for S3Gateway operations.
2024-04-06 10:33:17,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:17,601 [main] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(311)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2024-04-06 10:33:17,601 [main] WARN  utils.OzoneManagerRatisUtils (OzoneManagerRatisUtils.java:getOMRatisSnapshotDirectory(476)) - ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
2024-04-06 10:33:17,612 [main] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(311)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2024-04-06 10:33:17,629 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(167)) - Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: localhost:15007
2024-04-06 10:33:17,638 [main] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:loadSnapshotInfoFromDB(589)) - TransactionInfo not found in OM DB.
2024-04-06 10:33:17,800 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-04-06 10:33:17,807 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-04-06 10:33:17,808 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.port = 15007 (fallback to raft.grpc.server.port)
2024-04-06 10:33:17,808 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-04-06 10:33:17,809 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.port = 15007 (fallback to raft.grpc.server.port)
2024-04-06 10:33:17,809 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-04-06 10:33:17,810 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15007 (custom)
2024-04-06 10:33:17,810 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 4194304 (custom)
2024-04-06 10:33:17,811 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2024-04-06 10:33:17,812 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2024-04-06 10:33:17,812 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2024-04-06 10:33:17,819 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-04-06 10:33:17,822 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-04-06 10:33:17,822 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-04-06 10:33:17,993 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2024-04-06 10:33:17,995 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:33:17,996 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-04-06 10:33:17,996 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:33:17,997 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/ratis] (custom)
2024-04-06 10:33:17,998 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-04-06 10:33:17,998 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-04-06 10:33:18,003 [main] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - om1: addNew group-C5BA1605619E:[om1|localhost:15007] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@e447d2d[Not completed]
2024-04-06 10:33:18,003 [main] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(2168)) - OzoneManager Ratis server initialized at port 15007
2024-04-06 10:33:18,006 [main] INFO  om.OzoneManager (OzoneManager.java:getRpcServer(1227)) - Creating RPC Server
2024-04-06 10:33:18,013 [om1-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - om1: new RaftServerImpl for group-C5BA1605619E:[om1|localhost:15007] with OzoneManagerStateMachine:uninitialized
2024-04-06 10:33:18,014 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2024-04-06 10:33:18,015 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 1200ms (custom)
2024-04-06 10:33:18,015 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-04-06 10:33:18,015 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2024-04-06 10:33:18,016 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:33:18,016 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-04-06 10:33:18,016 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:33:18,021 [om1-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - om1@group-C5BA1605619E: ConfigurationManager, init=-1: peers:[om1|localhost:15007]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-04-06 10:33:18,025 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 120s (custom)
2024-04-06 10:33:18,028 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-04-06 10:33:18,033 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 300s (custom)
2024-04-06 10:33:18,033 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-04-06 10:33:18,036 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-04-06 10:33:18,037 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-04-06 10:33:18,088 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2024-04-06 10:33:18,092 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:33:18,092 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-04-06 10:33:18,093 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-04-06 10:33:18,093 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-04-06 10:33:18,094 [om1-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-04-06 10:33:18,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:18,906 [main] INFO  reflections.Reflections (Reflections.java:scan(219)) - Reflections took 860 ms to scan 20 urls, producing 58 keys and 6519 values
2024-04-06 10:33:19,048 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-04-06 10:33:19,049 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 127.0.0.1:15004
2024-04-06 10:33:19,050 [Socket Reader #1 for port 15004] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15004
2024-04-06 10:33:19,076 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2024-04-06 10:33:19,085 [main] INFO  om.OzoneManager (OzoneManager.java:start(1649)) - OzoneManager RPC server is listening at localhost/127.0.0.1:15004
2024-04-06 10:33:19,086 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(588)) - Starting OzoneManagerRatisServer om1 at port 15007
2024-04-06 10:33:19,089 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-04-06 10:33:19,089 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-04-06 10:33:19,089 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/ratis] (custom)
2024-04-06 10:33:19,095 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2024-04-06 10:33:19,099 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 82778@fv-az526-218
2024-04-06 10:33:19,104 [om1-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2024-04-06 10:33:19,105 [om1-impl-thread1] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/raft-meta.conf
2024-04-06 10:33:19,108 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-04-06 10:33:19,117 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-04-06 10:33:19,117 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2024-04-06 10:33:19,119 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-04-06 10:33:19,119 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-04-06 10:33:19,123 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2024-04-06 10:33:19,129 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-04-06 10:33:19,129 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-04-06 10:33:19,130 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2024-04-06 10:33:19,131 [om1-impl-thread1] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[om1@group-C5BA1605619E-cacheEviction-AwaitToRun,5,main] started
2024-04-06 10:33:19,135 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2024-04-06 10:33:19,135 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2024-04-06 10:33:19,135 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2024-04-06 10:33:19,137 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2024-04-06 10:33:19,137 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-04-06 10:33:19,138 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-04-06 10:33:19,138 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-04-06 10:33:19,139 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-04-06 10:33:19,139 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2024-04-06 10:33:19,140 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 4194312 (custom)
2024-04-06 10:33:19,141 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 4194304 (custom)
2024-04-06 10:33:19,141 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-04-06 10:33:19,142 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-04-06 10:33:19,142 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2024-04-06 10:33:19,148 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-04-06 10:33:19,148 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-04-06 10:33:19,149 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - om1@group-C5BA1605619E: start as a follower, conf=-1: peers:[om1|localhost:15007]|listeners:[], old=null
2024-04-06 10:33:19,149 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-04-06 10:33:19,150 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-FollowerState
2024-04-06 10:33:19,151 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 1s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:33:19,151 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 1200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:33:19,152 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2024-04-06 10:33:19,153 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-04-06 10:33:19,153 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-04-06 10:33:19,154 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2024-04-06 10:33:19,154 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2024-04-06 10:33:19,154 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = true (custom)
2024-04-06 10:33:19,158 [main] INFO  server.RaftServer (RaftServerProxy.java:startImpl(406)) - om1: start RPC server
2024-04-06 10:33:19,194 [main] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - om1: GrpcService started, listening on 15007
2024-04-06 10:33:19,198 [main] INFO  om.OzoneManager (OzoneManager.java:start(1665)) - Version File has different layout version (6) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
2024-04-06 10:33:19,201 [JvmPauseMonitor1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-om1: Started
2024-04-06 10:33:19,215 [main] INFO  client.ScmTopologyClient (ScmTopologyClient.java:start(72)) - Initial network topology fetched from SCM: /.
2024-04-06 10:33:19,216 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [file:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/classes/network-topology-default.xml]
2024-04-06 10:33:19,216 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2024-04-06 10:33:19,233 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for ozoneManager at: http://0.0.0.0:15005
2024-04-06 10:33:19,234 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-04-06 10:33:19,235 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-04-06 10:33:19,236 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.ozoneManager is not defined
2024-04-06 10:33:19,237 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-04-06 10:33:19,238 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2024-04-06 10:33:19,238 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-04-06 10:33:19,239 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-04-06 10:33:19,240 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of ozoneManager uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/webserver
2024-04-06 10:33:19,242 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15005
2024-04-06 10:33:19,242 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-04-06 10:33:19,243 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-04-06 10:33:19,244 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-04-06 10:33:19,244 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2024-04-06 10:33:19,245 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@5c2bc446{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-04-06 10:33:19,245 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@44c7d474{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2024-04-06 10:33:19,248 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@7181f2ac{ozoneManager,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2024-04-06 10:33:19,250 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@287d872b{HTTP/1.1, (http/1.1)}{0.0.0.0:15005}
2024-04-06 10:33:19,250 [main] INFO  server.Server (Server.java:doStart(415)) - Started @7050ms
2024-04-06 10:33:19,250 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-04-06 10:33:19,251 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of ozoneManager listening at http://0.0.0.0:15005
2024-04-06 10:33:19,251 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-04-06 10:33:19,251 [IPC Server listener on 15004] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15004: starting
2024-04-06 10:33:19,257 [main] INFO  om.OzoneManager (OzoneManager.java:startTrashEmptier(2121)) - Trash Interval set to 0. Files deleted won't move to trash
2024-04-06 10:33:19,349 [main] INFO  db.CodecBuffer (CodecBuffer.java:set(63)) - Successfully set constructor to org.apache.hadoop.hdds.utils.db.CodecBuffer$$Lambda$1031/1312556204@2ad077c8
2024-04-06 10:33:19,457 [main] INFO  recon.ReconServer (StringUtils.java:startupShutdownMessage(132)) - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting ReconServer
STARTUP_MSG:   host = fv-az526-218/10.1.0.10
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.5.0-SNAPSHOT
STARTUP_MSG:   classpath = /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/classes:/home/runner/work/ozone/ozone/hadoop-ozone/common/target/classes:/home/runner/.m2/repository/io/grpc/grpc-netty/1.58.0/grpc-netty-1.58.0.jar:/home/runner/.m2/repository/io/grpc/grpc-core/1.58.0/grpc-core-1.58.0.jar:/home/runner/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/runner/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.23/animal-sniffer-annotations-1.23.jar:/home/runner/.m2/repository/io/grpc/grpc-context/1.58.0/grpc-context-1.58.0.jar:/home/runner/.m2/repository/io/grpc/grpc-util/1.58.0/grpc-util-1.58.0.jar:/home/runner/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/runner/.m2/repository/io/perfmark/perfmark-api/0.26.0/perfmark-api-0.26.0.jar:/home/runner/.m2/repository/io/netty/netty-codec-http2/4.1.100.Final/netty-codec-http2-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-common/4.1.100.Final/netty-common-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-buffer/4.1.100.Final/netty-buffer-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.100.Final/netty-codec-http-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-proxy/4.1.100.Final/netty-handler-proxy-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-socks/4.1.100.Final/netty-codec-socks-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-classes/2.0.61.Final/netty-tcnative-classes-2.0.61.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-linux-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-osx-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.61.Final/netty-tcnative-boringssl-static-2.0.61.Final-windows-x86_64.jar:/home/runner/.m2/repository/org/apache/commons/commons-compress/1.26.0/commons-compress-1.26.0.jar:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/classes:/home/runner/work/ozone/ozone/hadoop-hdds/client/target/classes:/home/runner/work/ozone/ozone/hadoop-ozone/interface-client/target/classes:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.3.6/hadoop-hdfs-client-3.3.6.jar:/home/runner/.m2/repository/com/squareup/okhttp3/okhttp/4.12.0/okhttp-4.12.0.jar:/home/runner/.m2/repository/com/squareup/okio/okio/3.6.0/okio-3.6.0.jar:/home/runner/.m2/repository/com/squareup/okio/okio-jvm/3.6.0/okio-jvm-3.6.0.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-jdk8/1.9.22/kotlin-stdlib-jdk8-1.9.22.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-jdk7/1.9.22/kotlin-stdlib-jdk7-1.9.22.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.9.22/kotlin-stdlib-common-1.9.22.jar:/home/runner/work/ozone/ozone/hadoop-hdds/test-utils/target/classes:/home/runner/.m2/repository/org/assertj/assertj-core/3.12.2/assertj-core-3.12.2.jar:/home/runner/.m2/repository/com/google/guava/guava/32.0.0-jre/guava-32.0.0-jre.jar:/home/runner/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/runner/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/runner/.m2/repository/org/checkerframework/checker-qual/3.33.0/checker-qual-3.33.0.jar:/home/runner/.m2/repository/com/google/j2objc/j2objc-annotations/2.8/j2objc-annotations-2.8.jar:/home/runner/.m2/repository/commons-io/commons-io/2.16.0/commons-io-2.16.0.jar:/home/runner/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.10.2/junit-jupiter-api-5.10.2.jar:/home/runner/.m2/repository/org/opentest4j/opentest4j/1.3.0/opentest4j-1.3.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-commons/1.10.2/junit-platform-commons-1.10.2.jar:/home/runner/.m2/repository/ch/qos/reload4j/reload4j/1.2.25/reload4j-1.2.25.jar:/home/runner/.m2/repository/jakarta/annotation/jakarta.annotation-api/2.1.1/jakarta.annotation-api-2.1.1.jar:/home/runner/.m2/repository/org/slf4j/slf4j-api/2.0.12/slf4j-api-2.0.12.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-api/2.17.1/log4j-api-2.17.1.jar:/home/runner/work/ozone/ozone/hadoop-hdds/server-scm/target/classes:/home/runner/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes:/home/runner/work/ozone/ozone/hadoop-hdds/hadoop-dependency-server/target/classes:/home/runner/.m2/repository/com/nimbusds/nimbus-jose-jwt/9.37.2/nimbus-jose-jwt-9.37.2.jar:/home/runner/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.6/hadoop-hdfs-3.3.6.jar:/home/runner/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.10.5/snappy-java-1.1.10.5.jar:/home/runner/work/ozone/ozone/hadoop-hdds/framework/target/classes:/home/runner/.m2/repository/org/bouncycastle/bcprov-jdk18on/1.77/bcprov-jdk18on-1.77.jar:/home/runner/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-text/1.11.0/commons-text-1.11.0.jar:/home/runner/work/ozone/ozone/hadoop-hdds/framework/target/test-classes:/home/runner/work/ozone/ozone/hadoop-hdds/interface-server/target/classes:/home/runner/work/ozone/ozone/hadoop-hdds/interface-admin/target/classes:/home/runner/work/ozone/ozone/hadoop-hdds/managed-rocksdb/target/classes:/home/runner/.m2/repository/org/rocksdb/rocksdbjni/7.7.3/rocksdbjni-7.7.3.jar:/home/runner/.m2/repository/org/slf4j/slf4j-reload4j/2.0.12/slf4j-reload4j-2.0.12.jar:/home/runner/.m2/repository/org/apache/commons/commons-configuration2/2.10.1/commons-configuration2-2.10.1.jar:/home/runner/.m2/repository/commons-fileupload/commons-fileupload/1.5/commons-fileupload-1.5.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-core/2.17.1/log4j-core-2.17.1.jar:/home/runner/.m2/repository/com/lmax/disruptor/3.4.4/disruptor-3.4.4.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util/9.4.53.v20231009/jetty-util-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-server/9.4.53.v20231009/jetty-server-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-http/9.4.53.v20231009/jetty-http-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-io/9.4.53.v20231009/jetty-io-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.53.v20231009/jetty-servlet-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-security/9.4.53.v20231009/jetty-security-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.53.v20231009/jetty-util-ajax-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.53.v20231009/jetty-webapp-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.53.v20231009/jetty-xml-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server/3.0.1/ratis-server-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/1.0.5/ratis-thirdparty-misc-1.0.5.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-proto/3.0.1/ratis-proto-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-common/3.0.1/ratis-common-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-client/3.0.1/ratis-client-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server-api/3.0.1/ratis-server-api-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics-api/3.0.1/ratis-metrics-api-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics-dropwizard3/3.0.1/ratis-metrics-dropwizard3-3.0.1.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_dropwizard/0.16.0/simpleclient_dropwizard-0.16.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient/0.16.0/simpleclient-0.16.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_common/0.16.0/simpleclient_common-0.16.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.16.1/jackson-datatype-jsr310-2.16.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.16.1/jackson-core-2.16.1.jar:/home/runner/work/ozone/ozone/hadoop-hdds/rocksdb-checkpoint-differ/target/classes:/home/runner/.m2/repository/org/jgrapht/jgrapht-core/1.4.0/jgrapht-core-1.4.0.jar:/home/runner/.m2/repository/org/jheaps/jheaps/0.11/jheaps-0.11.jar:/home/runner/.m2/repository/org/jgrapht/jgrapht-ext/1.4.0/jgrapht-ext-1.4.0.jar:/home/runner/.m2/repository/com/github/vlsi/mxgraph/jgraphx/3.9.8.1/jgraphx-3.9.8.1.jar:/home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/target/classes:/home/runner/.m2/repository/org/aspectj/aspectjrt/1.9.7/aspectjrt-1.9.7.jar:/home/runner/.m2/repository/org/aspectj/aspectjweaver/1.9.7/aspectjweaver-1.9.7.jar:/home/runner/work/ozone/ozone/hadoop-hdds/interface-client/target/classes:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-protobuf_3_7/1.1.1/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/runner/work/ozone/ozone/hadoop-ozone/interface-storage/target/classes:/home/runner/.m2/repository/org/reflections/reflections/0.10.2/reflections-0.10.2.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-client/1.19.4/jersey-client-1.19.4.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-intg/2.3.0/ranger-intg-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-common/2.3.0/ranger-plugins-common-2.3.0.jar:/home/runner/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-cred/2.3.0/ranger-plugins-cred-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-audit/2.3.0/ranger-plugins-audit-2.3.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-client/9.4.53.v20231009/jetty-client-9.4.53.v20231009.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpmime/4.5.6/httpmime-4.5.6.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore-nio/4.4.16/httpcore-nio-4.4.16.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpasyncclient/4.1.3/httpasyncclient-4.1.3.jar:/home/runner/.m2/repository/com/carrotsearch/hppc/0.8.0/hppc-0.8.0.jar:/home/runner/.m2/repository/org/apache/orc/orc-core/1.5.8/orc-core-1.5.8.jar:/home/runner/.m2/repository/net/java/dev/jna/jna/5.2.0/jna-5.2.0.jar:/home/runner/.m2/repository/net/java/dev/jna/jna-platform/5.2.0/jna-platform-5.2.0.jar:/home/runner/.m2/repository/com/kstruct/gethostname4j/0.0.2/gethostname4j-0.0.2.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugin-classloader/2.3.0/ranger-plugin-classloader-2.3.0.jar:/home/runner/work/ozone/ozone/hadoop-hdds/rocks-native/target/classes:/home/runner/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.3.6/hadoop-minikdc-3.3.6.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/runner/.m2/repository/junit/junit/4.13.2/junit-4.13.2.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/runner/work/ozone/ozone/hadoop-ozone/s3gateway/target/classes:/home/runner/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/home/runner/.m2/repository/org/jboss/weld/servlet/weld-servlet-shaded/3.1.9.Final/weld-servlet-shaded-3.1.9.Final.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.42/jersey-container-servlet-core-2.42.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-common/2.42/jersey-common-2.42.jar:/home/runner/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.42/jersey-cdi1x-2.42.jar:/home/runner/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.42/jersey-hk2-2.42.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.42/jersey-media-jaxb-2.42.jar:/home/runner/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-api/2.6.1/hk2-api-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-utils/2.6.1/hk2-utils-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.6.1/aopalliance-repackaged-2.6.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.16.1/jackson-dataformat-xml-2.16.1.jar:/home/runner/.m2/repository/org/codehaus/woodstox/stax2-api/4.2.2/stax2-api-4.2.2.jar:/home/runner/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.4.0/woodstox-core-5.4.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.16.1/jackson-module-jaxb-annotations-2.16.1.jar:/home/runner/.m2/repository/javax/enterprise/cdi-api/2.0/cdi-api-2.0.jar:/home/runner/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/runner/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/runner/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/runner/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.3/jakarta.xml.bind-api-2.3.3.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-runtime/2.3.9/jaxb-runtime-2.3.9.jar:/home/runner/.m2/repository/org/glassfish/jaxb/txw2/2.3.9/txw2-2.3.9.jar:/home/runner/.m2/repository/com/sun/istack/istack-commons-runtime/3.0.12/istack-commons-runtime-3.0.12.jar:/home/runner/.m2/repository/com/sun/activation/jakarta.activation/1.2.2/jakarta.activation-1.2.2.jar:/home/runner/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.2/jakarta.activation-api-1.2.2.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf/1.58.0/grpc-protobuf-1.58.0.jar:/home/runner/.m2/repository/com/google/api/grpc/proto-google-common-protos/2.22.0/proto-google-common-protos-2.22.0.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf-lite/1.58.0/grpc-protobuf-lite-1.58.0.jar:/home/runner/.m2/repository/io/grpc/grpc-stub/1.58.0/grpc-stub-1.58.0.jar:/home/runner/.m2/repository/io/netty/netty-transport/4.1.100.Final/netty-transport-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver/4.1.100.Final/netty-resolver-4.1.100.Final.jar:/home/runner/work/ozone/ozone/hadoop-ozone/csi/target/classes:/home/runner/.m2/repository/com/google/protobuf/protobuf-java-util/3.19.6/protobuf-java-util-3.19.6.jar:/home/runner/.m2/repository/com/google/code/gson/gson/2.10.1/gson-2.10.1.jar:/home/runner/work/ozone/ozone/hadoop-hdds/config/target/classes:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.100.Final/netty-transport-native-epoll-4.1.100.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.100.Final/netty-transport-classes-epoll-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.100.Final/netty-transport-native-unix-common-4.1.100.Final.jar:/home/runner/work/ozone/ozone/hadoop-ozone/recon/target/classes:/home/runner/work/ozone/ozone/hadoop-ozone/recon-codegen/target/classes:/home/runner/.m2/repository/com/google/inject/guice/6.0.0/guice-6.0.0.jar:/home/runner/.m2/repository/jakarta/inject/jakarta.inject-api/2.0.1/jakarta.inject-api-2.0.1.jar:/home/runner/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-assistedinject/6.0.0/guice-assistedinject-6.0.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-servlet/6.0.0/guice-servlet-6.0.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.42/jersey-container-servlet-2.42.jar:/home/runner/.m2/repository/org/glassfish/hk2/guice-bridge/2.6.1/guice-bridge-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-server/2.42/jersey-server-2.42.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-client/2.42/jersey-client-2.42.jar:/home/runner/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.42/jersey-media-json-jackson-2.42.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.42/jersey-entity-filtering-2.42.jar:/home/runner/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/runner/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/runner/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/runner/.m2/repository/org/xerial/sqlite-jdbc/3.44.1.0/sqlite-jdbc-3.44.1.0.jar:/home/runner/.m2/repository/org/springframework/spring-jdbc/5.3.27/spring-jdbc-5.3.27.jar:/home/runner/.m2/repository/org/springframework/spring-beans/5.3.27/spring-beans-5.3.27.jar:/home/runner/.m2/repository/org/springframework/spring-core/5.3.27/spring-core-5.3.27.jar:/home/runner/.m2/repository/org/springframework/spring-tx/5.3.27/spring-tx-5.3.27.jar:/home/runner/work/ozone/ozone/hadoop-ozone/client/target/classes:/home/runner/work/ozone/ozone/hadoop-hdds/erasurecode/target/classes:/home/runner/work/ozone/ozone/hadoop-ozone/ozonefs/target/classes:/home/runner/work/ozone/ozone/hadoop-ozone/ozonefs-common/target/classes:/home/runner/work/ozone/ozone/hadoop-ozone/tools/target/classes:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-core/1.12.661/aws-java-sdk-core-1.12.661.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpclient/4.5.14/httpclient-4.5.14.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore/4.4.16/httpcore-4.4.16.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.16.1/jackson-dataformat-cbor-2.16.1.jar:/home/runner/.m2/repository/joda-time/joda-time/2.12.7/joda-time-2.12.7.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.12.661/aws-java-sdk-s3-1.12.661.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.12.661/aws-java-sdk-kms-1.12.661.jar:/home/runner/.m2/repository/com/amazonaws/jmespath-java/1.12.661/jmespath-java-1.12.661.jar:/home/runner/.m2/repository/org/kohsuke/metainf-services/metainf-services/1.11/metainf-services-1.11.jar:/home/runner/work/ozone/ozone/hadoop-hdds/tools/target/classes:/home/runner/.m2/repository/org/apache/ratis/ratis-tools/3.0.1/ratis-tools-3.0.1.jar:/home/runner/.m2/repository/commons-cli/commons-cli/1.6.0/commons-cli-1.6.0.jar:/home/runner/.m2/repository/org/apache/commons/commons-lang3/3.14.0/commons-lang3-3.14.0.jar:/home/runner/work/ozone/ozone/hadoop-ozone/ozone-manager/target/test-classes:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/test-classes:/home/runner/work/ozone/ozone/hadoop-hdds/hadoop-dependency-client/target/classes:/home/runner/.m2/repository/info/picocli/picocli/4.7.5/picocli-4.7.5.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.16.1/jackson-annotations-2.16.1.jar:/home/runner/work/ozone/ozone/hadoop-hdds/annotations/target/classes:/home/runner/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-netty/3.0.1/ratis-netty-3.0.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-grpc/3.0.1/ratis-grpc-3.0.1.jar:/home/runner/.m2/repository/org/bouncycastle/bcpkix-jdk18on/1.77/bcpkix-jdk18on-1.77.jar:/home/runner/.m2/repository/org/bouncycastle/bcutil-jdk18on/1.77/bcutil-jdk18on-1.77.jar:/home/runner/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/runner/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/runner/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/runner/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-client/1.8.1/jaeger-client-1.8.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-thrift/1.8.1/jaeger-thrift-1.8.1.jar:/home/runner/.m2/repository/org/apache/thrift/libthrift/0.15.0/libthrift-0.15.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-core/1.8.1/jaeger-core-1.8.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.8.1/jaeger-tracerresolver-1.8.1.jar:/home/runner/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.9.22/kotlin-stdlib-1.9.22.jar:/home/runner/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/runner/.m2/repository/org/yaml/snakeyaml/2.0/snakeyaml-2.0.jar:/home/runner/.m2/repository/io/grpc/grpc-api/1.58.0/grpc-api-1.58.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-launcher/1.10.2/junit-platform-launcher-1.10.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-engine/1.10.2/junit-platform-engine-1.10.2.jar:/home/runner/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.6/hadoop-kms-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-auth/3.3.6/hadoop-auth-3.3.6.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper/3.8.4/zookeeper-3.8.4.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.8.4/zookeeper-jute-3.8.4.jar:/home/runner/.m2/repository/org/apache/yetus/audience-annotations/0.12.0/audience-annotations-0.12.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.2.0/hadoop-shaded-guava-1.2.0.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-core/1.19.4/jersey-core-1.19.4.jar:/home/runner/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-server/1.19.4/jersey-server-1.19.4.jar:/home/runner/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.6/hadoop-common-3.3.6.jar:/home/runner/.m2/repository/org/apache/commons/commons-math3/3.6.1/commons-math3-3.6.1.jar:/home/runner/.m2/repository/commons-net/commons-net/3.10.0/commons-net-3.10.0.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-servlet/1.19.4/jersey-servlet-1.19.4.jar:/home/runner/.m2/repository/com/github/pjfanning/jersey-json/1.20/jersey-json-1.20.jar:/home/runner/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/runner/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/runner/.m2/repository/com/google/re2j/re2j/1.7/re2j-1.7.jar:/home/runner/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/runner/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-recipes/5.2.0/curator-recipes-5.2.0.jar:/home/runner/.m2/repository/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/runner/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.16.1/jackson-databind-2.16.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.6/hadoop-kms-3.3.6-tests.jar:/home/runner/work/ozone/ozone/hadoop-hdds/server-scm/target/test-classes:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/test-classes:/home/runner/.m2/repository/com/github/luben/zstd-jni/1.5.6-2/zstd-jni-1.5.6-2.jar:/home/runner/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/runner/.m2/repository/io/netty/netty-codec/4.1.100.Final/netty-codec-4.1.100.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler/4.1.100.Final/netty-handler-4.1.100.Final.jar:/home/runner/work/ozone/ozone/hadoop-hdds/hadoop-dependency-test/target/classes:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.6/hadoop-common-3.3.6-tests.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.6/hadoop-hdfs-3.3.6-tests.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.10.2/junit-jupiter-engine-5.10.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.10.2/junit-jupiter-params-5.10.2.jar:/home/runner/.m2/repository/org/mockito/mockito-core/4.11.0/mockito-core-4.11.0.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy/1.12.19/byte-buddy-1.12.19.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy-agent/1.12.19/byte-buddy-agent-1.12.19.jar:/home/runner/.m2/repository/org/objenesis/objenesis/3.3/objenesis-3.3.jar:/home/runner/.m2/repository/org/mockito/mockito-junit-jupiter/4.11.0/mockito-junit-jupiter-4.11.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.6/hadoop-distcp-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.3.6/hadoop-mapreduce-client-jobclient-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.3.6/hadoop-mapreduce-client-common-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.3.6/hadoop-yarn-common-3.3.6.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.3.6/hadoop-yarn-api-3.3.6.jar:/home/runner/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/home/runner/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19.4/jersey-guice-1.19.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.16.1/jackson-jaxrs-json-provider-2.16.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.16.1/jackson-jaxrs-base-2.16.1.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.3.6/hadoop-yarn-client-3.3.6.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.4.51.v20230217/websocket-client-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.4.51.v20230217/websocket-common-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.4.51.v20230217/websocket-api-9.4.51.v20230217.jar:/home/runner/.m2/repository/org/jline/jline/3.9.0/jline-3.9.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.3.6/hadoop-mapreduce-client-core-3.3.6.jar:/home/runner/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/runner/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-annotations/3.3.6/hadoop-annotations-3.3.6.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/../lib/tools.jar:/home/runner/.m2/repository/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.6/hadoop-distcp-3.3.6-tests.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest/2.2/hamcrest-2.2.jar:/home/runner/.m2/repository/org/slf4j/jul-to-slf4j/2.0.12/jul-to-slf4j-2.0.12.jar:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/gradle-enterprise/test-listeners.jar:
STARTUP_MSG:   build = https://github.com/apache/ozone/87dd27347c2ec9419310e500f83b516418ecfc0a ; compiled by 'runner' on 2024-04-06T10:20Z
STARTUP_MSG:   java = 1.8.0_402
STARTUP_MSG:   conf = {hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=false, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.chunk.write.sync=false, hdds.container.close.threshold=0.9f, hdds.container.ipc.port=9859, hdds.container.ipc.random.port=false, hdds.container.ratis.admin.port=9857, hdds.container.ratis.datastream.enabled=true, hdds.container.ratis.datastream.port=9855, hdds.container.ratis.datastream.random.port=false, hdds.container.ratis.enabled=false, hdds.container.ratis.ipc.port=9858, hdds.container.ratis.ipc.random.port=false, hdds.container.ratis.leader.pending.bytes.limit=1GB, hdds.container.ratis.log.appender.queue.byte-limit=8MB, hdds.container.ratis.log.appender.queue.num-elements=1, hdds.container.ratis.log.purge.gap=1000000, hdds.container.ratis.log.queue.byte-limit=4GB, hdds.container.ratis.log.queue.num-elements=1024, hdds.container.ratis.num.container.op.executors=10, hdds.container.ratis.num.write.chunk.threads.per.volume=4, hdds.container.ratis.replication.level=MAJORITY, hdds.container.ratis.rpc.type=GRPC, hdds.container.ratis.segment.preallocated.size=4MB, hdds.container.ratis.segment.size=64MB, hdds.container.ratis.server.port=9856, hdds.container.ratis.statemachine.max.pending.apply-transactions=10000, hdds.container.ratis.statemachinedata.sync.timeout=10s, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60m, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=true, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=false, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.command.worker.interval=2s, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=19864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.factory.classname=org.apache.hadoop.hdds.fs.MockSpaceUsageCheckFactory$None, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.datanode.http.auth.type=simple, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.replication.zerocopy.enabled=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.slow.op.warning.threshold=500ms, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=5GB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=false, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=1s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.leader.election.minimum.timeout.duration=5s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=0us, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.ratis.server.retry-cache.timeout.duration=600000ms, hdds.ratis.snapshot.threshold=10000, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/_HOST@REALM, hdds.scm.http.auth.type=simple, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/SCM.keytab, hdds.scm.kerberos.principal=SCM/_HOST@REALM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=1, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=10m, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=7d, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=10m, hdds.secret.key.rotate.duration=1d, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneAccessAuthorizer, ozone.acl.enabled=false, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=1MB, ozone.chunk.read.mapped.buffer.threshold=32KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=4MB, ozone.client.datastream.min.packet.size=256KB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=8MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.reconstruct.stripe.write.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.max.retries=3, ozone.client.read.retry.interval=1, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=1MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=2MB, ozone.client.stream.buffer.size=1MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.csi.default-volume-size=1000000000, ozone.csi.mount.command=goofys --endpoint %s %s %s, ozone.csi.s3g.address=http://localhost:9878, ozone.csi.socket=/var/lib/csi.sock, ozone.directory.deleting.service.interval=1m, ozone.ec.grpc.zerocopy.enabled=true, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.http.policy=HTTP_ONLY, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=0.0.0.0:9862, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.client.rpc.timeout=15m, ozone.om.client.trash.core.pool.size=5, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.group.rights=ALL, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.port=8981, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.ha.raft.server.log.appender.wait-time.min=0ms, ozone.om.ha.raft.server.retrycache.expirytime=300s, ozone.om.handler.count.key=20, ozone.om.http-address=0.0.0.0:9874, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.om.http.auth.type=simple, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.init.default.layout.version=-1, ozone.om.kerberos.keytab.file=/etc/security/keytabs/OM.keytab, ozone.om.kerberos.principal=OM/_HOST@REALM, ozone.om.kerberos.principal.pattern=*, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.max.buckets=100000, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.network.topology.refresh.duration=1h, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=4MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.s3.grpc.server_enabled=false, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1s, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.load.native.lib=true, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.finalization.ratis.based.timeout=30s, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.user.rights=ALL, ozone.om.volume.listall.allowed=true, ozone.path.deleting.limit.per.task=6000, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.recon.http.auth.type=simple, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=1m, ozone.recon.om.snapshot.task.interval.delay=10m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.scmclient.failover.max.retry=3, ozone.recon.scmclient.max.retry.timeout=6s, ozone.recon.scmclient.rpc.timeout=1m, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.sql.db.auto.commit=true, ozone.recon.sql.db.conn.idle.max.age=3600s, ozone.recon.sql.db.conn.idle.test=SELECT 1, ozone.recon.sql.db.conn.idle.test.period=60s, ozone.recon.sql.db.conn.max.active=5, ozone.recon.sql.db.conn.max.age=1800s, ozone.recon.sql.db.conn.timeout=30000ms, ozone.recon.sql.db.driver=org.apache.derby.jdbc.EmbeddedDriver, ozone.recon.sql.db.jdbc.url=jdbc:derby:${ozone.recon.db.dir}/ozone_recon_derby.db, ozone.recon.sql.db.jooq.dialect=DERBY, ozone.recon.task.containercounttask.interval=60s, ozone.recon.task.missingcontainer.interval=300s, ozone.recon.task.pipelinesync.interval=300s, ozone.recon.task.safemode.wait.threshold=300s, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.s3g.http.auth.type=simple, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/_HOST@REALM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.metrics.percentiles.intervals.seconds=60, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=false, ozone.s3g.volume.name=s3v, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.handler.count.key=100, ozone.scm.block.size=4MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=1MB, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.handler.count.key=100, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=1s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=5GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.admin.monitor.logging.limit=1000, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.handler.count.key=100, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=1GB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=4MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=20, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=100ms, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=120s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=3, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.pipeline.limit=3, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=false, ozone.security.http.kerberos.enabled=false, ozone.security.reconfigure.protocol.acl=*, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.directory.service.interval=24h, ozone.snapshot.directory.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.test.test.key=value1, ozone.xceiver.client.metrics.percentiles.intervals.seconds=60, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256, test.scm.client.address=localhost, test.scm.client.bind.host=0.0.0.0, test.scm.client.class=java.lang.Object, test.scm.client.compression.enabled=true, test.scm.client.duration=1h, test.scm.client.enabled=true, test.scm.client.port=9878, test.scm.client.threshold=10, test.scm.client.wait=30m, yarn.app.mapreduce.am.container.log.backups=0, yarn.app.mapreduce.am.container.log.limit.kb=0, yarn.app.mapreduce.task.container.log.backups=0, yarn.nodemanager.container.stderr.pattern={*stderr*,*STDERR*}, yarn.nodemanager.container.stderr.tail.bytes=4096, yarn.nodemanager.windows-container.cpu-limit.enabled=false, yarn.nodemanager.windows-container.memory-limit.enabled=false, yarn.resourcemanager.container.liveness-monitor.interval-ms=600000}
************************************************************/
2024-04-06 10:33:19,487 [main] INFO  recon.ReconServer (SignalLogger.java:register(90)) - registered UNIX signal handlers for [TERM, HUP, INT]
2024-04-06 10:33:19,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:19,726 [main] INFO  reflections.Reflections (Reflections.java:scan(219)) - Reflections took 16 ms to scan 1 urls, producing 20 keys and 82 values
2024-04-06 10:33:19,921 [main] INFO  recon.ReconServer (ReconServer.java:call(116)) - Initializing Recon server...
2024-04-06 10:33:19,960 [main] INFO  persistence.DefaultDataSourceProvider (DefaultDataSourceProvider.java:get(51)) - JDBC Url for Recon : jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/recon/ozone_recon_derby.db 
2024-04-06 10:33:20,231 [om1@group-C5BA1605619E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1081189805ns, electionTimeout:1079ms
2024-04-06 10:33:20,232 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - om1: shutdown om1@group-C5BA1605619E-FollowerState
2024-04-06 10:33:20,233 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-04-06 10:33:20,237 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-04-06 10:33:20,237 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderElection1
2024-04-06 10:33:20,246 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - om1@group-C5BA1605619E-LeaderElection1 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[om1|localhost:15007]|listeners:[], old=null
2024-04-06 10:33:20,252 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - om1@group-C5BA1605619E-LeaderElection1 PRE_VOTE round 0: result PASSED (term=0)
2024-04-06 10:33:20,254 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - om1@group-C5BA1605619E-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[om1|localhost:15007]|listeners:[], old=null
2024-04-06 10:33:20,254 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - om1@group-C5BA1605619E-LeaderElection1 ELECTION round 0: result PASSED (term=1)
2024-04-06 10:33:20,255 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - om1: shutdown om1@group-C5BA1605619E-LeaderElection1
2024-04-06 10:33:20,256 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-04-06 10:33:20,263 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-04-06 10:33:20,267 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2024-04-06 10:33:20,268 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2024-04-06 10:33:20,272 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2024-04-06 10:33:20,273 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-04-06 10:33:20,274 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-04-06 10:33:20,280 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-04-06 10:33:20,282 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-04-06 10:33:20,283 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2024-04-06 10:33:20,283 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2024-04-06 10:33:20,284 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-04-06 10:33:20,286 [om1@group-C5BA1605619E-LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderStateImpl
2024-04-06 10:33:20,286 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - om1@group-C5BA1605619E: set firstElectionSinceStartup to false for becomeLeader
2024-04-06 10:33:20,289 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 2260ms
2024-04-06 10:33:20,323 [om1@group-C5BA1605619E-LeaderElection1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
2024-04-06 10:33:20,344 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-04-06 10:33:20,359 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2024-04-06 10:33:20,372 [om1@group-C5BA1605619E-LeaderElection1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - om1@group-C5BA1605619E: set configuration 0: peers:[om1|localhost:15007]|listeners:[], old=null
2024-04-06 10:33:20,485 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyConfigurationChanged(212)) - Received Configuration change notification from Ratis. New Peer list:
[id: "om1"
address: "localhost:15007"
startupRole: FOLLOWER
]
2024-04-06 10:33:20,486 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-04-06 10:33:20,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:20,634 [main] INFO  codegen.SqlDbUtils (SqlDbUtils.java:createNewDerbyDatabase(67)) - Created derby database at jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/recon/ozone_recon_derby.db.
2024-04-06 10:33:20,853 [main] INFO  impl.ReconContainerMetadataManagerImpl (ReconContainerMetadataManagerImpl.java:initializeTables(141)) - KEY_CONTAINER Table is empty, initializing from CONTAINER_KEY Table ...
2024-04-06 10:33:20,853 [main] INFO  impl.ReconContainerMetadataManagerImpl (ReconContainerMetadataManagerImpl.java:initializeKeyContainerTable(666)) - It took 0.0 seconds to initialized 0 records to KEY_CONTAINER table
2024-04-06 10:33:20,872 [main] INFO  persistence.DefaultDataSourceProvider (DefaultDataSourceProvider.java:get(51)) - JDBC Url for Recon : jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/recon/ozone_recon_derby.db 
2024-04-06 10:33:20,875 [main] INFO  codegen.SqlDbUtils (SqlDbUtils.java:createNewDerbyDatabase(67)) - Created derby database at jdbc:derby:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/recon/ozone_recon_derby.db.
2024-04-06 10:33:20,876 [main] INFO  recon.ReconServer (ReconServer.java:call(140)) - Creating Recon Schema.
2024-04-06 10:33:21,255 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for recon at: http://0.0.0.0:15008
2024-04-06 10:33:21,255 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-04-06 10:33:21,257 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-04-06 10:33:21,257 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.recon is not defined
2024-04-06 10:33:21,259 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-04-06 10:33:21,260 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context recon
2024-04-06 10:33:21,260 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-04-06 10:33:21,260 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-04-06 10:33:21,261 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of recon uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/webserver
2024-04-06 10:33:21,267 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(80)) - Registered task ContainerKeyMapperTask with controller.
2024-04-06 10:33:21,413 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(80)) - Registered task FileSizeCountTask with controller.
2024-04-06 10:33:21,418 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(80)) - Registered task OmTableInsightTask with controller.
2024-04-06 10:33:21,422 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:registerTask(80)) - Registered task NSSummaryTask with controller.
2024-04-06 10:33:21,425 [main] INFO  ozone.OmUtils (OmUtils.java:getOzoneManagerServiceId(685)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2024-04-06 10:33:21,425 [main] INFO  ozone.OmUtils (OmUtils.java:getOzoneManagerServiceId(704)) - No OzoneManager ServiceID configured.
2024-04-06 10:33:21,427 [main] INFO  protocolPB.OmTransportFactory (OmTransportFactory.java:createFactory(62)) - Loading OM transport implementation org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory as specified by configuration.
2024-04-06 10:33:21,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:21,813 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [file:/home/runner/work/ozone/ozone/hadoop-hdds/common/target/classes/network-topology-default.xml]
2024-04-06 10:33:21,813 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2024-04-06 10:33:21,904 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-04-06 10:33:21,907 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(241)) - Init the HA SequenceIdGenerator.
2024-04-06 10:33:21,911 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(177)) - Entering startup safe mode.
2024-04-06 10:33:21,912 [main] INFO  scm.ReconNodeManager (ReconNodeManager.java:loadExistingNodes(119)) - Loaded 0 nodes from node DB.
2024-04-06 10:33:21,912 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2024-04-06 10:33:21,913 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-04-06 10:33:21,914 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15009
2024-04-06 10:33:21,914 [Socket Reader #1 for port 15009] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15009
2024-04-06 10:33:21,918 [main] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2024-04-06 10:33:21,940 [main] INFO  recon.ReconServer (ReconServer.java:call(154)) - Initializing support of Recon Features...
2024-04-06 10:33:21,942 [main] INFO  recon.ReconServer (ReconServer.java:call(156)) - Recon server initialized successfully!
2024-04-06 10:33:21,943 [main] INFO  recon.ReconServer (ReconServer.java:start(211)) - Starting Recon server
2024-04-06 10:33:21,943 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Recon metrics system started (again)
2024-04-06 10:33:21,967 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15008
2024-04-06 10:33:21,969 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-04-06 10:33:21,975 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-04-06 10:33:21,975 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-04-06 10:33:21,976 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2024-04-06 10:33:21,977 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@3e848f48{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-04-06 10:33:21,978 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@46872fde{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/recon/target/classes/webapps/static,AVAILABLE}
2024-04-06 10:33:22,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:22,814 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@22dac77c{recon,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/recon/target/classes/webapps/recon/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/recon/target/classes/webapps/recon}
2024-04-06 10:33:22,815 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@2ec993d6{HTTP/1.1, (http/1.1)}{0.0.0.0:15008}
2024-04-06 10:33:22,815 [main] INFO  server.Server (Server.java:doStart(415)) - Started @10615ms
2024-04-06 10:33:22,815 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-04-06 10:33:22,816 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of recon listening at http://0.0.0.0:15008
2024-04-06 10:33:22,816 [main] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:start(239)) - Starting Ozone Manager Service Provider.
2024-04-06 10:33:22,820 [main] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:registerOMDBTasks(217)) - Registered OmDeltaRequest task 
2024-04-06 10:33:22,823 [main] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:registerOMDBTasks(227)) - Registered OmSnapshotRequest task 
2024-04-06 10:33:22,823 [main] INFO  recovery.ReconOmMetadataManagerImpl (ReconOmMetadataManagerImpl.java:start(82)) - Starting ReconOMMetadataManagerImpl
2024-04-06 10:33:22,823 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:start(222)) - Starting Recon Task Controller.
2024-04-06 10:33:22,824 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:start(388)) - Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:15009
2024-04-06 10:33:22,954 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:initializePipelinesFromScm(488)) - Obtained 0 pipelines from SCM.
2024-04-06 10:33:22,954 [main] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 0 pipelines in house.
2024-04-06 10:33:22,954 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:start(401)) - SCM DB initialized
2024-04-06 10:33:22,955 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(194)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:15009
2024-04-06 10:33:22,956 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-04-06 10:33:22,956 [IPC Server listener on 15009] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15009: starting
2024-04-06 10:33:23,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:24,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:25,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:26,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:27,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:28,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:29,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:30,606 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:31,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:32,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:33,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:33,971 [main] INFO  scm.ReconScmTask (ReconScmTask.java:register(46)) - Registered ContainerSizeCountTask task 
2024-04-06 10:33:33,971 [main] INFO  scm.ReconScmTask (ReconScmTask.java:start(56)) - Starting ContainerSizeCountTask Thread.
2024-04-06 10:33:33,975 [main] INFO  scm.ReconScmTask (ReconScmTask.java:register(46)) - Registered ContainerHealthTask task 
2024-04-06 10:33:33,975 [main] INFO  scm.ReconScmTask (ReconScmTask.java:start(56)) - Starting ContainerHealthTask Thread.
2024-04-06 10:33:33,979 [main] INFO  scm.ReconScmTask (ReconScmTask.java:register(46)) - Registered PipelineSyncTask task 
2024-04-06 10:33:33,979 [main] INFO  scm.ReconScmTask (ReconScmTask.java:start(56)) - Starting PipelineSyncTask Thread.
2024-04-06 10:33:33,993 [JvmPauseMonitor2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-Recon: Started
2024-04-06 10:33:33,996 [PipelineSyncTask] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 0 pipelines in house.
2024-04-06 10:33:33,997 [PipelineSyncTask] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 17 milliseconds.
2024-04-06 10:33:34,021 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 45 milliseconds to process 0 existing database records.
2024-04-06 10:33:34,023 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:34,048 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-04-06 10:33:34,049 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-04-06 10:33:34,049 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-04-06 10:33:34,061 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(240)) - HddsDatanodeService host:fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net ip:10.1.0.10
2024-04-06 10:33:34,086 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-04-06 10:33:34,089 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(299)) - Datanode State Machine Task Thread Pool size 2
2024-04-06 10:33:34,139 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(125)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/data-0/hdds of storage type : DISK capacity : 9223372036854775807
2024-04-06 10:33:34,142 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/data-0/hdds to VolumeSet
2024-04-06 10:33:34,145 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis to VolumeSet
2024-04-06 10:33:34,147 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 0ms
2024-04-06 10:33:34,185 [main] INFO  audit.AuditLogger (AuditLogger.java:refreshDebugCmdSet(135)) - Refresh DebugCmdSet for DNAudit to [].
2024-04-06 10:33:34,207 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-04-06 10:33:34,207 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-04-06 10:33:34,207 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15015 (custom)
2024-04-06 10:33:34,208 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-04-06 10:33:34,208 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15014 (custom)
2024-04-06 10:33:34,208 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-04-06 10:33:34,208 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15016 (custom)
2024-04-06 10:33:34,208 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-04-06 10:33:34,208 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:34,209 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-04-06 10:33:34,209 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:33:34,209 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-04-06 10:33:34,209 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-04-06 10:33:34,209 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-04-06 10:33:34,212 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-04-06 10:33:34,224 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-04-06 10:33:34,224 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-04-06 10:33:34,224 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-04-06 10:33:34,225 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-04-06 10:33:34,226 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-04-06 10:33:34,228 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-04-06 10:33:34,228 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-04-06 10:33:34,229 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 59c3495a-7636-40f9-8dfa-c28be8e98abd-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-04-06 10:33:34,230 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-04-06 10:33:34,230 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for 59c3495a-7636-40f9-8dfa-c28be8e98abd-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-04-06 10:33:34,231 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-04-06 10:33:34,232 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-04-06 10:33:34,232 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15017 (custom)
2024-04-06 10:33:34,237 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:33:34,237 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-04-06 10:33:34,237 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:33:34,237 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis] (custom)
2024-04-06 10:33:34,237 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-04-06 10:33:34,238 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-04-06 10:33:34,238 [59c3495a-7636-40f9-8dfa-c28be8e98abd-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/tmp
2024-04-06 10:33:34,239 [59c3495a-7636-40f9-8dfa-c28be8e98abd-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(269)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/tmp is not a group directory; ignoring it. 
2024-04-06 10:33:34,241 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-04-06 10:33:34,245 [59c3495a-7636-40f9-8dfa-c28be8e98abd-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x233533c1] REGISTERED
2024-04-06 10:33:34,246 [59c3495a-7636-40f9-8dfa-c28be8e98abd-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x233533c1] BIND: 0.0.0.0/0.0.0.0:15017
2024-04-06 10:33:34,246 [59c3495a-7636-40f9-8dfa-c28be8e98abd-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x233533c1, L:/0.0.0.0:15017] ACTIVE
2024-04-06 10:33:34,261 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-04-06 10:33:34,328 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(157)) - Initializing replication supervisor with thread count = 10
2024-04-06 10:33:34,329 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-04-06 10:33:34,371 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15011
2024-04-06 10:33:34,371 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-04-06 10:33:34,372 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-04-06 10:33:34,373 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-04-06 10:33:34,375 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-04-06 10:33:34,376 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-04-06 10:33:34,376 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-04-06 10:33:34,376 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-04-06 10:33:34,377 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/meta/webserver
2024-04-06 10:33:34,377 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15011
2024-04-06 10:33:34,378 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-04-06 10:33:34,379 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-04-06 10:33:34,380 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-04-06 10:33:34,380 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2024-04-06 10:33:34,381 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@4153239b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-04-06 10:33:34,381 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@53c1ab44{static,/static,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/static,AVAILABLE}
2024-04-06 10:33:34,384 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@317ed949{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode}
2024-04-06 10:33:34,386 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@3c437652{HTTP/1.1, (http/1.1)}{0.0.0.0:15011}
2024-04-06 10:33:34,386 [main] INFO  server.Server (Server.java:doStart(415)) - Started @22186ms
2024-04-06 10:33:34,386 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-04-06 10:33:34,387 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15011
2024-04-06 10:33:34,390 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-04-06 10:33:34,390 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15012
2024-04-06 10:33:34,390 [Socket Reader #1 for port 15012] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15012
2024-04-06 10:33:34,396 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(327)) - Datanode start with admins: [runner]
2024-04-06 10:33:34,397 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15012
2024-04-06 10:33:34,397 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-04-06 10:33:34,397 [IPC Server listener on 15012] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15012: starting
2024-04-06 10:33:34,399 [59c3495a-7636-40f9-8dfa-c28be8e98abd-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(555)) - Ozone container server started.
2024-04-06 10:33:34,401 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-04-06 10:33:34,401 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-04-06 10:33:34,401 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-04-06 10:33:34,411 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(240)) - HddsDatanodeService host:fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net ip:10.1.0.10
2024-04-06 10:33:34,428 [59c3495a-7636-40f9-8dfa-c28be8e98abd-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-04-06 10:33:34,429 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-04-06 10:33:34,430 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(299)) - Datanode State Machine Task Thread Pool size 2
2024-04-06 10:33:34,433 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(125)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/data-0/hdds of storage type : DISK capacity : 9223372036854775807
2024-04-06 10:33:34,434 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/data-0/hdds to VolumeSet
2024-04-06 10:33:34,435 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis to VolumeSet
2024-04-06 10:33:34,436 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 0ms
2024-04-06 10:33:34,440 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-04-06 10:33:34,440 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-04-06 10:33:34,440 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15024 (custom)
2024-04-06 10:33:34,440 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-04-06 10:33:34,441 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15023 (custom)
2024-04-06 10:33:34,441 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-04-06 10:33:34,441 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15025 (custom)
2024-04-06 10:33:34,442 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-04-06 10:33:34,442 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:34,442 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-04-06 10:33:34,442 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:33:34,442 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-04-06 10:33:34,442 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-04-06 10:33:34,443 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-04-06 10:33:34,445 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-04-06 10:33:34,445 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-04-06 10:33:34,445 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-04-06 10:33:34,446 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-04-06 10:33:34,446 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-04-06 10:33:34,446 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-04-06 10:33:34,446 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-04-06 10:33:34,446 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-04-06 10:33:34,446 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for cc1e4d3c-2283-4c28-b737-db868cb45369-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-04-06 10:33:34,447 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-04-06 10:33:34,447 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for cc1e4d3c-2283-4c28-b737-db868cb45369-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-04-06 10:33:34,447 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-04-06 10:33:34,448 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-04-06 10:33:34,448 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15026 (custom)
2024-04-06 10:33:34,448 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:33:34,450 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-04-06 10:33:34,450 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:33:34,451 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis] (custom)
2024-04-06 10:33:34,451 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-04-06 10:33:34,451 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-04-06 10:33:34,450 [cc1e4d3c-2283-4c28-b737-db868cb45369-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xe72b909d] REGISTERED
2024-04-06 10:33:34,452 [cc1e4d3c-2283-4c28-b737-db868cb45369-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xe72b909d] BIND: 0.0.0.0/0.0.0.0:15026
2024-04-06 10:33:34,452 [cc1e4d3c-2283-4c28-b737-db868cb45369-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xe72b909d, L:/0.0.0.0:15026] ACTIVE
2024-04-06 10:33:34,453 [cc1e4d3c-2283-4c28-b737-db868cb45369-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - cc1e4d3c-2283-4c28-b737-db868cb45369: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/tmp
2024-04-06 10:33:34,453 [cc1e4d3c-2283-4c28-b737-db868cb45369-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(269)) - cc1e4d3c-2283-4c28-b737-db868cb45369: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/tmp is not a group directory; ignoring it. 
2024-04-06 10:33:34,454 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-04-06 10:33:34,456 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-04-06 10:33:34,474 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(157)) - Initializing replication supervisor with thread count = 10
2024-04-06 10:33:34,475 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-04-06 10:33:34,487 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15020
2024-04-06 10:33:34,490 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-04-06 10:33:34,492 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-04-06 10:33:34,494 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-04-06 10:33:34,496 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-04-06 10:33:34,497 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-04-06 10:33:34,497 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-04-06 10:33:34,498 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-04-06 10:33:34,499 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/meta/webserver
2024-04-06 10:33:34,500 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15020
2024-04-06 10:33:34,500 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-04-06 10:33:34,508 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-04-06 10:33:34,508 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-04-06 10:33:34,508 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2024-04-06 10:33:34,509 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2e0e9e3e{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-04-06 10:33:34,510 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@2de15438{static,/static,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/static,AVAILABLE}
2024-04-06 10:33:34,512 [59c3495a-7636-40f9-8dfa-c28be8e98abd-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/meta/datanode.id
2024-04-06 10:33:34,514 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@59692457{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode}
2024-04-06 10:33:34,518 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@858ef7c{HTTP/1.1, (http/1.1)}{0.0.0.0:15020}
2024-04-06 10:33:34,518 [main] INFO  server.Server (Server.java:doStart(415)) - Started @22317ms
2024-04-06 10:33:34,518 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-04-06 10:33:34,519 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15020
2024-04-06 10:33:34,520 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-04-06 10:33:34,520 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15021
2024-04-06 10:33:34,521 [Socket Reader #1 for port 15021] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15021
2024-04-06 10:33:34,526 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(327)) - Datanode start with admins: [runner]
2024-04-06 10:33:34,526 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15021
2024-04-06 10:33:34,527 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-04-06 10:33:34,531 [IPC Server listener on 15021] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15021: starting
2024-04-06 10:33:34,532 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-04-06 10:33:34,532 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-04-06 10:33:34,533 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-04-06 10:33:34,532 [cc1e4d3c-2283-4c28-b737-db868cb45369-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(555)) - Ozone container server started.
2024-04-06 10:33:34,540 [cc1e4d3c-2283-4c28-b737-db868cb45369-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-04-06 10:33:34,557 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(240)) - HddsDatanodeService host:fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net ip:10.1.0.10
2024-04-06 10:33:34,559 [cc1e4d3c-2283-4c28-b737-db868cb45369-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/meta/datanode.id
2024-04-06 10:33:34,575 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-04-06 10:33:34,575 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(299)) - Datanode State Machine Task Thread Pool size 2
2024-04-06 10:33:34,578 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(125)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/data-0/hdds of storage type : DISK capacity : 9223372036854775807
2024-04-06 10:33:34,578 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/data-0/hdds to VolumeSet
2024-04-06 10:33:34,579 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis to VolumeSet
2024-04-06 10:33:34,580 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 0ms
2024-04-06 10:33:34,583 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-04-06 10:33:34,583 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-04-06 10:33:34,584 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15033 (custom)
2024-04-06 10:33:34,584 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-04-06 10:33:34,584 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15032 (custom)
2024-04-06 10:33:34,584 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-04-06 10:33:34,584 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15034 (custom)
2024-04-06 10:33:34,584 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-04-06 10:33:34,585 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:34,585 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-04-06 10:33:34,585 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:33:34,585 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-04-06 10:33:34,585 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-04-06 10:33:34,585 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-04-06 10:33:34,589 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-04-06 10:33:34,589 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-04-06 10:33:34,590 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-04-06 10:33:34,590 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-04-06 10:33:34,590 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-04-06 10:33:34,590 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-04-06 10:33:34,590 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-04-06 10:33:34,591 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-04-06 10:33:34,591 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for d1715241-1ffa-4146-b219-94c9c0fc171f-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-04-06 10:33:34,591 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-04-06 10:33:34,591 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for d1715241-1ffa-4146-b219-94c9c0fc171f-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-04-06 10:33:34,592 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-04-06 10:33:34,592 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-04-06 10:33:34,592 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15035 (custom)
2024-04-06 10:33:34,593 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:33:34,593 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-04-06 10:33:34,593 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:33:34,593 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis] (custom)
2024-04-06 10:33:34,593 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-04-06 10:33:34,594 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-04-06 10:33:34,595 [d1715241-1ffa-4146-b219-94c9c0fc171f-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - d1715241-1ffa-4146-b219-94c9c0fc171f: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/tmp
2024-04-06 10:33:34,595 [d1715241-1ffa-4146-b219-94c9c0fc171f-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(269)) - d1715241-1ffa-4146-b219-94c9c0fc171f: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/tmp is not a group directory; ignoring it. 
2024-04-06 10:33:34,596 [d1715241-1ffa-4146-b219-94c9c0fc171f-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x776ff116] REGISTERED
2024-04-06 10:33:34,596 [d1715241-1ffa-4146-b219-94c9c0fc171f-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x776ff116] BIND: 0.0.0.0/0.0.0.0:15035
2024-04-06 10:33:34,596 [d1715241-1ffa-4146-b219-94c9c0fc171f-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x776ff116, L:/0.0.0.0:15035] ACTIVE
2024-04-06 10:33:34,596 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-04-06 10:33:34,598 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-04-06 10:33:34,600 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(157)) - Initializing replication supervisor with thread count = 10
2024-04-06 10:33:34,600 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-04-06 10:33:34,602 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15029
2024-04-06 10:33:34,603 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-04-06 10:33:34,604 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-04-06 10:33:34,605 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-04-06 10:33:34,606 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-04-06 10:33:34,607 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-04-06 10:33:34,607 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-04-06 10:33:34,608 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-04-06 10:33:34,607 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:34,608 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/meta/webserver
2024-04-06 10:33:34,609 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15029
2024-04-06 10:33:34,609 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-04-06 10:33:34,612 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-04-06 10:33:34,612 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-04-06 10:33:34,612 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2024-04-06 10:33:34,623 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@541ac2ba{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-04-06 10:33:34,623 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@1f7d0816{static,/static,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/static,AVAILABLE}
2024-04-06 10:33:34,627 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@67b19b53{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode}
2024-04-06 10:33:34,628 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@1d2133d3{HTTP/1.1, (http/1.1)}{0.0.0.0:15029}
2024-04-06 10:33:34,629 [main] INFO  server.Server (Server.java:doStart(415)) - Started @22428ms
2024-04-06 10:33:34,629 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-04-06 10:33:34,630 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15029
2024-04-06 10:33:34,630 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-04-06 10:33:34,630 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15030
2024-04-06 10:33:34,630 [Socket Reader #1 for port 15030] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15030
2024-04-06 10:33:34,641 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(327)) - Datanode start with admins: [runner]
2024-04-06 10:33:34,642 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15030
2024-04-06 10:33:34,642 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-04-06 10:33:34,642 [IPC Server listener on 15030] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15030: starting
2024-04-06 10:33:34,644 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-04-06 10:33:34,644 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-04-06 10:33:34,644 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-04-06 10:33:34,650 [d1715241-1ffa-4146-b219-94c9c0fc171f-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(555)) - Ozone container server started.
2024-04-06 10:33:34,658 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(240)) - HddsDatanodeService host:fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net ip:10.1.0.10
2024-04-06 10:33:34,673 [d1715241-1ffa-4146-b219-94c9c0fc171f-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-04-06 10:33:34,677 [d1715241-1ffa-4146-b219-94c9c0fc171f-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/meta/datanode.id
2024-04-06 10:33:34,677 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-04-06 10:33:34,679 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(299)) - Datanode State Machine Task Thread Pool size 2
2024-04-06 10:33:34,681 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(125)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/data-0/hdds of storage type : DISK capacity : 9223372036854775807
2024-04-06 10:33:34,681 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/data-0/hdds to VolumeSet
2024-04-06 10:33:34,682 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis to VolumeSet
2024-04-06 10:33:34,683 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 0ms
2024-04-06 10:33:34,686 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-04-06 10:33:34,686 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-04-06 10:33:34,687 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15042 (custom)
2024-04-06 10:33:34,687 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-04-06 10:33:34,687 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15041 (custom)
2024-04-06 10:33:34,687 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-04-06 10:33:34,688 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15043 (custom)
2024-04-06 10:33:34,688 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-04-06 10:33:34,688 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:34,688 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-04-06 10:33:34,688 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:33:34,689 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-04-06 10:33:34,689 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-04-06 10:33:34,689 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-04-06 10:33:34,692 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-04-06 10:33:34,693 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-04-06 10:33:34,693 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-04-06 10:33:34,693 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-04-06 10:33:34,694 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-04-06 10:33:34,694 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-04-06 10:33:34,694 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-04-06 10:33:34,694 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-04-06 10:33:34,694 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for a40aef6e-dfc7-4141-9a41-17d72bf4eeff-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-04-06 10:33:34,695 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-04-06 10:33:34,695 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for a40aef6e-dfc7-4141-9a41-17d72bf4eeff-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-04-06 10:33:34,696 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-04-06 10:33:34,696 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-04-06 10:33:34,696 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15044 (custom)
2024-04-06 10:33:34,697 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:33:34,697 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-04-06 10:33:34,698 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:33:34,698 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis] (custom)
2024-04-06 10:33:34,699 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-04-06 10:33:34,699 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-04-06 10:33:34,698 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xfad1c7c9] REGISTERED
2024-04-06 10:33:34,703 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xfad1c7c9] BIND: 0.0.0.0/0.0.0.0:15044
2024-04-06 10:33:34,704 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xfad1c7c9, L:/0.0.0.0:15044] ACTIVE
2024-04-06 10:33:34,711 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/tmp
2024-04-06 10:33:34,711 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(269)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/tmp is not a group directory; ignoring it. 
2024-04-06 10:33:34,711 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-04-06 10:33:34,713 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-04-06 10:33:34,715 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(157)) - Initializing replication supervisor with thread count = 10
2024-04-06 10:33:34,715 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-04-06 10:33:34,718 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15038
2024-04-06 10:33:34,718 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-04-06 10:33:34,720 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-04-06 10:33:34,721 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-04-06 10:33:34,723 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-04-06 10:33:34,723 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-04-06 10:33:34,724 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-04-06 10:33:34,724 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-04-06 10:33:34,724 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/meta/webserver
2024-04-06 10:33:34,725 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15038
2024-04-06 10:33:34,725 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-04-06 10:33:34,726 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-04-06 10:33:34,726 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-04-06 10:33:34,726 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2024-04-06 10:33:34,727 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@35fb66e5{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-04-06 10:33:34,727 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@10295010{static,/static,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/static,AVAILABLE}
2024-04-06 10:33:34,736 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@40e55d45{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode}
2024-04-06 10:33:34,738 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@4b4eece8{HTTP/1.1, (http/1.1)}{0.0.0.0:15038}
2024-04-06 10:33:34,738 [main] INFO  server.Server (Server.java:doStart(415)) - Started @22537ms
2024-04-06 10:33:34,738 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-04-06 10:33:34,741 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15038
2024-04-06 10:33:34,741 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-04-06 10:33:34,741 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15039
2024-04-06 10:33:34,741 [Socket Reader #1 for port 15039] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15039
2024-04-06 10:33:34,752 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(327)) - Datanode start with admins: [runner]
2024-04-06 10:33:34,752 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15039
2024-04-06 10:33:34,752 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-04-06 10:33:34,753 [IPC Server listener on 15039] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15039: starting
2024-04-06 10:33:34,755 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-04-06 10:33:34,755 [main] WARN  dropwizard3.Dm3MetricRegistriesImpl (Dm3MetricRegistriesImpl.java:addReporterRegistration(113)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2024-04-06 10:33:34,755 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-04-06 10:33:34,762 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(555)) - Ozone container server started.
2024-04-06 10:33:34,767 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-04-06 10:33:34,769 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/meta/datanode.id
2024-04-06 10:33:34,770 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(240)) - HddsDatanodeService host:fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net ip:10.1.0.10
2024-04-06 10:33:34,786 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-04-06 10:33:34,787 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(299)) - Datanode State Machine Task Thread Pool size 2
2024-04-06 10:33:34,790 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(125)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/data-0/hdds of storage type : DISK capacity : 9223372036854775807
2024-04-06 10:33:34,790 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/data-0/hdds to VolumeSet
2024-04-06 10:33:34,791 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis to VolumeSet
2024-04-06 10:33:34,792 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 0ms
2024-04-06 10:33:34,795 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-04-06 10:33:34,795 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-04-06 10:33:34,795 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15051 (custom)
2024-04-06 10:33:34,796 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-04-06 10:33:34,796 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15050 (custom)
2024-04-06 10:33:34,796 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-04-06 10:33:34,796 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15052 (custom)
2024-04-06 10:33:34,797 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-04-06 10:33:34,797 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:34,797 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-04-06 10:33:34,798 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:33:34,798 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-04-06 10:33:34,798 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-04-06 10:33:34,798 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-04-06 10:33:34,801 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-04-06 10:33:34,801 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-04-06 10:33:34,802 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-04-06 10:33:34,802 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-04-06 10:33:34,802 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-04-06 10:33:34,803 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-04-06 10:33:34,803 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-04-06 10:33:34,803 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-04-06 10:33:34,804 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-04-06 10:33:34,804 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-04-06 10:33:34,805 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-04-06 10:33:34,805 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-04-06 10:33:34,805 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-04-06 10:33:34,806 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15053 (custom)
2024-04-06 10:33:34,806 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:33:34,808 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-04-06 10:33:34,808 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:33:34,808 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis] (custom)
2024-04-06 10:33:34,809 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-04-06 10:33:34,809 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-04-06 10:33:34,808 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd606ca47] REGISTERED
2024-04-06 10:33:34,809 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis/tmp
2024-04-06 10:33:34,809 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd606ca47] BIND: 0.0.0.0/0.0.0.0:15053
2024-04-06 10:33:34,810 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd606ca47, L:/0.0.0.0:15053] ACTIVE
2024-04-06 10:33:34,810 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(269)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis/tmp is not a group directory; ignoring it. 
2024-04-06 10:33:34,810 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-04-06 10:33:34,811 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-04-06 10:33:34,813 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(157)) - Initializing replication supervisor with thread count = 10
2024-04-06 10:33:34,814 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-04-06 10:33:34,816 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15047
2024-04-06 10:33:34,817 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-04-06 10:33:34,819 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-04-06 10:33:34,819 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-04-06 10:33:34,821 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-04-06 10:33:34,822 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-04-06 10:33:34,823 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-04-06 10:33:34,823 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-04-06 10:33:34,824 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/meta/webserver
2024-04-06 10:33:34,824 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15047
2024-04-06 10:33:34,824 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-04-06 10:33:34,828 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-04-06 10:33:34,828 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-04-06 10:33:34,829 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2024-04-06 10:33:34,829 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@529dcc4b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-04-06 10:33:34,830 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6a989646{static,/static,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/static,AVAILABLE}
2024-04-06 10:33:34,833 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@415d089d{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode}
2024-04-06 10:33:34,836 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@7bab2266{HTTP/1.1, (http/1.1)}{0.0.0.0:15047}
2024-04-06 10:33:34,836 [main] INFO  server.Server (Server.java:doStart(415)) - Started @22635ms
2024-04-06 10:33:34,836 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-04-06 10:33:34,837 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15047
2024-04-06 10:33:34,837 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-04-06 10:33:34,837 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15048
2024-04-06 10:33:34,844 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(327)) - Datanode start with admins: [runner]
2024-04-06 10:33:34,844 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15048
2024-04-06 10:33:34,844 [Socket Reader #1 for port 15048] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15048
2024-04-06 10:33:34,851 [IPC Server listener on 15048] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15048: starting
2024-04-06 10:33:34,851 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(555)) - Ozone container server started.
2024-04-06 10:33:34,852 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-04-06 10:33:34,854 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 0 of 5 DN Heartbeats.
2024-04-06 10:33:34,855 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-04-06 10:33:34,855 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-04-06 10:33:34,864 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-04-06 10:33:34,866 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/meta/datanode.id
2024-04-06 10:33:35,025 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:33:35,025 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:35,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:35,859 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 0 of 5 DN Heartbeats.
2024-04-06 10:33:35,859 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-04-06 10:33:35,859 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-04-06 10:33:36,026 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:33:36,026 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:36,487 [59c3495a-7636-40f9-8dfa-c28be8e98abd-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-4675313e-af28-48bb-b976-c300dd20b142/container.db to cache
2024-04-06 10:33:36,487 [59c3495a-7636-40f9-8dfa-c28be8e98abd-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(420)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-4675313e-af28-48bb-b976-c300dd20b142/container.db for volume DS-4675313e-af28-48bb-b976-c300dd20b142
2024-04-06 10:33:36,496 [59c3495a-7636-40f9-8dfa-c28be8e98abd-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/data-0/hdds
2024-04-06 10:33:36,496 [59c3495a-7636-40f9-8dfa-c28be8e98abd-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/data-0/hdds
2024-04-06 10:33:36,496 [59c3495a-7636-40f9-8dfa-c28be8e98abd-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-04-06 10:33:36,497 [59c3495a-7636-40f9-8dfa-c28be8e98abd-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/data-0/hdds
2024-04-06 10:33:36,504 [59c3495a-7636-40f9-8dfa-c28be8e98abd-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/data-0/hdds
2024-04-06 10:33:36,507 [59c3495a-7636-40f9-8dfa-c28be8e98abd-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis
2024-04-06 10:33:36,507 [59c3495a-7636-40f9-8dfa-c28be8e98abd-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis
2024-04-06 10:33:36,507 [59c3495a-7636-40f9-8dfa-c28be8e98abd-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-04-06 10:33:36,513 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-04-06 10:33:36,516 [59c3495a-7636-40f9-8dfa-c28be8e98abd-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15018
2024-04-06 10:33:36,517 [59c3495a-7636-40f9-8dfa-c28be8e98abd-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(566)) - Starting XceiverServerRatis 59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:33:36,518 [59c3495a-7636-40f9-8dfa-c28be8e98abd-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(406)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: start RPC server
2024-04-06 10:33:36,518 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-04-06 10:33:36,524 [59c3495a-7636-40f9-8dfa-c28be8e98abd-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: GrpcService started, listening on 15014
2024-04-06 10:33:36,526 [59c3495a-7636-40f9-8dfa-c28be8e98abd-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: GrpcService started, listening on 15016
2024-04-06 10:33:36,527 [59c3495a-7636-40f9-8dfa-c28be8e98abd-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: GrpcService started, listening on 15015
2024-04-06 10:33:36,527 [JvmPauseMonitor3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-59c3495a-7636-40f9-8dfa-c28be8e98abd: Started
2024-04-06 10:33:36,527 [59c3495a-7636-40f9-8dfa-c28be8e98abd-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 59c3495a-7636-40f9-8dfa-c28be8e98abd is started using port 15014 for RATIS
2024-04-06 10:33:36,528 [59c3495a-7636-40f9-8dfa-c28be8e98abd-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 59c3495a-7636-40f9-8dfa-c28be8e98abd is started using port 15015 for RATIS_ADMIN
2024-04-06 10:33:36,528 [59c3495a-7636-40f9-8dfa-c28be8e98abd-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 59c3495a-7636-40f9-8dfa-c28be8e98abd is started using port 15016 for RATIS_SERVER
2024-04-06 10:33:36,528 [59c3495a-7636-40f9-8dfa-c28be8e98abd-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis 59c3495a-7636-40f9-8dfa-c28be8e98abd is started using port 15017 for RATIS_DATASTREAM
2024-04-06 10:33:36,537 [59c3495a-7636-40f9-8dfa-c28be8e98abd-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-04-06 10:33:36,563 [cc1e4d3c-2283-4c28-b737-db868cb45369-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-0073f244-62c3-44f0-a0dd-f946c3c303ab/container.db to cache
2024-04-06 10:33:36,563 [cc1e4d3c-2283-4c28-b737-db868cb45369-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(420)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-0073f244-62c3-44f0-a0dd-f946c3c303ab/container.db for volume DS-0073f244-62c3-44f0-a0dd-f946c3c303ab
2024-04-06 10:33:36,566 [cc1e4d3c-2283-4c28-b737-db868cb45369-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/data-0/hdds
2024-04-06 10:33:36,566 [cc1e4d3c-2283-4c28-b737-db868cb45369-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/data-0/hdds
2024-04-06 10:33:36,566 [cc1e4d3c-2283-4c28-b737-db868cb45369-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-04-06 10:33:36,567 [cc1e4d3c-2283-4c28-b737-db868cb45369-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/data-0/hdds
2024-04-06 10:33:36,568 [cc1e4d3c-2283-4c28-b737-db868cb45369-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/data-0/hdds
2024-04-06 10:33:36,569 [cc1e4d3c-2283-4c28-b737-db868cb45369-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis
2024-04-06 10:33:36,569 [cc1e4d3c-2283-4c28-b737-db868cb45369-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis
2024-04-06 10:33:36,570 [cc1e4d3c-2283-4c28-b737-db868cb45369-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-04-06 10:33:36,571 [cc1e4d3c-2283-4c28-b737-db868cb45369-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(75)) - Trying to initialize on demand scanner a second time on a datanode.
2024-04-06 10:33:36,572 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-04-06 10:33:36,572 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-04-06 10:33:36,574 [cc1e4d3c-2283-4c28-b737-db868cb45369-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15027
2024-04-06 10:33:36,574 [cc1e4d3c-2283-4c28-b737-db868cb45369-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(566)) - Starting XceiverServerRatis cc1e4d3c-2283-4c28-b737-db868cb45369
2024-04-06 10:33:36,579 [cc1e4d3c-2283-4c28-b737-db868cb45369-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(406)) - cc1e4d3c-2283-4c28-b737-db868cb45369: start RPC server
2024-04-06 10:33:36,581 [cc1e4d3c-2283-4c28-b737-db868cb45369-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - cc1e4d3c-2283-4c28-b737-db868cb45369: GrpcService started, listening on 15023
2024-04-06 10:33:36,582 [cc1e4d3c-2283-4c28-b737-db868cb45369-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - cc1e4d3c-2283-4c28-b737-db868cb45369: GrpcService started, listening on 15025
2024-04-06 10:33:36,585 [cc1e4d3c-2283-4c28-b737-db868cb45369-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - cc1e4d3c-2283-4c28-b737-db868cb45369: GrpcService started, listening on 15024
2024-04-06 10:33:36,585 [cc1e4d3c-2283-4c28-b737-db868cb45369-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis cc1e4d3c-2283-4c28-b737-db868cb45369 is started using port 15023 for RATIS
2024-04-06 10:33:36,585 [JvmPauseMonitor4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-cc1e4d3c-2283-4c28-b737-db868cb45369: Started
2024-04-06 10:33:36,585 [cc1e4d3c-2283-4c28-b737-db868cb45369-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis cc1e4d3c-2283-4c28-b737-db868cb45369 is started using port 15024 for RATIS_ADMIN
2024-04-06 10:33:36,586 [cc1e4d3c-2283-4c28-b737-db868cb45369-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis cc1e4d3c-2283-4c28-b737-db868cb45369 is started using port 15025 for RATIS_SERVER
2024-04-06 10:33:36,586 [cc1e4d3c-2283-4c28-b737-db868cb45369-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis cc1e4d3c-2283-4c28-b737-db868cb45369 is started using port 15026 for RATIS_DATASTREAM
2024-04-06 10:33:36,590 [cc1e4d3c-2283-4c28-b737-db868cb45369-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-04-06 10:33:36,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:36,732 [d1715241-1ffa-4146-b219-94c9c0fc171f-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-94805b0f-2d69-4e9a-b453-7c1f770fc019/container.db to cache
2024-04-06 10:33:36,733 [d1715241-1ffa-4146-b219-94c9c0fc171f-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(420)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-94805b0f-2d69-4e9a-b453-7c1f770fc019/container.db for volume DS-94805b0f-2d69-4e9a-b453-7c1f770fc019
2024-04-06 10:33:36,734 [d1715241-1ffa-4146-b219-94c9c0fc171f-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/data-0/hdds
2024-04-06 10:33:36,734 [d1715241-1ffa-4146-b219-94c9c0fc171f-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/data-0/hdds
2024-04-06 10:33:36,735 [d1715241-1ffa-4146-b219-94c9c0fc171f-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-04-06 10:33:36,735 [d1715241-1ffa-4146-b219-94c9c0fc171f-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/data-0/hdds
2024-04-06 10:33:36,736 [d1715241-1ffa-4146-b219-94c9c0fc171f-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/data-0/hdds
2024-04-06 10:33:36,737 [d1715241-1ffa-4146-b219-94c9c0fc171f-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis
2024-04-06 10:33:36,737 [d1715241-1ffa-4146-b219-94c9c0fc171f-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis
2024-04-06 10:33:36,738 [d1715241-1ffa-4146-b219-94c9c0fc171f-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-04-06 10:33:36,738 [d1715241-1ffa-4146-b219-94c9c0fc171f-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(75)) - Trying to initialize on demand scanner a second time on a datanode.
2024-04-06 10:33:36,739 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-04-06 10:33:36,739 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-04-06 10:33:36,741 [d1715241-1ffa-4146-b219-94c9c0fc171f-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15036
2024-04-06 10:33:36,741 [d1715241-1ffa-4146-b219-94c9c0fc171f-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(566)) - Starting XceiverServerRatis d1715241-1ffa-4146-b219-94c9c0fc171f
2024-04-06 10:33:36,742 [d1715241-1ffa-4146-b219-94c9c0fc171f-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(406)) - d1715241-1ffa-4146-b219-94c9c0fc171f: start RPC server
2024-04-06 10:33:36,744 [d1715241-1ffa-4146-b219-94c9c0fc171f-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - d1715241-1ffa-4146-b219-94c9c0fc171f: GrpcService started, listening on 15032
2024-04-06 10:33:36,745 [d1715241-1ffa-4146-b219-94c9c0fc171f-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - d1715241-1ffa-4146-b219-94c9c0fc171f: GrpcService started, listening on 15034
2024-04-06 10:33:36,747 [d1715241-1ffa-4146-b219-94c9c0fc171f-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - d1715241-1ffa-4146-b219-94c9c0fc171f: GrpcService started, listening on 15033
2024-04-06 10:33:36,747 [d1715241-1ffa-4146-b219-94c9c0fc171f-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis d1715241-1ffa-4146-b219-94c9c0fc171f is started using port 15032 for RATIS
2024-04-06 10:33:36,747 [JvmPauseMonitor5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-d1715241-1ffa-4146-b219-94c9c0fc171f: Started
2024-04-06 10:33:36,747 [d1715241-1ffa-4146-b219-94c9c0fc171f-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis d1715241-1ffa-4146-b219-94c9c0fc171f is started using port 15033 for RATIS_ADMIN
2024-04-06 10:33:36,748 [d1715241-1ffa-4146-b219-94c9c0fc171f-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis d1715241-1ffa-4146-b219-94c9c0fc171f is started using port 15034 for RATIS_SERVER
2024-04-06 10:33:36,748 [d1715241-1ffa-4146-b219-94c9c0fc171f-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis d1715241-1ffa-4146-b219-94c9c0fc171f is started using port 15035 for RATIS_DATASTREAM
2024-04-06 10:33:36,751 [d1715241-1ffa-4146-b219-94c9c0fc171f-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-04-06 10:33:36,790 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-db18787f-e7de-4e98-b685-d88b6726d128/container.db to cache
2024-04-06 10:33:36,791 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(420)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-db18787f-e7de-4e98-b685-d88b6726d128/container.db for volume DS-db18787f-e7de-4e98-b685-d88b6726d128
2024-04-06 10:33:36,793 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/data-0/hdds
2024-04-06 10:33:36,793 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/data-0/hdds
2024-04-06 10:33:36,793 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-04-06 10:33:36,794 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/data-0/hdds
2024-04-06 10:33:36,794 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/data-0/hdds
2024-04-06 10:33:36,795 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis
2024-04-06 10:33:36,796 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis
2024-04-06 10:33:36,796 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-04-06 10:33:36,796 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(75)) - Trying to initialize on demand scanner a second time on a datanode.
2024-04-06 10:33:36,797 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-04-06 10:33:36,799 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-04-06 10:33:36,800 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15045
2024-04-06 10:33:36,800 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(566)) - Starting XceiverServerRatis a40aef6e-dfc7-4141-9a41-17d72bf4eeff
2024-04-06 10:33:36,802 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(406)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: start RPC server
2024-04-06 10:33:36,804 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: GrpcService started, listening on 15041
2024-04-06 10:33:36,805 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: GrpcService started, listening on 15043
2024-04-06 10:33:36,811 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: GrpcService started, listening on 15042
2024-04-06 10:33:36,811 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis a40aef6e-dfc7-4141-9a41-17d72bf4eeff is started using port 15041 for RATIS
2024-04-06 10:33:36,812 [JvmPauseMonitor6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-a40aef6e-dfc7-4141-9a41-17d72bf4eeff: Started
2024-04-06 10:33:36,812 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis a40aef6e-dfc7-4141-9a41-17d72bf4eeff is started using port 15042 for RATIS_ADMIN
2024-04-06 10:33:36,812 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis a40aef6e-dfc7-4141-9a41-17d72bf4eeff is started using port 15043 for RATIS_SERVER
2024-04-06 10:33:36,812 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis a40aef6e-dfc7-4141-9a41-17d72bf4eeff is started using port 15044 for RATIS_DATASTREAM
2024-04-06 10:33:36,816 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-04-06 10:33:36,859 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 0 of 5 DN Heartbeats.
2024-04-06 10:33:36,859 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-04-06 10:33:36,859 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-04-06 10:33:36,887 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-efa4f3ca-3766-4044-9fcf-6b2e56cb6fe0/container.db to cache
2024-04-06 10:33:36,887 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(420)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-efa4f3ca-3766-4044-9fcf-6b2e56cb6fe0/container.db for volume DS-efa4f3ca-3766-4044-9fcf-6b2e56cb6fe0
2024-04-06 10:33:36,889 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(148)) - Start to verify containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/data-0/hdds
2024-04-06 10:33:36,889 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-ContainerReader-0] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(178)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/data-0/hdds
2024-04-06 10:33:36,889 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(328)) - Build ContainerSet costs 0s
2024-04-06 10:33:36,890 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/data-0/hdds
2024-04-06 10:33:36,890 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/data-0/hdds
2024-04-06 10:33:36,892 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis
2024-04-06 10:33:36,892 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(218)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis
2024-04-06 10:33:36,893 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(459)) - Attempting to start container services.
2024-04-06 10:33:36,893 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] WARN  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:init(75)) - Trying to initialize on demand scanner a second time on a datanode.
2024-04-06 10:33:36,894 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-04-06 10:33:36,894 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:runIteration(87)) - Completed an iteration in 0 minutes. Number of iterations (since the data-node restart) : 1, Number of containers scanned in this iteration : 0, Number of unhealthy containers found in this iteration : 0
2024-04-06 10:33:36,895 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(142)) - ReplicationServer is started using port 15054
2024-04-06 10:33:36,895 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(566)) - Starting XceiverServerRatis ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2
2024-04-06 10:33:36,896 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(406)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: start RPC server
2024-04-06 10:33:36,897 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: GrpcService started, listening on 15050
2024-04-06 10:33:36,897 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: GrpcService started, listening on 15052
2024-04-06 10:33:36,898 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  server.GrpcService (GrpcService.java:startImpl(302)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: GrpcService started, listening on 15051
2024-04-06 10:33:36,898 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2 is started using port 15050 for RATIS
2024-04-06 10:33:36,899 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2 is started using port 15051 for RATIS_ADMIN
2024-04-06 10:33:36,899 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2 is started using port 15052 for RATIS_SERVER
2024-04-06 10:33:36,899 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(592)) - XceiverServerRatis ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2 is started using port 15053 for RATIS_DATASTREAM
2024-04-06 10:33:36,898 [JvmPauseMonitor7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(146)) - JvmPauseMonitor-ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: Started
2024-04-06 10:33:36,902 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-04-06 10:33:37,027 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:33:37,027 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:37,608 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:37,860 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 0 of 5 DN Heartbeats.
2024-04-06 10:33:37,860 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-04-06 10:33:37,860 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-04-06 10:33:38,028 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:33:38,029 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:38,413 [IPC Server handler 0 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:33:38,413 [IPC Server handler 0 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:33:38,416 [IPC Server handler 0 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: 59c3495a-7636-40f9-8dfa-c28be8e98abd{ip: 10.1.0.10, host: fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net, ports: [HTTP=15011, CLIENT_RPC=15012, REPLICATION=15018, RATIS=15014, RATIS_ADMIN=15015, RATIS_SERVER=15016, RATIS_DATASTREAM=15017, STANDALONE=15013], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-04-06 10:33:38,416 [IPC Server handler 0 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: 59c3495a-7636-40f9-8dfa-c28be8e98abd{ip: 10.1.0.10, host: fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net, ports: [HTTP=15011, CLIENT_RPC=15012, REPLICATION=15018, RATIS=15014, RATIS_ADMIN=15015, RATIS_SERVER=15016, RATIS_DATASTREAM=15017, STANDALONE=15013], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-04-06 10:33:38,419 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-04-06 10:33:38,422 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(138)) - Adding new node 59c3495a-7636-40f9-8dfa-c28be8e98abd to Node DB.
2024-04-06 10:33:38,443 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 23 millisec, 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 0}
2024-04-06 10:33:38,443 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2024-04-06 10:33:38,442 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - ContainerSafeModeRule rule is successfully validated
2024-04-06 10:33:38,444 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 24 millisec, 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 0}
2024-04-06 10:33:38,442 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 22 millisec, 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 0}
2024-04-06 10:33:38,446 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - AtleastOneDatanodeReportedRule rule is successfully validated
2024-04-06 10:33:38,449 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 30 millisec, 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 0}
2024-04-06 10:33:38,451 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=9db4cf61-9812-4683-bf84-8188ee38776f to datanode:59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:33:38,460 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 9db4cf61-9812-4683-bf84-8188ee38776f, Nodes: 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-04-06T10:33:38.450Z[Etc/UTC]]
2024-04-06 10:33:38,542 [IPC Server handler 3 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/cc1e4d3c-2283-4c28-b737-db868cb45369
2024-04-06 10:33:38,542 [IPC Server handler 3 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: cc1e4d3c-2283-4c28-b737-db868cb45369{ip: 10.1.0.10, host: fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net, ports: [HTTP=15020, CLIENT_RPC=15021, REPLICATION=15027, RATIS=15023, RATIS_ADMIN=15024, RATIS_SERVER=15025, RATIS_DATASTREAM=15026, STANDALONE=15022], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-04-06 10:33:38,542 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2024-04-06 10:33:38,543 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-04-06 10:33:38,544 [IPC Server handler 1 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/cc1e4d3c-2283-4c28-b737-db868cb45369
2024-04-06 10:33:38,544 [IPC Server handler 1 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: cc1e4d3c-2283-4c28-b737-db868cb45369{ip: 10.1.0.10, host: fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net, ports: [HTTP=15020, CLIENT_RPC=15021, REPLICATION=15027, RATIS=15023, RATIS_ADMIN=15024, RATIS_SERVER=15025, RATIS_DATASTREAM=15026, STANDALONE=15022], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-04-06 10:33:38,544 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=8be94057-6f6e-4ca0-8619-73828bace674 to datanode:cc1e4d3c-2283-4c28-b737-db868cb45369
2024-04-06 10:33:38,546 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(138)) - Adding new node cc1e4d3c-2283-4c28-b737-db868cb45369 to Node DB.
2024-04-06 10:33:38,546 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 8be94057-6f6e-4ca0-8619-73828bace674, Nodes: cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-04-06T10:33:38.544Z[Etc/UTC]]
2024-04-06 10:33:38,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:38,678 [IPC Server handler 3 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/d1715241-1ffa-4146-b219-94c9c0fc171f
2024-04-06 10:33:38,678 [IPC Server handler 4 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/d1715241-1ffa-4146-b219-94c9c0fc171f
2024-04-06 10:33:38,679 [IPC Server handler 3 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: d1715241-1ffa-4146-b219-94c9c0fc171f{ip: 10.1.0.10, host: fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net, ports: [HTTP=15029, CLIENT_RPC=15030, REPLICATION=15036, RATIS=15032, RATIS_ADMIN=15033, RATIS_SERVER=15034, RATIS_DATASTREAM=15035, STANDALONE=15031], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-04-06 10:33:38,679 [IPC Server handler 4 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: d1715241-1ffa-4146-b219-94c9c0fc171f{ip: 10.1.0.10, host: fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net, ports: [HTTP=15029, CLIENT_RPC=15030, REPLICATION=15036, RATIS=15032, RATIS_ADMIN=15033, RATIS_SERVER=15034, RATIS_DATASTREAM=15035, STANDALONE=15031], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-04-06 10:33:38,679 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-04-06 10:33:38,679 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2024-04-06 10:33:38,680 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - DataNodeSafeModeRule rule is successfully validated
2024-04-06 10:33:38,680 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(229)) - All SCM safe mode pre check rules have passed
2024-04-06 10:33:38,680 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(225)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2024-04-06 10:33:38,680 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-04-06 10:33:38,681 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(138)) - Adding new node d1715241-1ffa-4146-b219-94c9c0fc171f to Node DB.
2024-04-06 10:33:38,682 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 4 millisec, d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 0}
2024-04-06 10:33:38,683 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 4 millisec, d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 0}
2024-04-06 10:33:38,684 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=47341687-34d7-44e9-a74c-836518d32a71 to datanode:d1715241-1ffa-4146-b219-94c9c0fc171f
2024-04-06 10:33:38,685 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 47341687-34d7-44e9-a74c-836518d32a71, Nodes: d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-04-06T10:33:38.684Z[Etc/UTC]]
2024-04-06 10:33:38,689 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 to datanode:cc1e4d3c-2283-4c28-b737-db868cb45369
2024-04-06 10:33:38,689 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 to datanode:d1715241-1ffa-4146-b219-94c9c0fc171f
2024-04-06 10:33:38,689 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 to datanode:59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:33:38,690 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: b4229e37-69d0-4c7f-a467-673fb5e812e7, Nodes: cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-04-06T10:33:38.689Z[Etc/UTC]]
2024-04-06 10:33:38,769 [IPC Server handler 4 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/a40aef6e-dfc7-4141-9a41-17d72bf4eeff
2024-04-06 10:33:38,769 [IPC Server handler 2 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/a40aef6e-dfc7-4141-9a41-17d72bf4eeff
2024-04-06 10:33:38,769 [IPC Server handler 4 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: a40aef6e-dfc7-4141-9a41-17d72bf4eeff{ip: 10.1.0.10, host: fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net, ports: [HTTP=15038, CLIENT_RPC=15039, REPLICATION=15045, RATIS=15041, RATIS_ADMIN=15042, RATIS_SERVER=15043, RATIS_DATASTREAM=15044, STANDALONE=15040], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-04-06 10:33:38,772 [IPC Server handler 2 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: a40aef6e-dfc7-4141-9a41-17d72bf4eeff{ip: 10.1.0.10, host: fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net, ports: [HTTP=15038, CLIENT_RPC=15039, REPLICATION=15045, RATIS=15041, RATIS_ADMIN=15042, RATIS_SERVER=15043, RATIS_DATASTREAM=15044, STANDALONE=15040], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-04-06 10:33:38,772 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(138)) - Adding new node a40aef6e-dfc7-4141-9a41-17d72bf4eeff to Node DB.
2024-04-06 10:33:38,773 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-04-06 10:33:38,774 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 0}
2024-04-06 10:33:38,774 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 0}
2024-04-06 10:33:38,774 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 0}
2024-04-06 10:33:38,774 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=97b25c4a-3cf1-4ab4-a703-2d61d60de43d to datanode:a40aef6e-dfc7-4141-9a41-17d72bf4eeff
2024-04-06 10:33:38,774 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 0}
2024-04-06 10:33:38,775 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 97b25c4a-3cf1-4ab4-a703-2d61d60de43d, Nodes: a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-04-06T10:33:38.774Z[Etc/UTC]]
2024-04-06 10:33:38,860 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Waiting for nodes to be ready. Got 4 of 5 DN Heartbeats.
2024-04-06 10:33:38,860 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-04-06 10:33:38,861 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-04-06 10:33:38,864 [IPC Server handler 5 on default port 15002] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2
2024-04-06 10:33:38,865 [IPC Server handler 5 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2{ip: 10.1.0.10, host: fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net, ports: [HTTP=15047, CLIENT_RPC=15048, REPLICATION=15054, RATIS=15050, RATIS_ADMIN=15051, RATIS_SERVER=15052, RATIS_DATASTREAM=15053, STANDALONE=15049], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-04-06 10:33:38,864 [IPC Server handler 5 on default port 15009] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(134)) - Added a new node: /default-rack/ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2
2024-04-06 10:33:38,865 [IPC Server handler 5 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:register(421)) - Registered datanode: ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2{ip: 10.1.0.10, host: fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net, ports: [HTTP=15047, CLIENT_RPC=15048, REPLICATION=15054, RATIS=15050, RATIS_ADMIN=15051, RATIS_SERVER=15052, RATIS_DATASTREAM=15053, STANDALONE=15049], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2024-04-06 10:33:38,866 [Recon-EventQueue-NewNodeForReconNewNodeHandler] INFO  scm.ReconNodeManager (ReconNodeManager.java:addNodeToDB(138)) - Adding new node ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2 to Node DB.
2024-04-06 10:33:38,867 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-04-06 10:33:38,868 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=15039d4b-d7f6-4769-9a85-becc45517e23 to datanode:ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2
2024-04-06 10:33:38,869 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 15039d4b-d7f6-4769-9a85-becc45517e23, Nodes: ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-04-06T10:33:38.868Z[Etc/UTC]]
2024-04-06 10:33:39,030 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:33:39,030 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:39,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:39,861 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-04-06 10:33:39,861 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-04-06 10:33:39,861 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-04-06 10:33:40,031 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:33:40,031 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:40,423 [IPC Server handler 0 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net
2024-04-06 10:33:40,426 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 0}
2024-04-06 10:33:40,427 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 0}
2024-04-06 10:33:40,430 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 7 millisec, 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 0}
2024-04-06 10:33:40,431 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 7 millisec, 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 0}
2024-04-06 10:33:40,542 [IPC Server handler 1 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net
2024-04-06 10:33:40,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:40,675 [IPC Server handler 2 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net
2024-04-06 10:33:40,769 [IPC Server handler 4 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net
2024-04-06 10:33:40,861 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-04-06 10:33:40,862 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-04-06 10:33:40,862 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-04-06 10:33:40,866 [IPC Server handler 5 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:processHeartbeat(232)) - Sending ReregisterCommand() for fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net
2024-04-06 10:33:41,032 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:33:41,032 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:41,430 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: addNew group-8188EE38776F:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016] returns group-8188EE38776F:java.util.concurrent.CompletableFuture@74f65989[Not completed]
2024-04-06 10:33:41,436 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  lib.Interns (Interns.java:removeEldestEntry(50)) - Metrics intern cache overflow at 2011 for MetricsSystem={MetricsSystem=MetricsInfoImpl{name=MetricsSystem, description=MetricsSystem}, MetricsSystem record=MetricsInfoImpl{name=MetricsSystem, description=MetricsSystem record}}
2024-04-06 10:33:41,438 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: new RaftServerImpl for group-8188EE38776F:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016] with ContainerStateMachine:uninitialized
2024-04-06 10:33:41,439 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:33:41,439 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-04-06 10:33:41,439 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-04-06 10:33:41,439 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-04-06 10:33:41,439 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:33:41,439 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-04-06 10:33:41,439 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:33:41,439 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F: ConfigurationManager, init=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-04-06 10:33:41,439 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-04-06 10:33:41,439 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-04-06 10:33:41,440 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-04-06 10:33:41,440 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-04-06 10:33:41,440 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-04-06 10:33:41,440 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-04-06 10:33:41,446 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:33:41,446 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:33:41,446 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-04-06 10:33:41,446 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-04-06 10:33:41,446 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-04-06 10:33:41,446 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-04-06 10:33:41,447 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-04-06 10:33:41,447 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-04-06 10:33:41,447 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis] (custom)
2024-04-06 10:33:41,447 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) moved to stale state. Finalizing its pipelines []
2024-04-06 10:33:41,447 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/9db4cf61-9812-4683-bf84-8188ee38776f does not exist. Creating ...
2024-04-06 10:33:41,449 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/9db4cf61-9812-4683-bf84-8188ee38776f/in_use.lock acquired by nodename 82778@fv-az526-218
2024-04-06 10:33:41,452 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 0 pipelines in house.
2024-04-06 10:33:41,452 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(110)) - Adding new pipeline PipelineID=8be94057-6f6e-4ca0-8619-73828bace674 from SCM.
2024-04-06 10:33:41,452 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/9db4cf61-9812-4683-bf84-8188ee38776f has been successfully formatted.
2024-04-06 10:33:41,452 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/9db4cf61-9812-4683-bf84-8188ee38776f/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/9db4cf61-9812-4683-bf84-8188ee38776f/current/raft-meta.conf
2024-04-06 10:33:41,454 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-8188EE38776F: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-04-06 10:33:41,462 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-04-06 10:33:41,462 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-04-06 10:33:41,462 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:41,462 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-04-06 10:33:41,462 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-04-06 10:33:41,463 [IPC Server handler 1 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net
2024-04-06 10:33:41,464 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=9db4cf61-9812-4683-bf84-8188ee38776f. Trying to get from SCM.
2024-04-06 10:33:41,465 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=9db4cf61-9812-4683-bf84-8188ee38776f
2024-04-06 10:33:41,467 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-04-06 10:33:41,468 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:33:41,469 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-04-06 10:33:41,469 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-04-06 10:33:41,469 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:41,469 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(110)) - Adding new pipeline PipelineID=47341687-34d7-44e9-a74c-836518d32a71 from SCM.
2024-04-06 10:33:41,469 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-cacheEviction-AwaitToRun,5,main] started
2024-04-06 10:33:41,469 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/9db4cf61-9812-4683-bf84-8188ee38776f
2024-04-06 10:33:41,469 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-04-06 10:33:41,469 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-04-06 10:33:41,470 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:33:41,470 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-04-06 10:33:41,470 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-04-06 10:33:41,470 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-04-06 10:33:41,470 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(86)) - Adding new pipeline Pipeline[ Id: 9db4cf61-9812-4683-bf84-8188ee38776f, Nodes: 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:59c3495a-7636-40f9-8dfa-c28be8e98abd, CreationTimestamp2024-04-06T10:33:38.450Z[Etc/UTC]] to Recon pipeline metadata.
2024-04-06 10:33:41,470 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-04-06 10:33:41,470 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(110)) - Adding new pipeline PipelineID=15039d4b-d7f6-4769-9a85-becc45517e23 from SCM.
2024-04-06 10:33:41,470 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-04-06 10:33:41,472 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(110)) - Adding new pipeline PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 from SCM.
2024-04-06 10:33:41,472 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-04-06 10:33:41,473 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(110)) - Adding new pipeline PipelineID=9db4cf61-9812-4683-bf84-8188ee38776f from SCM.
2024-04-06 10:33:41,474 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:41,474 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-04-06 10:33:41,474 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-04-06 10:33:41,474 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-04-06 10:33:41,474 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(110)) - Adding new pipeline PipelineID=97b25c4a-3cf1-4ab4-a703-2d61d60de43d from SCM.
2024-04-06 10:33:41,475 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-04-06 10:33:41,475 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-04-06 10:33:41,475 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F: start as a follower, conf=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016]|listeners:[], old=null
2024-04-06 10:33:41,476 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-04-06 10:33:41,476 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: start 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-FollowerState
2024-04-06 10:33:41,476 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 28 milliseconds.
2024-04-06 10:33:41,476 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] WARN  pipeline.PipelineStateMap (PipelineStateMap.java:addPipeline(84)) - Duplicate pipeline ID detected. PipelineID=9db4cf61-9812-4683-bf84-8188ee38776f
2024-04-06 10:33:41,477 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] ERROR pipeline.PipelineReportHandler (PipelineReportHandler.java:onMessage(100)) - Could not process pipeline report=pipelineID {
  id: "9db4cf61-9812-4683-bf84-8188ee38776f"
  uuid128 {
    mostSigBits: -7082808295876835709
    leastSigBits: -4646446490427295889
  }
}
isLeader: false
bytesWritten: 0
 from dn=59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10).
org.apache.hadoop.hdds.scm.exceptions.SCMException: org.apache.ratis.protocol.exceptions.StateMachineException: org.apache.hadoop.hdds.scm.pipeline.DuplicatedPipelineIdException from Server peer@group-D42D0E60F3C4: Duplicate pipeline ID PipelineID=9db4cf61-9812-4683-bf84-8188ee38776f detected.
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.translateException(SCMHAInvocationHandler.java:165)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:115)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:74)
	at com.sun.proxy.$Proxy39.addPipeline(Unknown Source)
	at org.apache.hadoop.ozone.recon.scm.ReconPipelineManager.addPipeline(ReconPipelineManager.java:173)
	at org.apache.hadoop.ozone.recon.scm.ReconPipelineReportHandler.processPipelineReport(ReconPipelineReportHandler.java:88)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:93)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineReportHandler.onMessage(PipelineReportHandler.java:52)
	at org.apache.hadoop.hdds.server.events.SingleThreadExecutor.lambda$onMessage$1(SingleThreadExecutor.java:86)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.protocol.exceptions.StateMachineException: org.apache.hadoop.hdds.scm.pipeline.DuplicatedPipelineIdException from Server peer@group-D42D0E60F3C4: Duplicate pipeline ID PipelineID=9db4cf61-9812-4683-bf84-8188ee38776f detected.
	at org.apache.hadoop.hdds.scm.ha.SCMHAManagerStub$RatisServerStub.submitRequest(SCMHAManagerStub.java:199)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatisServer(SCMHAInvocationHandler.java:123)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeRatis(SCMHAInvocationHandler.java:112)
	... 10 more
Caused by: org.apache.hadoop.hdds.scm.pipeline.DuplicatedPipelineIdException: Duplicate pipeline ID PipelineID=9db4cf61-9812-4683-bf84-8188ee38776f detected.
	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.addPipeline(PipelineStateMap.java:86)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManagerImpl.addPipeline(PipelineStateManagerImpl.java:99)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.scm.ha.SCMHAManagerStub$RatisServerStub.process(SCMHAManagerStub.java:229)
	at org.apache.hadoop.hdds.scm.ha.SCMHAManagerStub$RatisServerStub.submitRequest(SCMHAManagerStub.java:191)
	... 12 more
2024-04-06 10:33:41,479 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:33:41,479 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8188EE38776F,id=59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:33:41,479 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:33:41,480 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-04-06 10:33:41,480 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-04-06 10:33:41,480 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-04-06 10:33:41,480 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-04-06 10:33:41,480 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-04-06 10:33:41,488 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=9db4cf61-9812-4683-bf84-8188ee38776f
2024-04-06 10:33:41,489 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=9db4cf61-9812-4683-bf84-8188ee38776f.
2024-04-06 10:33:41,489 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: addNew group-673FB5E812E7:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025] returns group-673FB5E812E7:java.util.concurrent.CompletableFuture@188f7ff2[Not completed]
2024-04-06 10:33:41,491 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: new RaftServerImpl for group-673FB5E812E7:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025] with ContainerStateMachine:uninitialized
2024-04-06 10:33:41,491 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:33:41,491 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-04-06 10:33:41,491 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-04-06 10:33:41,491 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-04-06 10:33:41,491 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:33:41,491 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-04-06 10:33:41,491 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:33:41,491 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7: ConfigurationManager, init=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-04-06 10:33:41,492 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-04-06 10:33:41,492 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-04-06 10:33:41,492 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-04-06 10:33:41,492 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-04-06 10:33:41,492 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-04-06 10:33:41,492 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-04-06 10:33:41,498 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:33:41,498 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:33:41,498 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-04-06 10:33:41,498 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-04-06 10:33:41,499 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-04-06 10:33:41,499 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-04-06 10:33:41,499 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-04-06 10:33:41,499 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-04-06 10:33:41,499 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis] (custom)
2024-04-06 10:33:41,499 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7 does not exist. Creating ...
2024-04-06 10:33:41,500 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7/in_use.lock acquired by nodename 82778@fv-az526-218
2024-04-06 10:33:41,502 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7 has been successfully formatted.
2024-04-06 10:33:41,502 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7/current/raft-meta.conf
2024-04-06 10:33:41,503 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-673FB5E812E7: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-04-06 10:33:41,503 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-04-06 10:33:41,503 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-04-06 10:33:41,503 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:41,503 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-04-06 10:33:41,503 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-04-06 10:33:41,504 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-04-06 10:33:41,507 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 reported by 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:33:41,508 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/ONE PipelineID=9db4cf61-9812-4683-bf84-8188ee38776f reported by 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:33:41,509 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:33:41,510 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-04-06 10:33:41,510 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-04-06 10:33:41,510 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:41,510 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-cacheEviction-AwaitToRun,5,main] started
2024-04-06 10:33:41,510 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7
2024-04-06 10:33:41,511 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-04-06 10:33:41,511 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-04-06 10:33:41,511 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:33:41,511 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-04-06 10:33:41,511 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-04-06 10:33:41,511 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-04-06 10:33:41,511 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-04-06 10:33:41,511 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-04-06 10:33:41,512 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-04-06 10:33:41,513 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:41,513 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-04-06 10:33:41,513 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-04-06 10:33:41,513 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-04-06 10:33:41,514 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-04-06 10:33:41,514 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-04-06 10:33:41,514 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7: start as a follower, conf=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:33:41,514 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-04-06 10:33:41,514 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: start 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-FollowerState
2024-04-06 10:33:41,518 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:33:41,518 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-673FB5E812E7,id=59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:33:41,519 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-04-06 10:33:41,519 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-04-06 10:33:41,519 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-04-06 10:33:41,519 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-04-06 10:33:41,519 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-04-06 10:33:41,519 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:33:41,522 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7
2024-04-06 10:33:41,540 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - cc1e4d3c-2283-4c28-b737-db868cb45369: addNew group-73828BACE674:[cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025] returns group-73828BACE674:java.util.concurrent.CompletableFuture@464cf8e5[Not completed]
2024-04-06 10:33:41,542 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - cc1e4d3c-2283-4c28-b737-db868cb45369: new RaftServerImpl for group-73828BACE674:[cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025] with ContainerStateMachine:uninitialized
2024-04-06 10:33:41,542 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:33:41,543 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-04-06 10:33:41,543 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-04-06 10:33:41,543 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-04-06 10:33:41,543 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:33:41,543 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-04-06 10:33:41,543 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:33:41,543 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674: ConfigurationManager, init=-1: peers:[cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-04-06 10:33:41,543 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-04-06 10:33:41,543 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-04-06 10:33:41,543 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-04-06 10:33:41,543 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-04-06 10:33:41,544 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-04-06 10:33:41,544 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-04-06 10:33:41,547 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) moved to stale state. Finalizing its pipelines [PipelineID=8be94057-6f6e-4ca0-8619-73828bace674, PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7]
2024-04-06 10:33:41,548 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:33:41,548 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:33:41,548 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-04-06 10:33:41,548 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-04-06 10:33:41,548 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-04-06 10:33:41,548 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-04-06 10:33:41,548 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-04-06 10:33:41,548 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-04-06 10:33:41,548 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis] (custom)
2024-04-06 10:33:41,548 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=8be94057-6f6e-4ca0-8619-73828bace674 moved to CLOSED state
2024-04-06 10:33:41,549 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/8be94057-6f6e-4ca0-8619-73828bace674 does not exist. Creating ...
2024-04-06 10:33:41,551 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/8be94057-6f6e-4ca0-8619-73828bace674/in_use.lock acquired by nodename 82778@fv-az526-218
2024-04-06 10:33:41,551 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 moved to CLOSED state
2024-04-06 10:33:41,556 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 6 pipelines in house.
2024-04-06 10:33:41,560 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 9 milliseconds.
2024-04-06 10:33:41,552 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/8be94057-6f6e-4ca0-8619-73828bace674 has been successfully formatted.
2024-04-06 10:33:41,565 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/8be94057-6f6e-4ca0-8619-73828bace674/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/8be94057-6f6e-4ca0-8619-73828bace674/current/raft-meta.conf
2024-04-06 10:33:41,566 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-73828BACE674: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-04-06 10:33:41,567 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-04-06 10:33:41,567 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-04-06 10:33:41,567 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:41,567 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-04-06 10:33:41,567 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-04-06 10:33:41,569 [IPC Server handler 4 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net
2024-04-06 10:33:41,571 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/ONE PipelineID=8be94057-6f6e-4ca0-8619-73828bace674 reported by cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:33:41,572 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=8be94057-6f6e-4ca0-8619-73828bace674
2024-04-06 10:33:41,572 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-04-06 10:33:41,574 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:33:41,574 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-04-06 10:33:41,574 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-04-06 10:33:41,575 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:41,575 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-cacheEviction-AwaitToRun,5,main] started
2024-04-06 10:33:41,576 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/8be94057-6f6e-4ca0-8619-73828bace674
2024-04-06 10:33:41,576 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-04-06 10:33:41,576 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-04-06 10:33:41,576 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:33:41,577 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-04-06 10:33:41,577 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-04-06 10:33:41,577 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-04-06 10:33:41,577 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-04-06 10:33:41,577 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-04-06 10:33:41,577 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-04-06 10:33:41,581 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:41,581 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-04-06 10:33:41,581 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-04-06 10:33:41,581 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-04-06 10:33:41,581 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-04-06 10:33:41,581 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-04-06 10:33:41,582 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674: start as a follower, conf=-1: peers:[cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:33:41,583 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-04-06 10:33:41,583 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - cc1e4d3c-2283-4c28-b737-db868cb45369: start cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-FollowerState
2024-04-06 10:33:41,583 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-73828BACE674,id=cc1e4d3c-2283-4c28-b737-db868cb45369
2024-04-06 10:33:41,584 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-04-06 10:33:41,584 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:33:41,584 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-04-06 10:33:41,584 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:33:41,584 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-04-06 10:33:41,584 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-04-06 10:33:41,584 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-04-06 10:33:41,586 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=8be94057-6f6e-4ca0-8619-73828bace674
2024-04-06 10:33:41,586 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=8be94057-6f6e-4ca0-8619-73828bace674.
2024-04-06 10:33:41,586 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - cc1e4d3c-2283-4c28-b737-db868cb45369: addNew group-673FB5E812E7:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025] returns group-673FB5E812E7:java.util.concurrent.CompletableFuture@427374f4[Not completed]
2024-04-06 10:33:41,588 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - cc1e4d3c-2283-4c28-b737-db868cb45369: new RaftServerImpl for group-673FB5E812E7:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025] with ContainerStateMachine:uninitialized
2024-04-06 10:33:41,588 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:33:41,589 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-04-06 10:33:41,589 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-04-06 10:33:41,589 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-04-06 10:33:41,589 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:33:41,589 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-04-06 10:33:41,589 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:33:41,589 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7: ConfigurationManager, init=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-04-06 10:33:41,589 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-04-06 10:33:41,589 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-04-06 10:33:41,589 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-04-06 10:33:41,590 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-04-06 10:33:41,590 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-04-06 10:33:41,590 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-04-06 10:33:41,598 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:33:41,602 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:33:41,602 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-04-06 10:33:41,602 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-04-06 10:33:41,602 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-04-06 10:33:41,602 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-04-06 10:33:41,603 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-04-06 10:33:41,604 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-04-06 10:33:41,604 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis] (custom)
2024-04-06 10:33:41,604 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7 does not exist. Creating ...
2024-04-06 10:33:41,605 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7/in_use.lock acquired by nodename 82778@fv-az526-218
2024-04-06 10:33:41,607 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7 has been successfully formatted.
2024-04-06 10:33:41,607 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7/current/raft-meta.conf
2024-04-06 10:33:41,607 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-673FB5E812E7: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-04-06 10:33:41,607 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-04-06 10:33:41,607 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-04-06 10:33:41,607 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:41,608 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-04-06 10:33:41,608 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-04-06 10:33:41,609 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:41,610 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 0}
2024-04-06 10:33:41,611 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-04-06 10:33:41,611 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 reported by cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:33:41,612 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:33:41,612 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-04-06 10:33:41,613 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-04-06 10:33:41,613 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:41,613 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-cacheEviction-AwaitToRun,5,main] started
2024-04-06 10:33:41,613 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7
2024-04-06 10:33:41,613 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-04-06 10:33:41,613 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-04-06 10:33:41,613 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:33:41,613 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-04-06 10:33:41,614 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-04-06 10:33:41,614 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-04-06 10:33:41,614 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-04-06 10:33:41,614 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-04-06 10:33:41,614 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-04-06 10:33:41,616 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:41,616 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-04-06 10:33:41,616 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-04-06 10:33:41,616 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-04-06 10:33:41,617 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-04-06 10:33:41,617 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-04-06 10:33:41,619 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7: start as a follower, conf=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:33:41,619 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-04-06 10:33:41,619 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - cc1e4d3c-2283-4c28-b737-db868cb45369: start cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-FollowerState
2024-04-06 10:33:41,620 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-673FB5E812E7,id=cc1e4d3c-2283-4c28-b737-db868cb45369
2024-04-06 10:33:41,620 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-04-06 10:33:41,621 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-04-06 10:33:41,621 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-04-06 10:33:41,621 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-04-06 10:33:41,621 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-04-06 10:33:41,621 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:33:41,621 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:33:41,622 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7
2024-04-06 10:33:41,673 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - d1715241-1ffa-4146-b219-94c9c0fc171f: addNew group-836518D32A71:[d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034] returns group-836518D32A71:java.util.concurrent.CompletableFuture@740826d8[Not completed]
2024-04-06 10:33:41,675 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - d1715241-1ffa-4146-b219-94c9c0fc171f: new RaftServerImpl for group-836518D32A71:[d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034] with ContainerStateMachine:uninitialized
2024-04-06 10:33:41,675 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:33:41,675 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-04-06 10:33:41,675 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-04-06 10:33:41,675 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-04-06 10:33:41,675 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:33:41,676 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-04-06 10:33:41,676 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:33:41,676 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71: ConfigurationManager, init=-1: peers:[d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-04-06 10:33:41,676 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-04-06 10:33:41,676 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-04-06 10:33:41,676 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-04-06 10:33:41,676 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-04-06 10:33:41,676 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-04-06 10:33:41,676 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-04-06 10:33:41,680 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:33:41,680 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:33:41,680 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-04-06 10:33:41,680 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-04-06 10:33:41,680 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-04-06 10:33:41,680 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-04-06 10:33:41,681 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-04-06 10:33:41,681 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-04-06 10:33:41,681 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis] (custom)
2024-04-06 10:33:41,681 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/47341687-34d7-44e9-a74c-836518d32a71 does not exist. Creating ...
2024-04-06 10:33:41,682 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/47341687-34d7-44e9-a74c-836518d32a71/in_use.lock acquired by nodename 82778@fv-az526-218
2024-04-06 10:33:41,683 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/47341687-34d7-44e9-a74c-836518d32a71 has been successfully formatted.
2024-04-06 10:33:41,684 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/47341687-34d7-44e9-a74c-836518d32a71/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/47341687-34d7-44e9-a74c-836518d32a71/current/raft-meta.conf
2024-04-06 10:33:41,684 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-836518D32A71: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-04-06 10:33:41,684 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-04-06 10:33:41,684 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-04-06 10:33:41,684 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:41,685 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-04-06 10:33:41,685 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-04-06 10:33:41,686 [IPC Server handler 7 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net
2024-04-06 10:33:41,686 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=47341687-34d7-44e9-a74c-836518d32a71
2024-04-06 10:33:41,687 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-04-06 10:33:41,687 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/ONE PipelineID=47341687-34d7-44e9-a74c-836518d32a71 reported by d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:33:41,689 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:33:41,689 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-04-06 10:33:41,689 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-04-06 10:33:41,690 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:41,690 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-cacheEviction-AwaitToRun,5,main] started
2024-04-06 10:33:41,690 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/47341687-34d7-44e9-a74c-836518d32a71
2024-04-06 10:33:41,690 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-04-06 10:33:41,690 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-04-06 10:33:41,690 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:33:41,690 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-04-06 10:33:41,690 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-04-06 10:33:41,691 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-04-06 10:33:41,691 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-04-06 10:33:41,691 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-04-06 10:33:41,691 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-04-06 10:33:41,692 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:41,692 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-04-06 10:33:41,692 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-04-06 10:33:41,692 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-04-06 10:33:41,693 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-04-06 10:33:41,693 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-04-06 10:33:41,693 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71: start as a follower, conf=-1: peers:[d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034]|listeners:[], old=null
2024-04-06 10:33:41,693 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-04-06 10:33:41,694 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d1715241-1ffa-4146-b219-94c9c0fc171f: start d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-FollowerState
2024-04-06 10:33:41,694 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:33:41,694 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-836518D32A71,id=d1715241-1ffa-4146-b219-94c9c0fc171f
2024-04-06 10:33:41,694 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:33:41,694 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-04-06 10:33:41,694 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-04-06 10:33:41,694 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-04-06 10:33:41,695 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-04-06 10:33:41,695 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-04-06 10:33:41,697 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=47341687-34d7-44e9-a74c-836518d32a71
2024-04-06 10:33:41,697 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=47341687-34d7-44e9-a74c-836518d32a71.
2024-04-06 10:33:41,698 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - d1715241-1ffa-4146-b219-94c9c0fc171f: addNew group-673FB5E812E7:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025] returns group-673FB5E812E7:java.util.concurrent.CompletableFuture@7037ac81[Not completed]
2024-04-06 10:33:41,700 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - d1715241-1ffa-4146-b219-94c9c0fc171f: new RaftServerImpl for group-673FB5E812E7:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025] with ContainerStateMachine:uninitialized
2024-04-06 10:33:41,700 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:33:41,700 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-04-06 10:33:41,700 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-04-06 10:33:41,700 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-04-06 10:33:41,700 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:33:41,700 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-04-06 10:33:41,700 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:33:41,700 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7: ConfigurationManager, init=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-04-06 10:33:41,700 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-04-06 10:33:41,701 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-04-06 10:33:41,701 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-04-06 10:33:41,701 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-04-06 10:33:41,701 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-04-06 10:33:41,701 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-04-06 10:33:41,707 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:33:41,707 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:33:41,707 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-04-06 10:33:41,707 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-04-06 10:33:41,707 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-04-06 10:33:41,707 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-04-06 10:33:41,707 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-04-06 10:33:41,707 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-04-06 10:33:41,707 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis] (custom)
2024-04-06 10:33:41,707 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7 does not exist. Creating ...
2024-04-06 10:33:41,708 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7/in_use.lock acquired by nodename 82778@fv-az526-218
2024-04-06 10:33:41,710 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7 has been successfully formatted.
2024-04-06 10:33:41,710 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7/current/raft-meta.conf
2024-04-06 10:33:41,710 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-673FB5E812E7: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-04-06 10:33:41,710 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-04-06 10:33:41,710 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-04-06 10:33:41,710 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:41,711 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-04-06 10:33:41,711 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-04-06 10:33:41,712 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-04-06 10:33:41,713 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 reported by d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:33:41,717 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:33:41,717 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-04-06 10:33:41,717 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-04-06 10:33:41,717 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:41,718 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-cacheEviction-AwaitToRun,5,main] started
2024-04-06 10:33:41,718 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7
2024-04-06 10:33:41,718 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-04-06 10:33:41,718 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-04-06 10:33:41,719 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:33:41,719 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-04-06 10:33:41,719 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-04-06 10:33:41,719 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-04-06 10:33:41,719 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-04-06 10:33:41,719 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-04-06 10:33:41,720 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-04-06 10:33:41,721 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:41,721 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-04-06 10:33:41,721 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-04-06 10:33:41,721 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-04-06 10:33:41,721 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-04-06 10:33:41,721 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-04-06 10:33:41,722 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7: start as a follower, conf=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:33:41,722 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-04-06 10:33:41,722 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d1715241-1ffa-4146-b219-94c9c0fc171f: start d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-FollowerState
2024-04-06 10:33:41,722 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:33:41,722 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:33:41,722 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-673FB5E812E7,id=d1715241-1ffa-4146-b219-94c9c0fc171f
2024-04-06 10:33:41,722 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-04-06 10:33:41,722 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-04-06 10:33:41,723 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-04-06 10:33:41,723 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-04-06 10:33:41,723 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-04-06 10:33:41,724 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7
2024-04-06 10:33:41,766 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: addNew group-2D61D60DE43D:[a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043] returns group-2D61D60DE43D:java.util.concurrent.CompletableFuture@443e0036[Not completed]
2024-04-06 10:33:41,768 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: new RaftServerImpl for group-2D61D60DE43D:[a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043] with ContainerStateMachine:uninitialized
2024-04-06 10:33:41,768 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:33:41,768 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-04-06 10:33:41,768 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-04-06 10:33:41,768 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-04-06 10:33:41,769 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:33:41,769 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-04-06 10:33:41,769 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:33:41,769 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D: ConfigurationManager, init=-1: peers:[a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-04-06 10:33:41,769 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-04-06 10:33:41,769 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-04-06 10:33:41,769 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-04-06 10:33:41,769 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-04-06 10:33:41,770 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-04-06 10:33:41,770 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-04-06 10:33:41,774 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:33:41,774 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:33:41,775 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-04-06 10:33:41,775 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-04-06 10:33:41,775 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-04-06 10:33:41,775 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-04-06 10:33:41,775 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-04-06 10:33:41,775 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-04-06 10:33:41,775 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis] (custom)
2024-04-06 10:33:41,775 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/97b25c4a-3cf1-4ab4-a703-2d61d60de43d does not exist. Creating ...
2024-04-06 10:33:41,776 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/97b25c4a-3cf1-4ab4-a703-2d61d60de43d/in_use.lock acquired by nodename 82778@fv-az526-218
2024-04-06 10:33:41,778 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/97b25c4a-3cf1-4ab4-a703-2d61d60de43d has been successfully formatted.
2024-04-06 10:33:41,778 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/97b25c4a-3cf1-4ab4-a703-2d61d60de43d/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/97b25c4a-3cf1-4ab4-a703-2d61d60de43d/current/raft-meta.conf
2024-04-06 10:33:41,780 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=97b25c4a-3cf1-4ab4-a703-2d61d60de43d
2024-04-06 10:33:41,780 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-04-06 10:33:41,783 [IPC Server handler 10 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net
2024-04-06 10:33:41,783 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/ONE PipelineID=97b25c4a-3cf1-4ab4-a703-2d61d60de43d reported by a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:33:41,782 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-2D61D60DE43D: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-04-06 10:33:41,785 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-04-06 10:33:41,785 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-04-06 10:33:41,785 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:41,785 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-04-06 10:33:41,785 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-04-06 10:33:41,787 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:33:41,788 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-04-06 10:33:41,788 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-04-06 10:33:41,788 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:41,789 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-cacheEviction-AwaitToRun,5,main] started
2024-04-06 10:33:41,789 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/97b25c4a-3cf1-4ab4-a703-2d61d60de43d
2024-04-06 10:33:41,789 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-04-06 10:33:41,789 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-04-06 10:33:41,789 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:33:41,789 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-04-06 10:33:41,789 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-04-06 10:33:41,789 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-04-06 10:33:41,790 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-04-06 10:33:41,790 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-04-06 10:33:41,790 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-04-06 10:33:41,792 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:41,792 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-04-06 10:33:41,792 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-04-06 10:33:41,792 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-04-06 10:33:41,792 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-04-06 10:33:41,792 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-04-06 10:33:41,793 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D: start as a follower, conf=-1: peers:[a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043]|listeners:[], old=null
2024-04-06 10:33:41,793 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-04-06 10:33:41,793 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: start a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-FollowerState
2024-04-06 10:33:41,793 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:33:41,793 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2D61D60DE43D,id=a40aef6e-dfc7-4141-9a41-17d72bf4eeff
2024-04-06 10:33:41,793 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:33:41,793 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-04-06 10:33:41,794 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-04-06 10:33:41,794 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-04-06 10:33:41,794 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-04-06 10:33:41,794 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-04-06 10:33:41,795 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=97b25c4a-3cf1-4ab4-a703-2d61d60de43d
2024-04-06 10:33:41,795 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=97b25c4a-3cf1-4ab4-a703-2d61d60de43d.
2024-04-06 10:33:41,848 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) moved to stale state. Finalizing its pipelines [PipelineID=97b25c4a-3cf1-4ab4-a703-2d61d60de43d]
2024-04-06 10:33:41,849 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=97b25c4a-3cf1-4ab4-a703-2d61d60de43d moved to CLOSED state
2024-04-06 10:33:41,852 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 6 pipelines in house.
2024-04-06 10:33:41,857 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 8 milliseconds.
2024-04-06 10:33:41,862 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-04-06 10:33:41,862 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-04-06 10:33:41,862 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-04-06 10:33:41,868 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: addNew group-BECC45517E23:[ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052] returns group-BECC45517E23:java.util.concurrent.CompletableFuture@75abb893[Not completed]
2024-04-06 10:33:41,871 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: new RaftServerImpl for group-BECC45517E23:[ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052] with ContainerStateMachine:uninitialized
2024-04-06 10:33:41,871 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:33:41,871 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-04-06 10:33:41,871 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-04-06 10:33:41,872 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-04-06 10:33:41,872 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:33:41,872 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-04-06 10:33:41,872 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:33:41,873 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23: ConfigurationManager, init=-1: peers:[ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-04-06 10:33:41,873 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-04-06 10:33:41,873 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-04-06 10:33:41,873 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-04-06 10:33:41,873 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-04-06 10:33:41,874 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-04-06 10:33:41,874 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-04-06 10:33:41,877 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:33:41,877 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:33:41,878 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-04-06 10:33:41,878 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-04-06 10:33:41,878 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-04-06 10:33:41,878 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-04-06 10:33:41,878 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-04-06 10:33:41,879 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-04-06 10:33:41,879 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis] (custom)
2024-04-06 10:33:41,879 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis/15039d4b-d7f6-4769-9a85-becc45517e23 does not exist. Creating ...
2024-04-06 10:33:41,880 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis/15039d4b-d7f6-4769-9a85-becc45517e23/in_use.lock acquired by nodename 82778@fv-az526-218
2024-04-06 10:33:41,881 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis/15039d4b-d7f6-4769-9a85-becc45517e23 has been successfully formatted.
2024-04-06 10:33:41,882 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis/15039d4b-d7f6-4769-9a85-becc45517e23/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis/15039d4b-d7f6-4769-9a85-becc45517e23/current/raft-meta.conf
2024-04-06 10:33:41,882 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-BECC45517E23: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-04-06 10:33:41,882 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-04-06 10:33:41,883 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-04-06 10:33:41,883 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:41,884 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-04-06 10:33:41,884 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-04-06 10:33:41,887 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:33:41,887 [IPC Server handler 12 on default port 15009] INFO  scm.ReconNodeManager (ReconNodeManager.java:register(273)) - Updating nodeDB for fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net
2024-04-06 10:33:41,889 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/ONE PipelineID=15039d4b-d7f6-4769-9a85-becc45517e23 reported by ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:33:41,890 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=15039d4b-d7f6-4769-9a85-becc45517e23
2024-04-06 10:33:41,890 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-04-06 10:33:41,891 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-04-06 10:33:41,891 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-04-06 10:33:41,891 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:41,897 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-cacheEviction-AwaitToRun,5,main] started
2024-04-06 10:33:41,897 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis/15039d4b-d7f6-4769-9a85-becc45517e23
2024-04-06 10:33:41,897 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-04-06 10:33:41,898 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-04-06 10:33:41,898 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:33:41,898 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-04-06 10:33:41,898 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-04-06 10:33:41,898 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-04-06 10:33:41,898 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-04-06 10:33:41,898 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-04-06 10:33:41,899 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-04-06 10:33:41,901 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:41,901 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-04-06 10:33:41,901 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-04-06 10:33:41,901 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-04-06 10:33:41,901 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-04-06 10:33:41,901 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-04-06 10:33:41,902 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23: start as a follower, conf=-1: peers:[ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null
2024-04-06 10:33:41,902 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-04-06 10:33:41,902 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: start ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-FollowerState
2024-04-06 10:33:41,902 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:33:41,902 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BECC45517E23,id=ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2
2024-04-06 10:33:41,902 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:33:41,902 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-04-06 10:33:41,902 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-04-06 10:33:41,903 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-04-06 10:33:41,903 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-04-06 10:33:41,903 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-04-06 10:33:41,905 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=15039d4b-d7f6-4769-9a85-becc45517e23
2024-04-06 10:33:41,905 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=15039d4b-d7f6-4769-9a85-becc45517e23.
2024-04-06 10:33:41,948 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) moved to stale state. Finalizing its pipelines [PipelineID=15039d4b-d7f6-4769-9a85-becc45517e23]
2024-04-06 10:33:41,949 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=15039d4b-d7f6-4769-9a85-becc45517e23 moved to CLOSED state
2024-04-06 10:33:41,955 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 6 pipelines in house.
2024-04-06 10:33:41,960 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 11 milliseconds.
2024-04-06 10:33:42,035 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 2 milliseconds to process 0 existing database records.
2024-04-06 10:33:42,035 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:42,061 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7.
2024-04-06 10:33:42,066 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7.
2024-04-06 10:33:42,069 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7.
2024-04-06 10:33:42,504 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 reported by 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:33:42,504 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-04-06 10:33:42,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:42,711 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 reported by d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:33:42,711 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-04-06 10:33:42,779 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-04-06 10:33:42,863 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-04-06 10:33:42,863 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-04-06 10:33:42,863 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-04-06 10:33:43,036 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:33:43,036 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:43,609 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-04-06 10:33:43,609 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 reported by cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:33:43,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:43,712 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-04-06 10:33:43,712 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 reported by d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:33:43,863 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-04-06 10:33:43,863 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-04-06 10:33:43,864 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-04-06 10:33:43,884 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-04-06 10:33:44,037 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:33:44,037 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:44,504 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 reported by 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:33:44,504 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-04-06 10:33:44,506 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 0}
2024-04-06 10:33:44,506 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 0}
2024-04-06 10:33:44,610 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:44,711 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-04-06 10:33:44,712 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 reported by d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:33:44,780 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-04-06 10:33:44,864 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-04-06 10:33:44,864 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-04-06 10:33:44,864 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-04-06 10:33:44,884 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-04-06 10:33:45,038 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:33:45,038 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:45,505 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 reported by 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:33:45,505 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-04-06 10:33:45,608 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 reported by cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:33:45,608 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-04-06 10:33:45,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:45,712 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-04-06 10:33:45,712 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 reported by d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:33:45,779 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-04-06 10:33:45,864 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-04-06 10:33:45,865 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Waiting for cluster to exit safe mode
2024-04-06 10:33:45,865 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-04-06 10:33:46,039 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-04-06 10:33:46,039 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:46,516 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5040609304ns, electionTimeout:5035ms
2024-04-06 10:33:46,516 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: shutdown 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-FollowerState
2024-04-06 10:33:46,517 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-04-06 10:33:46,517 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-04-06 10:33:46,517 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: start 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2
2024-04-06 10:33:46,518 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016]|listeners:[], old=null
2024-04-06 10:33:46,519 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2 PRE_VOTE round 0: result PASSED (term=0)
2024-04-06 10:33:46,520 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016]|listeners:[], old=null
2024-04-06 10:33:46,520 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2 ELECTION round 0: result PASSED (term=1)
2024-04-06 10:33:46,520 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: shutdown 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2
2024-04-06 10:33:46,521 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-04-06 10:33:46,521 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-04-06 10:33:46,521 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-04-06 10:33:46,521 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-04-06 10:33:46,522 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-04-06 10:33:46,522 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-04-06 10:33:46,522 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-04-06 10:33:46,522 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-04-06 10:33:46,522 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-04-06 10:33:46,522 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:33:46,522 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-04-06 10:33:46,522 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-04-06 10:33:46,522 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: start 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderStateImpl
2024-04-06 10:33:46,523 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F: set firstElectionSinceStartup to false for becomeLeader
2024-04-06 10:33:46,523 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-8188EE38776F with new leaderId: 59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:33:46,523 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F: change Leader from null to 59c3495a-7636-40f9-8dfa-c28be8e98abd at term 1 for becomeLeader, leader elected after 5083ms
2024-04-06 10:33:46,523 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-SegmentedRaftLogWorker: Starting segment from index:0
2024-04-06 10:33:46,524 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-04-06 10:33:46,525 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderElection2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F: set configuration 0: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016]|listeners:[], old=null
2024-04-06 10:33:46,526 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 reported by 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:33:46,527 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-04-06 10:33:46,533 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/9db4cf61-9812-4683-bf84-8188ee38776f/current/log_inprogress_0
2024-04-06 10:33:46,536 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-04-06 10:33:46,572 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5057952245ns, electionTimeout:5052ms
2024-04-06 10:33:46,573 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: shutdown 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-FollowerState
2024-04-06 10:33:46,574 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-04-06 10:33:46,574 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-04-06 10:33:46,574 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: start 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3
2024-04-06 10:33:46,575 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:33:46,581 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:33:46,581 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:33:46,582 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034
2024-04-06 10:33:46,582 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025
2024-04-06 10:33:46,597 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7: receive requestVote(PRE_VOTE, 59c3495a-7636-40f9-8dfa-c28be8e98abd, group-673FB5E812E7, 0, (t:0, i:0))
2024-04-06 10:33:46,598 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5015103445ns, electionTimeout:5013ms
2024-04-06 10:33:46,598 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - cc1e4d3c-2283-4c28-b737-db868cb45369: shutdown cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-FollowerState
2024-04-06 10:33:46,598 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-04-06 10:33:46,598 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-04-06 10:33:46,598 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - cc1e4d3c-2283-4c28-b737-db868cb45369: start cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4
2024-04-06 10:33:46,599 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7: receive requestVote(PRE_VOTE, 59c3495a-7636-40f9-8dfa-c28be8e98abd, group-673FB5E812E7, 0, (t:0, i:0))
2024-04-06 10:33:46,601 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:33:46,601 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4 PRE_VOTE round 0: result PASSED (term=0)
2024-04-06 10:33:46,602 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-FOLLOWER: accept PRE_VOTE from 59c3495a-7636-40f9-8dfa-c28be8e98abd: our priority 0 <= candidate's priority 1
2024-04-06 10:33:46,603 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4 ELECTION round 0: submit vote requests at term 1 for -1: peers:[cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:33:46,603 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4 ELECTION round 0: result PASSED (term=1)
2024-04-06 10:33:46,603 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - cc1e4d3c-2283-4c28-b737-db868cb45369: shutdown cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4
2024-04-06 10:33:46,604 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-04-06 10:33:46,604 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-04-06 10:33:46,604 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-04-06 10:33:46,604 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-04-06 10:33:46,605 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-04-06 10:33:46,605 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-04-06 10:33:46,605 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-04-06 10:33:46,605 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-04-06 10:33:46,606 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-04-06 10:33:46,606 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:33:46,606 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-04-06 10:33:46,606 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-04-06 10:33:46,606 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - cc1e4d3c-2283-4c28-b737-db868cb45369: start cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderStateImpl
2024-04-06 10:33:46,606 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674: set firstElectionSinceStartup to false for becomeLeader
2024-04-06 10:33:46,606 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-73828BACE674 with new leaderId: cc1e4d3c-2283-4c28-b737-db868cb45369
2024-04-06 10:33:46,606 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-FOLLOWER: accept PRE_VOTE from 59c3495a-7636-40f9-8dfa-c28be8e98abd: our priority 0 <= candidate's priority 1
2024-04-06 10:33:46,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:46,611 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674: change Leader from null to cc1e4d3c-2283-4c28-b737-db868cb45369 at term 1 for becomeLeader, leader elected after 5063ms
2024-04-06 10:33:46,611 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-SegmentedRaftLogWorker: Starting segment from index:0
2024-04-06 10:33:46,613 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderElection4] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674: set configuration 0: peers:[cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:33:46,614 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7 replies to PRE_VOTE vote request: 59c3495a-7636-40f9-8dfa-c28be8e98abd<-cc1e4d3c-2283-4c28-b737-db868cb45369#0:OK-t0. Peer's state: cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7:t0, leader=null, voted=, raftlog=Memoized:cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:33:46,614 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7 replies to PRE_VOTE vote request: 59c3495a-7636-40f9-8dfa-c28be8e98abd<-d1715241-1ffa-4146-b219-94c9c0fc171f#0:OK-t0. Peer's state: d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7:t0, leader=null, voted=, raftlog=Memoized:d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:33:46,616 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 reported by cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:33:46,617 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-04-06 10:33:46,616 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2024-04-06 10:33:46,620 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2024-04-06 10:33:46,623 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 59c3495a-7636-40f9-8dfa-c28be8e98abd<-cc1e4d3c-2283-4c28-b737-db868cb45369#0:OK-t0
2024-04-06 10:33:46,623 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3 PRE_VOTE round 0: result PASSED
2024-04-06 10:33:46,624 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:33:46,626 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:33:46,626 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:33:46,627 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:33:46,627 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:33:46,629 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/8be94057-6f6e-4ca0-8619-73828bace674/current/log_inprogress_0
2024-04-06 10:33:46,631 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7: receive requestVote(ELECTION, 59c3495a-7636-40f9-8dfa-c28be8e98abd, group-673FB5E812E7, 1, (t:0, i:0))
2024-04-06 10:33:46,631 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-FOLLOWER: accept ELECTION from 59c3495a-7636-40f9-8dfa-c28be8e98abd: our priority 0 <= candidate's priority 1
2024-04-06 10:33:46,631 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7: receive requestVote(ELECTION, 59c3495a-7636-40f9-8dfa-c28be8e98abd, group-673FB5E812E7, 1, (t:0, i:0))
2024-04-06 10:33:46,632 [grpc-default-executor-1] INFO  impl.VoteContext (VoteContext.java:log(49)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-FOLLOWER: accept ELECTION from 59c3495a-7636-40f9-8dfa-c28be8e98abd: our priority 0 <= candidate's priority 1
2024-04-06 10:33:46,632 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:33:46,632 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - cc1e4d3c-2283-4c28-b737-db868cb45369: shutdown cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-FollowerState
2024-04-06 10:33:46,632 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - cc1e4d3c-2283-4c28-b737-db868cb45369: start cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-FollowerState
2024-04-06 10:33:46,632 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:33:46,633 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - d1715241-1ffa-4146-b219-94c9c0fc171f: shutdown d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-FollowerState
2024-04-06 10:33:46,635 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-FollowerState was interrupted
2024-04-06 10:33:46,636 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7: set firstElectionSinceStartup to false for candidate:59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:33:46,637 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-FollowerState was interrupted
2024-04-06 10:33:46,637 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d1715241-1ffa-4146-b219-94c9c0fc171f: start d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-FollowerState
2024-04-06 10:33:46,638 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7: set firstElectionSinceStartup to false for candidate:59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:33:46,639 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-04-06 10:33:46,639 [grpc-default-executor-1] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7 replies to ELECTION vote request: 59c3495a-7636-40f9-8dfa-c28be8e98abd<-cc1e4d3c-2283-4c28-b737-db868cb45369#0:OK-t1. Peer's state: cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7:t1, leader=null, voted=59c3495a-7636-40f9-8dfa-c28be8e98abd, raftlog=Memoized:cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:33:46,641 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3: ELECTION PASSED received 1 response(s) and 0 exception(s):
2024-04-06 10:33:46,642 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 59c3495a-7636-40f9-8dfa-c28be8e98abd<-cc1e4d3c-2283-4c28-b737-db868cb45369#0:OK-t1
2024-04-06 10:33:46,642 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7 replies to ELECTION vote request: 59c3495a-7636-40f9-8dfa-c28be8e98abd<-d1715241-1ffa-4146-b219-94c9c0fc171f#0:OK-t1. Peer's state: d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7:t1, leader=null, voted=59c3495a-7636-40f9-8dfa-c28be8e98abd, raftlog=Memoized:d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:33:46,642 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3 ELECTION round 0: result PASSED
2024-04-06 10:33:46,643 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: shutdown 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3
2024-04-06 10:33:46,643 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-04-06 10:33:46,643 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-04-06 10:33:46,644 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-04-06 10:33:46,645 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-04-06 10:33:46,645 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-04-06 10:33:46,646 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-04-06 10:33:46,646 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-04-06 10:33:46,646 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-04-06 10:33:46,646 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-04-06 10:33:46,646 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:33:46,646 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-04-06 10:33:46,646 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-04-06 10:33:46,654 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-04-06 10:33:46,654 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:46,654 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2024-04-06 10:33:46,656 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0μs (custom)
2024-04-06 10:33:46,658 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-04-06 10:33:46,658 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:33:46,658 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-04-06 10:33:46,658 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-04-06 10:33:46,658 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-04-06 10:33:46,659 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:33:46,659 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-04-06 10:33:46,665 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-04-06 10:33:46,665 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:46,666 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2024-04-06 10:33:46,666 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0μs (custom)
2024-04-06 10:33:46,666 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-04-06 10:33:46,666 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:33:46,666 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-04-06 10:33:46,666 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-04-06 10:33:46,666 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-04-06 10:33:46,666 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:33:46,667 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-04-06 10:33:46,667 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: start 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderStateImpl
2024-04-06 10:33:46,667 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7: set firstElectionSinceStartup to false for becomeLeader
2024-04-06 10:33:46,667 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-673FB5E812E7 with new leaderId: 59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:33:46,668 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7: change Leader from null to 59c3495a-7636-40f9-8dfa-c28be8e98abd at term 1 for becomeLeader, leader elected after 5175ms
2024-04-06 10:33:46,668 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-SegmentedRaftLogWorker: Starting segment from index:0
2024-04-06 10:33:46,668 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-04-06 10:33:46,674 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderElection3] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7: set configuration 0: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:33:46,676 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 reported by 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:33:46,677 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7
2024-04-06 10:33:46,677 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(140)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2024-04-06 10:33:46,678 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - HealthyPipelineSafeModeRule rule is successfully validated
2024-04-06 10:33:46,678 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2024-04-06 10:33:46,678 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2024-04-06 10:33:46,678 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(225)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2024-04-06 10:33:46,678 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(258)) - Service BackgroundPipelineCreator transitions to RUNNING.
2024-04-06 10:33:46,678 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(79)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2024-04-06 10:33:46,678 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(79)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2024-04-06 10:33:46,678 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  block.SCMBlockDeletingService (SCMBlockDeletingService.java:notifyStatusChanged(247)) - notifyStatusChanged:RUNNING
2024-04-06 10:33:46,678 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(1403)) - Service ReplicationManager transitions to RUNNING.
2024-04-06 10:33:46,679 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(134)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2024-04-06 10:33:46,680 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7/current/log_inprogress_0
2024-04-06 10:33:46,702 [d1715241-1ffa-4146-b219-94c9c0fc171f-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-673FB5E812E7 with new leaderId: 59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:33:46,703 [d1715241-1ffa-4146-b219-94c9c0fc171f-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7: change Leader from null to 59c3495a-7636-40f9-8dfa-c28be8e98abd at term 1 for appendEntries, leader elected after 5002ms
2024-04-06 10:33:46,705 [cc1e4d3c-2283-4c28-b737-db868cb45369-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-673FB5E812E7 with new leaderId: 59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:33:46,705 [cc1e4d3c-2283-4c28-b737-db868cb45369-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7: change Leader from null to 59c3495a-7636-40f9-8dfa-c28be8e98abd at term 1 for appendEntries, leader elected after 5115ms
2024-04-06 10:33:46,714 [d1715241-1ffa-4146-b219-94c9c0fc171f-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7: set configuration 0: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:33:46,714 [cc1e4d3c-2283-4c28-b737-db868cb45369-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7: set configuration 0: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:33:46,719 [d1715241-1ffa-4146-b219-94c9c0fc171f-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-SegmentedRaftLogWorker: Starting segment from index:0
2024-04-06 10:33:46,719 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5025574135ns, electionTimeout:5025ms
2024-04-06 10:33:46,720 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - d1715241-1ffa-4146-b219-94c9c0fc171f: shutdown d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-FollowerState
2024-04-06 10:33:46,720 [cc1e4d3c-2283-4c28-b737-db868cb45369-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-SegmentedRaftLogWorker: Starting segment from index:0
2024-04-06 10:33:46,720 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-04-06 10:33:46,720 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-04-06 10:33:46,720 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d1715241-1ffa-4146-b219-94c9c0fc171f: start d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5
2024-04-06 10:33:46,720 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-04-06 10:33:46,722 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034]|listeners:[], old=null
2024-04-06 10:33:46,722 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5 PRE_VOTE round 0: result PASSED (term=0)
2024-04-06 10:33:46,722 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-04-06 10:33:46,723 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5 ELECTION round 0: submit vote requests at term 1 for -1: peers:[d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034]|listeners:[], old=null
2024-04-06 10:33:46,723 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5 ELECTION round 0: result PASSED (term=1)
2024-04-06 10:33:46,723 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - d1715241-1ffa-4146-b219-94c9c0fc171f: shutdown d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5
2024-04-06 10:33:46,723 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-04-06 10:33:46,723 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-04-06 10:33:46,724 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-04-06 10:33:46,724 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-04-06 10:33:46,724 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-04-06 10:33:46,724 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-04-06 10:33:46,724 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-04-06 10:33:46,724 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-04-06 10:33:46,724 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-04-06 10:33:46,724 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:33:46,725 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-04-06 10:33:46,725 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-04-06 10:33:46,725 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d1715241-1ffa-4146-b219-94c9c0fc171f: start d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderStateImpl
2024-04-06 10:33:46,733 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7/current/log_inprogress_0
2024-04-06 10:33:46,734 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71: set firstElectionSinceStartup to false for becomeLeader
2024-04-06 10:33:46,734 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-836518D32A71 with new leaderId: d1715241-1ffa-4146-b219-94c9c0fc171f
2024-04-06 10:33:46,734 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71: change Leader from null to d1715241-1ffa-4146-b219-94c9c0fc171f at term 1 for becomeLeader, leader elected after 5057ms
2024-04-06 10:33:46,735 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-SegmentedRaftLogWorker: Starting segment from index:0
2024-04-06 10:33:46,735 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-04-06 10:33:46,741 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderElection5] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71: set configuration 0: peers:[d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034]|listeners:[], old=null
2024-04-06 10:33:46,743 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7/current/log_inprogress_0
2024-04-06 10:33:46,744 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-04-06 10:33:46,744 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/47341687-34d7-44e9-a74c-836518d32a71/current/log_inprogress_0
2024-04-06 10:33:46,747 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-04-06 10:33:46,825 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5031662465ns, electionTimeout:5031ms
2024-04-06 10:33:46,825 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: shutdown a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-FollowerState
2024-04-06 10:33:46,825 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-04-06 10:33:46,825 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-04-06 10:33:46,825 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: start a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6
2024-04-06 10:33:46,826 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043]|listeners:[], old=null
2024-04-06 10:33:46,827 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6 PRE_VOTE round 0: result PASSED (term=0)
2024-04-06 10:33:46,828 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6 ELECTION round 0: submit vote requests at term 1 for -1: peers:[a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043]|listeners:[], old=null
2024-04-06 10:33:46,828 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6 ELECTION round 0: result PASSED (term=1)
2024-04-06 10:33:46,828 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: shutdown a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6
2024-04-06 10:33:46,828 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-04-06 10:33:46,828 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-04-06 10:33:46,829 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-04-06 10:33:46,829 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-04-06 10:33:46,829 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-04-06 10:33:46,829 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-04-06 10:33:46,829 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-04-06 10:33:46,829 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-04-06 10:33:46,829 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-04-06 10:33:46,830 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:33:46,830 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-04-06 10:33:46,830 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-04-06 10:33:46,830 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: start a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderStateImpl
2024-04-06 10:33:46,830 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D: set firstElectionSinceStartup to false for becomeLeader
2024-04-06 10:33:46,830 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-2D61D60DE43D with new leaderId: a40aef6e-dfc7-4141-9a41-17d72bf4eeff
2024-04-06 10:33:46,830 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D: change Leader from null to a40aef6e-dfc7-4141-9a41-17d72bf4eeff at term 1 for becomeLeader, leader elected after 5060ms
2024-04-06 10:33:46,830 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-SegmentedRaftLogWorker: Starting segment from index:0
2024-04-06 10:33:46,831 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-04-06 10:33:46,836 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderElection6] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D: set configuration 0: peers:[a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043]|listeners:[], old=null
2024-04-06 10:33:46,838 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/97b25c4a-3cf1-4ab4-a703-2d61d60de43d/current/log_inprogress_0
2024-04-06 10:33:46,840 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-04-06 10:33:46,865 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(194)) - Nodes are ready. Got 5 of 5 DN Heartbeats.
2024-04-06 10:33:46,865 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(197)) - Cluster exits safe mode
2024-04-06 10:33:46,865 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(199)) - SCM became leader
2024-04-06 10:33:46,866 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(59)) - No unit for hdds.scmclient.rpc.timeout(60000) assuming MILLISECONDS
2024-04-06 10:33:46,866 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(59)) - No unit for hdds.scmclient.max.retry.timeout(6000) assuming MILLISECONDS
2024-04-06 10:33:46,869 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(59)) - No unit for hdds.scmclient.rpc.timeout(60000) assuming MILLISECONDS
2024-04-06 10:33:46,869 [main] WARN  conf.TimeDurationUtil (TimeDurationUtil.java:getDuration(59)) - No unit for hdds.scmclient.max.retry.timeout(6000) assuming MILLISECONDS
2024-04-06 10:33:46,940 [main] INFO  protocolPB.OmTransportFactory (OmTransportFactory.java:createFactory(62)) - Loading OM transport implementation org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory as specified by configuration.
2024-04-06 10:33:47,040 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:33:47,041 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 0 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:47,056 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5154640470ns, electionTimeout:5154ms
2024-04-06 10:33:47,057 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: shutdown ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-FollowerState
2024-04-06 10:33:47,057 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-04-06 10:33:47,057 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-04-06 10:33:47,057 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: start ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7
2024-04-06 10:33:47,058 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null
2024-04-06 10:33:47,059 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7 PRE_VOTE round 0: result PASSED (term=0)
2024-04-06 10:33:47,060 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7 ELECTION round 0: submit vote requests at term 1 for -1: peers:[ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null
2024-04-06 10:33:47,060 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7 ELECTION round 0: result PASSED (term=1)
2024-04-06 10:33:47,060 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: shutdown ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7
2024-04-06 10:33:47,060 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-04-06 10:33:47,060 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-04-06 10:33:47,060 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-04-06 10:33:47,061 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-04-06 10:33:47,061 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-04-06 10:33:47,061 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-04-06 10:33:47,061 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-04-06 10:33:47,061 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-04-06 10:33:47,061 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-04-06 10:33:47,061 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:33:47,062 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-04-06 10:33:47,062 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-04-06 10:33:47,062 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: start ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderStateImpl
2024-04-06 10:33:47,062 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23: set firstElectionSinceStartup to false for becomeLeader
2024-04-06 10:33:47,062 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-BECC45517E23 with new leaderId: ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2
2024-04-06 10:33:47,062 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23: change Leader from null to ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2 at term 1 for becomeLeader, leader elected after 5189ms
2024-04-06 10:33:47,062 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-SegmentedRaftLogWorker: Starting segment from index:0
2024-04-06 10:33:47,064 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderElection7] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23: set configuration 0: peers:[ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null
2024-04-06 10:33:47,064 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-04-06 10:33:47,075 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis/15039d4b-d7f6-4769-9a85-becc45517e23/current/log_inprogress_0
2024-04-06 10:33:47,077 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-04-06 10:33:47,176 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(464)) - Creating Volume: vol1, with user86827 as owner and space quota set to -1 bytes, counts quota set to -1
2024-04-06 10:33:47,228 [om1-OMStateMachineApplyTransactionThread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(198)) - created volume:vol1 for user:user86827
2024-04-06 10:33:47,234 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(71)) - OmKeyInfo.getCodec ignorePipeline = true
2024-04-06 10:33:47,234 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(71)) - OmKeyInfo.getCodec ignorePipeline = true
2024-04-06 10:33:47,235 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(71)) - OmKeyInfo.getCodec ignorePipeline = true
2024-04-06 10:33:47,235 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(71)) - OmKeyInfo.getCodec ignorePipeline = true
2024-04-06 10:33:47,235 [om1-OMDoubleBufferFlushThread] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(71)) - OmKeyInfo.getCodec ignorePipeline = true
2024-04-06 10:33:47,246 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(690)) - Creating Bucket: vol1/bucket1, with bucket layout FILE_SYSTEM_OPTIMIZED, runner as owner, Versioning false, Storage Type set to DISK and Encryption set to false, Replication Type set to server-side default replication type, Namespace Quota set to -1, Space Quota set to -1 
2024-04-06 10:33:47,259 [om1-OMStateMachineApplyTransactionThread - 0] INFO  bucket.OMBucketCreateRequest (OMBucketCreateRequest.java:validateAndUpdateCache(293)) - created bucket: bucket1 of layout FILE_SYSTEM_OPTIMIZED in volume: vol1
2024-04-06 10:33:47,303 [IPC Server handler 4 on default port 15001] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(145)) - Allocate a batch for containerId, change lastId from 0 to 1000.
2024-04-06 10:33:47,311 [IPC Server handler 4 on default port 15001] WARN  ha.SequenceIdGenerator (SequenceIdGenerator.java:allocateBatch(258)) - Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 113750153625600000.
2024-04-06 10:33:47,311 [IPC Server handler 4 on default port 15001] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(145)) - Allocate a batch for localId, change lastId from 113750153625600000 to 113750153625601000.
2024-04-06 10:33:47,377 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - XceiverClientMetrics metrics system started (again)
2024-04-06 10:33:47,559 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 5 millisec, 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: ICR, size: 1}
2024-04-06 10:33:47,563 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 9 millisec, 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: ICR, size: 1}
2024-04-06 10:33:47,566 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: ICR, size: 1}
2024-04-06 10:33:47,566 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 12 millisec, d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: ICR, size: 1}
2024-04-06 10:33:47,567 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 12 millisec, d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: ICR, size: 1}
2024-04-06 10:33:47,567 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 4 millisec, cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 0}
2024-04-06 10:33:47,567 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 4 millisec, cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 0}
2024-04-06 10:33:47,567 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 5 millisec, cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: ICR, size: 1}
2024-04-06 10:33:47,577 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:addNewContainer(246)) - Successfully added container #1 to Recon.
2024-04-06 10:33:47,577 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:addNewContainer(246)) - Successfully added container #1 to Recon.
2024-04-06 10:33:47,594 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 31 millisec, cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: ICR, size: 1}
2024-04-06 10:33:47,596 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 43 millisec, 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: ICR, size: 1}
2024-04-06 10:33:47,597 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 42 millisec, d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: ICR, size: 1}
2024-04-06 10:33:47,597 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 43 millisec, d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: ICR, size: 1}
2024-04-06 10:33:47,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
Connecting to Recon: http://0.0.0.0:15008/api/v1/triggerdbsync/om ...
2024-04-06 10:33:47,779 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:33:47,780 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(537)) - Obtaining full snapshot from Ozone Manager
2024-04-06 10:33:47,801 [qtp2139799663-408] INFO  utils.DBCheckpointServlet (DBCheckpointServlet.java:doGet(301)) - Received GET request to obtain DB checkpoint snapshot
2024-04-06 10:33:48,042 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:33:48,052 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 11 milliseconds for processing 1 containers.
2024-04-06 10:33:48,053 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:33:48,053 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:48,053 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:33:48,053 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:33:48,053 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:48,053 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:48,053 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:48,611 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:48,650 [qtp2139799663-408] INFO  om.OMDBCheckpointServlet (OMDBCheckpointServlet.java:getCheckpoint(246)) - Compaction pausing 1 started.
2024-04-06 10:33:48,681 [qtp2139799663-408] INFO  db.RDBCheckpointManager (RDBCheckpointManager.java:createCheckpoint(89)) - Created checkpoint in rocksDB at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/db.checkpoints/om.db_checkpoint_1712399628657 in 24 milliseconds
2024-04-06 10:33:48,684 [qtp2139799663-408] INFO  om.OMDBCheckpointServlet (OMDBCheckpointServlet.java:getCheckpoint(258)) - Compaction pausing 1 ended. Elapsed ms: 34
2024-04-06 10:33:48,703 [qtp2139799663-408] INFO  utils.DBCheckpointServlet (DBCheckpointServlet.java:generateSnapshotCheckpoint(225)) - Time taken to write the checkpoint to response output stream: 19 milliseconds
2024-04-06 10:33:48,703 [qtp2139799663-408] INFO  utils.DBCheckpointServlet (DBCheckpointServlet.java:generateSnapshotCheckpoint(228)) - Excluded SST [] from the latest checkpoint.
2024-04-06 10:33:48,714 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:updateReconOmDBWithNewSnapshot(390)) - Got new checkpoint from OM : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/recon/om.snapshot.db_1712399627780
2024-04-06 10:33:48,715 [Recon-SyncOM-1] INFO  helpers.OmKeyInfo (OmKeyInfo.java:getCodec(71)) - OmKeyInfo.getCodec ignorePipeline = true
2024-04-06 10:33:48,716 [qtp2139799663-408] INFO  db.RocksDBCheckpoint (RocksDBCheckpoint.java:cleanupCheckpoint(78)) - Cleaning up RocksDB checkpoint at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/db.checkpoints/om.db_checkpoint_1712399628657
2024-04-06 10:33:48,746 [Recon-SyncOM-1] INFO  recovery.ReconOmMetadataManagerImpl (ReconOmMetadataManagerImpl.java:initializeNewRdbStore(107)) - Created OM DB handle from snapshot at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/recon/om.snapshot.db_1712399627780.
2024-04-06 10:33:48,754 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(550)) - Calling reprocess on Recon tasks.
2024-04-06 10:33:48,887 [ReconTaskThread-0] INFO  tasks.OmTableInsightTask (OmTableInsightTask.java:reprocess(137)) - Completed a 'reprocess' run of OmTableInsightTask.
2024-04-06 10:33:48,889 [Recon-NSSummaryTask-1] INFO  tasks.NSSummaryTaskWithLegacy (NSSummaryTaskWithLegacy.java:reprocessWithLegacy(297)) - Completed a reprocess run of NSSummaryTaskWithLegacy
2024-04-06 10:33:48,889 [Recon-NSSummaryTask-1] INFO  tasks.NSSummaryTaskWithOBS (NSSummaryTaskWithOBS.java:reprocessWithOBS(110)) - Completed a reprocess run of NSSummaryTaskWithOBS
2024-04-06 10:33:48,890 [Recon-NSSummaryTask-0] INFO  tasks.NSSummaryTaskWithFSO (NSSummaryTaskWithFSO.java:reprocessWithFSO(213)) - Completed a reprocess run of NSSummaryTaskWithFSO
2024-04-06 10:33:48,891 [ReconTaskThread-0] INFO  tasks.NSSummaryTask (NSSummaryTask.java:reprocess(169)) - Task execution time: 3 milliseconds
2024-04-06 10:33:48,891 [ReconTaskThread-0] INFO  tasks.ContainerKeyMapperTask (ContainerKeyMapperTask.java:reprocess(97)) - Starting a 'reprocess' run of ContainerKeyMapperTask.
2024-04-06 10:33:48,891 [ReconTaskThread-0] INFO  impl.ReconContainerMetadataManagerImpl (ReconContainerMetadataManagerImpl.java:initializeTables(141)) - KEY_CONTAINER Table is empty, initializing from CONTAINER_KEY Table ...
2024-04-06 10:33:48,891 [ReconTaskThread-0] INFO  impl.ReconContainerMetadataManagerImpl (ReconContainerMetadataManagerImpl.java:initializeKeyContainerTable(666)) - It took 0.0 seconds to initialized 0 records to KEY_CONTAINER table
2024-04-06 10:33:48,905 [ReconTaskThread-0] INFO  tasks.ContainerKeyMapperTask (ContainerKeyMapperTask.java:reprocess(140)) - Completed 'reprocess' of ContainerKeyMapperTask.
2024-04-06 10:33:48,906 [ReconTaskThread-0] INFO  tasks.ContainerKeyMapperTask (ContainerKeyMapperTask.java:reprocess(143)) - It took me 0.014 seconds to process 1 keys.
2024-04-06 10:33:48,918 [ReconTaskThread-0] INFO  tasks.FileSizeCountTask (FileSizeCountTask.java:reprocess(84)) - Deleted 0 records from "FILE_COUNT_BY_SIZE"
2024-04-06 10:33:48,926 [ReconTaskThread-0] INFO  tasks.FileSizeCountTask (FileSizeCountTask.java:reprocess(99)) - Completed a 'reprocess' run of FileSizeCountTask.
2024-04-06 10:33:49,055 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:33:49,057 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:33:49,057 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:33:49,057 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:49,057 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:33:49,057 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:33:49,057 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:49,058 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:49,058 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:49,612 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(371)) - Replication Manager is not ready to run until 3000ms after safemode exit
2024-04-06 10:33:49,887 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) moved to HEALTHY state.
2024-04-06 10:33:49,887 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-04-06 10:33:49,888 [IPC Server handler 3 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startMaintenance(520)) - Starting Maintenance for node cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
2024-04-06 10:33:49,928 [qtp1360692538-457] INFO  impl.Tools (JooqLogger.java:info(338)) - Kotlin is available, but not kotlin-reflect. Add the kotlin-reflect dependency to better use Kotlin features like data classes
2024-04-06 10:33:49,931 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:33:49,933 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:33:49,933 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:33:49,942 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:33:49,942 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-04-06 10:33:50,059 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:33:50,061 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:33:50,061 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:33:50,061 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:50,061 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:33:50,061 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:33:50,061 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:50,062 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:50,062 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:50,561 [IPC Server handler 5 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-04-06 10:33:50,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:33:50,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d51e89fb. There are 2 pipelines
2024-04-06 10:33:50,622 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(55)) - Admin start on datanode cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10). Finalizing its pipelines [PipelineID=8be94057-6f6e-4ca0-8619-73828bace674, PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7]
2024-04-06 10:33:50,623 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-04-06 10:33:50,623 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=8be94057-6f6e-4ca0-8619-73828bace674 moved to CLOSED state
2024-04-06 10:33:50,626 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(484)) - Container #1 closed for pipeline=PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7
2024-04-06 10:33:50,626 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #1, current state: CLOSING
2024-04-06 10:33:50,626 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 moved to CLOSED state
2024-04-06 10:33:50,945 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:33:50,945 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:33:50,945 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:33:50,947 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:33:50,947 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:33:51,063 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:33:51,066 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 3 milliseconds for processing 1 containers.
2024-04-06 10:33:51,066 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:33:51,066 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:51,066 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:33:51,066 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:33:51,066 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:51,066 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:51,066 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:51,561 [IPC Server handler 12 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-04-06 10:33:51,563 [cc1e4d3c-2283-4c28-b737-db868cb45369-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to ENTERING_MAINTENANCE, scaling executor pool size to 20
2024-04-06 10:33:51,614 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-04-06T10:33:50.625Z, pipelineID=PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7, owner=omServiceIdDefault} to d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) with datanode deadline 1712400201614 and scm deadline 1712400231614
2024-04-06 10:33:51,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-04-06T10:33:50.625Z, pipelineID=PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7, owner=omServiceIdDefault} to 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) with datanode deadline 1712400201615 and scm deadline 1712400231615
2024-04-06 10:33:51,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-04-06T10:33:50.625Z, pipelineID=PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7, owner=omServiceIdDefault} to cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) with datanode deadline 1712400201615 and scm deadline 1712400231615
2024-04-06 10:33:51,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:33:51,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d51e89fb. There are 2 pipelines
2024-04-06 10:33:51,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-04-06 10:33:51,949 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:33:51,949 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:33:51,949 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:33:51,951 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:33:51,951 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:33:52,067 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:33:52,070 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:33:52,070 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:33:52,070 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:52,070 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:33:52,070 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:33:52,070 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:52,070 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:52,070 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:52,556 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 1}
2024-04-06 10:33:52,556 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 1}
2024-04-06 10:33:52,562 [IPC Server handler 9 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-04-06 10:33:52,562 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 1}
2024-04-06 10:33:52,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-04-06T10:33:50.625Z, pipelineID=PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7, owner=omServiceIdDefault} to d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) with datanode deadline 1712400202615 and scm deadline 1712400232615
2024-04-06 10:33:52,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-04-06T10:33:50.625Z, pipelineID=PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7, owner=omServiceIdDefault} to 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) with datanode deadline 1712400202615 and scm deadline 1712400232615
2024-04-06 10:33:52,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 1, pipelineID: PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7, force: false] for container ContainerInfo{id=#1, state=CLOSING, stateEnterTime=2024-04-06T10:33:50.625Z, pipelineID=PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7, owner=omServiceIdDefault} to cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) with datanode deadline 1712400202615 and scm deadline 1712400232615
2024-04-06 10:33:52,615 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:33:52,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d51e89fb. There are 2 pipelines
2024-04-06 10:33:52,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-04-06 10:33:52,953 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:33:52,953 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:33:52,953 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:33:52,955 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:33:52,955 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:33:53,071 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-04-06 10:33:53,075 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 3 milliseconds for processing 1 containers.
2024-04-06 10:33:53,075 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:33:53,075 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:53,075 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:33:53,075 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:33:53,075 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:53,075 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:53,075 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:53,559 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:checkContainerStateAndUpdate(199)) - Container #1 has state OPEN, but given state is CLOSING.
2024-04-06 10:33:53,560 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: ICR, size: 1}
2024-04-06 10:33:53,561 [d1715241-1ffa-4146-b219-94c9c0fc171f-CloseContainerThread-0] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-04-06 10:33:53,564 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 1}
2024-04-06 10:33:53,564 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 1}
2024-04-06 10:33:53,569 [59c3495a-7636-40f9-8dfa-c28be8e98abd-ContainerOp-b4229e37-69d0-4c7f-a467-673fb5e812e7-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-04-06 10:33:53,569 [59c3495a-7636-40f9-8dfa-c28be8e98abd-ContainerOp-b4229e37-69d0-4c7f-a467-673fb5e812e7-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-04-06 10:33:53,574 [59c3495a-7636-40f9-8dfa-c28be8e98abd-ContainerOp-b4229e37-69d0-4c7f-a467-673fb5e812e7-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(437)) - Container 1 is closed with bcsId 2.
2024-04-06 10:33:53,583 [d1715241-1ffa-4146-b219-94c9c0fc171f-ContainerOp-b4229e37-69d0-4c7f-a467-673fb5e812e7-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-04-06 10:33:53,584 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 4 millisec, 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: ICR, size: 1}
2024-04-06 10:33:53,584 [d1715241-1ffa-4146-b219-94c9c0fc171f-ContainerOp-b4229e37-69d0-4c7f-a467-673fb5e812e7-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-04-06 10:33:53,584 [FixedThreadPoolWithAffinityExecutor-1-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(312)) - Moving container #1 to CLOSED state, datanode 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) reported CLOSED replica with index 0.
2024-04-06 10:33:53,585 [FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 5 millisec, 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: ICR, size: 1}
2024-04-06 10:33:53,585 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 5 millisec, 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: ICR, size: 1}
2024-04-06 10:33:53,585 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(312)) - Moving container #1 to CLOSED state, datanode 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) reported CLOSED replica with index 0.
2024-04-06 10:33:53,587 [cc1e4d3c-2283-4c28-b737-db868cb45369-CloseContainerThread-0] INFO  commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:lambda$handle$0(154)) - Follower cannot close container #1.
2024-04-06 10:33:53,589 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 9 millisec, 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: ICR, size: 1}
2024-04-06 10:33:53,589 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: ICR, size: 1}
2024-04-06 10:33:53,590 [cc1e4d3c-2283-4c28-b737-db868cb45369-ContainerOp-b4229e37-69d0-4c7f-a467-673fb5e812e7-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-04-06 10:33:53,590 [cc1e4d3c-2283-4c28-b737-db868cb45369-ContainerOp-b4229e37-69d0-4c7f-a467-673fb5e812e7-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(522)) - Container 1 is synced with bcsId 2.
2024-04-06 10:33:53,591 [d1715241-1ffa-4146-b219-94c9c0fc171f-ContainerOp-b4229e37-69d0-4c7f-a467-673fb5e812e7-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(437)) - Container 1 is closed with bcsId 2.
2024-04-06 10:33:53,593 [cc1e4d3c-2283-4c28-b737-db868cb45369-ContainerOp-b4229e37-69d0-4c7f-a467-673fb5e812e7-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(437)) - Container 1 is closed with bcsId 2.
2024-04-06 10:33:53,617 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:33:53,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d51e89fb. There are 2 pipelines
2024-04-06 10:33:53,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-04-06 10:33:53,957 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:33:53,957 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:33:53,957 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:33:53,959 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:33:53,959 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:33:54,076 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:33:54,079 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:33:54,079 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:33:54,079 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:54,079 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:33:54,079 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:33:54,079 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:54,079 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:54,079 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:54,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:33:54,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d51e89fb. There are 2 pipelines
2024-04-06 10:33:54,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-04-06 10:33:54,961 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:33:54,962 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:33:54,962 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:33:54,963 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:33:54,963 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:33:55,080 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:33:55,082 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:33:55,082 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:33:55,082 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:55,083 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:33:55,083 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:33:55,083 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:55,083 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:55,083 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:55,618 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:33:55,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d51e89fb. There are 2 pipelines
2024-04-06 10:33:55,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-04-06 10:33:55,966 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:33:55,966 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:33:55,966 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:33:55,968 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:33:55,968 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:33:56,084 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:33:56,086 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:33:56,086 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:33:56,086 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:56,086 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:33:56,086 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:33:56,086 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:56,086 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:56,086 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:56,619 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:33:56,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d51e89fb. There are 2 pipelines
2024-04-06 10:33:56,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-04-06 10:33:56,970 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:33:56,970 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:33:56,970 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:33:56,972 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:33:56,972 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:33:57,087 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:33:57,089 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:33:57,089 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:33:57,089 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:57,089 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:33:57,089 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:33:57,089 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:57,089 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:57,089 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:57,421 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=8be94057-6f6e-4ca0-8619-73828bace674 since it stays at CLOSED stage.
2024-04-06 10:33:57,422 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=8be94057-6f6e-4ca0-8619-73828bace674 close command to datanode cc1e4d3c-2283-4c28-b737-db868cb45369
2024-04-06 10:33:57,423 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 8be94057-6f6e-4ca0-8619-73828bace674, Nodes: cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:cc1e4d3c-2283-4c28-b737-db868cb45369, CreationTimestamp2024-04-06T10:33:38.544Z[Etc/UTC]] removed.
2024-04-06 10:33:57,423 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 since it stays at CLOSED stage.
2024-04-06 10:33:57,423 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 close command to datanode cc1e4d3c-2283-4c28-b737-db868cb45369
2024-04-06 10:33:57,423 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 close command to datanode d1715241-1ffa-4146-b219-94c9c0fc171f
2024-04-06 10:33:57,423 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 close command to datanode 59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:33:57,423 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: b4229e37-69d0-4c7f-a467-673fb5e812e7, Nodes: cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:59c3495a-7636-40f9-8dfa-c28be8e98abd, CreationTimestamp2024-04-06T10:33:38.689Z[Etc/UTC]] removed.
2024-04-06 10:33:57,580 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 is not found
2024-04-06 10:33:57,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:33:57,623 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(472)) - org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d51e89fb has 1 sufficientlyReplicated, 0 deleting, 0 underReplicated and 0 unclosed containers
2024-04-06 10:33:57,623 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:putIntoMaintenance(529)) - Datanode cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) has entered maintenance
2024-04-06 10:33:57,623 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-04-06 10:33:57,624 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) moved to HEALTHY state.
2024-04-06 10:33:57,624 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-04-06 10:33:57,625 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 to datanode:a40aef6e-dfc7-4141-9a41-17d72bf4eeff
2024-04-06 10:33:57,625 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 to datanode:59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:33:57,625 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 to datanode:ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2
2024-04-06 10:33:57,626 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246, Nodes: a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-04-06T10:33:57.625Z[Etc/UTC]]
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-04-06 10:33:57,832 [IPC Server handler 8 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startMaintenance(520)) - Starting Maintenance for node d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:33:57,832 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) moved to HEALTHY state.
2024-04-06 10:33:57,832 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-04-06 10:33:57,974 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:33:57,974 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:33:57,974 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:33:57,976 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:33:57,976 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:33:58,090 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:33:58,093 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:33:58,093 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:33:58,093 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:58,093 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:33:58,093 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:33:58,093 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:58,093 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:58,093 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:58,575 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: remove    LEADER 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7:t1, leader=59c3495a-7636-40f9-8dfa-c28be8e98abd, voted=59c3495a-7636-40f9-8dfa-c28be8e98abd, raftlog=Memoized:59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-SegmentedRaftLog:OPENED:c6, conf=0: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null RUNNING
2024-04-06 10:33:58,577 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7: shutdown
2024-04-06 10:33:58,577 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-673FB5E812E7,id=59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:33:58,577 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: shutdown 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-LeaderStateImpl
2024-04-06 10:33:58,578 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-PendingRequests: sendNotLeaderResponses
2024-04-06 10:33:58,580 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7->cc1e4d3c-2283-4c28-b737-db868cb45369-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7->cc1e4d3c-2283-4c28-b737-db868cb45369-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-04-06 10:33:58,582 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7->d1715241-1ffa-4146-b219-94c9c0fc171f-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7->d1715241-1ffa-4146-b219-94c9c0fc171f-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-04-06 10:33:58,583 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - cc1e4d3c-2283-4c28-b737-db868cb45369: Completed APPEND_ENTRIES, lastRequest: 59c3495a-7636-40f9-8dfa-c28be8e98abd->cc1e4d3c-2283-4c28-b737-db868cb45369#16-t1,previous=(t:1, i:5),leaderCommit=5,initializing? false,entries: size=1, first=(t:1, i:6), METADATAENTRY(c:5)
2024-04-06 10:33:58,584 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - cc1e4d3c-2283-4c28-b737-db868cb45369: Completed APPEND_ENTRIES, lastReply: null
2024-04-06 10:33:58,587 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - cc1e4d3c-2283-4c28-b737-db868cb45369: Completed APPEND_ENTRIES, lastRequest: null
2024-04-06 10:33:58,588 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - d1715241-1ffa-4146-b219-94c9c0fc171f: Completed APPEND_ENTRIES, lastRequest: 59c3495a-7636-40f9-8dfa-c28be8e98abd->d1715241-1ffa-4146-b219-94c9c0fc171f#18-t1,previous=(t:1, i:5),leaderCommit=5,initializing? false,entries: size=1, first=(t:1, i:6), METADATAENTRY(c:5)
2024-04-06 10:33:58,588 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - d1715241-1ffa-4146-b219-94c9c0fc171f: Completed APPEND_ENTRIES, lastReply: null
2024-04-06 10:33:58,588 [grpc-default-executor-1] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7->d1715241-1ffa-4146-b219-94c9c0fc171f-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-04-06 10:33:58,589 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - d1715241-1ffa-4146-b219-94c9c0fc171f: Completed APPEND_ENTRIES, lastRequest: null
2024-04-06 10:33:58,590 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-StateMachineUpdater: set stopIndex = 6
2024-04-06 10:33:58,591 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-673FB5E812E7: Taking a snapshot at:(t:1, i:6) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7/sm/snapshot.1_6
2024-04-06 10:33:58,592 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - d1715241-1ffa-4146-b219-94c9c0fc171f: remove  FOLLOWER d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7:t1, leader=59c3495a-7636-40f9-8dfa-c28be8e98abd, voted=59c3495a-7636-40f9-8dfa-c28be8e98abd, raftlog=Memoized:d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-SegmentedRaftLog:OPENED:c6, conf=0: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null RUNNING
2024-04-06 10:33:58,592 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7: shutdown
2024-04-06 10:33:58,592 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-673FB5E812E7,id=d1715241-1ffa-4146-b219-94c9c0fc171f
2024-04-06 10:33:58,592 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - d1715241-1ffa-4146-b219-94c9c0fc171f: shutdown d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-FollowerState
2024-04-06 10:33:58,592 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-StateMachineUpdater: set stopIndex = 6
2024-04-06 10:33:58,592 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-673FB5E812E7: Taking a snapshot at:(t:1, i:6) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7/sm/snapshot.1_6
2024-04-06 10:33:58,592 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-FollowerState was interrupted
2024-04-06 10:33:58,593 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7->cc1e4d3c-2283-4c28-b737-db868cb45369-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-04-06 10:33:58,594 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - cc1e4d3c-2283-4c28-b737-db868cb45369: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "59c3495a-7636-40f9-8dfa-c28be8e98abd"
  replyId: "cc1e4d3c-2283-4c28-b737-db868cb45369"
  raftGroupId {
    id: "\264\"\2367i\320L\177\244gg?\265\350\022\347"
  }
  callId: 20
  success: true
}
term: 1
nextIndex: 7
followerCommit: 6
matchIndex: 18446744073709551615
isHearbeat: true

2024-04-06 10:33:58,593 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 1}
2024-04-06 10:33:58,594 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 5 millisec, 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 1}
2024-04-06 10:33:58,595 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - cc1e4d3c-2283-4c28-b737-db868cb45369: remove    LEADER cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674:t1, leader=cc1e4d3c-2283-4c28-b737-db868cb45369, voted=cc1e4d3c-2283-4c28-b737-db868cb45369, raftlog=Memoized:cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-SegmentedRaftLog:OPENED:c0, conf=0: peers:[cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null RUNNING
2024-04-06 10:33:58,595 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674: shutdown
2024-04-06 10:33:58,599 [IPC Server handler 13 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-04-06 10:33:58,595 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - d1715241-1ffa-4146-b219-94c9c0fc171f: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "59c3495a-7636-40f9-8dfa-c28be8e98abd"
  replyId: "d1715241-1ffa-4146-b219-94c9c0fc171f"
  raftGroupId {
    id: "\264\"\2367i\320L\177\244gg?\265\350\022\347"
  }
  callId: 22
  success: true
}
term: 1
nextIndex: 7
followerCommit: 6
matchIndex: 18446744073709551615
isHearbeat: true

2024-04-06 10:33:58,600 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 is not found
2024-04-06 10:33:58,595 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7->cc1e4d3c-2283-4c28-b737-db868cb45369-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-04-06 10:33:58,600 [IPC Server handler 10 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2024-04-06 10:33:58,601 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7->d1715241-1ffa-4146-b219-94c9c0fc171f-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-04-06 10:33:58,600 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-73828BACE674,id=cc1e4d3c-2283-4c28-b737-db868cb45369
2024-04-06 10:33:58,601 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - cc1e4d3c-2283-4c28-b737-db868cb45369: shutdown cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-LeaderStateImpl
2024-04-06 10:33:58,602 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-PendingRequests: sendNotLeaderResponses
2024-04-06 10:33:58,602 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=8be94057-6f6e-4ca0-8619-73828bace674 is not found
2024-04-06 10:33:58,602 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 is not found
2024-04-06 10:33:58,602 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-StateMachineUpdater: set stopIndex = 0
2024-04-06 10:33:58,602 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-73828BACE674: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/8be94057-6f6e-4ca0-8619-73828bace674/sm/snapshot.1_0
2024-04-06 10:33:58,620 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:33:58,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@bc6e90d1. There are 1 pipelines
2024-04-06 10:33:58,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-04-06 10:33:58,622 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(55)) - Admin start on datanode d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10). Finalizing its pipelines [PipelineID=47341687-34d7-44e9-a74c-836518d32a71]
2024-04-06 10:33:58,623 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=47341687-34d7-44e9-a74c-836518d32a71 moved to CLOSED state
2024-04-06 10:33:58,631 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-73828BACE674: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/8be94057-6f6e-4ca0-8619-73828bace674/sm/snapshot.1_0 took: 29 ms
2024-04-06 10:33:58,632 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-StateMachineUpdater: Took a snapshot at index 0
2024-04-06 10:33:58,632 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-04-06 10:33:58,634 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-673FB5E812E7: Finished taking a snapshot at:(t:1, i:6) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7/sm/snapshot.1_6 took: 43 ms
2024-04-06 10:33:58,634 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-673FB5E812E7: Finished taking a snapshot at:(t:1, i:6) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7/sm/snapshot.1_6 took: 42 ms
2024-04-06 10:33:58,634 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-StateMachineUpdater: Took a snapshot at index 6
2024-04-06 10:33:58,634 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-StateMachineUpdater: Took a snapshot at index 6
2024-04-06 10:33:58,634 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 6
2024-04-06 10:33:58,634 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 6
2024-04-06 10:33:58,635 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674: applyIndex: 0
2024-04-06 10:33:58,635 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7: applyIndex: 6
2024-04-06 10:33:58,635 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7: applyIndex: 6
2024-04-06 10:33:58,636 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-04-06 10:33:58,637 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-04-06 10:33:58,637 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-04-06 10:33:58,978 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:33:58,978 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:33:58,978 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:33:58,980 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:33:58,980 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:33:59,063 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: addNew group-87AD1B61A246:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052] returns group-87AD1B61A246:java.util.concurrent.CompletableFuture@719432fe[Not completed]
2024-04-06 10:33:59,065 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: new RaftServerImpl for group-87AD1B61A246:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052] with ContainerStateMachine:uninitialized
2024-04-06 10:33:59,065 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:33:59,065 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-04-06 10:33:59,065 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-04-06 10:33:59,065 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-04-06 10:33:59,065 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:33:59,065 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-04-06 10:33:59,065 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:33:59,066 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246: ConfigurationManager, init=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-04-06 10:33:59,066 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-04-06 10:33:59,066 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-04-06 10:33:59,066 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-04-06 10:33:59,066 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-04-06 10:33:59,066 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-04-06 10:33:59,066 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-04-06 10:33:59,069 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:33:59,070 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:33:59,070 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-04-06 10:33:59,070 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-04-06 10:33:59,070 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-04-06 10:33:59,070 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-04-06 10:33:59,070 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-04-06 10:33:59,070 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-04-06 10:33:59,070 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis] (custom)
2024-04-06 10:33:59,070 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 does not exist. Creating ...
2024-04-06 10:33:59,071 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246/in_use.lock acquired by nodename 82778@fv-az526-218
2024-04-06 10:33:59,072 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 has been successfully formatted.
2024-04-06 10:33:59,073 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246/current/raft-meta.conf
2024-04-06 10:33:59,073 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-87AD1B61A246: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-04-06 10:33:59,073 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-04-06 10:33:59,073 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-04-06 10:33:59,074 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:59,074 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-04-06 10:33:59,074 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-04-06 10:33:59,074 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246. Trying to get from SCM.
2024-04-06 10:33:59,079 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:33:59,080 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-04-06 10:33:59,080 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-04-06 10:33:59,080 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:59,080 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-cacheEviction-AwaitToRun,5,main] started
2024-04-06 10:33:59,080 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246
2024-04-06 10:33:59,080 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-04-06 10:33:59,080 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-04-06 10:33:59,080 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:33:59,081 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-04-06 10:33:59,081 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(86)) - Adding new pipeline Pipeline[ Id: 6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246, Nodes: a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-04-06T10:33:57.625Z[Etc/UTC]] to Recon pipeline metadata.
2024-04-06 10:33:59,081 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-04-06 10:33:59,081 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-04-06 10:33:59,081 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-04-06 10:33:59,081 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-04-06 10:33:59,081 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-04-06 10:33:59,082 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 reported by ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:33:59,083 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:59,083 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-04-06 10:33:59,083 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-04-06 10:33:59,083 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-04-06 10:33:59,084 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-04-06 10:33:59,084 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-04-06 10:33:59,084 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246: start as a follower, conf=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null
2024-04-06 10:33:59,084 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-04-06 10:33:59,084 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: start ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-FollowerState
2024-04-06 10:33:59,084 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:33:59,085 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:33:59,084 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-87AD1B61A246,id=ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2
2024-04-06 10:33:59,085 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-04-06 10:33:59,085 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-04-06 10:33:59,085 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-04-06 10:33:59,085 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-04-06 10:33:59,085 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-04-06 10:33:59,086 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246
2024-04-06 10:33:59,094 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:33:59,096 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:33:59,097 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:33:59,097 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:59,097 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:33:59,097 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:33:59,097 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:59,097 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:33:59,097 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:33:59,101 [grpc-default-executor-4] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: addNew group-87AD1B61A246:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052] returns group-87AD1B61A246:java.util.concurrent.CompletableFuture@5785bc78[Not completed]
2024-04-06 10:33:59,102 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: new RaftServerImpl for group-87AD1B61A246:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052] with ContainerStateMachine:uninitialized
2024-04-06 10:33:59,102 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:33:59,102 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-04-06 10:33:59,102 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-04-06 10:33:59,102 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-04-06 10:33:59,102 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:33:59,102 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-04-06 10:33:59,103 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:33:59,103 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246: ConfigurationManager, init=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-04-06 10:33:59,103 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-04-06 10:33:59,103 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-04-06 10:33:59,103 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-04-06 10:33:59,103 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-04-06 10:33:59,103 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-04-06 10:33:59,103 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-04-06 10:33:59,107 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:33:59,107 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:33:59,107 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-04-06 10:33:59,107 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-04-06 10:33:59,107 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-04-06 10:33:59,107 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-04-06 10:33:59,107 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-04-06 10:33:59,107 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-04-06 10:33:59,108 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis] (custom)
2024-04-06 10:33:59,108 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 does not exist. Creating ...
2024-04-06 10:33:59,109 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246/in_use.lock acquired by nodename 82778@fv-az526-218
2024-04-06 10:33:59,110 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 has been successfully formatted.
2024-04-06 10:33:59,110 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246/current/raft-meta.conf
2024-04-06 10:33:59,111 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-87AD1B61A246: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-04-06 10:33:59,111 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-04-06 10:33:59,111 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-04-06 10:33:59,111 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:59,111 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-04-06 10:33:59,111 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-04-06 10:33:59,112 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 reported by a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:33:59,113 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:33:59,113 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-04-06 10:33:59,113 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-04-06 10:33:59,113 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:59,114 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-cacheEviction-AwaitToRun,5,main] started
2024-04-06 10:33:59,114 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246
2024-04-06 10:33:59,114 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-04-06 10:33:59,114 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-04-06 10:33:59,114 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:33:59,114 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-04-06 10:33:59,114 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-04-06 10:33:59,114 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-04-06 10:33:59,114 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-04-06 10:33:59,114 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-04-06 10:33:59,115 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-04-06 10:33:59,116 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:59,116 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-04-06 10:33:59,116 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-04-06 10:33:59,116 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-04-06 10:33:59,116 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-04-06 10:33:59,117 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-04-06 10:33:59,121 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246: start as a follower, conf=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null
2024-04-06 10:33:59,122 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-04-06 10:33:59,122 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: start a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-FollowerState
2024-04-06 10:33:59,122 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:33:59,122 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-87AD1B61A246,id=a40aef6e-dfc7-4141-9a41-17d72bf4eeff
2024-04-06 10:33:59,123 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:33:59,123 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-04-06 10:33:59,123 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-04-06 10:33:59,123 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-04-06 10:33:59,123 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-04-06 10:33:59,123 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-04-06 10:33:59,151 [grpc-default-executor-4] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: addNew group-87AD1B61A246:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052] returns group-87AD1B61A246:java.util.concurrent.CompletableFuture@740f686d[Not completed]
2024-04-06 10:33:59,152 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: new RaftServerImpl for group-87AD1B61A246:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052] with ContainerStateMachine:uninitialized
2024-04-06 10:33:59,152 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:33:59,152 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-04-06 10:33:59,152 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-04-06 10:33:59,152 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-04-06 10:33:59,152 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:33:59,152 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-04-06 10:33:59,152 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:33:59,153 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246: ConfigurationManager, init=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-04-06 10:33:59,153 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-04-06 10:33:59,153 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-04-06 10:33:59,153 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-04-06 10:33:59,153 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-04-06 10:33:59,153 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-04-06 10:33:59,153 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-04-06 10:33:59,156 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:33:59,156 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:33:59,156 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-04-06 10:33:59,156 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-04-06 10:33:59,156 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-04-06 10:33:59,156 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-04-06 10:33:59,156 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-04-06 10:33:59,156 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-04-06 10:33:59,156 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis] (custom)
2024-04-06 10:33:59,157 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 does not exist. Creating ...
2024-04-06 10:33:59,158 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246/in_use.lock acquired by nodename 82778@fv-az526-218
2024-04-06 10:33:59,162 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 has been successfully formatted.
2024-04-06 10:33:59,163 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246/current/raft-meta.conf
2024-04-06 10:33:59,164 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-87AD1B61A246: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-04-06 10:33:59,164 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-04-06 10:33:59,164 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-04-06 10:33:59,165 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 reported by 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:33:59,165 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:59,166 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-04-06 10:33:59,166 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-04-06 10:33:59,167 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:33:59,168 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-04-06 10:33:59,168 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-04-06 10:33:59,168 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:59,170 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-cacheEviction-AwaitToRun,5,main] started
2024-04-06 10:33:59,171 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246
2024-04-06 10:33:59,171 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-04-06 10:33:59,171 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-04-06 10:33:59,171 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:33:59,171 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-04-06 10:33:59,171 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-04-06 10:33:59,171 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-04-06 10:33:59,171 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-04-06 10:33:59,171 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-04-06 10:33:59,172 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-04-06 10:33:59,173 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:33:59,173 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-04-06 10:33:59,173 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-04-06 10:33:59,174 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-04-06 10:33:59,174 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-04-06 10:33:59,174 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-04-06 10:33:59,178 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246: start as a follower, conf=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null
2024-04-06 10:33:59,179 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-04-06 10:33:59,179 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: start 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-FollowerState
2024-04-06 10:33:59,182 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:33:59,183 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-87AD1B61A246,id=59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:33:59,183 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-04-06 10:33:59,183 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-04-06 10:33:59,183 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-04-06 10:33:59,183 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-04-06 10:33:59,183 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-04-06 10:33:59,183 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:33:59,206 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246.
2024-04-06 10:33:59,571 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7-SegmentedRaftLogWorker close()
2024-04-06 10:33:59,574 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7-SegmentedRaftLogWorker close()
2024-04-06 10:33:59,577 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-673FB5E812E7: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7
2024-04-06 10:33:59,577 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-673FB5E812E7: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7
2024-04-06 10:33:59,577 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7
org.apache.ratis.protocol.exceptions.GroupMismatchException: 59c3495a-7636-40f9-8dfa-c28be8e98abd: group-673FB5E812E7 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-04-06 10:33:59,577 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7
org.apache.ratis.protocol.exceptions.GroupMismatchException: d1715241-1ffa-4146-b219-94c9c0fc171f: group-673FB5E812E7 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-04-06 10:33:59,593 [IPC Server handler 16 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-04-06 10:33:59,596 [IPC Server handler 13 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2024-04-06 10:33:59,597 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 is not found
2024-04-06 10:33:59,621 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:33:59,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@bc6e90d1. There are 1 pipelines
2024-04-06 10:33:59,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-04-06 10:33:59,636 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674-SegmentedRaftLogWorker close()
2024-04-06 10:33:59,638 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-73828BACE674: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/8be94057-6f6e-4ca0-8619-73828bace674
2024-04-06 10:33:59,639 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=8be94057-6f6e-4ca0-8619-73828bace674
org.apache.ratis.protocol.exceptions.GroupMismatchException: cc1e4d3c-2283-4c28-b737-db868cb45369: group-73828BACE674 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-04-06 10:33:59,639 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - cc1e4d3c-2283-4c28-b737-db868cb45369: remove  FOLLOWER cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7:t1, leader=59c3495a-7636-40f9-8dfa-c28be8e98abd, voted=59c3495a-7636-40f9-8dfa-c28be8e98abd, raftlog=Memoized:cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-SegmentedRaftLog:OPENED:c6, conf=0: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null RUNNING
2024-04-06 10:33:59,639 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7: shutdown
2024-04-06 10:33:59,639 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-673FB5E812E7,id=cc1e4d3c-2283-4c28-b737-db868cb45369
2024-04-06 10:33:59,639 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - cc1e4d3c-2283-4c28-b737-db868cb45369: shutdown cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-FollowerState
2024-04-06 10:33:59,639 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-StateMachineUpdater: set stopIndex = 6
2024-04-06 10:33:59,639 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-673FB5E812E7: Taking a snapshot at:(t:1, i:6) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7/sm/snapshot.1_6
2024-04-06 10:33:59,639 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-FollowerState was interrupted
2024-04-06 10:33:59,641 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-673FB5E812E7: Finished taking a snapshot at:(t:1, i:6) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7/sm/snapshot.1_6 took: 1 ms
2024-04-06 10:33:59,641 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-StateMachineUpdater: Took a snapshot at index 6
2024-04-06 10:33:59,642 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 6
2024-04-06 10:33:59,642 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7: applyIndex: 6
2024-04-06 10:33:59,642 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-04-06 10:33:59,982 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:33:59,982 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:33:59,982 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:33:59,984 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:33:59,984 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:00,098 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:00,101 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 3 milliseconds for processing 1 containers.
2024-04-06 10:34:00,101 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:00,101 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:00,101 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:00,101 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:00,101 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:00,101 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:00,101 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:00,572 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7-SegmentedRaftLogWorker close()
2024-04-06 10:34:00,574 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-673FB5E812E7: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/b4229e37-69d0-4c7f-a467-673fb5e812e7
2024-04-06 10:34:00,574 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7
org.apache.ratis.protocol.exceptions.GroupMismatchException: cc1e4d3c-2283-4c28-b737-db868cb45369: group-673FB5E812E7 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-04-06 10:34:00,593 [d1715241-1ffa-4146-b219-94c9c0fc171f-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to ENTERING_MAINTENANCE, scaling executor pool size to 20
2024-04-06 10:34:00,595 [IPC Server handler 18 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-04-06 10:34:00,595 [IPC Server handler 23 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) as the reported value (IN_MAINTENANCE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-04-06 10:34:00,597 [cc1e4d3c-2283-4c28-b737-db868cb45369-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_MAINTENANCE, scaling executor pool size to 20
2024-04-06 10:34:00,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:34:00,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@bc6e90d1. There are 1 pipelines
2024-04-06 10:34:00,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-04-06 10:34:00,986 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:00,986 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:00,986 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:00,988 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:00,988 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:01,075 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 reported by ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:01,102 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-04-06 10:34:01,114 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 reported by a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:01,115 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 14 milliseconds for processing 1 containers.
2024-04-06 10:34:01,115 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:01,116 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:01,116 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:01,116 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:01,116 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	TOTAL_KEYS -> 1 , CONTAINER_COUNT -> 1 , TOTAL_USED_BYTES -> 7 , 
2024-04-06 10:34:01,116 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:01,116 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:01,165 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 reported by 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:01,615 [UnderReplicatedProcessor] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:chooseNodeInternal(672)) - No available node in (scope="/" excludedScope="[/default-rack/d1715241-1ffa-4146-b219-94c9c0fc171f, /default-rack/cc1e4d3c-2283-4c28-b737-db868cb45369, /default-rack/59c3495a-7636-40f9-8dfa-c28be8e98abd]" excludedNodes="[d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)]"  ancestorGen="1").
2024-04-06 10:34:01,615 [UnderReplicatedProcessor] WARN  algorithms.SCMContainerPlacementRackAware (SCMContainerPlacementRackAware.java:chooseNode(485)) - Failed to find the datanode for container. excludedNodes:[d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)], affinityNode:
2024-04-06 10:34:01,616 [UnderReplicatedProcessor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [replicateContainerCommand: containerId=1, replicaIndex=0, targetNode=ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), priority=NORMAL] for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-04-06T10:33:53.584Z, pipelineID=PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7, owner=omServiceIdDefault} to d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) with datanode deadline 1712400211616 and scm deadline 1712400241616
2024-04-06 10:34:01,617 [UnderReplicatedProcessor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(138)) - Processed 1 containers with health state counts {UNDER_REPLICATED=1}, failed processing 0, deferred due to load 0
2024-04-06 10:34:01,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@bc6e90d1. There are 1 pipelines
2024-04-06 10:34:01,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-04-06 10:34:01,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:01,990 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:01,990 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:01,990 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:01,992 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:01,992 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:02,075 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 reported by ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:02,114 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 reported by a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:02,119 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 3 milliseconds to process 1 existing database records.
2024-04-06 10:34:02,120 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:34:02,120 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:02,120 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:02,120 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:02,120 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:02,120 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:02,121 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:02,121 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:02,166 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 1}
2024-04-06 10:34:02,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@bc6e90d1. There are 1 pipelines
2024-04-06 10:34:02,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-04-06 10:34:02,622 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:02,994 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:02,994 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:02,994 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:02,996 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:02,996 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:03,114 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 reported by a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:03,122 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 1 existing database records.
2024-04-06 10:34:03,124 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:03,124 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:03,124 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:03,124 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:03,124 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:03,124 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:03,124 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:03,124 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:03,165 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 reported by 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:03,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@bc6e90d1. There are 1 pipelines
2024-04-06 10:34:03,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-04-06 10:34:03,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:34:03,998 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:03,998 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:03,998 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:04,000 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:04,000 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:04,075 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 reported by ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:04,126 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 1 existing database records.
2024-04-06 10:34:04,127 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:04,127 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:04,128 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:04,128 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:04,128 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:04,128 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:04,128 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:04,128 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:04,192 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5070147700ns, electionTimeout:5069ms
2024-04-06 10:34:04,192 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: shutdown a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-FollowerState
2024-04-06 10:34:04,192 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-04-06 10:34:04,193 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-04-06 10:34:04,193 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: start a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-LeaderElection8
2024-04-06 10:34:04,195 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-LeaderElection8 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null
2024-04-06 10:34:04,195 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-LeaderElection8-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for 59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016
2024-04-06 10:34:04,195 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-LeaderElection8-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052
2024-04-06 10:34:04,195 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:34:04,196 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:34:04,204 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246: receive requestVote(PRE_VOTE, a40aef6e-dfc7-4141-9a41-17d72bf4eeff, group-87AD1B61A246, 0, (t:0, i:0))
2024-04-06 10:34:04,206 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-FOLLOWER: reject PRE_VOTE from a40aef6e-dfc7-4141-9a41-17d72bf4eeff: our priority 1 > candidate's priority 0
2024-04-06 10:34:04,206 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246: receive requestVote(PRE_VOTE, a40aef6e-dfc7-4141-9a41-17d72bf4eeff, group-87AD1B61A246, 0, (t:0, i:0))
2024-04-06 10:34:04,206 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246 replies to PRE_VOTE vote request: a40aef6e-dfc7-4141-9a41-17d72bf4eeff<-59c3495a-7636-40f9-8dfa-c28be8e98abd#0:FAIL-t0. Peer's state: 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246:t0, leader=null, voted=, raftlog=Memoized:59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null
2024-04-06 10:34:04,206 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-FOLLOWER: accept PRE_VOTE from a40aef6e-dfc7-4141-9a41-17d72bf4eeff: our priority 0 <= candidate's priority 0
2024-04-06 10:34:04,206 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246 replies to PRE_VOTE vote request: a40aef6e-dfc7-4141-9a41-17d72bf4eeff<-ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2#0:OK-t0. Peer's state: ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246:t0, leader=null, voted=, raftlog=Memoized:ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null
2024-04-06 10:34:04,206 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5027343669ns, electionTimeout:5021ms
2024-04-06 10:34:04,206 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: shutdown 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-FollowerState
2024-04-06 10:34:04,206 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-04-06 10:34:04,208 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-04-06 10:34:04,208 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: start 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9
2024-04-06 10:34:04,210 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null
2024-04-06 10:34:04,211 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043
2024-04-06 10:34:04,213 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:34:04,213 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(65)) - Build channel for ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052
2024-04-06 10:34:04,213 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:34:04,213 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-LeaderElection8: PRE_VOTE REJECTED received 1 response(s) and 0 exception(s):
2024-04-06 10:34:04,213 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: a40aef6e-dfc7-4141-9a41-17d72bf4eeff<-59c3495a-7636-40f9-8dfa-c28be8e98abd#0:FAIL-t0
2024-04-06 10:34:04,213 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-LeaderElection8 PRE_VOTE round 0: result REJECTED
2024-04-06 10:34:04,214 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-LeaderElection8] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246: changes role from CANDIDATE to FOLLOWER at term 0 for REJECTED
2024-04-06 10:34:04,214 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: shutdown a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-LeaderElection8
2024-04-06 10:34:04,214 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: start a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-FollowerState
2024-04-06 10:34:04,219 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-LeaderElection8] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246: set firstElectionSinceStartup to false for REJECTED
2024-04-06 10:34:04,224 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246: receive requestVote(PRE_VOTE, 59c3495a-7636-40f9-8dfa-c28be8e98abd, group-87AD1B61A246, 0, (t:0, i:0))
2024-04-06 10:34:04,226 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-FOLLOWER: accept PRE_VOTE from 59c3495a-7636-40f9-8dfa-c28be8e98abd: our priority 0 <= candidate's priority 1
2024-04-06 10:34:04,227 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246 replies to PRE_VOTE vote request: 59c3495a-7636-40f9-8dfa-c28be8e98abd<-a40aef6e-dfc7-4141-9a41-17d72bf4eeff#0:OK-t0. Peer's state: a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246:t0, leader=null, voted=, raftlog=Memoized:a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null
2024-04-06 10:34:04,233 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246: receive requestVote(PRE_VOTE, 59c3495a-7636-40f9-8dfa-c28be8e98abd, group-87AD1B61A246, 0, (t:0, i:0))
2024-04-06 10:34:04,233 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-FOLLOWER: accept PRE_VOTE from 59c3495a-7636-40f9-8dfa-c28be8e98abd: our priority 0 <= candidate's priority 1
2024-04-06 10:34:04,233 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246 replies to PRE_VOTE vote request: 59c3495a-7636-40f9-8dfa-c28be8e98abd<-ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2#0:OK-t0. Peer's state: ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246:t0, leader=null, voted=, raftlog=Memoized:ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null
2024-04-06 10:34:04,233 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2024-04-06 10:34:04,233 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 59c3495a-7636-40f9-8dfa-c28be8e98abd<-a40aef6e-dfc7-4141-9a41-17d72bf4eeff#0:OK-t0
2024-04-06 10:34:04,233 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9 PRE_VOTE round 0: result PASSED
2024-04-06 10:34:04,236 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9 ELECTION round 0: submit vote requests at term 1 for -1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null
2024-04-06 10:34:04,237 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:34:04,237 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:34:04,238 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246: receive requestVote(ELECTION, 59c3495a-7636-40f9-8dfa-c28be8e98abd, group-87AD1B61A246, 1, (t:0, i:0))
2024-04-06 10:34:04,239 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-FOLLOWER: accept ELECTION from 59c3495a-7636-40f9-8dfa-c28be8e98abd: our priority 0 <= candidate's priority 1
2024-04-06 10:34:04,239 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:34:04,239 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: shutdown a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-FollowerState
2024-04-06 10:34:04,240 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: start a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-FollowerState
2024-04-06 10:34:04,240 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246: receive requestVote(ELECTION, 59c3495a-7636-40f9-8dfa-c28be8e98abd, group-87AD1B61A246, 1, (t:0, i:0))
2024-04-06 10:34:04,240 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-FollowerState was interrupted
2024-04-06 10:34:04,241 [grpc-default-executor-4] INFO  impl.VoteContext (VoteContext.java:log(49)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-FOLLOWER: accept ELECTION from 59c3495a-7636-40f9-8dfa-c28be8e98abd: our priority 0 <= candidate's priority 1
2024-04-06 10:34:04,241 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246 replies to ELECTION vote request: 59c3495a-7636-40f9-8dfa-c28be8e98abd<-a40aef6e-dfc7-4141-9a41-17d72bf4eeff#0:OK-t1. Peer's state: a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246:t1, leader=null, voted=59c3495a-7636-40f9-8dfa-c28be8e98abd, raftlog=Memoized:a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null
2024-04-06 10:34:04,241 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:34:04,241 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: shutdown ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-FollowerState
2024-04-06 10:34:04,242 [grpc-default-executor-4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: start ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-FollowerState
2024-04-06 10:34:04,242 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-FollowerState was interrupted
2024-04-06 10:34:04,242 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246: set firstElectionSinceStartup to false for candidate:59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:34:04,244 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9: ELECTION PASSED received 1 response(s) and 0 exception(s):
2024-04-06 10:34:04,244 [grpc-default-executor-4] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246 replies to ELECTION vote request: 59c3495a-7636-40f9-8dfa-c28be8e98abd<-ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2#0:OK-t1. Peer's state: ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246:t1, leader=null, voted=59c3495a-7636-40f9-8dfa-c28be8e98abd, raftlog=Memoized:ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null
2024-04-06 10:34:04,244 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 59c3495a-7636-40f9-8dfa-c28be8e98abd<-a40aef6e-dfc7-4141-9a41-17d72bf4eeff#0:OK-t1
2024-04-06 10:34:04,245 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9 ELECTION round 0: result PASSED
2024-04-06 10:34:04,245 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: shutdown 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9
2024-04-06 10:34:04,245 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-04-06 10:34:04,245 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-04-06 10:34:04,245 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-04-06 10:34:04,245 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-04-06 10:34:04,246 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-04-06 10:34:04,246 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-04-06 10:34:04,246 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-04-06 10:34:04,246 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-04-06 10:34:04,246 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-04-06 10:34:04,246 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:34:04,246 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-04-06 10:34:04,246 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-04-06 10:34:04,247 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-04-06 10:34:04,247 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:34:04,247 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2024-04-06 10:34:04,247 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0μs (custom)
2024-04-06 10:34:04,247 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-04-06 10:34:04,248 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:34:04,248 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-04-06 10:34:04,248 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-04-06 10:34:04,248 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-04-06 10:34:04,248 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:34:04,248 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-04-06 10:34:04,251 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-04-06 10:34:04,251 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:34:04,251 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2024-04-06 10:34:04,251 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0μs (custom)
2024-04-06 10:34:04,251 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-04-06 10:34:04,251 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:34:04,251 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-04-06 10:34:04,251 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-04-06 10:34:04,252 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-04-06 10:34:04,252 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:34:04,252 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-04-06 10:34:04,252 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: start 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderStateImpl
2024-04-06 10:34:04,252 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246: set firstElectionSinceStartup to false for becomeLeader
2024-04-06 10:34:04,252 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-87AD1B61A246 with new leaderId: 59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:34:04,252 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246: change Leader from null to 59c3495a-7636-40f9-8dfa-c28be8e98abd at term 1 for becomeLeader, leader elected after 5099ms
2024-04-06 10:34:04,253 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-SegmentedRaftLogWorker: Starting segment from index:0
2024-04-06 10:34:04,253 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-04-06 10:34:04,255 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246
2024-04-06 10:34:04,255 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 reported by 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:04,258 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderElection9] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246: set configuration 0: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null
2024-04-06 10:34:04,265 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246/current/log_inprogress_0
2024-04-06 10:34:04,272 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-87AD1B61A246 with new leaderId: 59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:34:04,273 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246: change Leader from null to 59c3495a-7636-40f9-8dfa-c28be8e98abd at term 1 for appendEntries, leader elected after 5206ms
2024-04-06 10:34:04,297 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-server-thread3] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246: set configuration 0: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null
2024-04-06 10:34:04,298 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-server-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-SegmentedRaftLogWorker: Starting segment from index:0
2024-04-06 10:34:04,304 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-87AD1B61A246 with new leaderId: 59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:34:04,304 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246: change Leader from null to 59c3495a-7636-40f9-8dfa-c28be8e98abd at term 1 for appendEntries, leader elected after 5200ms
2024-04-06 10:34:04,309 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-04-06 10:34:04,311 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246: set configuration 0: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null
2024-04-06 10:34:04,311 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-SegmentedRaftLogWorker: Starting segment from index:0
2024-04-06 10:34:04,312 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-04-06 10:34:04,323 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246/current/log_inprogress_0
2024-04-06 10:34:04,324 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246/current/log_inprogress_0
2024-04-06 10:34:04,328 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-04-06 10:34:04,598 [d1715241-1ffa-4146-b219-94c9c0fc171f-ContainerReplicationThread-0] INFO  replication.PushReplicator (PushReplicator.java:replicate(58)) - Starting replication of container 1 to ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) using NO_COMPRESSION
2024-04-06 10:34:04,618 [d1715241-1ffa-4146-b219-94c9c0fc171f-ContainerReplicationThread-0] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(116)) - Sent 16384 bytes for container 1
2024-04-06 10:34:04,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@bc6e90d1. There are 1 pipelines
2024-04-06 10:34:04,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-04-06 10:34:04,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:04,625 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-ReplicationContainerReader-1] INFO  replication.SendContainerRequestHandler (SendContainerRequestHandler.java:onNext(96)) - Accepting container 1
2024-04-06 10:34:04,625 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-ReplicationContainerReader-1] INFO  replication.SendContainerRequestHandler (SendContainerRequestHandler.java:onCompleted(131)) - Container 1 is downloaded with size 16384, starting to import.
2024-04-06 10:34:04,672 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-ReplicationContainerReader-1] INFO  replication.SendContainerRequestHandler (SendContainerRequestHandler.java:onCompleted(137)) - Container 1 is replicated successfully
2024-04-06 10:34:04,678 [grpc-default-executor-2] INFO  replication.GrpcContainerUploader (GrpcContainerUploader.java:onCompleted(132)) - Finished uploading container 1 to ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:04,681 [d1715241-1ffa-4146-b219-94c9c0fc171f-ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(369)) - Successful DONE replicateContainerCommand: containerId=1, replicaIndex=0, targetNode=ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), priority=NORMAL, transferred 16384 bytes
2024-04-06 10:34:05,001 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:05,002 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:05,002 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:05,004 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:05,004 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:05,129 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:processExistingDBRecords(299)) - DELETED existing unhealthy container record...for Container: 1
2024-04-06 10:34:05,138 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 10 milliseconds to process 1 existing database records.
2024-04-06 10:34:05,139 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:05,140 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:05,140 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:05,140 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:05,140 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:05,140 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:05,140 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:05,140 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:05,424 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=47341687-34d7-44e9-a74c-836518d32a71 since it stays at CLOSED stage.
2024-04-06 10:34:05,424 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=47341687-34d7-44e9-a74c-836518d32a71 close command to datanode d1715241-1ffa-4146-b219-94c9c0fc171f
2024-04-06 10:34:05,425 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 47341687-34d7-44e9-a74c-836518d32a71, Nodes: d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:d1715241-1ffa-4146-b219-94c9c0fc171f, CreationTimestamp2024-04-06T10:33:38.684Z[Etc/UTC]] removed.
2024-04-06 10:34:05,594 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=47341687-34d7-44e9-a74c-836518d32a71 is not found
2024-04-06 10:34:05,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(472)) - org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@bc6e90d1 has 1 sufficientlyReplicated, 0 deleting, 0 underReplicated and 0 unclosed containers
2024-04-06 10:34:05,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:putIntoMaintenance(529)) - Datanode d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) has entered maintenance
2024-04-06 10:34:05,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 2 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-04-06 10:34:05,622 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) moved to HEALTHY state.
2024-04-06 10:34:05,623 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-04-06 10:34:05,623 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:05,658 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 4 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2, d1715241-1ffa-4146-b219-94c9c0fc171f]
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-04-06 10:34:05,674 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 1}
2024-04-06 10:34:05,675 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 1}
2024-04-06 10:34:05,677 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 1}
2024-04-06 10:34:05,677 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 1}
2024-04-06 10:34:05,690 [IPC Server handler 3 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:recommission(475)) - Queued node cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) for recommission
2024-04-06 10:34:05,690 [IPC Server handler 3 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:recommission(475)) - Queued node d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) for recommission
2024-04-06 10:34:06,005 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:06,005 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:06,006 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:06,007 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:06,007 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:06,141 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:06,143 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:06,143 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:06,143 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:06,143 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:06,143 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:06,143 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:06,143 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:06,143 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:06,594 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - d1715241-1ffa-4146-b219-94c9c0fc171f: remove    LEADER d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71:t1, leader=d1715241-1ffa-4146-b219-94c9c0fc171f, voted=d1715241-1ffa-4146-b219-94c9c0fc171f, raftlog=Memoized:d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-SegmentedRaftLog:OPENED:c0, conf=0: peers:[d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034]|listeners:[], old=null RUNNING
2024-04-06 10:34:06,594 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71: shutdown
2024-04-06 10:34:06,594 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-836518D32A71,id=d1715241-1ffa-4146-b219-94c9c0fc171f
2024-04-06 10:34:06,594 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - d1715241-1ffa-4146-b219-94c9c0fc171f: shutdown d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-LeaderStateImpl
2024-04-06 10:34:06,594 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-PendingRequests: sendNotLeaderResponses
2024-04-06 10:34:06,594 [IPC Server handler 16 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2024-04-06 10:34:06,595 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-StateMachineUpdater: set stopIndex = 0
2024-04-06 10:34:06,595 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-836518D32A71: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/47341687-34d7-44e9-a74c-836518d32a71/sm/snapshot.1_0
2024-04-06 10:34:06,595 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=47341687-34d7-44e9-a74c-836518d32a71 is not found
2024-04-06 10:34:06,596 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-836518D32A71: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/47341687-34d7-44e9-a74c-836518d32a71/sm/snapshot.1_0 took: 1 ms
2024-04-06 10:34:06,596 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-StateMachineUpdater: Took a snapshot at index 0
2024-04-06 10:34:06,596 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-04-06 10:34:06,596 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71: applyIndex: 0
2024-04-06 10:34:06,596 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-04-06 10:34:06,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:processCancelledNodes(292)) - Recommissioned node org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@d51e89fb
2024-04-06 10:34:06,622 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) moved to HEALTHY state.
2024-04-06 10:34:06,622 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-04-06 10:34:06,622 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) moved to HEALTHY state.
2024-04-06 10:34:06,622 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-04-06 10:34:06,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:processCancelledNodes(292)) - Recommissioned node org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@bc6e90d1
2024-04-06 10:34:06,624 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=b495966f-4ec9-40fc-9038-a7988bf88c1c to datanode:cc1e4d3c-2283-4c28-b737-db868cb45369
2024-04-06 10:34:06,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:34:06,624 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: b495966f-4ec9-40fc-9038-a7988bf88c1c, Nodes: cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-04-06T10:34:06.624Z[Etc/UTC]]
2024-04-06 10:34:06,625 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=62748d4a-78e9-4857-a2b6-89087e71b146 to datanode:d1715241-1ffa-4146-b219-94c9c0fc171f
2024-04-06 10:34:06,625 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 62748d4a-78e9-4857-a2b6-89087e71b146, Nodes: d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2024-04-06T10:34:06.625Z[Etc/UTC]]
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-04-06 10:34:06,738 [IPC Server handler 11 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:decommissionNodes(320)) - Force flag = false. Checking if decommission is possible for dns: [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)]
2024-04-06 10:34:06,738 [IPC Server handler 11 on default port 15000] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startDecommission(376)) - Starting Decommission for node ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:06,738 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) moved to HEALTHY state.
2024-04-06 10:34:06,738 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/UNDER_REPLICATED ...
2024-04-06 10:34:06,748 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71-SegmentedRaftLogWorker close()
2024-04-06 10:34:06,752 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-836518D32A71: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/47341687-34d7-44e9-a74c-836518d32a71
2024-04-06 10:34:06,752 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=47341687-34d7-44e9-a74c-836518d32a71
org.apache.ratis.protocol.exceptions.GroupMismatchException: d1715241-1ffa-4146-b219-94c9c0fc171f: group-836518D32A71 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/OVER_REPLICATED ...
2024-04-06 10:34:07,009 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:07,009 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:07,009 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:07,011 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:07,011 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:07,144 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-04-06 10:34:07,146 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:07,146 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:07,146 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:07,146 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:07,146 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:07,146 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:07,147 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:07,147 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:07,594 [IPC Server handler 16 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-04-06 10:34:07,597 [IPC Server handler 10 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) as the reported value (IN_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-04-06 10:34:07,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@ace0092f. There are 2 pipelines
2024-04-06 10:34:07,622 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(55)) - Admin start on datanode ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10). Finalizing its pipelines [PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246, PipelineID=15039d4b-d7f6-4769-9a85-becc45517e23]
2024-04-06 10:34:07,623 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 moved to CLOSED state
2024-04-06 10:34:07,623 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=15039d4b-d7f6-4769-9a85-becc45517e23 moved to CLOSED state
2024-04-06 10:34:07,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-04-06 10:34:07,624 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:07,673 [IPC Server handler 15 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (DECOMMISSIONING, 0)
2024-04-06 10:34:08,013 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:08,013 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:08,014 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:08,015 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:08,015 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:08,147 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-04-06 10:34:08,150 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:08,150 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:08,150 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:08,150 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:08,150 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:08,150 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:08,150 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:08,150 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:08,594 [IPC Server handler 17 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) as the reported value (IN_MAINTENANCE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2024-04-06 10:34:08,594 [d1715241-1ffa-4146-b219-94c9c0fc171f-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_MAINTENANCE, scaling executor pool size to 20
2024-04-06 10:34:08,594 [IPC Server handler 16 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) as the reported value (IN_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-04-06 10:34:08,595 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - d1715241-1ffa-4146-b219-94c9c0fc171f: addNew group-89087E71B146:[d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034] returns group-89087E71B146:java.util.concurrent.CompletableFuture@1ebacfc4[Not completed]
2024-04-06 10:34:08,596 [d1715241-1ffa-4146-b219-94c9c0fc171f-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-04-06 10:34:08,596 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - d1715241-1ffa-4146-b219-94c9c0fc171f: new RaftServerImpl for group-89087E71B146:[d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034] with ContainerStateMachine:uninitialized
2024-04-06 10:34:08,597 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:34:08,597 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-04-06 10:34:08,597 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-04-06 10:34:08,597 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-04-06 10:34:08,597 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:34:08,597 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-04-06 10:34:08,597 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:34:08,597 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146: ConfigurationManager, init=-1: peers:[d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-04-06 10:34:08,597 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-04-06 10:34:08,597 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-04-06 10:34:08,597 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-04-06 10:34:08,597 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-04-06 10:34:08,598 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-04-06 10:34:08,598 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-04-06 10:34:08,600 [IPC Server handler 10 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) as the reported value (IN_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-04-06 10:34:08,601 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:34:08,601 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:34:08,601 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-04-06 10:34:08,601 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-04-06 10:34:08,601 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-04-06 10:34:08,601 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-04-06 10:34:08,601 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-04-06 10:34:08,601 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-04-06 10:34:08,601 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis] (custom)
2024-04-06 10:34:08,601 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/62748d4a-78e9-4857-a2b6-89087e71b146 does not exist. Creating ...
2024-04-06 10:34:08,603 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/62748d4a-78e9-4857-a2b6-89087e71b146/in_use.lock acquired by nodename 82778@fv-az526-218
2024-04-06 10:34:08,604 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/62748d4a-78e9-4857-a2b6-89087e71b146 has been successfully formatted.
2024-04-06 10:34:08,605 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/62748d4a-78e9-4857-a2b6-89087e71b146/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/62748d4a-78e9-4857-a2b6-89087e71b146/current/raft-meta.conf
2024-04-06 10:34:08,605 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-89087E71B146: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-04-06 10:34:08,605 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-04-06 10:34:08,605 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-04-06 10:34:08,605 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:34:08,605 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-04-06 10:34:08,606 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-04-06 10:34:08,606 [IPC Server handler 21 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2024-04-06 10:34:08,606 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 6 millisec, cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 1}
2024-04-06 10:34:08,606 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=62748d4a-78e9-4857-a2b6-89087e71b146
2024-04-06 10:34:08,606 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=62748d4a-78e9-4857-a2b6-89087e71b146. Trying to get from SCM.
2024-04-06 10:34:08,607 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 7 millisec, cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 1}
2024-04-06 10:34:08,608 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:34:08,609 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(86)) - Adding new pipeline Pipeline[ Id: 62748d4a-78e9-4857-a2b6-89087e71b146, Nodes: d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:d1715241-1ffa-4146-b219-94c9c0fc171f, CreationTimestamp2024-04-06T10:34:06.625Z[Etc/UTC]] to Recon pipeline metadata.
2024-04-06 10:34:08,609 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-04-06 10:34:08,609 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-04-06 10:34:08,609 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:34:08,609 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-cacheEviction-AwaitToRun,5,main] started
2024-04-06 10:34:08,609 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/62748d4a-78e9-4857-a2b6-89087e71b146
2024-04-06 10:34:08,609 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-04-06 10:34:08,610 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-04-06 10:34:08,610 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:34:08,610 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-04-06 10:34:08,610 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-04-06 10:34:08,610 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-04-06 10:34:08,610 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-04-06 10:34:08,610 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-04-06 10:34:08,611 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-04-06 10:34:08,612 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:34:08,612 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-04-06 10:34:08,612 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-04-06 10:34:08,612 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-04-06 10:34:08,613 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-04-06 10:34:08,613 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-04-06 10:34:08,613 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146: start as a follower, conf=-1: peers:[d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034]|listeners:[], old=null
2024-04-06 10:34:08,613 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-04-06 10:34:08,613 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d1715241-1ffa-4146-b219-94c9c0fc171f: start d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-FollowerState
2024-04-06 10:34:08,614 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-89087E71B146,id=d1715241-1ffa-4146-b219-94c9c0fc171f
2024-04-06 10:34:08,614 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-04-06 10:34:08,614 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-04-06 10:34:08,614 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-04-06 10:34:08,614 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-04-06 10:34:08,614 [d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-04-06 10:34:08,615 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:34:08,615 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:34:08,617 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=62748d4a-78e9-4857-a2b6-89087e71b146
2024-04-06 10:34:08,617 [d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=62748d4a-78e9-4857-a2b6-89087e71b146.
2024-04-06 10:34:08,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@ace0092f. There are 2 pipelines
2024-04-06 10:34:08,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-04-06 10:34:08,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:34:08,674 [IPC Server handler 15 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (DECOMMISSIONING, 0)
2024-04-06 10:34:09,017 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:09,017 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:09,017 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:09,019 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:09,019 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:09,151 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:09,153 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:09,153 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:09,153 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:09,153 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:09,153 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:09,153 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:09,153 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:09,153 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:09,597 [IPC Server handler 13 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) as the reported value (IN_MAINTENANCE, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-04-06 10:34:09,597 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - cc1e4d3c-2283-4c28-b737-db868cb45369: addNew group-A7988BF88C1C:[cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025] returns group-A7988BF88C1C:java.util.concurrent.CompletableFuture@501123d3[Not completed]
2024-04-06 10:34:09,599 [cc1e4d3c-2283-4c28-b737-db868cb45369-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-04-06 10:34:09,599 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - cc1e4d3c-2283-4c28-b737-db868cb45369: new RaftServerImpl for group-A7988BF88C1C:[cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025] with ContainerStateMachine:uninitialized
2024-04-06 10:34:09,599 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:34:09,599 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-04-06 10:34:09,599 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-04-06 10:34:09,599 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-04-06 10:34:09,599 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:34:09,599 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-04-06 10:34:09,599 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:34:09,599 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C: ConfigurationManager, init=-1: peers:[cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-04-06 10:34:09,600 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-04-06 10:34:09,600 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-04-06 10:34:09,600 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-04-06 10:34:09,600 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-04-06 10:34:09,600 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-04-06 10:34:09,600 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-04-06 10:34:09,603 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:34:09,603 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:34:09,603 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-04-06 10:34:09,603 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-04-06 10:34:09,603 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-04-06 10:34:09,603 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-04-06 10:34:09,604 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-04-06 10:34:09,604 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-04-06 10:34:09,604 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis] (custom)
2024-04-06 10:34:09,604 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/b495966f-4ec9-40fc-9038-a7988bf88c1c does not exist. Creating ...
2024-04-06 10:34:09,607 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/b495966f-4ec9-40fc-9038-a7988bf88c1c/in_use.lock acquired by nodename 82778@fv-az526-218
2024-04-06 10:34:09,608 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/b495966f-4ec9-40fc-9038-a7988bf88c1c has been successfully formatted.
2024-04-06 10:34:09,609 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/b495966f-4ec9-40fc-9038-a7988bf88c1c/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/b495966f-4ec9-40fc-9038-a7988bf88c1c/current/raft-meta.conf
2024-04-06 10:34:09,609 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-A7988BF88C1C: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-04-06 10:34:09,609 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-04-06 10:34:09,609 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-04-06 10:34:09,609 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:34:09,609 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-04-06 10:34:09,610 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-04-06 10:34:09,610 [IPC Server handler 22 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2024-04-06 10:34:09,610 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=b495966f-4ec9-40fc-9038-a7988bf88c1c. Trying to get from SCM.
2024-04-06 10:34:09,611 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=b495966f-4ec9-40fc-9038-a7988bf88c1c
2024-04-06 10:34:09,611 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(86)) - Adding new pipeline Pipeline[ Id: b495966f-4ec9-40fc-9038-a7988bf88c1c, Nodes: cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:cc1e4d3c-2283-4c28-b737-db868cb45369, CreationTimestamp2024-04-06T10:34:06.624Z[Etc/UTC]] to Recon pipeline metadata.
2024-04-06 10:34:09,611 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:34:09,612 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-04-06 10:34:09,612 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-04-06 10:34:09,612 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:34:09,612 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-cacheEviction-AwaitToRun,5,main] started
2024-04-06 10:34:09,612 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/b495966f-4ec9-40fc-9038-a7988bf88c1c
2024-04-06 10:34:09,612 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-04-06 10:34:09,612 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-04-06 10:34:09,613 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:34:09,613 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-04-06 10:34:09,613 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-04-06 10:34:09,613 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-04-06 10:34:09,613 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-04-06 10:34:09,613 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-04-06 10:34:09,613 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-04-06 10:34:09,615 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:34:09,615 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-04-06 10:34:09,615 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-04-06 10:34:09,615 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-04-06 10:34:09,616 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-04-06 10:34:09,616 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-04-06 10:34:09,616 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C: start as a follower, conf=-1: peers:[cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:34:09,616 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-04-06 10:34:09,616 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - cc1e4d3c-2283-4c28-b737-db868cb45369: start cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-FollowerState
2024-04-06 10:34:09,616 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A7988BF88C1C,id=cc1e4d3c-2283-4c28-b737-db868cb45369
2024-04-06 10:34:09,616 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-04-06 10:34:09,616 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-04-06 10:34:09,617 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-04-06 10:34:09,617 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-04-06 10:34:09,617 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-04-06 10:34:09,617 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:34:09,617 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:34:09,618 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=b495966f-4ec9-40fc-9038-a7988bf88c1c
2024-04-06 10:34:09,618 [cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS ONE PipelineID=b495966f-4ec9-40fc-9038-a7988bf88c1c.
2024-04-06 10:34:09,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@ace0092f. There are 2 pipelines
2024-04-06 10:34:09,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-04-06 10:34:09,625 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:09,673 [IPC Server handler 22 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (DECOMMISSIONING, 0)
2024-04-06 10:34:09,674 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to DECOMMISSIONING, scaling executor pool size to 20
2024-04-06 10:34:10,021 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:10,021 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:10,021 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:10,023 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:10,023 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:10,154 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-04-06 10:34:10,157 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 3 milliseconds for processing 1 containers.
2024-04-06 10:34:10,158 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:10,158 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	TOTAL_KEYS -> 1 , CONTAINER_COUNT -> 1 , TOTAL_USED_BYTES -> 7 , 
2024-04-06 10:34:10,158 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:10,158 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:10,158 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:10,158 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:10,158 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:10,612 [OverReplicatedProcessor] INFO  replication.RatisOverReplicationHandler (RatisOverReplicationHandler.java:processAndSendCommands(115)) - Container #1 is over replicated. Actual replica count is 4, with 0 pending delete(s). Expected replica count is 3.
2024-04-06 10:34:10,613 [OverReplicatedProcessor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [deleteContainerCommand: containerID: 1, replicaIndex: 0, force: true] for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-04-06T10:33:53.584Z, pipelineID=PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7, owner=omServiceIdDefault} to ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) with datanode deadline 1712400220613 and scm deadline 1712400250613
2024-04-06 10:34:10,613 [OverReplicatedProcessor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(138)) - Processed 1 containers with health state counts {OVER_REPLICATED=1}, failed processing 0, deferred due to load 0
2024-04-06 10:34:10,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@ace0092f. There are 2 pipelines
2024-04-06 10:34:10,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-04-06 10:34:10,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:34:10,673 [IPC Server handler 24 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) as the reported value (DECOMMISSIONING, 0) does not match the value stored in SCM (IN_SERVICE, 0)
2024-04-06 10:34:11,025 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:11,025 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:11,025 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:11,026 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:11,027 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:11,159 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:processExistingDBRecords(299)) - DELETED existing unhealthy container record...for Container: 1
2024-04-06 10:34:11,160 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 3 milliseconds to process 1 existing database records.
2024-04-06 10:34:11,162 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:34:11,162 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:11,162 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:11,162 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:11,162 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:11,162 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:11,162 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:11,162 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:11,612 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 1}
2024-04-06 10:34:11,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@ace0092f. There are 2 pipelines
2024-04-06 10:34:11,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-04-06 10:34:11,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:11,674 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 1}
2024-04-06 10:34:11,675 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 1}
2024-04-06 10:34:11,675 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-DeleteContainerThread-0] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:markContainerForDelete(424)) - Moving container /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/current/containerDir0/1 to state DELETED from state:CLOSED
2024-04-06 10:34:12,028 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:12,029 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:12,029 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:12,030 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:12,030 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:12,163 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:12,165 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:12,165 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:12,165 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:12,165 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:12,165 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:12,165 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:12,165 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:12,165 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:12,620 [UnderReplicatedProcessor] INFO  replication.RatisUnderReplicationHandler (RatisUnderReplicationHandler.java:verifyUnderReplication(314)) - The container #1 state changed and it's not under replicated any more.
2024-04-06 10:34:12,620 [UnderReplicatedProcessor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(138)) - Processed 1 containers with health state counts {UNDER_REPLICATED=1}, failed processing 0, deferred due to load 0
2024-04-06 10:34:12,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(398)) - Waiting for pipelines to close for org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@ace0092f. There are 2 pipelines
2024-04-06 10:34:12,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(240)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2024-04-06 10:34:12,626 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:13,032 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:13,033 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:13,033 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:13,034 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:13,034 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:13,166 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-04-06 10:34:13,168 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:13,169 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:13,169 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:13,169 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:13,169 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:13,169 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:13,169 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:13,169 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:13,425 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 since it stays at CLOSED stage.
2024-04-06 10:34:13,425 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 close command to datanode a40aef6e-dfc7-4141-9a41-17d72bf4eeff
2024-04-06 10:34:13,426 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 close command to datanode 59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:34:13,426 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 close command to datanode ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2
2024-04-06 10:34:13,426 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246, Nodes: a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:59c3495a-7636-40f9-8dfa-c28be8e98abd, CreationTimestamp2024-04-06T10:33:57.625Z[Etc/UTC]] removed.
2024-04-06 10:34:13,426 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:scrubPipelines(610)) - Scrubbing pipeline: id: PipelineID=15039d4b-d7f6-4769-9a85-becc45517e23 since it stays at CLOSED stage.
2024-04-06 10:34:13,426 [BackgroundPipelineScrubber] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=15039d4b-d7f6-4769-9a85-becc45517e23 close command to datanode ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2
2024-04-06 10:34:13,427 [BackgroundPipelineScrubber] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 15039d4b-d7f6-4769-9a85-becc45517e23, Nodes: ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2, CreationTimestamp2024-04-06T10:33:38.868Z[Etc/UTC]] removed.
2024-04-06 10:34:13,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(472)) - org.apache.hadoop.hdds.scm.node.DatanodeAdminMonitorImpl$TrackedNode@ace0092f has 0 sufficientlyReplicated, 0 deleting, 0 underReplicated and 0 unclosed containers
2024-04-06 10:34:13,622 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:completeDecommission(522)) - Datanode ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) has completed the admin workflow. The operational state has been set to DECOMMISSIONED
2024-04-06 10:34:13,622 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) moved to HEALTHY state.
2024-04-06 10:34:13,622 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(280)) - trigger a one-shot run on RatisPipelineUtilsThread.
2024-04-06 10:34:13,623 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 to datanode:59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:34:13,623 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 to datanode:a40aef6e-dfc7-4141-9a41-17d72bf4eeff
2024-04-06 10:34:13,623 [RatisPipelineUtilsThread-0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(205)) - Sending CreatePipelineCommand for pipeline:PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 to datanode:cc1e4d3c-2283-4c28-b737-db868cb45369
2024-04-06 10:34:13,624 [RatisPipelineUtilsThread-0] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:createPipelines(236)) - Created new pipeline Pipeline[ Id: 25178013-1aaf-49ea-9109-82a21d15cbf7, Nodes: 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-04-06T10:34:13.623Z[Etc/UTC]]
2024-04-06 10:34:13,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:13,679 [IPC Server handler 23 on default port 15002] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) as the reported value (DECOMMISSIONING, 0) does not match the value stored in SCM (DECOMMISSIONED, 0)
2024-04-06 10:34:13,765 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:13,804 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5190853868ns, electionTimeout:5189ms
2024-04-06 10:34:13,804 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - d1715241-1ffa-4146-b219-94c9c0fc171f: shutdown d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-FollowerState
2024-04-06 10:34:13,804 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-04-06 10:34:13,805 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-04-06 10:34:13,806 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d1715241-1ffa-4146-b219-94c9c0fc171f: start d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10
2024-04-06 10:34:13,808 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034]|listeners:[], old=null
2024-04-06 10:34:13,808 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10 PRE_VOTE round 0: result PASSED (term=0)
2024-04-06 10:34:13,810 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10 ELECTION round 0: submit vote requests at term 1 for -1: peers:[d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034]|listeners:[], old=null
2024-04-06 10:34:13,810 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10 ELECTION round 0: result PASSED (term=1)
2024-04-06 10:34:13,810 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - d1715241-1ffa-4146-b219-94c9c0fc171f: shutdown d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10
2024-04-06 10:34:13,810 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-04-06 10:34:13,810 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-04-06 10:34:13,810 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-04-06 10:34:13,810 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-04-06 10:34:13,811 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-04-06 10:34:13,811 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-04-06 10:34:13,811 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-04-06 10:34:13,811 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-04-06 10:34:13,811 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-04-06 10:34:13,811 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:34:13,811 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-04-06 10:34:13,811 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-04-06 10:34:13,812 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - d1715241-1ffa-4146-b219-94c9c0fc171f: start d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderStateImpl
2024-04-06 10:34:13,812 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146: set firstElectionSinceStartup to false for becomeLeader
2024-04-06 10:34:13,812 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-89087E71B146 with new leaderId: d1715241-1ffa-4146-b219-94c9c0fc171f
2024-04-06 10:34:13,812 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146: change Leader from null to d1715241-1ffa-4146-b219-94c9c0fc171f at term 1 for becomeLeader, leader elected after 5214ms
2024-04-06 10:34:13,812 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-SegmentedRaftLogWorker: Starting segment from index:0
2024-04-06 10:34:13,812 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-04-06 10:34:13,815 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderElection10] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146: set configuration 0: peers:[d1715241-1ffa-4146-b219-94c9c0fc171f|10.1.0.10:15034]|listeners:[], old=null
2024-04-06 10:34:13,820 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/62748d4a-78e9-4857-a2b6-89087e71b146/current/log_inprogress_0
2024-04-06 10:34:13,822 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-04-06 10:34:14,036 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:14,036 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:14,036 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:14,038 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:14,038 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:14,115 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 is not found
2024-04-06 10:34:14,170 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:14,172 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:14,172 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:14,172 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:14,172 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:14,172 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:14,172 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:14,172 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:14,172 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:14,627 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:14,678 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: remove  FOLLOWER ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246:t1, leader=59c3495a-7636-40f9-8dfa-c28be8e98abd, voted=59c3495a-7636-40f9-8dfa-c28be8e98abd, raftlog=Memoized:ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-SegmentedRaftLog:OPENED:c0, conf=0: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null RUNNING
2024-04-06 10:34:14,678 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246: shutdown
2024-04-06 10:34:14,678 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-87AD1B61A246,id=ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2
2024-04-06 10:34:14,678 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: shutdown ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-FollowerState
2024-04-06 10:34:14,678 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-StateMachineUpdater: set stopIndex = 0
2024-04-06 10:34:14,678 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-87AD1B61A246: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246/sm/snapshot.1_0
2024-04-06 10:34:14,678 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-FollowerState was interrupted
2024-04-06 10:34:14,680 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-87AD1B61A246: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246/sm/snapshot.1_0 took: 1 ms
2024-04-06 10:34:14,681 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-StateMachineUpdater: Took a snapshot at index 0
2024-04-06 10:34:14,681 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-04-06 10:34:14,681 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-CommandProcessorThread] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to DECOMMISSIONED, scaling executor pool size to 20
2024-04-06 10:34:14,681 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246: applyIndex: 0
2024-04-06 10:34:14,681 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-04-06 10:34:14,682 [IPC Server handler 25 on default port 15009] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(582)) - Scheduling a command to update the operationalState persisted on ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) as the reported value (DECOMMISSIONED, 0) does not match the value stored in SCM (DECOMMISSIONING, 0)
2024-04-06 10:34:14,684 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 is not found
2024-04-06 10:34:14,684 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=15039d4b-d7f6-4769-9a85-becc45517e23 is not found
2024-04-06 10:34:14,729 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5112630125ns, electionTimeout:5111ms
2024-04-06 10:34:14,729 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - cc1e4d3c-2283-4c28-b737-db868cb45369: shutdown cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-FollowerState
2024-04-06 10:34:14,729 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-04-06 10:34:14,730 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-04-06 10:34:14,730 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - cc1e4d3c-2283-4c28-b737-db868cb45369: start cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11
2024-04-06 10:34:14,731 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:34:14,732 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11 PRE_VOTE round 0: result PASSED (term=0)
2024-04-06 10:34:14,733 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11 ELECTION round 0: submit vote requests at term 1 for -1: peers:[cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:34:14,733 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11 ELECTION round 0: result PASSED (term=1)
2024-04-06 10:34:14,733 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - cc1e4d3c-2283-4c28-b737-db868cb45369: shutdown cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11
2024-04-06 10:34:14,733 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-04-06 10:34:14,733 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-04-06 10:34:14,734 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-04-06 10:34:14,734 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-04-06 10:34:14,734 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-04-06 10:34:14,734 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-04-06 10:34:14,734 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-04-06 10:34:14,734 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-04-06 10:34:14,734 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-04-06 10:34:14,735 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:34:14,735 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-04-06 10:34:14,735 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-04-06 10:34:14,735 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - cc1e4d3c-2283-4c28-b737-db868cb45369: start cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderStateImpl
2024-04-06 10:34:14,735 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C: set firstElectionSinceStartup to false for becomeLeader
2024-04-06 10:34:14,735 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-A7988BF88C1C with new leaderId: cc1e4d3c-2283-4c28-b737-db868cb45369
2024-04-06 10:34:14,735 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C: change Leader from null to cc1e4d3c-2283-4c28-b737-db868cb45369 at term 1 for becomeLeader, leader elected after 5135ms
2024-04-06 10:34:14,735 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-SegmentedRaftLogWorker: Starting segment from index:0
2024-04-06 10:34:14,736 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-04-06 10:34:14,739 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderElection11] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C: set configuration 0: peers:[cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:34:14,744 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/b495966f-4ec9-40fc-9038-a7988bf88c1c/current/log_inprogress_0
2024-04-06 10:34:14,745 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-04-06 10:34:14,765 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:15,040 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:15,040 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:15,040 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:15,041 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:15,041 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:15,116 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 is not found
2024-04-06 10:34:15,173 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:15,175 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:15,175 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:15,175 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:15,175 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:15,175 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:15,175 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:15,175 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:15,175 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:15,254 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: remove    LEADER 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246:t1, leader=59c3495a-7636-40f9-8dfa-c28be8e98abd, voted=59c3495a-7636-40f9-8dfa-c28be8e98abd, raftlog=Memoized:59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-SegmentedRaftLog:OPENED:c0, conf=0: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null RUNNING
2024-04-06 10:34:15,254 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246: shutdown
2024-04-06 10:34:15,254 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-87AD1B61A246,id=59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:34:15,254 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: shutdown 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-LeaderStateImpl
2024-04-06 10:34:15,254 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246->ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246->ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-04-06 10:34:15,255 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: Completed APPEND_ENTRIES, lastRequest: null
2024-04-06 10:34:15,255 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 is not found
2024-04-06 10:34:15,255 [grpc-default-executor-1] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "59c3495a-7636-40f9-8dfa-c28be8e98abd"
  replyId: "ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2"
  raftGroupId {
    id: "l\257\236]\311\304O>\216\220\207\255\033a\242F"
  }
  callId: 6
  success: true
}
term: 1
nextIndex: 1
matchIndex: 18446744073709551615
isHearbeat: true

2024-04-06 10:34:15,254 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246->a40aef6e-dfc7-4141-9a41-17d72bf4eeff-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246->a40aef6e-dfc7-4141-9a41-17d72bf4eeff-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-04-06 10:34:15,259 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: Completed APPEND_ENTRIES, lastRequest: 59c3495a-7636-40f9-8dfa-c28be8e98abd->ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "59c3495a-7636-40f9-8dfa-c28be8e98abd"
address: "10.1.0.10:15016"
priority: 1
dataStreamAddress: "10.1.0.10:15017"
clientAddress: "10.1.0.10:15014"
adminAddress: "10.1.0.10:15015"
startupRole: FOLLOWER
,id: "a40aef6e-dfc7-4141-9a41-17d72bf4eeff"
address: "10.1.0.10:15043"
dataStreamAddress: "10.1.0.10:15044"
clientAddress: "10.1.0.10:15041"
adminAddress: "10.1.0.10:15042"
startupRole: FOLLOWER
,id: "ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2"
address: "10.1.0.10:15052"
dataStreamAddress: "10.1.0.10:15053"
clientAddress: "10.1.0.10:15050"
adminAddress: "10.1.0.10:15051"
startupRole: FOLLOWER
, old:)
2024-04-06 10:34:15,259 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: Completed APPEND_ENTRIES, lastReply: null
2024-04-06 10:34:15,259 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: Completed APPEND_ENTRIES, lastRequest: 59c3495a-7636-40f9-8dfa-c28be8e98abd->a40aef6e-dfc7-4141-9a41-17d72bf4eeff#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "59c3495a-7636-40f9-8dfa-c28be8e98abd"
address: "10.1.0.10:15016"
priority: 1
dataStreamAddress: "10.1.0.10:15017"
clientAddress: "10.1.0.10:15014"
adminAddress: "10.1.0.10:15015"
startupRole: FOLLOWER
,id: "a40aef6e-dfc7-4141-9a41-17d72bf4eeff"
address: "10.1.0.10:15043"
dataStreamAddress: "10.1.0.10:15044"
clientAddress: "10.1.0.10:15041"
adminAddress: "10.1.0.10:15042"
startupRole: FOLLOWER
,id: "ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2"
address: "10.1.0.10:15052"
dataStreamAddress: "10.1.0.10:15053"
clientAddress: "10.1.0.10:15050"
adminAddress: "10.1.0.10:15051"
startupRole: FOLLOWER
, old:)
2024-04-06 10:34:15,259 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: Completed APPEND_ENTRIES, lastReply: null
2024-04-06 10:34:15,259 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: Completed APPEND_ENTRIES, lastRequest: null
2024-04-06 10:34:15,260 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "59c3495a-7636-40f9-8dfa-c28be8e98abd"
  replyId: "a40aef6e-dfc7-4141-9a41-17d72bf4eeff"
  raftGroupId {
    id: "l\257\236]\311\304O>\216\220\207\255\033a\242F"
  }
  callId: 7
  success: true
}
term: 1
nextIndex: 1
matchIndex: 18446744073709551615
isHearbeat: true

2024-04-06 10:34:15,260 [grpc-default-executor-6] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246->a40aef6e-dfc7-4141-9a41-17d72bf4eeff-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-04-06 10:34:15,254 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-PendingRequests: sendNotLeaderResponses
2024-04-06 10:34:15,259 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246->ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-04-06 10:34:15,261 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-87AD1B61A246: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246/sm/snapshot.1_0
2024-04-06 10:34:15,261 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-StateMachineUpdater: set stopIndex = 0
2024-04-06 10:34:15,262 [grpc-default-executor-4] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246->ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-04-06 10:34:15,262 [grpc-default-executor-6] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246->a40aef6e-dfc7-4141-9a41-17d72bf4eeff-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-04-06 10:34:15,265 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-87AD1B61A246: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246/sm/snapshot.1_0 took: 4 ms
2024-04-06 10:34:15,265 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-StateMachineUpdater: Took a snapshot at index 0
2024-04-06 10:34:15,265 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-04-06 10:34:15,265 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246: applyIndex: 0
2024-04-06 10:34:15,265 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-04-06 10:34:15,267 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246-SegmentedRaftLogWorker close()
2024-04-06 10:34:15,269 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-87AD1B61A246: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246
2024-04-06 10:34:15,269 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246
org.apache.ratis.protocol.exceptions.GroupMismatchException: 59c3495a-7636-40f9-8dfa-c28be8e98abd: group-87AD1B61A246 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-04-06 10:34:15,269 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: addNew group-82A21D15CBF7:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025] returns group-82A21D15CBF7:java.util.concurrent.CompletableFuture@4efd2c3d[Not completed]
2024-04-06 10:34:15,270 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: new RaftServerImpl for group-82A21D15CBF7:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025] with ContainerStateMachine:uninitialized
2024-04-06 10:34:15,270 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:34:15,270 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-04-06 10:34:15,270 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-04-06 10:34:15,270 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-04-06 10:34:15,270 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:34:15,270 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-04-06 10:34:15,270 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:34:15,271 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7: ConfigurationManager, init=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-04-06 10:34:15,271 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-04-06 10:34:15,271 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-04-06 10:34:15,271 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-04-06 10:34:15,271 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-04-06 10:34:15,271 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-04-06 10:34:15,271 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-04-06 10:34:15,275 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:34:15,276 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:34:15,276 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-04-06 10:34:15,276 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-04-06 10:34:15,276 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-04-06 10:34:15,276 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-04-06 10:34:15,276 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-04-06 10:34:15,276 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-04-06 10:34:15,276 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis] (custom)
2024-04-06 10:34:15,277 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7 does not exist. Creating ...
2024-04-06 10:34:15,278 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7/in_use.lock acquired by nodename 82778@fv-az526-218
2024-04-06 10:34:15,279 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7 has been successfully formatted.
2024-04-06 10:34:15,279 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7/current/raft-meta.conf
2024-04-06 10:34:15,279 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-82A21D15CBF7: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-04-06 10:34:15,279 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-04-06 10:34:15,280 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-04-06 10:34:15,280 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:34:15,280 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-04-06 10:34:15,280 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-04-06 10:34:15,281 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7. Trying to get from SCM.
2024-04-06 10:34:15,283 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:34:15,283 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-04-06 10:34:15,283 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-04-06 10:34:15,283 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:34:15,283 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-cacheEviction-AwaitToRun,5,main] started
2024-04-06 10:34:15,283 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7
2024-04-06 10:34:15,283 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-04-06 10:34:15,284 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-04-06 10:34:15,284 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:34:15,284 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-04-06 10:34:15,284 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-04-06 10:34:15,284 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-04-06 10:34:15,284 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-04-06 10:34:15,284 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-04-06 10:34:15,285 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-04-06 10:34:15,286 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:34:15,286 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-04-06 10:34:15,286 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-04-06 10:34:15,286 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-04-06 10:34:15,287 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-04-06 10:34:15,287 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-04-06 10:34:15,288 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7: start as a follower, conf=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:34:15,288 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-04-06 10:34:15,288 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: start 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-FollowerState
2024-04-06 10:34:15,298 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:34:15,299 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:34:15,299 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(86)) - Adding new pipeline Pipeline[ Id: 25178013-1aaf-49ea-9109-82a21d15cbf7, Nodes: 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2024-04-06T10:34:13.623Z[Etc/UTC]] to Recon pipeline metadata.
2024-04-06 10:34:15,300 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 reported by 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:15,300 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-82A21D15CBF7,id=59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:34:15,300 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-04-06 10:34:15,301 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-04-06 10:34:15,301 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-04-06 10:34:15,301 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-04-06 10:34:15,301 [59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-04-06 10:34:15,306 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(864)) - Created group PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7
2024-04-06 10:34:15,314 [grpc-default-executor-6] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: addNew group-82A21D15CBF7:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025] returns group-82A21D15CBF7:java.util.concurrent.CompletableFuture@e700a29[Not completed]
2024-04-06 10:34:15,315 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: new RaftServerImpl for group-82A21D15CBF7:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025] with ContainerStateMachine:uninitialized
2024-04-06 10:34:15,315 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:34:15,315 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-04-06 10:34:15,315 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-04-06 10:34:15,315 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-04-06 10:34:15,315 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:34:15,315 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-04-06 10:34:15,315 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:34:15,315 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7: ConfigurationManager, init=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-04-06 10:34:15,315 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-04-06 10:34:15,316 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-04-06 10:34:15,316 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-04-06 10:34:15,316 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-04-06 10:34:15,316 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-04-06 10:34:15,316 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-04-06 10:34:15,318 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:34:15,318 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:34:15,318 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-04-06 10:34:15,318 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-04-06 10:34:15,318 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-04-06 10:34:15,321 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-04-06 10:34:15,321 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-04-06 10:34:15,321 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-04-06 10:34:15,321 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis] (custom)
2024-04-06 10:34:15,321 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7 does not exist. Creating ...
2024-04-06 10:34:15,322 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7/in_use.lock acquired by nodename 82778@fv-az526-218
2024-04-06 10:34:15,323 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7 has been successfully formatted.
2024-04-06 10:34:15,324 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7/current/raft-meta.conf
2024-04-06 10:34:15,324 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-82A21D15CBF7: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-04-06 10:34:15,324 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-04-06 10:34:15,324 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-04-06 10:34:15,324 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:34:15,324 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-04-06 10:34:15,324 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-04-06 10:34:15,325 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 reported by a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:15,325 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 is not found
2024-04-06 10:34:15,328 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:34:15,328 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246-SegmentedRaftLogWorker close()
2024-04-06 10:34:15,330 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-04-06 10:34:15,330 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-04-06 10:34:15,330 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:34:15,330 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-87AD1B61A246: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246
2024-04-06 10:34:15,330 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246
org.apache.ratis.protocol.exceptions.GroupMismatchException: ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: group-87AD1B61A246 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-04-06 10:34:15,330 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: remove    LEADER ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23:t1, leader=ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2, voted=ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2, raftlog=Memoized:ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-SegmentedRaftLog:OPENED:c0, conf=0: peers:[ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null RUNNING
2024-04-06 10:34:15,331 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23: shutdown
2024-04-06 10:34:15,331 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-BECC45517E23,id=ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2
2024-04-06 10:34:15,331 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: shutdown ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-LeaderStateImpl
2024-04-06 10:34:15,331 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-PendingRequests: sendNotLeaderResponses
2024-04-06 10:34:15,331 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-StateMachineUpdater: set stopIndex = 0
2024-04-06 10:34:15,331 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-BECC45517E23: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis/15039d4b-d7f6-4769-9a85-becc45517e23/sm/snapshot.1_0
2024-04-06 10:34:15,332 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-BECC45517E23: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis/15039d4b-d7f6-4769-9a85-becc45517e23/sm/snapshot.1_0 took: 1 ms
2024-04-06 10:34:15,333 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-StateMachineUpdater: Took a snapshot at index 0
2024-04-06 10:34:15,333 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-04-06 10:34:15,333 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23: applyIndex: 0
2024-04-06 10:34:15,337 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-cacheEviction-AwaitToRun,5,main] started
2024-04-06 10:34:15,338 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-04-06 10:34:15,338 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7
2024-04-06 10:34:15,338 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-04-06 10:34:15,338 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-04-06 10:34:15,338 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:34:15,338 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-04-06 10:34:15,338 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-04-06 10:34:15,338 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-04-06 10:34:15,338 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-04-06 10:34:15,339 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-04-06 10:34:15,339 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-04-06 10:34:15,340 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:34:15,340 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-04-06 10:34:15,340 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-04-06 10:34:15,340 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-04-06 10:34:15,340 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-04-06 10:34:15,340 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-04-06 10:34:15,341 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7: start as a follower, conf=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:34:15,341 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-04-06 10:34:15,341 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: start a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-FollowerState
2024-04-06 10:34:15,341 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-82A21D15CBF7,id=a40aef6e-dfc7-4141-9a41-17d72bf4eeff
2024-04-06 10:34:15,341 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-04-06 10:34:15,341 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-04-06 10:34:15,341 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-04-06 10:34:15,341 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-04-06 10:34:15,341 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-04-06 10:34:15,342 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:34:15,342 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:34:15,354 [grpc-default-executor-6] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - cc1e4d3c-2283-4c28-b737-db868cb45369: addNew group-82A21D15CBF7:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025] returns group-82A21D15CBF7:java.util.concurrent.CompletableFuture@185ecdca[Not completed]
2024-04-06 10:34:15,355 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - cc1e4d3c-2283-4c28-b737-db868cb45369: new RaftServerImpl for group-82A21D15CBF7:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025] with ContainerStateMachine:uninitialized
2024-04-06 10:34:15,355 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:34:15,355 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-04-06 10:34:15,355 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-04-06 10:34:15,355 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-04-06 10:34:15,356 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:34:15,356 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-04-06 10:34:15,356 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:34:15,356 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7: ConfigurationManager, init=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-04-06 10:34:15,356 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-04-06 10:34:15,356 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-04-06 10:34:15,356 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-04-06 10:34:15,356 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-04-06 10:34:15,356 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-04-06 10:34:15,356 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-04-06 10:34:15,359 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:34:15,359 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:34:15,359 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-04-06 10:34:15,359 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-04-06 10:34:15,359 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-04-06 10:34:15,359 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-04-06 10:34:15,359 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2024-04-06 10:34:15,359 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2024-04-06 10:34:15,359 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis] (custom)
2024-04-06 10:34:15,360 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(138)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7 does not exist. Creating ...
2024-04-06 10:34:15,361 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(228)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7/in_use.lock acquired by nodename 82778@fv-az526-218
2024-04-06 10:34:15,362 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  storage.RaftStorage (RaftStorageImpl.java:format(99)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7 has been successfully formatted.
2024-04-06 10:34:15,362 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] WARN  util.FileUtils (LogUtils.java:supplyAndLog(63)) - Failed to Files.newInputStream /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7/current/raft-meta.conf with options []: java.nio.file.NoSuchFileException: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7/current/raft-meta.conf
2024-04-06 10:34:15,363 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(287)) - group-82A21D15CBF7: The snapshot info is null. Setting the last applied index to:(t:0, i:~)
2024-04-06 10:34:15,363 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2024-04-06 10:34:15,363 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2024-04-06 10:34:15,363 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:34:15,363 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2024-04-06 10:34:15,363 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2024-04-06 10:34:15,364 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 reported by cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:15,364 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:34:15,364 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2024-04-06 10:34:15,364 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2024-04-06 10:34:15,364 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:34:15,365 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  util.AwaitToRun (AwaitToRun.java:start(81)) - Thread[cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-cacheEviction-AwaitToRun,5,main] started
2024-04-06 10:34:15,365 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(182)) - new cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7
2024-04-06 10:34:15,365 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2024-04-06 10:34:15,365 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2024-04-06 10:34:15,365 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 67108864 (custom)
2024-04-06 10:34:15,365 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2024-04-06 10:34:15,366 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2024-04-06 10:34:15,366 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2024-04-06 10:34:15,366 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2024-04-06 10:34:15,366 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = 0 (custom)
2024-04-06 10:34:15,366 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 8388616 (custom)
2024-04-06 10:34:15,367 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:34:15,367 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2024-04-06 10:34:15,367 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2024-04-06 10:34:15,367 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2024-04-06 10:34:15,367 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2024-04-06 10:34:15,367 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(134)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2024-04-06 10:34:15,367 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:start(396)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7: start as a follower, conf=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:34:15,368 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7: changes role from      null to FOLLOWER at term 0 for startAsFollower
2024-04-06 10:34:15,368 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - cc1e4d3c-2283-4c28-b737-db868cb45369: start cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-FollowerState
2024-04-06 10:34:15,368 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-82A21D15CBF7,id=cc1e4d3c-2283-4c28-b737-db868cb45369
2024-04-06 10:34:15,368 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.trigger-when-stop.enabled = true (default)
2024-04-06 10:34:15,368 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2024-04-06 10:34:15,368 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2024-04-06 10:34:15,368 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2024-04-06 10:34:15,368 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2024-04-06 10:34:15,369 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:34:15,369 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:34:15,373 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:lambda$handle$2(124)) - Created Pipeline RATIS THREE PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7.
2024-04-06 10:34:15,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:15,766 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:16,043 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:16,043 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:16,043 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:16,045 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:16,045 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:16,080 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23-SegmentedRaftLogWorker close()
2024-04-06 10:34:16,082 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2@group-BECC45517E23: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/ratis/15039d4b-d7f6-4769-9a85-becc45517e23
2024-04-06 10:34:16,082 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=15039d4b-d7f6-4769-9a85-becc45517e23
org.apache.ratis.protocol.exceptions.GroupMismatchException: ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: group-BECC45517E23 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-04-06 10:34:16,114 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: remove  FOLLOWER a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246:t1, leader=59c3495a-7636-40f9-8dfa-c28be8e98abd, voted=59c3495a-7636-40f9-8dfa-c28be8e98abd, raftlog=Memoized:a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-SegmentedRaftLog:OPENED:c0, conf=0: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2|10.1.0.10:15052]|listeners:[], old=null RUNNING
2024-04-06 10:34:16,114 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246: shutdown
2024-04-06 10:34:16,114 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-87AD1B61A246,id=a40aef6e-dfc7-4141-9a41-17d72bf4eeff
2024-04-06 10:34:16,115 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: shutdown a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-FollowerState
2024-04-06 10:34:16,115 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-StateMachineUpdater: set stopIndex = 0
2024-04-06 10:34:16,115 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-87AD1B61A246: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246/sm/snapshot.1_0
2024-04-06 10:34:16,115 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-FollowerState was interrupted
2024-04-06 10:34:16,116 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-87AD1B61A246: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246/sm/snapshot.1_0 took: 1 ms
2024-04-06 10:34:16,116 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-StateMachineUpdater: Took a snapshot at index 0
2024-04-06 10:34:16,116 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-04-06 10:34:16,117 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246: applyIndex: 0
2024-04-06 10:34:16,117 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-04-06 10:34:16,176 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:16,178 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:16,178 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:16,178 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:16,178 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:16,178 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:16,178 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:16,178 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:16,179 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:16,329 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246-SegmentedRaftLogWorker close()
2024-04-06 10:34:16,330 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-87AD1B61A246: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246
2024-04-06 10:34:16,331 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246
org.apache.ratis.protocol.exceptions.GroupMismatchException: a40aef6e-dfc7-4141-9a41-17d72bf4eeff: group-87AD1B61A246 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-04-06 10:34:16,365 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 reported by cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:16,628 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:16,766 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:17,047 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:17,047 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:17,047 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:17,048 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:17,048 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:17,179 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-04-06 10:34:17,182 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:17,182 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:17,182 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:17,182 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:17,182 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:17,182 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:17,182 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:17,182 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:17,280 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 reported by 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:17,326 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 reported by a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:17,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:17,766 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:18,050 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:18,050 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:18,050 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:18,052 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:18,052 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:18,183 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:18,185 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:18,185 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:18,185 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:18,185 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:18,185 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:18,185 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:18,186 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:18,186 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:18,327 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 reported by a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:18,363 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 reported by cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:18,629 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:18,767 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:19,056 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:19,056 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:19,056 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:19,057 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:19,058 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:19,186 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:19,188 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:34:19,188 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:19,188 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:19,189 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:19,189 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:19,189 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:19,189 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:19,189 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:19,280 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 reported by 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:19,326 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 reported by a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:19,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:19,767 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:20,059 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:20,059 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:20,059 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:20,061 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:20,061 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:20,189 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:20,191 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:34:20,191 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:20,191 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:20,191 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:20,191 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:20,192 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:20,192 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:20,192 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:20,364 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 reported by cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:20,426 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5137988005ns, electionTimeout:5127ms
2024-04-06 10:34:20,426 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: shutdown 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-FollowerState
2024-04-06 10:34:20,426 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2024-04-06 10:34:20,426 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = true (default)
2024-04-06 10:34:20,426 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: start 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12
2024-04-06 10:34:20,430 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12 PRE_VOTE round 0: submit vote requests at term 0 for -1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:34:20,430 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:34:20,430 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:34:20,432 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7: receive requestVote(PRE_VOTE, 59c3495a-7636-40f9-8dfa-c28be8e98abd, group-82A21D15CBF7, 0, (t:0, i:0))
2024-04-06 10:34:20,432 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-FOLLOWER: accept PRE_VOTE from 59c3495a-7636-40f9-8dfa-c28be8e98abd: our priority 0 <= candidate's priority 1
2024-04-06 10:34:20,433 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7 replies to PRE_VOTE vote request: 59c3495a-7636-40f9-8dfa-c28be8e98abd<-a40aef6e-dfc7-4141-9a41-17d72bf4eeff#0:OK-t0. Peer's state: a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7:t0, leader=null, voted=, raftlog=Memoized:a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:34:20,434 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7: receive requestVote(PRE_VOTE, 59c3495a-7636-40f9-8dfa-c28be8e98abd, group-82A21D15CBF7, 0, (t:0, i:0))
2024-04-06 10:34:20,434 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12: PRE_VOTE PASSED received 1 response(s) and 0 exception(s):
2024-04-06 10:34:20,434 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-FOLLOWER: accept PRE_VOTE from 59c3495a-7636-40f9-8dfa-c28be8e98abd: our priority 0 <= candidate's priority 1
2024-04-06 10:34:20,435 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7 replies to PRE_VOTE vote request: 59c3495a-7636-40f9-8dfa-c28be8e98abd<-cc1e4d3c-2283-4c28-b737-db868cb45369#0:OK-t0. Peer's state: cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7:t0, leader=null, voted=, raftlog=Memoized:cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:34:20,435 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 59c3495a-7636-40f9-8dfa-c28be8e98abd<-a40aef6e-dfc7-4141-9a41-17d72bf4eeff#0:OK-t0
2024-04-06 10:34:20,435 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12 PRE_VOTE round 0: result PASSED
2024-04-06 10:34:20,436 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(321)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12 ELECTION round 0: submit vote requests at term 1 for -1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:34:20,437 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2024-04-06 10:34:20,437 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2024-04-06 10:34:20,439 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7: receive requestVote(ELECTION, 59c3495a-7636-40f9-8dfa-c28be8e98abd, group-82A21D15CBF7, 1, (t:0, i:0))
2024-04-06 10:34:20,439 [grpc-default-executor-6] INFO  impl.VoteContext (VoteContext.java:log(49)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-FOLLOWER: accept ELECTION from 59c3495a-7636-40f9-8dfa-c28be8e98abd: our priority 0 <= candidate's priority 1
2024-04-06 10:34:20,439 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:34:20,439 [grpc-default-executor-6] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: shutdown a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-FollowerState
2024-04-06 10:34:20,439 [grpc-default-executor-6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: start a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-FollowerState
2024-04-06 10:34:20,439 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-FollowerState was interrupted
2024-04-06 10:34:20,443 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1389)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7: receive requestVote(ELECTION, 59c3495a-7636-40f9-8dfa-c28be8e98abd, group-82A21D15CBF7, 1, (t:0, i:0))
2024-04-06 10:34:20,443 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7: set firstElectionSinceStartup to false for candidate:59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:34:20,445 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-FOLLOWER: accept ELECTION from 59c3495a-7636-40f9-8dfa-c28be8e98abd: our priority 0 <= candidate's priority 1
2024-04-06 10:34:20,445 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:34:20,445 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - cc1e4d3c-2283-4c28-b737-db868cb45369: shutdown cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-FollowerState
2024-04-06 10:34:20,445 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - cc1e4d3c-2283-4c28-b737-db868cb45369: start cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-FollowerState
2024-04-06 10:34:20,445 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-FollowerState was interrupted
2024-04-06 10:34:20,445 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7: set firstElectionSinceStartup to false for candidate:59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:34:20,446 [grpc-default-executor-6] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7 replies to ELECTION vote request: 59c3495a-7636-40f9-8dfa-c28be8e98abd<-a40aef6e-dfc7-4141-9a41-17d72bf4eeff#0:OK-t1. Peer's state: a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7:t1, leader=null, voted=59c3495a-7636-40f9-8dfa-c28be8e98abd, raftlog=Memoized:a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:34:20,446 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1422)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7 replies to ELECTION vote request: 59c3495a-7636-40f9-8dfa-c28be8e98abd<-cc1e4d3c-2283-4c28-b737-db868cb45369#0:OK-t1. Peer's state: cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7:t1, leader=null, voted=59c3495a-7636-40f9-8dfa-c28be8e98abd, raftlog=Memoized:cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:34:20,447 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(89)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12: ELECTION PASSED received 1 response(s) and 0 exception(s):
2024-04-06 10:34:20,447 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(93)) -   Response 0: 59c3495a-7636-40f9-8dfa-c28be8e98abd<-cc1e4d3c-2283-4c28-b737-db868cb45369#0:OK-t1
2024-04-06 10:34:20,447 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(323)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12 ELECTION round 0: result PASSED
2024-04-06 10:34:20,447 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: shutdown 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12
2024-04-06 10:34:20,448 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(383)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2024-04-06 10:34:20,448 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2024-04-06 10:34:20,448 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-04-06 10:34:20,448 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2024-04-06 10:34:20,448 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2024-04-06 10:34:20,448 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2024-04-06 10:34:20,448 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2024-04-06 10:34:20,449 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.enabled = false (default)
2024-04-06 10:34:20,449 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.leader.lease.timeout.ratio = 0.9 (default)
2024-04-06 10:34:20,449 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:34:20,449 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2024-04-06 10:34:20,449 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2024-04-06 10:34:20,449 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-04-06 10:34:20,449 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:34:20,450 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2024-04-06 10:34:20,450 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0μs (custom)
2024-04-06 10:34:20,450 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-04-06 10:34:20,450 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:34:20,450 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-04-06 10:34:20,450 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-04-06 10:34:20,450 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-04-06 10:34:20,450 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:34:20,450 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-04-06 10:34:20,451 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2024-04-06 10:34:20,451 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:34:20,451 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2024-04-06 10:34:20,452 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 0μs (custom)
2024-04-06 10:34:20,452 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 8 (default)
2024-04-06 10:34:20,452 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:34:20,452 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2024-04-06 10:34:20,452 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2024-04-06 10:34:20,452 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.log-message.batch.duration = 5s (default)
2024-04-06 10:34:20,452 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:34:20,452 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-04-06 10:34:20,452 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: start 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderStateImpl
2024-04-06 10:34:20,452 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServer$Division (RaftServerImpl.java:setFirstElection(574)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7: set firstElectionSinceStartup to false for becomeLeader
2024-04-06 10:34:20,452 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-82A21D15CBF7 with new leaderId: 59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:34:20,453 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7: change Leader from null to 59c3495a-7636-40f9-8dfa-c28be8e98abd at term 1 for becomeLeader, leader elected after 5181ms
2024-04-06 10:34:20,453 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-SegmentedRaftLogWorker: Starting segment from index:0
2024-04-06 10:34:20,454 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderElection12] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7: set configuration 0: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:34:20,455 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-04-06 10:34:20,455 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(103)) - Pipeline RATIS/THREE PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 reported by 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:20,456 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(136)) - Opened pipeline PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7
2024-04-06 10:34:20,460 [cc1e4d3c-2283-4c28-b737-db868cb45369-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-82A21D15CBF7 with new leaderId: 59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:34:20,460 [cc1e4d3c-2283-4c28-b737-db868cb45369-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7: change Leader from null to 59c3495a-7636-40f9-8dfa-c28be8e98abd at term 1 for appendEntries, leader elected after 5103ms
2024-04-06 10:34:20,468 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7/current/log_inprogress_0
2024-04-06 10:34:20,487 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-server-thread2] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(966)) - Leader change notification received for group: group-82A21D15CBF7 with new leaderId: 59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:34:20,488 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setLeader(269)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7: change Leader from null to 59c3495a-7636-40f9-8dfa-c28be8e98abd at term 1 for appendEntries, leader elected after 5171ms
2024-04-06 10:34:20,489 [cc1e4d3c-2283-4c28-b737-db868cb45369-server-thread3] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7: set configuration 0: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:34:20,489 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(386)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7: set configuration 0: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null
2024-04-06 10:34:20,489 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-SegmentedRaftLogWorker: Starting segment from index:0
2024-04-06 10:34:20,489 [cc1e4d3c-2283-4c28-b737-db868cb45369-server-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(430)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-SegmentedRaftLogWorker: Starting segment from index:0
2024-04-06 10:34:20,490 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-04-06 10:34:20,491 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-SegmentedRaftLogWorker] INFO  segmented.BufferedWriteChannel (BufferedWriteChannel.java:open(62)) - open log_inprogress_0 at position 0
2024-04-06 10:34:20,501 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7/current/log_inprogress_0
2024-04-06 10:34:20,501 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(634)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7/current/log_inprogress_0
2024-04-06 10:34:20,504 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-StateMachineUpdater] INFO  server.RaftServer$Division (LeaderStateImpl.java:isApplied(320)) - leader is ready since appliedIndex == 0 >= startIndex == 0
2024-04-06 10:34:20,630 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:20,768 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:21,063 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:21,063 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:21,063 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:21,065 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:21,065 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:21,193 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:21,195 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:21,195 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:21,195 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:21,195 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:21,195 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:21,195 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:21,195 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:21,195 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:21,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:34:21,768 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:22,066 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:22,067 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:22,067 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:22,068 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:22,068 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:22,196 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-04-06 10:34:22,198 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:22,198 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:22,198 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:22,199 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:22,199 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:22,199 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:22,199 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:22,199 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:22,631 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:22,769 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:22,963 [Recon-SyncSCMContainerInfo-0] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:syncWithSCMContainerInfo(557)) - Got list of containers from SCM : 1
2024-04-06 10:34:23,070 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:23,070 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:23,071 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:23,072 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:23,072 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:23,199 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:23,202 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:23,202 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:23,202 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:23,202 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:23,202 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:23,202 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:23,202 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:23,202 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:23,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:34:23,769 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:24,074 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:24,074 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:24,074 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:24,076 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:24,076 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:24,203 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:24,205 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:24,205 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:24,205 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:24,205 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:24,205 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:24,205 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:24,205 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:24,205 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:24,632 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:24,770 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:25,077 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:25,078 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:25,078 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:25,079 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:25,079 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:25,206 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-04-06 10:34:25,208 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:34:25,208 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:25,208 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:25,208 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:25,208 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:25,209 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:25,209 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:25,209 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:25,365 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 2 millisec, cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 1}
2024-04-06 10:34:25,366 [FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 2 millisec, cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 1}
2024-04-06 10:34:25,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:34:25,770 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:26,081 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:26,081 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:26,082 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:26,083 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:26,083 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:26,209 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:26,211 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:26,211 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:26,212 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:26,212 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:26,212 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:26,212 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:26,212 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:26,212 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:26,633 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:26,771 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:27,085 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:27,085 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:27,085 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:27,087 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:27,087 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:27,212 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:27,214 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:27,214 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:27,215 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:27,215 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:27,215 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:27,215 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:27,215 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:27,215 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:27,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:34:27,771 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:28,088 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:28,088 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:28,088 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:28,090 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:28,090 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:28,216 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:28,218 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:28,218 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:28,218 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:28,218 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:28,218 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:28,218 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:28,218 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:28,218 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:28,634 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:28,772 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:29,092 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:29,092 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:29,092 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:29,093 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:29,093 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:29,219 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:29,221 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:29,221 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:29,221 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:29,221 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:29,221 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:29,221 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:29,221 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:29,221 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:29,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:34:29,772 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:29,818 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 5 millisec, d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 1}
2024-04-06 10:34:29,819 [Recon-FixedThreadPoolWithAffinityExecutor-1-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 5 millisec, d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 1}
2024-04-06 10:34:30,095 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:30,095 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:30,095 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:30,097 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:30,097 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:30,222 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-04-06 10:34:30,224 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:30,224 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:30,224 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:30,224 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:30,224 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:30,224 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:30,224 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:30,224 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:30,635 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:30,773 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:31,098 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:31,099 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:31,099 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:31,100 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:31,100 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:31,225 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-04-06 10:34:31,228 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:31,228 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:31,228 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:31,228 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:31,228 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:31,228 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:31,228 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:31,228 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:31,636 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:34:31,773 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:32,102 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:32,102 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:32,102 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:32,104 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:32,104 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:32,229 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:32,231 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:32,231 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:32,231 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:32,231 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:32,231 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:32,231 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:32,231 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:32,231 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:32,636 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:32,773 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:33,106 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:33,106 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:33,106 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:33,108 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:33,108 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:33,232 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-04-06 10:34:33,234 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:33,234 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:33,234 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:33,234 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:33,234 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:33,234 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:33,234 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:33,234 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:33,637 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:34:33,774 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:33,998 [ContainerSizeCountTask] INFO  tasks.ContainerSizeCountTask (ContainerSizeCountTask.java:run(101)) - Deleted 0 records from "CONTAINER_COUNT_BY_SIZE"
2024-04-06 10:34:34,012 [ContainerSizeCountTask] INFO  tasks.ContainerSizeCountTask (ContainerSizeCountTask.java:process(200)) - Completed a 'process' run of ContainerSizeCountTask.
2024-04-06 10:34:34,012 [ContainerSizeCountTask] INFO  tasks.ContainerSizeCountTask (ContainerSizeCountTask.java:run(114)) - Elapsed Time in milliseconds for Process() execution: 13
2024-04-06 10:34:34,109 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:34,110 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:34,110 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:34,111 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:34,111 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:34,235 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-04-06 10:34:34,237 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:34:34,237 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:34,237 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:34,237 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:34,237 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:34,237 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:34,237 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:34,237 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:34,637 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:34,774 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:35,114 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:35,114 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:35,114 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:35,116 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:35,116 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:35,238 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-04-06 10:34:35,240 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:34:35,240 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:35,240 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:35,240 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:35,240 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:35,240 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:35,240 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:35,241 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:35,366 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(276)) - Event remained in queue for long time 3 millisec, cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 1}
2024-04-06 10:34:35,367 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 3 millisec, cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: FCR, size: 1}
2024-04-06 10:34:35,637 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:35,775 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:36,118 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:36,118 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:36,118 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:36,119 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:36,119 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:36,241 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-04-06 10:34:36,243 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:34:36,243 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:36,243 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:36,243 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:36,243 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:36,243 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:36,243 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:36,243 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:36,537 [59c3495a-7636-40f9-8dfa-c28be8e98abd-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-04-06 10:34:36,591 [cc1e4d3c-2283-4c28-b737-db868cb45369-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-04-06 10:34:36,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:36,752 [d1715241-1ffa-4146-b219-94c9c0fc171f-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-04-06 10:34:36,775 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:36,816 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-04-06 10:34:36,902 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-BlockDeletingService#0] INFO  interfaces.ContainerDeletionChoosingPolicyTemplate (ContainerDeletionChoosingPolicyTemplate.java:chooseContainerForBlockDeletion(85)) - Chosen 0/5000 blocks from 0 candidate containers.
2024-04-06 10:34:37,121 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:37,121 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:37,121 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:37,123 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:37,123 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:37,244 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-04-06 10:34:37,246 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:34:37,246 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:37,246 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:37,246 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:37,246 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:37,246 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:37,246 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:37,246 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:37,638 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:37,775 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:38,124 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:38,125 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:38,125 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:38,126 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:38,126 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:38,247 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-04-06 10:34:38,249 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:38,249 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:38,249 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:38,249 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:38,249 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:38,249 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:38,249 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:38,249 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:38,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:38,776 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:39,128 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:39,128 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:39,128 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:39,130 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:39,130 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:39,250 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-04-06 10:34:39,252 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:39,252 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:39,252 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:39,252 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:39,252 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:39,252 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:39,252 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:39,252 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:39,639 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:39,776 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:40,131 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:40,132 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:40,132 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:40,133 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:40,133 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:40,253 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-04-06 10:34:40,255 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:40,255 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:40,255 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:40,255 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:40,255 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:40,255 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:40,255 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:40,255 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:40,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:40,777 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:41,135 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:41,135 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:41,135 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:41,137 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:41,137 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:41,256 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-04-06 10:34:41,258 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:34:41,258 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:41,258 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:41,258 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:41,258 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:41,258 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:41,258 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:41,258 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:41,640 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:41,777 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:42,139 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:42,139 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:42,139 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:42,140 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:42,140 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:42,259 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-04-06 10:34:42,261 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:42,261 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:42,262 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:42,262 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:42,262 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:42,262 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:42,262 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:42,262 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:42,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 1 containers.
2024-04-06 10:34:42,778 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
2024-04-06 10:34:43,142 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:43,142 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:43,142 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:43,144 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:43,144 [Recon-SyncOM-1] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:43,263 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:43,265 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 1 containers.
2024-04-06 10:34:43,265 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:43,265 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:43,265 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:43,265 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:43,265 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:43,265 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:43,265 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:43,641 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2024-04-06 10:34:43,778 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 1 has 3 replicas on [59c3495a-7636-40f9-8dfa-c28be8e98abd, cc1e4d3c-2283-4c28-b737-db868cb45369, d1715241-1ffa-4146-b219-94c9c0fc171f]
====> [2] DECOMMISSIONING, DECOMMISSIONED, false TIMED OUT. PRINTING THREAD DUMP. <====

Timestamp: 2024-04-06 10:34:43,849

"IPC Server handler 98 on default port 15001" daemon prio=5 tid=254 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp226609535-641" daemon prio=5 tid=641 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=38 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"qtp976190925-695-acceptor-0@738df869-ServerConnector@7bab2266{HTTP/1.1, (http/1.1)}{0.0.0.0:15047}" daemon prio=3 tid=695 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 95 on default port 15000" daemon prio=5 tid=151 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 38 on default port 15002" daemon prio=5 tid=294 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 6 on default port 15000" daemon prio=5 tid=62 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"JvmPauseMonitor3" daemon prio=5 tid=733 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$626/349677922.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 23 on default port 15001" daemon prio=5 tid=179 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 62 on default port 15009" daemon prio=5 tid=531 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Session-HouseKeeper-378d7124-1"  prio=5 tid=589 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1115963634-363" daemon prio=5 tid=363 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp2041857678-581" daemon prio=5 tid=581 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$666/1273065937.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 76 on default port 15009" daemon prio=5 tid=545 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 27 on default port 15000" daemon prio=5 tid=83 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=706 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-SegmentedRaftLogWorker"  prio=5 tid=1151 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$997/2039256444.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"d1715241-1ffa-4146-b219-94c9c0fc171f-DatanodeStateMachineTaskThread-0"  prio=5 tid=659 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 49 on default port 15000" daemon prio=5 tid=105 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d1715241-1ffa-4146-b219-94c9c0fc171f-DatanodeStateMachineDaemonThread" daemon prio=5 tid=652 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:369)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:556)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1466/1250399292.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"SSL Certificates Store Monitor" daemon prio=5 tid=1120 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 19 on default port 15002" daemon prio=5 tid=275 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-BlockDeletingService#1" daemon prio=5 tid=814 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 15002" daemon prio=5 tid=263 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 71 on default port 15001" daemon prio=5 tid=227 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-DatanodeCommandForSCMNodeManager"  prio=5 tid=822 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 15012" daemon prio=5 tid=590 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 88 on default port 15001" daemon prio=5 tid=244 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 1 on default port 15000" daemon prio=5 tid=57 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"surefire-forkedjvm-command-thread" daemon prio=5 tid=10 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.FileInputStream.readBytes(Native Method)
        at java.io.FileInputStream.read(FileInputStream.java:255)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
        at java.io.DataInputStream.readInt(DataInputStream.java:387)
        at org.apache.maven.surefire.booter.MasterProcessCommand.decode(MasterProcessCommand.java:113)
        at org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:383)
        at java.lang.Thread.run(Thread.java:750)
"qtp976190925-698" daemon prio=5 tid=698 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-cacheEviction-AwaitToRun" daemon prio=5 tid=1126 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.lang.Thread.run(Thread.java:750)
"cc1e4d3c-2283-4c28-b737-db868cb45369-DatanodeReportManager-0" daemon prio=5 tid=625 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 15009"  prio=5 tid=442 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 28 on default port 15009" daemon prio=5 tid=497 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 79 on default port 15001" daemon prio=5 tid=235 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1-DirectoryDeletingService#0" daemon prio=5 tid=396 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 84 on default port 15000" daemon prio=5 tid=140 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-201-thread-1" daemon prio=5 tid=802 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 27 on default port 15009" daemon prio=5 tid=496 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 85 on default port 15002" daemon prio=5 tid=341 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"JvmPauseMonitor7" daemon prio=5 tid=809 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$626/349677922.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-StateMachineUpdater" daemon prio=5 tid=872 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.lang.Thread.run(Thread.java:750)
"om1-OMStateMachineApplyTransactionThread - 0" daemon prio=5 tid=930 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-server-thread1" daemon prio=5 tid=1171 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 25 on default port 15001" daemon prio=5 tid=181 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-ChunkWriter-3-0" daemon prio=5 tid=789 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 15030" daemon prio=5 tid=648 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 67 on default port 15002" daemon prio=5 tid=323 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 5 on default port 15004" daemon prio=5 tid=417 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1-MultipartUploadCleanupService#0" daemon prio=5 tid=401 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 56 on default port 15001" daemon prio=5 tid=212 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d1715241-1ffa-4146-b219-94c9c0fc171f-DatanodeReportManager-0" daemon prio=5 tid=653 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 65 on default port 15000" daemon prio=5 tid=121 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Finalizer" daemon prio=8 tid=3 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:188)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-ChunkWriter-2-0" daemon prio=5 tid=788 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp976190925-699" daemon prio=5 tid=699 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"cc1e4d3c-2283-4c28-b737-db868cb45369-ChunkWriter-0-0" daemon prio=5 tid=748 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-CloseContainerThread-0"  prio=5 tid=1049 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2041857678-587" daemon prio=5 tid=587 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 87 on default port 15002" daemon prio=5 tid=343 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 38 on default port 15009" daemon prio=5 tid=507 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 81 on default port 15001" daemon prio=5 tid=237 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SSL Certificates Store Monitor" daemon prio=5 tid=1117 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 28 on default port 15002" daemon prio=5 tid=284 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 82 on default port 15000" daemon prio=5 tid=138 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 6 on default port 15009" daemon prio=5 tid=475 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerHealthTask" daemon prio=5 tid=570 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.recon.fsck.ContainerHealthTask.run(ContainerHealthTask.java:111)
        at org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda$1379/2055376904.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 83 on default port 15001" daemon prio=5 tid=239 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 9 on default port 15001" daemon prio=5 tid=165 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 8 on default port 15009" daemon prio=5 tid=477 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"cc1e4d3c-2283-4c28-b737-db868cb45369-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=741 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 87 on default port 15000" daemon prio=5 tid=143 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=44 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp462164160-614" daemon prio=5 tid=614 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 80 on default port 15001" daemon prio=5 tid=236 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 89 on default port 15000" daemon prio=5 tid=145 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp2041857678-582" daemon prio=5 tid=582 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$666/1273065937.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=383 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 37 on default port 15001" daemon prio=5 tid=193 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"DatanodeAdminManager-0" daemon prio=5 tid=28 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 54 on default port 15000" daemon prio=5 tid=110 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 15 on default port 15000" daemon prio=5 tid=71 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-DatanodeStateMachineTaskThread-0"  prio=5 tid=603 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-ReplicationContainerReader-0" daemon prio=5 tid=1111 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 15009" daemon prio=5 tid=472 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp963735699-667-acceptor-0@168219b5-ServerConnector@4b4eece8{HTTP/1.1, (http/1.1)}{0.0.0.0:15038}" daemon prio=3 tid=667 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 74 on default port 15002" daemon prio=5 tid=330 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"cc1e4d3c-2283-4c28-b737-db868cb45369-CommandProcessorThread" daemon prio=5 tid=630 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:684)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1468/14604698.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache-Cleanup-0" daemon prio=5 tid=952 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 69 on default port 15001" daemon prio=5 tid=225 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 67 on default port 15001" daemon prio=5 tid=223 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1176 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SSL Certificates Store Monitor" daemon prio=5 tid=438 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 46 on default port 15002" daemon prio=5 tid=302 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 90 on default port 15000" daemon prio=5 tid=146 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Timer for 'StorageContainerManager' metrics system" daemon prio=5 tid=55 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-DatanodeReportManager-1" daemon prio=5 tid=710 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderStateImpl" daemon prio=5 tid=923 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:762)
"IPC Server handler 14 on default port 15002" daemon prio=5 tid=270 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 60 on default port 15000" daemon prio=5 tid=116 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 8 on default port 15001" daemon prio=5 tid=164 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15001"  prio=5 tid=36 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 11 on default port 15004" daemon prio=5 tid=423 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 64 on default port 15000" daemon prio=5 tid=120 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 47 on default port 15001" daemon prio=5 tid=203 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15030"  prio=5 tid=647 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"SSL Certificates Store Monitor" daemon prio=5 tid=1045 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 44 on default port 15001" daemon prio=5 tid=200 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/data-0/hdds)" daemon prio=5 tid=804 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-DatanodeReportManager-0" daemon prio=5 tid=681 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 68 on default port 15009" daemon prio=5 tid=537 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1-client-thread1" daemon prio=5 tid=929 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7->a40aef6e-dfc7-4141-9a41-17d72bf4eeff-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=1165 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:286)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:254)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:80)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1703/982418488.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 56 on default port 15009" daemon prio=5 tid=525 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-DatanodeStateMachineDaemonThread" daemon prio=5 tid=596 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:369)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:556)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1466/1250399292.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 25 on default port 15002" daemon prio=5 tid=281 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 2 on default port 15000" daemon prio=5 tid=58 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"LeakDetector-ManagedRocksObject0" daemon prio=5 tid=20 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at org.apache.hadoop.hdds.utils.LeakDetector.run(LeakDetector.java:80)
        at org.apache.hadoop.hdds.utils.LeakDetector$$Lambda$497/1402400433.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 50 on default port 15009" daemon prio=5 tid=519 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"timer4" daemon prio=5 tid=919 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 76 on default port 15002" daemon prio=5 tid=332 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=622 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"process reaper" daemon prio=10 tid=12 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 39 on default port 15001" daemon prio=5 tid=195 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-executor-6" daemon prio=5 tid=1138 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 38 on default port 15000" daemon prio=5 tid=94 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Client (583361835) connection to localhost/127.0.0.1:15004 from runner" daemon prio=5 tid=959 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1026)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1077)
"om1-SnapshotDeletingService#0" daemon prio=5 tid=399 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 24 on default port 15002" daemon prio=5 tid=280 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15012" daemon prio=5 tid=595 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"cc1e4d3c-2283-4c28-b737-db868cb45369-server-thread1" daemon prio=5 tid=1167 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 15009" daemon prio=5 tid=486 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 93 on default port 15000" daemon prio=5 tid=149 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 74 on default port 15000" daemon prio=5 tid=130 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 3 on default port 15001" daemon prio=5 tid=159 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"cc1e4d3c-2283-4c28-b737-db868cb45369-CloseContainerThread-0"  prio=5 tid=1051 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=705 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"IPC Server handler 79 on default port 15002" daemon prio=5 tid=335 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 62 on default port 15001" daemon prio=5 tid=218 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1360692538-458-acceptor-0@283546c9-ServerConnector@2ec993d6{HTTP/1.1, (http/1.1)}{0.0.0.0:15008}" daemon prio=3 tid=458 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 31 on default port 15001" daemon prio=5 tid=187 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-ChunkReader-ELG-0" daemon prio=5 tid=734 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 15004" daemon prio=5 tid=381 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 53 on default port 15000" daemon prio=5 tid=109 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 13 on default port 15001" daemon prio=5 tid=169 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 9 on default port 15000" daemon prio=5 tid=65 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SSL Certificates Store Monitor" daemon prio=5 tid=1118 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 16 on default port 15002" daemon prio=5 tid=272 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 34 on default port 15001" daemon prio=5 tid=190 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 12 on default port 15001" daemon prio=5 tid=168 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 1 on default port 15001" daemon prio=5 tid=157 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-ChunkReader-ELG-0" daemon prio=5 tid=810 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-DatanodeStateMachineTaskThread-0"  prio=5 tid=715 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 70 on default port 15009" daemon prio=5 tid=539 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1360692538-457" daemon prio=5 tid=457 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.reservedWait(ReservedThreadExecutor.java:324)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:399)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp2139799663-405-acceptor-0@59e40878-ServerConnector@287d872b{HTTP/1.1, (http/1.1)}{0.0.0.0:15005}" daemon prio=3 tid=405 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 15000" daemon prio=5 tid=61 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 72 on default port 15000" daemon prio=5 tid=128 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 4 on default port 15004" daemon prio=5 tid=416 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15004" daemon prio=5 tid=412 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 98 on default port 15000" daemon prio=5 tid=154 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 20 on default port 15002" daemon prio=5 tid=276 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 30 on default port 15009" daemon prio=5 tid=499 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 92 on default port 15009" daemon prio=5 tid=561 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 64 on default port 15009" daemon prio=5 tid=533 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1178 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 15004" daemon prio=5 tid=418 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-DatanodeReportManager-3" daemon prio=5 tid=684 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 63 on default port 15000" daemon prio=5 tid=119 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@690ece45" daemon prio=5 tid=607 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.lang.Thread.run(Thread.java:750)
"cc1e4d3c-2283-4c28-b737-db868cb45369-server-thread2" daemon prio=5 tid=1168 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 52 on default port 15002" daemon prio=5 tid=308 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=450 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 15004" daemon prio=5 tid=429 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 95 on default port 15001" daemon prio=5 tid=251 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 45 on default port 15002" daemon prio=5 tid=301 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 46 on default port 15009" daemon prio=5 tid=515 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 43 on default port 15000" daemon prio=5 tid=99 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"pool-123-thread-1" daemon prio=5 tid=745 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 15001" daemon prio=5 tid=170 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 28 on default port 15001" daemon prio=5 tid=184 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1-SnapshotDiffCleanupService#0" daemon prio=5 tid=373 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 43 on default port 15001" daemon prio=5 tid=199 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 86 on default port 15009" daemon prio=5 tid=555 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-BlockDeletingService#0" daemon prio=5 tid=792 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 21 on default port 15000" daemon prio=5 tid=77 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 73 on default port 15000" daemon prio=5 tid=129 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 80 on default port 15009" daemon prio=5 tid=549 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1180 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/data-0/hdds)" daemon prio=5 tid=747 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server handler 15 on default port 15009" daemon prio=5 tid=484 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"cc1e4d3c-2283-4c28-b737-db868cb45369-DatanodeReportManager-4" daemon prio=5 tid=629 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-DatanodeReportManager-2" daemon prio=5 tid=711 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-ChunkWriter-1-0" daemon prio=5 tid=730 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 71 on default port 15000" daemon prio=5 tid=127 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SSL Certificates Store Monitor" daemon prio=5 tid=1116 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 50 on default port 15000" daemon prio=5 tid=106 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"LeaseManager#LeaseMonitor" daemon prio=5 tid=357 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1037)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1328)
        at java.util.concurrent.Semaphore.tryAcquire(Semaphore.java:409)
        at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:285)
        at java.lang.Thread.run(Thread.java:750)
"pool-34-thread-1"  prio=5 tid=359 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=677 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-PeriodicHDDSVolumeChecker" daemon prio=5 tid=781 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-DatanodeCommandQueueUpdatedForDatanodeCommandCountUpdatedHandler" daemon prio=5 tid=826 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 76 on default port 15001" daemon prio=5 tid=232 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-BlockDeletingService#2" daemon prio=5 tid=1181 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"d1715241-1ffa-4146-b219-94c9c0fc171f-ChunkReader-ELG-0" daemon prio=5 tid=772 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Recon-SyncOM-1"  prio=5 tid=958 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"cc1e4d3c-2283-4c28-b737-db868cb45369-BlockDeletingService#1" daemon prio=5 tid=757 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 93 on default port 15002" daemon prio=5 tid=349 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SSL Certificates Store Monitor" daemon prio=5 tid=956 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=775 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 15000" daemon prio=5 tid=42 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp462164160-609" daemon prio=5 tid=609 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$666/1273065937.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 15002" daemon prio=5 tid=30 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 1 on default port 15004" daemon prio=5 tid=413 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 42 on default port 15002" daemon prio=5 tid=298 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-CommandProcessorThread" daemon prio=5 tid=714 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:684)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1468/14604698.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ContainerMetadataScanner" daemon prio=5 tid=765 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server handler 57 on default port 15009" daemon prio=5 tid=526 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 83 on default port 15002" daemon prio=5 tid=339 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 48 on default port 15000" daemon prio=5 tid=104 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Parameter Sending Thread for localhost/127.0.0.1:15004" daemon prio=5 tid=960 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferQueue.awaitFulfill(SynchronousQueue.java:764)
        at java.util.concurrent.SynchronousQueue$TransferQueue.transfer(SynchronousQueue.java:695)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1105)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 15002" daemon prio=5 tid=267 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 33 on default port 15009" daemon prio=5 tid=502 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=453 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 81 on default port 15009" daemon prio=5 tid=550 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule" daemon prio=5 tid=818 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-groupManagement"  prio=5 tid=829 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 77 on default port 15000" daemon prio=5 tid=133 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 92 on default port 15001" daemon prio=5 tid=248 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 56 on default port 15002" daemon prio=5 tid=312 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp963735699-671" daemon prio=5 tid=671 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 70 on default port 15001" daemon prio=5 tid=226 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp2139799663-407" daemon prio=5 tid=407 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-DatanodeReportManager-1" daemon prio=5 tid=598 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 86 on default port 15000" daemon prio=5 tid=142 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-DatanodeReportManager-0" daemon prio=5 tid=709 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-StateMachineUpdater" daemon prio=5 tid=388 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=593 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"IPC Server handler 54 on default port 15001" daemon prio=5 tid=210 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 12 on default port 15009" daemon prio=5 tid=481 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=49 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-SegmentedRaftLogWorker"  prio=5 tid=870 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$997/2039256444.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2139799663-410" daemon prio=5 tid=410 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ContainerMetadataScanner" daemon prio=5 tid=784 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"Session-HouseKeeper-56f12cfa-1"  prio=5 tid=411 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 15000" daemon prio=5 tid=59 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-boss-ELG-1-1" daemon prio=5 tid=389 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"cc1e4d3c-2283-4c28-b737-db868cb45369-CloseContainerThread-2"  prio=5 tid=1062 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 79 on default port 15000" daemon prio=5 tid=135 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=778 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PipelineCommandHandlerThread-0"  prio=5 tid=873 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 71 on default port 15009" daemon prio=5 tid=540 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 29 on default port 15001" daemon prio=5 tid=185 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SSL Certificates Store Monitor" daemon prio=5 tid=1121 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"qtp963735699-665" daemon prio=5 tid=665 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$666/1273065937.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor5" daemon prio=5 tid=771 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$626/349677922.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor2" daemon prio=5 tid=572 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$626/349677922.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 15001" daemon prio=5 tid=160 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 35 on default port 15001" daemon prio=5 tid=191 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerMetadataScanner" daemon prio=5 tid=727 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Parameter Sending Thread for 0.0.0.0/0.0.0.0:15009" daemon prio=5 tid=722 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferQueue.awaitFulfill(SynchronousQueue.java:764)
        at java.util.concurrent.SynchronousQueue$TransferQueue.transfer(SynchronousQueue.java:695)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1105)
        at java.lang.Thread.run(Thread.java:750)
"timer3" daemon prio=5 tid=918 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-DatanodeStateMachineDaemonThread" daemon prio=5 tid=708 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:369)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:556)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1466/1250399292.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 91 on default port 15002" daemon prio=5 tid=347 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-SegmentedRaftLogWorker"  prio=5 tid=1140 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$997/2039256444.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp462164160-611" daemon prio=5 tid=611 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-BlockDeletingService#0" daemon prio=5 tid=735 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 87 on default port 15001" daemon prio=5 tid=243 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 53 on default port 15001" daemon prio=5 tid=209 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d1715241-1ffa-4146-b219-94c9c0fc171f-groupManagement"  prio=5 tid=851 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"cc1e4d3c-2283-4c28-b737-db868cb45369-DatanodeReportManager-1" daemon prio=5 tid=626 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-71-thread-1"  prio=5 tid=437 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-ChunkWriter-0-0" daemon prio=5 tid=729 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 15009" daemon prio=5 tid=441 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 39 on default port 15000" daemon prio=5 tid=95 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"derby.rawStoreDaemon" daemon prio=5 tid=434 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.derby.impl.services.daemon.BasicDaemon.rest(Unknown Source)
        at org.apache.derby.impl.services.daemon.BasicDaemon.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 32 on default port 15002" daemon prio=5 tid=288 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-BlockDeletingService#0" daemon prio=5 tid=811 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 21 on default port 15009" daemon prio=5 tid=490 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1-groupManagement"  prio=5 tid=377 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 60 on default port 15001" daemon prio=5 tid=216 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"client-write-TID-0" daemon prio=5 tid=951 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=661 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 15009" daemon prio=5 tid=470 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-StateMachineUpdater" daemon prio=5 tid=1125 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 46 on default port 15000" daemon prio=5 tid=102 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"MutableQuantiles-0" daemon prio=5 tid=937 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 93 on default port 15009" daemon prio=5 tid=562 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15048"  prio=5 tid=703 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 41 on default port 15000" daemon prio=5 tid=97 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-PipelineCommandHandlerThread-0"  prio=5 tid=867 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SSL Certificates Store Monitor" daemon prio=5 tid=1067 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 32 on default port 15009" daemon prio=5 tid=501 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 61 on default port 15009" daemon prio=5 tid=530 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 17 on default port 15001" daemon prio=5 tid=173 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15039"  prio=5 tid=675 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-ReplicationContainerReader-1" daemon prio=5 tid=1112 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 55 on default port 15001" daemon prio=5 tid=211 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-StateMachineUpdater" daemon prio=5 tid=835 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 88 on default port 15002" daemon prio=5 tid=344 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1115963634-364" daemon prio=5 tid=364 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache-Cleanup-0" daemon prio=5 tid=931 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2041857678-588" daemon prio=5 tid=588 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Recon-FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=452 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"d1715241-1ffa-4146-b219-94c9c0fc171f-CloseContainerThread-2"  prio=5 tid=1060 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 15000" daemon prio=5 tid=72 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 53 on default port 15002" daemon prio=5 tid=309 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 98 on default port 15009" daemon prio=5 tid=567 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 33 on default port 15001" daemon prio=5 tid=189 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 10 on default port 15000" daemon prio=5 tid=66 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=825 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 15004" daemon prio=5 tid=419 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"CompactionDagPruningService" daemon prio=5 tid=372 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=51 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 87 on default port 15009" daemon prio=5 tid=556 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 69 on default port 15000" daemon prio=5 tid=125 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 10 on default port 15009" daemon prio=5 tid=479 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 67 on default port 15009" daemon prio=5 tid=536 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"gradle-enterprise-test-client-gradle-enterprise-test-listener"  prio=5 tid=14 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.io.ObjectOutputStream$BlockDataOutputStream.getUTFLength(ObjectOutputStream.java:2152)
        at java.io.ObjectOutputStream.writeString(ObjectOutputStream.java:1303)
        at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1172)
        at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)
        at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)
        at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)
        at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
        at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)
        at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)
        at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)
        at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
        at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)
        at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)
        at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)
        at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
        at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
        at com.gradle.maven.scan.extension.test.listener.obfuscated.k.a.a(SourceFile:141)
        at com.gradle.maven.scan.extension.test.listener.obfuscated.k.a.b(SourceFile:93)
        at com.gradle.maven.scan.extension.test.listener.obfuscated.k.a$$Lambda$256/233519968.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 15000" daemon prio=5 tid=69 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 66 on default port 15002" daemon prio=5 tid=322 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15002"  prio=5 tid=31 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-ChunkWriter-0-0" daemon prio=5 tid=786 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 15048" daemon prio=5 tid=702 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"qtp226609535-639" daemon prio=5 tid=639 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$666/1273065937.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 15000" daemon prio=5 tid=40 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 28 on default port 15000" daemon prio=5 tid=84 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 26 on default port 15000" daemon prio=5 tid=82 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-DatanodeReportManager-4" daemon prio=5 tid=601 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 21 on default port 15002" daemon prio=5 tid=277 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d1715241-1ffa-4146-b219-94c9c0fc171f-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=759 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule" daemon prio=5 tid=820 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-OpenKeyCleanupService#0" daemon prio=5 tid=397 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 52 on default port 15000" daemon prio=5 tid=108 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SCMHeartbeatProcessor-0" daemon prio=5 tid=21 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 15009" daemon prio=5 tid=488 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 7 on default port 15001" daemon prio=5 tid=163 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 53 on default port 15009" daemon prio=5 tid=522 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server listener on 15021" daemon prio=5 tid=618 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 93 on default port 15001" daemon prio=5 tid=249 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=50 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-DatanodeStateMachineTaskThread-1"  prio=5 tid=796 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 65 on default port 15001" daemon prio=5 tid=221 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 71 on default port 15002" daemon prio=5 tid=327 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 94 on default port 15000" daemon prio=5 tid=150 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 16 on default port 15001" daemon prio=5 tid=172 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-executor-1" daemon prio=5 tid=859 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"cc1e4d3c-2283-4c28-b737-db868cb45369-DatanodeStateMachineTaskThread-0"  prio=5 tid=631 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 15009" daemon prio=5 tid=478 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 43 on default port 15002" daemon prio=5 tid=299 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-cacheEviction-AwaitToRun" daemon prio=5 tid=1139 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 15009" daemon prio=5 tid=485 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 36 on default port 15000" daemon prio=5 tid=92 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 10 on default port 15002" daemon prio=5 tid=266 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 29 on default port 15002" daemon prio=5 tid=285 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/data-0/hdds)" daemon prio=5 tid=728 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server handler 26 on default port 15009" daemon prio=5 tid=495 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 91 on default port 15009" daemon prio=5 tid=560 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server idle connection scanner for port 15002" daemon prio=5 tid=32 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"JvmPauseMonitor0" daemon prio=5 tid=358 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$626/349677922.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 49 on default port 15009" daemon prio=5 tid=518 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 62 on default port 15002" daemon prio=5 tid=318 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 97 on default port 15000" daemon prio=5 tid=153 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 76 on default port 15000" daemon prio=5 tid=132 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 59 on default port 15000" daemon prio=5 tid=115 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=52 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-5" daemon prio=5 tid=1137 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1115963634-362-acceptor-0@2a99429-ServerConnector@6517bc6b{HTTP/1.1, (http/1.1)}{0.0.0.0:15003}" daemon prio=3 tid=362 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 59 on default port 15001" daemon prio=5 tid=215 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 20 on default port 15001" daemon prio=5 tid=176 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1115963634-361" daemon prio=5 tid=361 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$666/1273065937.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"SSL Certificates Store Monitor" daemon prio=5 tid=1044 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"Recon-FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=448 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 61 on default port 15002" daemon prio=5 tid=317 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d1715241-1ffa-4146-b219-94c9c0fc171f-DatanodeReportManager-4" daemon prio=5 tid=657 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 59 on default port 15002" daemon prio=5 tid=315 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp2139799663-406" daemon prio=5 tid=406 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-worker-ELG-3-4" daemon prio=5 tid=861 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:312)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:376)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 15009" daemon prio=5 tid=480 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 52 on default port 15009" daemon prio=5 tid=521 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-cacheEviction-AwaitToRun" daemon prio=5 tid=869 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 74 on default port 15001" daemon prio=5 tid=230 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d1715241-1ffa-4146-b219-94c9c0fc171f-PeriodicHDDSVolumeChecker" daemon prio=5 tid=762 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"cc1e4d3c-2283-4c28-b737-db868cb45369-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=740 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 23 on default port 15002" daemon prio=5 tid=279 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 73 on default port 15002" daemon prio=5 tid=329 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/data-0/hdds)" daemon prio=5 tid=785 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-BlockDeletingService#1" daemon prio=5 tid=795 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 15030" daemon prio=5 tid=646 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 24 on default port 15001" daemon prio=5 tid=180 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=737 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-SegmentedRaftLogWorker"  prio=5 tid=386 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$997/2039256444.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp226609535-638" daemon prio=5 tid=638 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$666/1273065937.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 58 on default port 15001" daemon prio=5 tid=214 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 58 on default port 15009" daemon prio=5 tid=527 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 20 on default port 15000" daemon prio=5 tid=76 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 37 on default port 15002" daemon prio=5 tid=293 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 68 on default port 15000" daemon prio=5 tid=124 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 23 on default port 15000" daemon prio=5 tid=79 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=689 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=827 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-149-thread-1" daemon prio=5 tid=764 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 77 on default port 15009" daemon prio=5 tid=546 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 18 on default port 15002" daemon prio=5 tid=274 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 29 on default port 15000" daemon prio=5 tid=85 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1-SnapshotDirectoryCleaningService#0" daemon prio=5 tid=400 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-629b2ae5-1"  prio=5 tid=701 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 88 on default port 15009" daemon prio=5 tid=557 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 80 on default port 15000" daemon prio=5 tid=136 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 50 on default port 15002" daemon prio=5 tid=306 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d1715241-1ffa-4146-b219-94c9c0fc171f-DatanodeReportManager-3" daemon prio=5 tid=656 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-DatanodeReportManager-4" daemon prio=5 tid=713 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"cc1e4d3c-2283-4c28-b737-db868cb45369-BlockDeletingService#2" daemon prio=5 tid=1175 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 98 on default port 15002" daemon prio=5 tid=354 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-worker-ELG-3-2" daemon prio=5 tid=852 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:312)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:376)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"qtp2041857678-584" daemon prio=5 tid=584 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 35 on default port 15002" daemon prio=5 tid=291 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 56 on default port 15000" daemon prio=5 tid=112 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server idle connection scanner for port 15012" daemon prio=5 tid=592 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-CloseContainerThread-1"  prio=5 tid=1057 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"cc1e4d3c-2283-4c28-b737-db868cb45369-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=605 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 51 on default port 15001" daemon prio=5 tid=207 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 69 on default port 15002" daemon prio=5 tid=325 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 22 on default port 15000" daemon prio=5 tid=78 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp976190925-700" daemon prio=5 tid=700 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 90 on default port 15002" daemon prio=5 tid=346 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-cacheEviction-AwaitToRun" daemon prio=5 tid=832 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.lang.Thread.run(Thread.java:750)
"timer0" daemon prio=5 tid=943 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 11 on default port 15000" daemon prio=5 tid=67 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 19 on default port 15004" daemon prio=5 tid=431 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-BlockDeletingService#2" daemon prio=5 tid=1179 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@4f4cba01" daemon prio=5 tid=635 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 73 on default port 15009" daemon prio=5 tid=542 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=53 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 84 on default port 15002" daemon prio=5 tid=340 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 84 on default port 15001" daemon prio=5 tid=240 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"timer5" daemon prio=5 tid=938 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"pool-64-thread-1"  prio=5 tid=402 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 37 on default port 15000" daemon prio=5 tid=93 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@4bbe05c4" daemon prio=5 tid=663 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.lang.Thread.run(Thread.java:750)
"ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/data-0/hdds)" daemon prio=5 tid=766 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"qtp226609535-637" daemon prio=5 tid=637 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache-Cleanup-0" daemon prio=5 tid=953 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-DatanodeStateMachineTaskThread-1"  prio=5 tid=777 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-cacheEviction-AwaitToRun" daemon prio=5 tid=1150 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache-Cleanup-0" daemon prio=5 tid=936 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@bd9f64" daemon prio=5 tid=579 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache-Cleanup-0" daemon prio=5 tid=932 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-groupManagement"  prio=5 tid=874 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp976190925-697" daemon prio=5 tid=697 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ExpiredContainerReplicaOpScrubber" daemon prio=5 tid=24 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:107)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$561/2086062353.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-DatanodeReportManager-2" daemon prio=5 tid=599 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 36 on default port 15002" daemon prio=5 tid=292 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 49 on default port 15001" daemon prio=5 tid=205 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Connector-Scheduler-2ec993d6-1"  prio=5 tid=957 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 51 on default port 15009" daemon prio=5 tid=520 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 75 on default port 15009" daemon prio=5 tid=544 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 13 on default port 15004" daemon prio=5 tid=425 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d1715241-1ffa-4146-b219-94c9c0fc171f-BlockDeletingService#2" daemon prio=5 tid=1177 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"d1715241-1ffa-4146-b219-94c9c0fc171f-DatanodeReportManager-2" daemon prio=5 tid=655 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 43 on default port 15009" daemon prio=5 tid=512 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 64 on default port 15001" daemon prio=5 tid=220 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Signal Dispatcher" daemon prio=9 tid=4 runnable
java.lang.Thread.State: RUNNABLE
"qtp1360692538-462" daemon prio=5 tid=462 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp2139799663-404" daemon prio=5 tid=404 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 40 on default port 15001" daemon prio=5 tid=196 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15001" daemon prio=5 tid=156 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 83 on default port 15009" daemon prio=5 tid=552 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 44 on default port 15000" daemon prio=5 tid=100 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 22 on default port 15009" daemon prio=5 tid=491 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=755 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-114-thread-1"  prio=5 tid=580 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1115963634-367" daemon prio=5 tid=367 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0"  prio=5 tid=828 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-LeaderStateImpl" daemon prio=5 tid=436 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:762)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=774 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 15001" daemon prio=5 tid=175 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 3 on default port 15002" daemon prio=5 tid=259 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-EventQueue-NewNodeForReconNewNodeHandler" daemon prio=5 tid=816 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerMetadataScanner" daemon prio=5 tid=803 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"Socket Reader #1 for port 15021"  prio=5 tid=619 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 68 on default port 15001" daemon prio=5 tid=224 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=48 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=46 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1360692538-463" daemon prio=5 tid=463 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 41 on default port 15009" daemon prio=5 tid=510 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler" daemon prio=5 tid=1041 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer2" daemon prio=5 tid=913 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 14 on default port 15004" daemon prio=5 tid=426 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"cc1e4d3c-2283-4c28-b737-db868cb45369-PeriodicHDDSVolumeChecker" daemon prio=5 tid=743 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-StateMachineUpdater" daemon prio=5 tid=1153 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 55 on default port 15002" daemon prio=5 tid=311 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=650 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"null-request--thread1" daemon prio=5 tid=940 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 41 on default port 15001" daemon prio=5 tid=197 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 63 on default port 15009" daemon prio=5 tid=532 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 13 on default port 15002" daemon prio=5 tid=269 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server idle connection scanner for port 15001" daemon prio=5 tid=37 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=594 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 33 on default port 15000" daemon prio=5 tid=89 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 78 on default port 15009" daemon prio=5 tid=547 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-worker-ELG-3-1" daemon prio=5 tid=853 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:312)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:376)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 15002" daemon prio=5 tid=264 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-CommandProcessorThread" daemon prio=5 tid=686 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:684)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1468/14604698.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 15002" daemon prio=5 tid=273 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-server-thread2" daemon prio=5 tid=1169 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 15021" daemon prio=5 tid=620 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 74 on default port 15009" daemon prio=5 tid=543 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1115963634-360" daemon prio=5 tid=360 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$666/1273065937.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"pool-140-thread-1"  prio=5 tid=608 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Reference Handler" daemon prio=10 tid=2 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
        at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
"IPC Server handler 61 on default port 15001" daemon prio=5 tid=217 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-SegmentedRaftLogWorker"  prio=5 tid=1144 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$997/2039256444.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"cc1e4d3c-2283-4c28-b737-db868cb45369-ChunkWriter-1-0" daemon prio=5 tid=749 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1360692538-461" daemon prio=5 tid=461 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"d1715241-1ffa-4146-b219-94c9c0fc171f-BlockDeletingService#0" daemon prio=5 tid=773 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=43 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=815 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp976190925-693" daemon prio=5 tid=693 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$666/1273065937.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 51 on default port 15002" daemon prio=5 tid=307 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SCMHeartbeatProcessor-0" daemon prio=5 tid=440 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 15001" daemon prio=5 tid=166 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"JvmPauseMonitor4" daemon prio=5 tid=752 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$626/349677922.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 84 on default port 15009" daemon prio=5 tid=553 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=39 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-DatanodeStateMachineTaskThread-0"  prio=5 tid=687 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 85 on default port 15009" daemon prio=5 tid=554 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 42 on default port 15000" daemon prio=5 tid=98 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"cc1e4d3c-2283-4c28-b737-db868cb45369-ChunkReader-ELG-0" daemon prio=5 tid=753 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"PipelineSyncTask" daemon prio=5 tid=571 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.recon.scm.PipelineSyncTask.run(PipelineSyncTask.java:76)
        at org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda$1379/2055376904.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 47 on default port 15000" daemon prio=5 tid=103 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-DatanodeReportManager-4" daemon prio=5 tid=685 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"surefire-forkedjvm-ping-30s" daemon prio=5 tid=11 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-DatanodeReportManager-0" daemon prio=5 tid=597 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SSL Certificates Store Monitor" daemon prio=5 tid=1066 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 38 on default port 15001" daemon prio=5 tid=194 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 70 on default port 15000" daemon prio=5 tid=126 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d1715241-1ffa-4146-b219-94c9c0fc171f-ChunkWriter-3-0" daemon prio=5 tid=770 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"d1715241-1ffa-4146-b219-94c9c0fc171f-ChunkWriter-2-0" daemon prio=5 tid=769 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Recon-EventQueue-PipelineReportForReconPipelineReportHandler" daemon prio=5 tid=821 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp963735699-666" daemon prio=5 tid=666 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$666/1273065937.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1172 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"cc1e4d3c-2283-4c28-b737-db868cb45369-DatanodeStateMachineTaskThread-1"  prio=5 tid=739 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 15002" daemon prio=5 tid=256 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 25 on default port 15009" daemon prio=5 tid=494 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 37 on default port 15009" daemon prio=5 tid=506 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Timer-0"  prio=5 tid=391 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"EventQueue-OpenPipelineForHealthyPipelineSafeModeRule" daemon prio=5 tid=831 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp976190925-694" daemon prio=5 tid=694 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$666/1273065937.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 80 on default port 15002" daemon prio=5 tid=336 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-DatanodeReportManager-2" daemon prio=5 tid=683 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 24 on default port 15009" daemon prio=5 tid=493 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement"  prio=5 tid=841 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"cc1e4d3c-2283-4c28-b737-db868cb45369-BlockDeletingService#0" daemon prio=5 tid=754 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 15000" daemon prio=5 tid=74 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=1174 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp462164160-613" daemon prio=5 tid=613 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@332c8aba" daemon prio=5 tid=691 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:259)
        at java.lang.Thread.run(Thread.java:750)
"qtp2041857678-585" daemon prio=5 tid=585 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 66 on default port 15001" daemon prio=5 tid=222 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderStateImpl" daemon prio=5 tid=898 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:762)
"Socket Reader #1 for port 15004"  prio=5 tid=380 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-StateMachineUpdater" daemon prio=5 tid=1129 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=793 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 39 on default port 15002" daemon prio=5 tid=295 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=454 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 15001" daemon prio=5 tid=35 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"cc1e4d3c-2283-4c28-b737-db868cb45369-DatanodeStateMachineDaemonThread" daemon prio=5 tid=624 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:369)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:556)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1466/1250399292.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-175-thread-1" daemon prio=5 tid=783 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 55 on default port 15009" daemon prio=5 tid=524 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 57 on default port 15002" daemon prio=5 tid=313 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-BlockDeletingService#1" daemon prio=5 tid=738 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForPipelineReportHandler" daemon prio=5 tid=819 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 15004" daemon prio=5 tid=424 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 2 on default port 15004" daemon prio=5 tid=414 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 18 on default port 15004" daemon prio=5 tid=430 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 30 on default port 15002" daemon prio=5 tid=286 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 91 on default port 15001" daemon prio=5 tid=247 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"cc1e4d3c-2283-4c28-b737-db868cb45369-DatanodeReportManager-2" daemon prio=5 tid=627 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=798 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 25 on default port 15000" daemon prio=5 tid=81 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=446 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 89 on default port 15001" daemon prio=5 tid=245 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d1715241-1ffa-4146-b219-94c9c0fc171f-CloseContainerThread-1"  prio=5 tid=1059 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"main"  prio=5 tid=1 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.Thread.dumpThreads(Native Method)
        at java.lang.Thread.getAllStackTraces(Thread.java:1615)
        at org.apache.ozone.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:83)
        at org.apache.ozone.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:69)
        at org.apache.ozone.test.TimedOutTestsListener.lambda$executionFinished$0(TimedOutTestsListener.java:55)
        at org.apache.ozone.test.TimedOutTestsListener$$Lambda$2446/944761097.accept(Unknown Source)
        at java.util.Optional.ifPresent(Optional.java:159)
        at org.apache.ozone.test.TimedOutTestsListener.executionFinished(TimedOutTestsListener.java:51)
        at org.junit.platform.launcher.core.CompositeTestExecutionListener.lambda$executionFinished$10(CompositeTestExecutionListener.java:73)
        at org.junit.platform.launcher.core.CompositeTestExecutionListener$$Lambda$2410/1038340345.accept(Unknown Source)
        at org.junit.platform.launcher.core.CompositeTestExecutionListener.lambda$notifyEach$19(CompositeTestExecutionListener.java:102)
        at org.junit.platform.launcher.core.CompositeTestExecutionListener$$Lambda$247/678962690.accept(Unknown Source)
        at org.junit.platform.commons.util.CollectionUtils.forEachInReverseOrder(CollectionUtils.java:221)
        at org.junit.platform.launcher.core.IterationOrder$2.forEach(IterationOrder.java:30)
        at org.junit.platform.launcher.core.CompositeTestExecutionListener.notifyEach(CompositeTestExecutionListener.java:100)
        at org.junit.platform.launcher.core.CompositeTestExecutionListener.executionFinished(CompositeTestExecutionListener.java:72)
        at org.junit.platform.launcher.core.ExecutionListenerAdapter.executionFinished(ExecutionListenerAdapter.java:56)
        at org.junit.platform.launcher.core.CompositeEngineExecutionListener.lambda$executionFinished$6(CompositeEngineExecutionListener.java:59)
        at org.junit.platform.launcher.core.CompositeEngineExecutionListener$$Lambda$2401/154329705.accept(Unknown Source)
        at org.junit.platform.launcher.core.CompositeEngineExecutionListener.lambda$notifyEach$11(CompositeEngineExecutionListener.java:74)
        at org.junit.platform.launcher.core.CompositeEngineExecutionListener$$Lambda$296/168870325.accept(Unknown Source)
        at org.junit.platform.commons.util.CollectionUtils.forEachInReverseOrder(CollectionUtils.java:221)
        at org.junit.platform.launcher.core.IterationOrder$2.forEach(IterationOrder.java:30)
        at org.junit.platform.launcher.core.CompositeEngineExecutionListener.notifyEach(CompositeEngineExecutionListener.java:72)
        at org.junit.platform.launcher.core.CompositeEngineExecutionListener.executionFinished(CompositeEngineExecutionListener.java:58)
        at org.junit.platform.launcher.core.DelegatingEngineExecutionListener.executionFinished(DelegatingEngineExecutionListener.java:46)
        at org.junit.platform.launcher.core.StackTracePruningEngineExecutionListener.executionFinished(StackTracePruningEngineExecutionListener.java:46)
        at org.junit.platform.launcher.core.DelegatingEngineExecutionListener.executionFinished(DelegatingEngineExecutionListener.java:46)
        at org.junit.platform.launcher.core.OutcomeDelayingEngineExecutionListener.executionFinished(OutcomeDelayingEngineExecutionListener.java:63)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.reportCompletion(NodeTestTask.java:195)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:100)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:226)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:204)
        at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:142)
        at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.lambda$execute$2(TestTemplateTestDescriptor.java:110)
        at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor$$Lambda$2142/53330640.accept(Unknown Source)
        at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)
        at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:647)
        at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:272)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)
        at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
        at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
        at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
        at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
        at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
        at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
        at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:272)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193)
        at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384)
        at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
        at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
        at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
        at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
        at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
        at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
        at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:272)
        at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1384)
        at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
        at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472)
        at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
        at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
        at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
        at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485)
        at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:110)
        at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:44)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$317/1701436909.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$316/66845334.invoke(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$315/168468389.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService$$Lambda$321/1832284192.accept(Unknown Source)
        at java.util.ArrayList.forEach(ArrayList.java:1259)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$317/1701436909.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$316/66845334.invoke(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$315/168468389.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService$$Lambda$321/1832284192.accept(Unknown Source)
        at java.util.ArrayList.forEach(ArrayList.java:1259)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$317/1701436909.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$316/66845334.invoke(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$315/168468389.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
        at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
        at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:198)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:169)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:93)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:58)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator$$Lambda$235/2024945312.accept(Unknown Source)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:141)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:57)
        at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:103)
        at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:85)
        at org.junit.platform.launcher.core.DelegatingLauncher.execute(DelegatingLauncher.java:47)
        at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:63)
        at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
        at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:123)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
        at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
        at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
"IPC Server handler 63 on default port 15001" daemon prio=5 tid=219 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 8 on default port 15004" daemon prio=5 tid=420 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"cc1e4d3c-2283-4c28-b737-db868cb45369-server-thread3" daemon prio=5 tid=1170 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 60 on default port 15002" daemon prio=5 tid=316 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ContainerSizeCountTask" daemon prio=5 tid=569 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ozone.recon.tasks.ContainerSizeCountTask.run(ContainerSizeCountTask.java:94)
        at org.apache.hadoop.ozone.recon.scm.ReconScmTask$$Lambda$1379/2055376904.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 90 on default port 15009" daemon prio=5 tid=559 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderStateImpl" daemon prio=5 tid=1134 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:762)
"IPC Server handler 96 on default port 15001" daemon prio=5 tid=252 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp976190925-696" daemon prio=5 tid=696 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-192-thread-1"  prio=5 tid=664 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 75 on default port 15000" daemon prio=5 tid=131 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 31 on default port 15002" daemon prio=5 tid=287 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-PeriodicHDDSVolumeChecker" daemon prio=5 tid=800 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-DatanodeReportManager-3" daemon prio=5 tid=600 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 65 on default port 15002" daemon prio=5 tid=321 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-BlockDeletingService#2" daemon prio=5 tid=1173 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"d1715241-1ffa-4146-b219-94c9c0fc171f-ChunkWriter-0-0" daemon prio=5 tid=767 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 15002" daemon prio=5 tid=271 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"timer6" daemon prio=5 tid=941 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-PeriodicHDDSVolumeChecker" daemon prio=5 tid=724 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Recon-FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=455 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp462164160-616" daemon prio=5 tid=616 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 41 on default port 15002" daemon prio=5 tid=297 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 77 on default port 15001" daemon prio=5 tid=233 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d1715241-1ffa-4146-b219-94c9c0fc171f-ChunkWriter-1-0" daemon prio=5 tid=768 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 90 on default port 15001" daemon prio=5 tid=246 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 44 on default port 15009" daemon prio=5 tid=513 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SCMBlockDeletingService#0" daemon prio=5 tid=356 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 15009" daemon prio=5 tid=443 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Session-HouseKeeper-17d2221f-1"  prio=5 tid=673 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 15009" daemon prio=5 tid=471 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 22 on default port 15002" daemon prio=5 tid=278 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server listener on 15004" daemon prio=5 tid=379 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"Session-HouseKeeper-8d4bc4b-1"  prio=5 tid=645 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"UnderReplicatedProcessor" daemon prio=5 tid=26 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:174)
        at java.lang.Thread.run(Thread.java:750)
"qtp1360692538-456" daemon prio=5 tid=456 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"cc1e4d3c-2283-4c28-b737-db868cb45369-ChunkWriter-2-0" daemon prio=5 tid=750 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=445 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-0" daemon prio=5 tid=858 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-33-thread-1"  prio=5 tid=1048 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 83 on default port 15000" daemon prio=5 tid=139 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=797 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1360692538-459" daemon prio=5 tid=459 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-ChunkWriter-3-0" daemon prio=5 tid=732 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderStateImpl" daemon prio=5 tid=1164 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:762)
"Recon-FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=447 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 81 on default port 15002" daemon prio=5 tid=337 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=449 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 15009" daemon prio=5 tid=473 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 31 on default port 15000" daemon prio=5 tid=87 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 95 on default port 15002" daemon prio=5 tid=351 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 34 on default port 15002" daemon prio=5 tid=290 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-ChunkWriter-1-0" daemon prio=5 tid=806 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 57 on default port 15001" daemon prio=5 tid=213 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-ChunkWriter-2-0" daemon prio=5 tid=731 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 86 on default port 15002" daemon prio=5 tid=342 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 75 on default port 15001" daemon prio=5 tid=231 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 95 on default port 15009" daemon prio=5 tid=564 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=736 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=756 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 50 on default port 15001" daemon prio=5 tid=206 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"PartialTableCache-Cleanup-0" daemon prio=5 tid=935 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 85 on default port 15000" daemon prio=5 tid=141 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-StateMachineUpdater" daemon prio=5 tid=1142 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.lang.Thread.run(Thread.java:750)
"timer1" daemon prio=5 tid=912 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 1 on default port 15002" daemon prio=5 tid=257 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=678 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 15009" daemon prio=5 tid=482 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 27 on default port 15001" daemon prio=5 tid=183 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Connector-Scheduler-287d872b-1"  prio=5 tid=961 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 40 on default port 15009" daemon prio=5 tid=509 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 42 on default port 15001" daemon prio=5 tid=198 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-CloseContainerThread-2"  prio=5 tid=1058 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 78 on default port 15000" daemon prio=5 tid=134 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 35 on default port 15000" daemon prio=5 tid=91 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 19 on default port 15000" daemon prio=5 tid=75 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 99 on default port 15002" daemon prio=5 tid=355 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"NetworkTopologyPoller" daemon prio=5 tid=394 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"d1715241-1ffa-4146-b219-94c9c0fc171f-CloseContainerThread-0"  prio=5 tid=1050 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 92 on default port 15002" daemon prio=5 tid=348 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-executor-4" daemon prio=5 tid=1069 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 20 on default port 15009" daemon prio=5 tid=489 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SSL Certificates Store Monitor" daemon prio=5 tid=1068 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"qtp1115963634-365" daemon prio=5 tid=365 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"d1715241-1ffa-4146-b219-94c9c0fc171f-PipelineCommandHandlerThread-0"  prio=5 tid=850 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 79 on default port 15009" daemon prio=5 tid=548 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 22 on default port 15001" daemon prio=5 tid=178 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 35 on default port 15009" daemon prio=5 tid=504 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=779 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-OMDoubleBufferFlushThread" daemon prio=5 tid=375 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.canFlush(OzoneManagerDoubleBuffer.java:570)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.flushTransactions(OzoneManagerDoubleBuffer.java:294)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer$$Lambda$779/142020942.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 15039" daemon prio=5 tid=674 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1408)
"IPC Server handler 61 on default port 15000" daemon prio=5 tid=117 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-SegmentedRaftLogWorker"  prio=5 tid=833 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$997/2039256444.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 26 on default port 15001" daemon prio=5 tid=182 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 92 on default port 15000" daemon prio=5 tid=148 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 18 on default port 15001" daemon prio=5 tid=174 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp963735699-670" daemon prio=5 tid=670 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 57 on default port 15000" daemon prio=5 tid=113 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 40 on default port 15000" daemon prio=5 tid=96 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15009" daemon prio=5 tid=469 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 30 on default port 15000" daemon prio=5 tid=86 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 78 on default port 15001" daemon prio=5 tid=234 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 32 on default port 15000" daemon prio=5 tid=88 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 45 on default port 15000" daemon prio=5 tid=101 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-DatanodeStateMachineDaemonThread" daemon prio=5 tid=680 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:369)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$1(DatanodeStateMachine.java:556)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1466/1250399292.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-DatanodeStateMachineTaskThread-1"  prio=5 tid=716 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp963735699-669" daemon prio=5 tid=669 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 15048" daemon prio=5 tid=707 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 47 on default port 15009" daemon prio=5 tid=516 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 5 on default port 15009" daemon prio=5 tid=474 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=45 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp462164160-610" daemon prio=5 tid=610 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$666/1273065937.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp2139799663-409" daemon prio=5 tid=409 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.reservedWait(ReservedThreadExecutor.java:324)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:399)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=33 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"ContainerMetadataScanner" daemon prio=5 tid=746 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.handleRemainingSleep(AbstractBackgroundContainerScanner.java:131)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.runIteration(AbstractBackgroundContainerScanner.java:98)
        at org.apache.hadoop.ozone.container.ozoneimpl.AbstractBackgroundContainerScanner.run(AbstractBackgroundContainerScanner.java:57)
"IPC Server handler 73 on default port 15001" daemon prio=5 tid=229 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-FollowerState" daemon prio=5 tid=1163 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"IPC Server handler 15 on default port 15001" daemon prio=5 tid=171 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 75 on default port 15002" daemon prio=5 tid=331 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=54 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-ReplicationContainerReader-2" daemon prio=5 tid=1113 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-DeleteContainerThread-0"  prio=5 tid=1130 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 34 on default port 15000" daemon prio=5 tid=90 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15039" daemon prio=5 tid=679 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp963735699-672" daemon prio=5 tid=672 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp2139799663-408" daemon prio=5 tid=408 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 86 on default port 15001" daemon prio=5 tid=242 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 36 on default port 15009" daemon prio=5 tid=505 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 48 on default port 15009" daemon prio=5 tid=517 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 48 on default port 15002" daemon prio=5 tid=304 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"JvmPauseMonitor1" daemon prio=5 tid=390 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$626/349677922.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-cacheEviction-AwaitToRun" daemon prio=5 tid=1122 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 45 on default port 15001" daemon prio=5 tid=201 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 72 on default port 15001" daemon prio=5 tid=228 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 9 on default port 15002" daemon prio=5 tid=265 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"cc1e4d3c-2283-4c28-b737-db868cb45369-PipelineCommandHandlerThread-0"  prio=5 tid=840 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 70 on default port 15002" daemon prio=5 tid=326 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 11 on default port 15001" daemon prio=5 tid=167 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp226609535-642" daemon prio=5 tid=642 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-FollowerState" daemon prio=5 tid=1162 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"IPC Server handler 42 on default port 15009" daemon prio=5 tid=511 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 91 on default port 15000" daemon prio=5 tid=147 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp226609535-640-acceptor-0@3fd4501a-ServerConnector@1d2133d3{HTTP/1.1, (http/1.1)}{0.0.0.0:15029}" daemon prio=3 tid=640 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 15002" daemon prio=5 tid=268 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 18 on default port 15009" daemon prio=5 tid=487 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"timer7" daemon prio=5 tid=942 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-DatanodeReportManager-3" daemon prio=5 tid=712 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 89 on default port 15002" daemon prio=5 tid=345 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 24 on default port 15000" daemon prio=5 tid=80 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 99 on default port 15001" daemon prio=5 tid=255 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 29 on default port 15009" daemon prio=5 tid=498 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 6 on default port 15001" daemon prio=5 tid=162 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 99 on default port 15009" daemon prio=5 tid=568 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 7 on default port 15000" daemon prio=5 tid=63 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"OverReplicatedProcessor" daemon prio=5 tid=27 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:174)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=812 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2139799663-403" daemon prio=5 tid=403 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$666/1273065937.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-CommandProcessorThread" daemon prio=5 tid=602 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:684)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1468/14604698.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"SSL Certificates Store Monitor" daemon prio=5 tid=1065 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server Responder" daemon prio=5 tid=621 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"IPC Server handler 48 on default port 15001" daemon prio=5 tid=204 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-executor-2" daemon prio=5 tid=866 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp462164160-615" daemon prio=5 tid=615 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 27 on default port 15002" daemon prio=5 tid=283 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15030" daemon prio=5 tid=651 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Socket Reader #1 for port 15012"  prio=5 tid=591 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 97 on default port 15009" daemon prio=5 tid=566 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"grpc-default-executor-3" daemon prio=5 tid=911 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-SstFilteringService#0" daemon prio=5 tid=398 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ReconTaskThread-0"  prio=5 tid=1035 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 78 on default port 15002" daemon prio=5 tid=334 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 7 on default port 15009" daemon prio=5 tid=476 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-ChunkWriter-2-0" daemon prio=5 tid=807 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 40 on default port 15002" daemon prio=5 tid=296 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 77 on default port 15002" daemon prio=5 tid=333 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 47 on default port 15002" daemon prio=5 tid=303 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 33 on default port 15002" daemon prio=5 tid=289 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 49 on default port 15002" daemon prio=5 tid=305 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 59 on default port 15009" daemon prio=5 tid=528 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 3 on default port 15004" daemon prio=5 tid=415 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=649 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"qtp226609535-643" daemon prio=5 tid=643 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 55 on default port 15000" daemon prio=5 tid=111 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 14 on default port 15000" daemon prio=5 tid=70 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=718 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 94 on default port 15009" daemon prio=5 tid=563 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 99 on default port 15000" daemon prio=5 tid=155 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 6 on default port 15002" daemon prio=5 tid=262 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderStateImpl" daemon prio=5 tid=1136 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:164)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:762)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-ChunkWriter-3-0" daemon prio=5 tid=808 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 88 on default port 15000" daemon prio=5 tid=144 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 82 on default port 15002" daemon prio=5 tid=338 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"cc1e4d3c-2283-4c28-b737-db868cb45369-DatanodeReportManager-3" daemon prio=5 tid=628 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor6" daemon prio=5 tid=790 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:353)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:338)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:160)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:149)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$626/349677922.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 97 on default port 15001" daemon prio=5 tid=253 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 96 on default port 15009" daemon prio=5 tid=565 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-ChunkWriter-0-0" daemon prio=5 tid=805 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 26 on default port 15002" daemon prio=5 tid=282 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1360692538-460" daemon prio=5 tid=460 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.reservedWait(ReservedThreadExecutor.java:324)
        at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:399)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 72 on default port 15002" daemon prio=5 tid=328 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 65 on default port 15009" daemon prio=5 tid=534 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=444 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=794 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 66 on default port 15009" daemon prio=5 tid=535 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 60 on default port 15009" daemon prio=5 tid=529 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-StateMachineUpdater" daemon prio=5 tid=1146 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:211)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:180)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=813 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"d1715241-1ffa-4146-b219-94c9c0fc171f-CommandProcessorThread" daemon prio=5 tid=658 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$4(DatanodeStateMachine.java:684)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$1468/14604698.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=47 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp226609535-644" daemon prio=5 tid=644 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 62 on default port 15000" daemon prio=5 tid=118 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d1715241-1ffa-4146-b219-94c9c0fc171f-DatanodeStateMachineTaskThread-1"  prio=5 tid=758 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ReplicationMonitor" daemon prio=5 tid=25 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:931)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager$$Lambda$575/1322600748.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 15039" daemon prio=5 tid=676 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Recon-FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=451 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:269)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:253)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 36 on default port 15001" daemon prio=5 tid=192 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"cc1e4d3c-2283-4c28-b737-db868cb45369-CloseContainerThread-1"  prio=5 tid=1061 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 68 on default port 15002" daemon prio=5 tid=324 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-ChunkWriter-1-0" daemon prio=5 tid=787 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 23 on default port 15009" daemon prio=5 tid=492 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 30 on default port 15001" daemon prio=5 tid=186 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 72 on default port 15009" daemon prio=5 tid=541 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp2041857678-586" daemon prio=5 tid=586 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 15002" daemon prio=5 tid=258 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 54 on default port 15002" daemon prio=5 tid=310 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 4 on default port 15000" daemon prio=5 tid=60 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 82 on default port 15009" daemon prio=5 tid=551 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 4 on default port 15002" daemon prio=5 tid=260 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 0 on default port 15000" daemon prio=5 tid=56 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-CloseContainerForCloseContainerEventHandler" daemon prio=5 tid=1047 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 85 on default port 15001" daemon prio=5 tid=241 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Recon-SyncSCMContainerInfo-0"  prio=5 tid=468 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Recon-EventQueue-StaleNodeForReconStaleNodeHandler" daemon prio=5 tid=830 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 15000" daemon prio=5 tid=73 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 16 on default port 15004" daemon prio=5 tid=428 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 14 on default port 15009" daemon prio=5 tid=483 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 58 on default port 15002" daemon prio=5 tid=314 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 5 on default port 15002" daemon prio=5 tid=261 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 54 on default port 15009" daemon prio=5 tid=523 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp1115963634-366" daemon prio=5 tid=366 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 63 on default port 15002" daemon prio=5 tid=319 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 82 on default port 15001" daemon prio=5 tid=238 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 69 on default port 15009" daemon prio=5 tid=538 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Client (583361835) connection to 0.0.0.0/0.0.0.0:15002 from runner" daemon prio=5 tid=719 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1026)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1077)
"d1715241-1ffa-4146-b219-94c9c0fc171f-DatanodeReportManager-1" daemon prio=5 tid=654 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 46 on default port 15001" daemon prio=5 tid=202 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 51 on default port 15000" daemon prio=5 tid=107 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-cacheEviction-AwaitToRun" daemon prio=5 tid=1143 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-23471f48-1"  prio=5 tid=368 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 15000"  prio=5 tid=41 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1346)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1325)
"IPC Server handler 81 on default port 15000" daemon prio=5 tid=137 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 15 on default port 15004" daemon prio=5 tid=427 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-groupManagement"  prio=5 tid=868 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-EndpointStateMachineTaskThread-/0.0.0.0:15002-0 "  prio=5 tid=717 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"cc1e4d3c-2283-4c28-b737-db868cb45369-ChunkWriter-3-0" daemon prio=5 tid=751 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 15004" daemon prio=5 tid=422 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"59c3495a-7636-40f9-8dfa-c28be8e98abd-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=577 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-SegmentedRaftLogWorker"  prio=5 tid=1127 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$997/2039256444.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 66 on default port 15000" daemon prio=5 tid=122 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 96 on default port 15000" daemon prio=5 tid=152 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server idle connection scanner for port 15048" daemon prio=5 tid=704 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"pool-97-thread-1" daemon prio=5 tid=726 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 67 on default port 15000" daemon prio=5 tid=123 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Parameter Sending Thread for 0.0.0.0/0.0.0.0:15002" daemon prio=5 tid=720 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferQueue.awaitFulfill(SynchronousQueue.java:764)
        at java.util.concurrent.SynchronousQueue$TransferQueue.transfer(SynchronousQueue.java:695)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at org.apache.hadoop.ipc.Client$Connection$RpcRequestSender.run(Client.java:1105)
        at java.lang.Thread.run(Thread.java:750)
"qtp963735699-668" daemon prio=5 tid=668 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 21 on default port 15001" daemon prio=5 tid=177 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 94 on default port 15002" daemon prio=5 tid=350 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 39 on default port 15009" daemon prio=5 tid=508 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"d1715241-1ffa-4146-b219-94c9c0fc171f-EndpointStateMachineTaskThread-/0.0.0.0:15009-0 "  prio=5 tid=760 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Timer-1" daemon prio=5 tid=433 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"grpc-default-worker-ELG-3-3" daemon prio=5 tid=860 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:312)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:376)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"RatisPipelineUtilsThread-0"  prio=5 tid=22 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.run(BackgroundPipelineCreator.java:179)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator$$Lambda$559/1168882980.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 15021" daemon prio=5 tid=623 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"prometheus" daemon prio=5 tid=369 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.hadoop.metrics2.impl.SinkQueue.waitForData(SinkQueue.java:114)
        at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:83)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:135)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:89)
"pool-218-thread-1"  prio=5 tid=692 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 58 on default port 15000" daemon prio=5 tid=114 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"junit-jupiter-timeout-watcher"  prio=10 tid=1038 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 34 on default port 15009" daemon prio=5 tid=503 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1@group-C5BA1605619E-cacheEviction-AwaitToRun" daemon prio=5 tid=385 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:48)
        at org.apache.ratis.util.AwaitToRun$RunnableImpl.run(AwaitToRun.java:47)
        at java.lang.Thread.run(Thread.java:750)
"qtp2041857678-583-acceptor-0@30bfafbb-ServerConnector@3c437652{HTTP/1.1, (http/1.1)}{0.0.0.0:15011}" daemon prio=3 tid=583 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"pool-166-thread-1"  prio=5 tid=636 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 64 on default port 15002" daemon prio=5 tid=320 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server Responder" daemon prio=5 tid=382 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1582)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1565)
"d1715241-1ffa-4146-b219-94c9c0fc171f-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=633 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"d1715241-1ffa-4146-b219-94c9c0fc171f-BlockDeletingService#1" daemon prio=5 tid=776 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 44 on default port 15002" daemon prio=5 tid=300 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler" daemon prio=5 tid=1046 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7->cc1e4d3c-2283-4c28-b737-db868cb45369-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=1166 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:65)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:286)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:254)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:80)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1703/982418488.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 45 on default port 15009" daemon prio=5 tid=514 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule" daemon prio=5 tid=817 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 52 on default port 15001" daemon prio=5 tid=208 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"qtp462164160-612-acceptor-0@5809f453-ServerConnector@858ef7c{HTTP/1.1, (http/1.1)}{0.0.0.0:15020}" daemon prio=3 tid=612 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-DatanodeReportManager-1" daemon prio=5 tid=682 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 15001" daemon prio=5 tid=161 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"om1-KeyDeletingService#0" daemon prio=5 tid=395 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 31 on default port 15009" daemon prio=5 tid=500 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Client (583361835) connection to 0.0.0.0/0.0.0.0:15009 from runner" daemon prio=5 tid=721 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1026)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1077)
"IPC Server handler 97 on default port 15002" daemon prio=5 tid=353 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 89 on default port 15009" daemon prio=5 tid=558 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 8 on default port 15000" daemon prio=5 tid=64 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"a40aef6e-dfc7-4141-9a41-17d72bf4eeff-ChunkReader-ELG-0" daemon prio=5 tid=791 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:316)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:373)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-SegmentedRaftLogWorker"  prio=5 tid=1123 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:299)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$997/2039256444.run(Unknown Source)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 32 on default port 15001" daemon prio=5 tid=188 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 2 on default port 15001" daemon prio=5 tid=158 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Session-HouseKeeper-6ab23bf0-1"  prio=5 tid=617 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 94 on default port 15001" daemon prio=5 tid=250 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"IPC Server handler 9 on default port 15004" daemon prio=5 tid=421 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"SSL Certificates Store Monitor" daemon prio=5 tid=1119 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"d1715241-1ffa-4146-b219-94c9c0fc171f-ContainerReplicationThread-0" daemon prio=5 tid=1110 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.PriorityBlockingQueue.take(PriorityBlockingQueue.java:549)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-7a7d3cf4-1"  prio=5 tid=464 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 96 on default port 15002" daemon prio=5 tid=352 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)
"Hadoop-Metrics-Updater-0" daemon prio=5 tid=34 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SSL Certificates Store Monitor" daemon prio=5 tid=439 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.util.TimerThread.mainLoop(Timer.java:526)
        at java.util.TimerThread.run(Timer.java:505)
"BackgroundPipelineScrubber" daemon prio=5 tid=23 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:107)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$561/2086062353.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 15000" daemon prio=5 tid=68 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3014)

2024-04-06 10:34:43,995 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] INFO  scm.ReconContainerManager (ReconContainerManager.java:addNewContainer(246)) - Successfully added container #2 to Recon.
2024-04-06 10:34:43,996 [Recon-FixedThreadPoolWithAffinityExecutor-9-0] WARN  events.FixedThreadPoolWithAffinityExecutor (FixedThreadPoolWithAffinityExecutor.java:run(289)) - Event taken long execution time 23 millisec, cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), {type: ICR, size: 1}
Connecting to Recon: http://0.0.0.0:15008/api/v1/triggerdbsync/om ...
2024-04-06 10:34:44,018 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:44,019 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:44,019 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 15 
2024-04-06 10:34:44,031 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 2, SequenceNumber diff: 7, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:44,031 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 7 records
2024-04-06 10:34:44,111 [ReconTaskThread-0] INFO  tasks.OmTableInsightTask (OmTableInsightTask.java:process(211)) - Completed a 'process' run of OmTableInsightTask.
2024-04-06 10:34:44,112 [ReconTaskThread-0] INFO  tasks.NSSummaryTaskWithFSO (NSSummaryTaskWithFSO.java:processWithFSO(165)) - Completed a process run of NSSummaryTaskWithFSO
2024-04-06 10:34:44,113 [ReconTaskThread-0] INFO  tasks.NSSummaryTaskWithLegacy (NSSummaryTaskWithLegacy.java:processWithLegacy(130)) - Completed a process run of NSSummaryTaskWithLegacy
2024-04-06 10:34:44,113 [ReconTaskThread-0] INFO  tasks.NSSummaryTaskWithOBS (NSSummaryTaskWithOBS.java:processWithOBS(206)) - Completed a process run of NSSummaryTaskWithOBS
2024-04-06 10:34:44,120 [ReconTaskThread-0] INFO  tasks.ContainerKeyMapperTask (ContainerKeyMapperTask.java:process(261)) - ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
2024-04-06 10:34:44,145 [ReconTaskThread-0] INFO  tasks.FileSizeCountTask (FileSizeCountTask.java:process(201)) - Completed a 'process' run of FileSizeCountTask.
2024-04-06 10:34:44,266 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:44,268 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 2 containers.
2024-04-06 10:34:44,268 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:44,268 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:44,268 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:44,268 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:44,268 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:44,268 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:44,268 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:44,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 2 milliseconds for processing 2 containers.
2024-04-06 10:34:45,030 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-04-06 10:34:45,030 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-04-06 10:34:45,030 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-04-06 10:34:45,031 [main] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/data-0/hdds) is shutting down. 
2024-04-06 10:34:45,031 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-04-06 10:34:45,032 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/data-0/hdds, DS-0073f244-62c3-44f0-a0dd-f946c3c303ab) exiting.
2024-04-06 10:34:45,033 [main] INFO  ozoneimpl.OnDemandContainerDataScanner (OnDemandContainerDataScanner.java:shutdownScanner(206)) - On-demand container scanner is shutting down.
2024-04-06 10:34:45,037 [main] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(416)) - cc1e4d3c-2283-4c28-b737-db868cb45369: close
2024-04-06 10:34:45,038 [cc1e4d3c-2283-4c28-b737-db868cb45369-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7: shutdown
2024-04-06 10:34:45,038 [cc1e4d3c-2283-4c28-b737-db868cb45369-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C: shutdown
2024-04-06 10:34:45,038 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - cc1e4d3c-2283-4c28-b737-db868cb45369: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-04-06 10:34:45,038 [cc1e4d3c-2283-4c28-b737-db868cb45369-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-82A21D15CBF7,id=cc1e4d3c-2283-4c28-b737-db868cb45369
2024-04-06 10:34:45,039 [cc1e4d3c-2283-4c28-b737-db868cb45369-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - cc1e4d3c-2283-4c28-b737-db868cb45369: shutdown cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-FollowerState
2024-04-06 10:34:45,039 [cc1e4d3c-2283-4c28-b737-db868cb45369-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-StateMachineUpdater: set stopIndex = 0
2024-04-06 10:34:45,039 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-FollowerState was interrupted
2024-04-06 10:34:45,040 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-82A21D15CBF7: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7/sm/snapshot.1_0
2024-04-06 10:34:45,038 [cc1e4d3c-2283-4c28-b737-db868cb45369-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A7988BF88C1C,id=cc1e4d3c-2283-4c28-b737-db868cb45369
2024-04-06 10:34:45,042 [cc1e4d3c-2283-4c28-b737-db868cb45369-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - cc1e4d3c-2283-4c28-b737-db868cb45369: shutdown cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-LeaderStateImpl
2024-04-06 10:34:45,041 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-82A21D15CBF7: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7/sm/snapshot.1_0 took: 1 ms
2024-04-06 10:34:45,042 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-StateMachineUpdater: Took a snapshot at index 0
2024-04-06 10:34:45,042 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-04-06 10:34:45,042 [cc1e4d3c-2283-4c28-b737-db868cb45369-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-PendingRequests: sendNotLeaderResponses
2024-04-06 10:34:45,043 [cc1e4d3c-2283-4c28-b737-db868cb45369-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(427)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7: applyIndex: 0
2024-04-06 10:34:45,043 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-04-06 10:34:45,046 [grpc-default-executor-3] WARN  server.GrpcClientProtocolService (LogUtils.java:warn(121)) - 0-OrderedRequestStreamObserver0: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2024-04-06 10:34:45,047 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - cc1e4d3c-2283-4c28-b737-db868cb45369: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-04-06 10:34:45,047 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - cc1e4d3c-2283-4c28-b737-db868cb45369: shutdown server GrpcServerProtocolService now
2024-04-06 10:34:45,050 [grpc-default-executor-0] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(121)) - cc1e4d3c-2283-4c28-b737-db868cb45369: APPEND_ENTRIES onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2024-04-06 10:34:45,051 [grpc-default-executor-6] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(121)) - cc1e4d3c-2283-4c28-b737-db868cb45369: APPEND_ENTRIES onError, lastRequest: 59c3495a-7636-40f9-8dfa-c28be8e98abd->cc1e4d3c-2283-4c28-b737-db868cb45369#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "59c3495a-7636-40f9-8dfa-c28be8e98abd"
address: "10.1.0.10:15016"
priority: 1
dataStreamAddress: "10.1.0.10:15017"
clientAddress: "10.1.0.10:15014"
adminAddress: "10.1.0.10:15015"
startupRole: FOLLOWER
,id: "a40aef6e-dfc7-4141-9a41-17d72bf4eeff"
address: "10.1.0.10:15043"
dataStreamAddress: "10.1.0.10:15044"
clientAddress: "10.1.0.10:15041"
adminAddress: "10.1.0.10:15042"
startupRole: FOLLOWER
,id: "cc1e4d3c-2283-4c28-b737-db868cb45369"
address: "10.1.0.10:15025"
dataStreamAddress: "10.1.0.10:15026"
clientAddress: "10.1.0.10:15023"
adminAddress: "10.1.0.10:15024"
startupRole: FOLLOWER
, old:): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2024-04-06 10:34:45,054 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - cc1e4d3c-2283-4c28-b737-db868cb45369: shutdown server GrpcServerProtocolService successfully
2024-04-06 10:34:45,054 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - cc1e4d3c-2283-4c28-b737-db868cb45369: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-04-06 10:34:45,055 [cc1e4d3c-2283-4c28-b737-db868cb45369-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-StateMachineUpdater: set stopIndex = 3
2024-04-06 10:34:45,056 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(121)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7->cc1e4d3c-2283-4c28-b737-db868cb45369-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2024-04-06 10:34:45,057 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-A7988BF88C1C: Taking a snapshot at:(t:1, i:3) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/b495966f-4ec9-40fc-9038-a7988bf88c1c/sm/snapshot.1_3
2024-04-06 10:34:45,059 [grpc-default-executor-5] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(217)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7->cc1e4d3c-2283-4c28-b737-db868cb45369-GrpcLogAppender: Follower failed (request=null, errorCount=1); keep nextIndex (1) unchanged and retry.
2024-04-06 10:34:45,059 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-A7988BF88C1C: Finished taking a snapshot at:(t:1, i:3) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/b495966f-4ec9-40fc-9038-a7988bf88c1c/sm/snapshot.1_3 took: 2 ms
2024-04-06 10:34:45,059 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-StateMachineUpdater: Took a snapshot at index 3
2024-04-06 10:34:45,060 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - cc1e4d3c-2283-4c28-b737-db868cb45369: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-04-06 10:34:45,060 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 3
2024-04-06 10:34:45,060 [cc1e4d3c-2283-4c28-b737-db868cb45369-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(427)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C: applyIndex: 3
2024-04-06 10:34:45,061 [cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-04-06 10:34:45,071 [cc1e4d3c-2283-4c28-b737-db868cb45369-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xe72b909d, L:/0.0.0.0:15026] CLOSE
2024-04-06 10:34:45,071 [cc1e4d3c-2283-4c28-b737-db868cb45369-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xe72b909d, L:/0.0.0.0:15026] INACTIVE
2024-04-06 10:34:45,071 [cc1e4d3c-2283-4c28-b737-db868cb45369-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xe72b909d, L:/0.0.0.0:15026] UNREGISTERED
2024-04-06 10:34:45,151 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:45,151 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:45,151 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-04-06 10:34:45,153 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:45,153 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:45,269 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 0 milliseconds to process 0 existing database records.
2024-04-06 10:34:45,271 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 2 containers.
2024-04-06 10:34:45,271 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:45,271 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:45,271 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:45,271 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:45,271 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:45,271 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:45,272 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:45,505 [cc1e4d3c-2283-4c28-b737-db868cb45369-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7-SegmentedRaftLogWorker close()
2024-04-06 10:34:45,643 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-04-06 10:34:45,977 [cc1e4d3c-2283-4c28-b737-db868cb45369-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C-SegmentedRaftLogWorker close()
2024-04-06 10:34:45,978 [JvmPauseMonitor4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-cc1e4d3c-2283-4c28-b737-db868cb45369: Stopped
2024-04-06 10:34:46,154 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:46,155 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:46,155 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-04-06 10:34:46,157 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:46,157 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:46,272 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:46,275 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 2 containers.
2024-04-06 10:34:46,275 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:46,275 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:46,275 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:46,275 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:46,275 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:46,275 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:46,275 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:46,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-04-06 10:34:47,158 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:47,159 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:47,159 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-04-06 10:34:47,160 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:47,160 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:47,276 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:47,278 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 2 containers.
2024-04-06 10:34:47,278 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:47,278 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:47,278 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:47,278 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:47,278 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:47,278 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:47,279 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:47,644 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-04-06 10:34:47,991 [main] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-4675313e-af28-48bb-b976-c300dd20b142/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-0073f244-62c3-44f0-a0dd-f946c3c303ab/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-94805b0f-2d69-4e9a-b453-7c1f770fc019/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-db18787f-e7de-4e98-b685-d88b6726d128/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-efa4f3ca-3766-4044-9fcf-6b2e56cb6fe0/container.db]
2024-04-06 10:34:47,995 [main] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-0073f244-62c3-44f0-a0dd-f946c3c303ab/container.db from cache
2024-04-06 10:34:47,996 [main] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(451)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-0073f244-62c3-44f0-a0dd-f946c3c303ab/container.db for volume DS-0073f244-62c3-44f0-a0dd-f946c3c303ab
2024-04-06 10:34:47,996 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-04-06 10:34:47,996 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-04-06 10:34:47,997 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(638)) - Ozone container server stopped.
2024-04-06 10:34:48,000 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@59692457{hddsDatanode,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode}
2024-04-06 10:34:48,002 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@858ef7c{HTTP/1.1, (http/1.1)}{0.0.0.0:15020}
2024-04-06 10:34:48,003 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-04-06 10:34:48,003 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2de15438{static,/static,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/static,STOPPED}
2024-04-06 10:34:48,003 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2e0e9e3e{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-04-06 10:34:48,005 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-04-06 10:34:48,005 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15021
2024-04-06 10:34:48,006 [IPC Server listener on 15021] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15021
2024-04-06 10:34:48,006 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-04-06 10:34:48,007 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [cc1e4d3c-2283-4c28-b737-db868cb45369]
2024-04-06 10:34:48,032 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) moved to stale state. Finalizing its pipelines [PipelineID=8be94057-6f6e-4ca0-8619-73828bace674, PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7, PipelineID=b495966f-4ec9-40fc-9038-a7988bf88c1c, PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7]
2024-04-06 10:34:48,032 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) moved to stale state. Finalizing its pipelines [PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7, PipelineID=b495966f-4ec9-40fc-9038-a7988bf88c1c]
2024-04-06 10:34:48,033 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=8be94057-6f6e-4ca0-8619-73828bace674 moved to CLOSED state
2024-04-06 10:34:48,033 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 moved to CLOSED state
2024-04-06 10:34:48,034 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 moved to CLOSED state
2024-04-06 10:34:48,034 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(484)) - Container #2 closed for pipeline=PipelineID=b495966f-4ec9-40fc-9038-a7988bf88c1c
2024-04-06 10:34:48,034 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #2, current state: CLOSING
2024-04-06 10:34:48,034 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=b495966f-4ec9-40fc-9038-a7988bf88c1c moved to CLOSED state
2024-04-06 10:34:48,034 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(484)) - Container #2 closed for pipeline=PipelineID=b495966f-4ec9-40fc-9038-a7988bf88c1c
2024-04-06 10:34:48,034 [Recon-EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(88)) - Close container Event triggered for container : #2, current state: CLOSING
2024-04-06 10:34:48,035 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=b495966f-4ec9-40fc-9038-a7988bf88c1c moved to CLOSED state
2024-04-06 10:34:48,036 [Recon-EventQueue-DatanodeCommandForReconNodeManager] DEBUG scm.ReconNodeManager (ReconNodeManager.java:onMessage(213)) - Ignoring unsupported command closeContainerCommand for Datanode cc1e4d3c-2283-4c28-b737-db868cb45369.
2024-04-06 10:34:48,036 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 moved to CLOSED state
2024-04-06 10:34:48,039 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 10 pipelines in house.
2024-04-06 10:34:48,040 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(152)) - Removing invalid pipeline PipelineID=6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246 from Recon.
2024-04-06 10:34:48,041 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 6caf9e5d-c9c4-4f3e-8e90-87ad1b61a246, Nodes: a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:59c3495a-7636-40f9-8dfa-c28be8e98abd, CreationTimestamp2024-04-06T10:33:57.625Z[Etc/UTC]] removed.
2024-04-06 10:34:48,041 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(152)) - Removing invalid pipeline PipelineID=8be94057-6f6e-4ca0-8619-73828bace674 from Recon.
2024-04-06 10:34:48,041 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 8be94057-6f6e-4ca0-8619-73828bace674, Nodes: cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:cc1e4d3c-2283-4c28-b737-db868cb45369, CreationTimestamp2024-04-06T10:33:38.544Z[Etc/UTC]] removed.
2024-04-06 10:34:48,042 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(152)) - Removing invalid pipeline PipelineID=47341687-34d7-44e9-a74c-836518d32a71 from Recon.
2024-04-06 10:34:48,042 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 47341687-34d7-44e9-a74c-836518d32a71, Nodes: d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:d1715241-1ffa-4146-b219-94c9c0fc171f, CreationTimestamp2024-04-06T10:33:38.684Z[Etc/UTC]] removed.
2024-04-06 10:34:48,042 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(152)) - Removing invalid pipeline PipelineID=15039d4b-d7f6-4769-9a85-becc45517e23 from Recon.
2024-04-06 10:34:48,043 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 15039d4b-d7f6-4769-9a85-becc45517e23, Nodes: ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2, CreationTimestamp2024-04-06T10:33:38.868Z[Etc/UTC]] removed.
2024-04-06 10:34:48,043 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:lambda$removeInvalidPipelines$1(152)) - Removing invalid pipeline PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7 from Recon.
2024-04-06 10:34:48,043 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: b4229e37-69d0-4c7f-a467-673fb5e812e7, Nodes: cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:59c3495a-7636-40f9-8dfa-c28be8e98abd, CreationTimestamp2024-04-06T10:33:38.689Z[Etc/UTC]] removed.
2024-04-06 10:34:48,045 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 9 milliseconds.
2024-04-06 10:34:48,162 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:48,162 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:48,162 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-04-06 10:34:48,164 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:48,164 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:48,279 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:48,282 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 2 containers.
2024-04-06 10:34:48,282 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:48,282 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:48,282 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:48,282 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:48,282 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:48,282 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:48,282 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:48,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 2, pipelineID: PipelineID=b495966f-4ec9-40fc-9038-a7988bf88c1c, force: false] for container ContainerInfo{id=#2, state=CLOSING, stateEnterTime=2024-04-06T10:34:48.033Z, pipelineID=PipelineID=b495966f-4ec9-40fc-9038-a7988bf88c1c, owner=omServiceIdDefault} to cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) with datanode deadline 1712400258645 and scm deadline 1712400288645
2024-04-06 10:34:48,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-04-06 10:34:49,007 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [cc1e4d3c-2283-4c28-b737-db868cb45369]
2024-04-06 10:34:49,165 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:49,165 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:49,166 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-04-06 10:34:49,167 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:49,167 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:49,283 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:49,285 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 2 containers.
2024-04-06 10:34:49,285 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:49,285 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:49,285 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:49,285 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:49,285 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:49,285 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:49,285 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:49,645 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 2, pipelineID: PipelineID=b495966f-4ec9-40fc-9038-a7988bf88c1c, force: false] for container ContainerInfo{id=#2, state=CLOSING, stateEnterTime=2024-04-06T10:34:48.033Z, pipelineID=PipelineID=b495966f-4ec9-40fc-9038-a7988bf88c1c, owner=omServiceIdDefault} to cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) with datanode deadline 1712400259645 and scm deadline 1712400289645
2024-04-06 10:34:49,646 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-04-06 10:34:50,008 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [cc1e4d3c-2283-4c28-b737-db868cb45369]
2024-04-06 10:34:50,057 [timer1] WARN  server.GrpcLogAppender (LogUtils.java:warn(121)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7->cc1e4d3c-2283-4c28-b737-db868cb45369-AppendLogResponseHandler: Failed appendEntries (Repeated 10 times in the last 5.001s): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-04-06 10:34:50,059 [timer2] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(217)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7->cc1e4d3c-2283-4c28-b737-db868cb45369-GrpcLogAppender: Follower failed (request=null, errorCount=10); keep nextIndex (1) unchanged and retry. (Repeated 10 times in the last 5.000s)
2024-04-06 10:34:50,168 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:50,169 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:50,169 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-04-06 10:34:50,170 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:50,170 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:50,286 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 1 milliseconds to process 0 existing database records.
2024-04-06 10:34:50,288 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 2 milliseconds for processing 2 containers.
2024-04-06 10:34:50,288 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:50,288 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:50,288 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:50,288 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:50,289 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:50,289 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:50,289 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:50,542 [grpc-default-executor-4] WARN  server.GrpcLogAppender (LogUtils.java:warn(121)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7->cc1e4d3c-2283-4c28-b737-db868cb45369-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-04-06 10:34:50,544 [grpc-default-executor-5] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(217)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7->cc1e4d3c-2283-4c28-b737-db868cb45369-GrpcLogAppender: Follower failed (request=null, errorCount=11); keep nextIndex (1) unchanged and retry.
2024-04-06 10:34:50,646 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [closeContainerCommand: containerID: 2, pipelineID: PipelineID=b495966f-4ec9-40fc-9038-a7988bf88c1c, force: false] for container ContainerInfo{id=#2, state=CLOSING, stateEnterTime=2024-04-06T10:34:48.033Z, pipelineID=PipelineID=b495966f-4ec9-40fc-9038-a7988bf88c1c, owner=omServiceIdDefault} to cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) with datanode deadline 1712400260646 and scm deadline 1712400290646
2024-04-06 10:34:50,646 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-04-06 10:34:51,008 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 1 replicas on [cc1e4d3c-2283-4c28-b737-db868cb45369]
2024-04-06 10:34:51,035 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(95)) - A dead datanode is detected. cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:51,035 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(95)) - A dead datanode is detected. cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:51,036 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 close command to datanode 59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:34:51,037 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 close command to datanode a40aef6e-dfc7-4141-9a41-17d72bf4eeff
2024-04-06 10:34:51,037 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 close command to datanode cc1e4d3c-2283-4c28-b737-db868cb45369
2024-04-06 10:34:51,037 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 25178013-1aaf-49ea-9109-82a21d15cbf7, Nodes: 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:59c3495a-7636-40f9-8dfa-c28be8e98abd, CreationTimestamp2024-04-06T10:34:13.623Z[Etc/UTC]] removed.
2024-04-06 10:34:51,037 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: 25178013-1aaf-49ea-9109-82a21d15cbf7, Nodes: 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:59c3495a-7636-40f9-8dfa-c28be8e98abd, CreationTimestamp2024-04-06T10:34:13.623Z[Etc/UTC]] removed.
2024-04-06 10:34:51,037 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(270)) - Send pipeline:PipelineID=b495966f-4ec9-40fc-9038-a7988bf88c1c close command to datanode cc1e4d3c-2283-4c28-b737-db868cb45369
2024-04-06 10:34:51,037 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: b495966f-4ec9-40fc-9038-a7988bf88c1c, Nodes: cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:cc1e4d3c-2283-4c28-b737-db868cb45369, CreationTimestamp2024-04-06T10:34:06.624Z[Etc/UTC]] removed.
2024-04-06 10:34:51,038 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:removePipeline(459)) - Pipeline Pipeline[ Id: b495966f-4ec9-40fc-9038-a7988bf88c1c, Nodes: cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:cc1e4d3c-2283-4c28-b737-db868cb45369, CreationTimestamp2024-04-06T10:34:06.624Z[Etc/UTC]] removed.
2024-04-06 10:34:51,038 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(108)) - Clearing command queue of size 6 for DN cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:51,039 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(212)) - Removed a node: /default-rack/cc1e4d3c-2283-4c28-b737-db868cb45369
2024-04-06 10:34:51,039 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(108)) - Clearing command queue of size 0 for DN cc1e4d3c-2283-4c28-b737-db868cb45369(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)
2024-04-06 10:34:51,040 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(212)) - Removed a node: /default-rack/cc1e4d3c-2283-4c28-b737-db868cb45369
2024-04-06 10:34:51,049 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 2 milliseconds to process 0 existing database records.
2024-04-06 10:34:51,055 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:generateUnhealthyRecords(483)) - Non-empty container 2 is missing. It has 1 keys and 7 bytes used according to SCM metadata. Please visit Recon's missing container page for a list of keys (and their metadata) mapped to this container.
2024-04-06 10:34:51,057 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 9 milliseconds for processing 2 containers.
2024-04-06 10:34:51,058 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	TOTAL_KEYS -> 1 , CONTAINER_COUNT -> 1 , TOTAL_USED_BYTES -> 7 , 
2024-04-06 10:34:51,058 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:51,058 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:51,058 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:51,058 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	TOTAL_KEYS -> 1 , CONTAINER_COUNT -> 1 , TOTAL_USED_BYTES -> 7 , 
2024-04-06 10:34:51,058 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:51,058 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:51,060 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 3 pipelines in house.
2024-04-06 10:34:51,062 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 4 milliseconds.
2024-04-06 10:34:51,073 [Recon-EventQueue-DeadNodeForReconDeadNodeHandler] INFO  tasks.ContainerSizeCountTask (ContainerSizeCountTask.java:process(200)) - Completed a 'process' run of ContainerSizeCountTask.
2024-04-06 10:34:51,172 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:51,172 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:51,172 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-04-06 10:34:51,173 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:51,174 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:51,291 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 2 milliseconds to process 2 existing database records.
2024-04-06 10:34:51,293 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 2 containers.
2024-04-06 10:34:51,293 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:51,293 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:51,293 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:51,293 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:51,293 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:51,293 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:51,293 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:51,461 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7. Trying to get from SCM.
2024-04-06 10:34:51,461 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 is not found
2024-04-06 10:34:51,464 [IPC Server handler 0 on default port 15000] INFO  ipc.Server (Server.java:logException(3109)) - IPC Server handler 0 on default port 15000, call Call#902 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net:53534 / 10.1.0.10:53534
org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 not found
	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:158)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManagerImpl.getPipeline(PipelineStateManagerImpl.java:138)
	at sun.reflect.GeneratedMethodAccessor26.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeLocal(SCMHAInvocationHandler.java:92)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:75)
	at com.sun.proxy.$Proxy39.getPipeline(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.getPipeline(PipelineManagerImpl.java:335)
	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:761)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:960)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:607)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:89)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:232)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-04-06 10:34:51,473 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] ERROR scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(79)) - Could not find pipeline PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 at SCM.
2024-04-06 10:34:51,473 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] ERROR pipeline.PipelineReportHandler (PipelineReportHandler.java:onMessage(98)) - Could not find pipeline id: "25178013-1aaf-49ea-9109-82a21d15cbf7"
uuid128 {
  mostSigBits: 2672745723408108010
  leastSigBits: -7995716030635324425
}

2024-04-06 10:34:51,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-04-06 10:34:52,009 [main] INFO  container.TestHelper (TestHelper.java:countReplicas(427)) - Container 2 has 0 replicas on []
Connecting to Recon: http://0.0.0.0:15008/api/v1/containers/unhealthy/MISSING ...
2024-04-06 10:34:52,039 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2024-04-06 10:34:52,056 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(240)) - HddsDatanodeService host:fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net ip:10.1.0.10
2024-04-06 10:34:52,068 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2024-04-06 10:34:52,069 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(299)) - Datanode State Machine Task Thread Pool size 2
2024-04-06 10:34:52,070 [main] INFO  volume.HddsVolume (HddsVolume.java:<init>(125)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/data-0/hdds of storage type : DISK capacity : 9223372036854775807
2024-04-06 10:34:52,070 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/data-0/hdds to VolumeSet
2024-04-06 10:34:52,071 [main] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(173)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis to VolumeSet
2024-04-06 10:34:52,087 [ForkJoinPool.commonPool-worker-1] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(72)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-0073f244-62c3-44f0-a0dd-f946c3c303ab/container.db to cache
2024-04-06 10:34:52,088 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:loadDbStore(373)) - SchemaV3 db is loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-0073f244-62c3-44f0-a0dd-f946c3c303ab/container.db for volume DS-0073f244-62c3-44f0-a0dd-f946c3c303ab
2024-04-06 10:34:52,088 [main] INFO  ozoneimpl.OzoneContainer (HddsVolumeUtil.java:loadAllHddsVolumeDbStore(103)) - Load 1 volumes DbStore cost: 16ms
2024-04-06 10:34:52,091 [main] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2024-04-06 10:34:52,091 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2024-04-06 10:34:52,091 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 15024 (custom)
2024-04-06 10:34:52,091 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2024-04-06 10:34:52,091 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 15023 (custom)
2024-04-06 10:34:52,092 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2024-04-06 10:34:52,092 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 15025 (custom)
2024-04-06 10:34:52,092 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2024-04-06 10:34:52,092 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 8388608 (custom)
2024-04-06 10:34:52,092 [main] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2024-04-06 10:34:52,092 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:34:52,093 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2024-04-06 10:34:52,093 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2024-04-06 10:34:52,093 [main] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2024-04-06 10:34:52,096 [main] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2024-04-06 10:34:52,096 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2024-04-06 10:34:52,096 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2024-04-06 10:34:52,096 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2024-04-06 10:34:52,097 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.channel.inactive.grace-period = 10min (default)
2024-04-06 10:34:52,097 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2024-04-06 10:34:52,097 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = true (default)
2024-04-06 10:34:52,097 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2024-04-06 10:34:52,097 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for cc1e4d3c-2283-4c28-b737-db868cb45369-NettyServerStreamRpc-bossGroup; Thread size is 0.
2024-04-06 10:34:52,098 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2024-04-06 10:34:52,098 [main] INFO  netty.NettyUtils (NettyUtils.java:newEventLoopGroup(69)) - Create EpollEventLoopGroup for cc1e4d3c-2283-4c28-b737-db868cb45369-NettyServerStreamRpc-workerGroup; Thread size is 0.
2024-04-06 10:34:52,098 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2024-04-06 10:34:52,099 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2024-04-06 10:34:52,099 [main] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 15026 (custom)
2024-04-06 10:34:52,099 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:34:52,099 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.close.threshold = 60s (default)
2024-04-06 10:34:52,100 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:34:52,099 [cc1e4d3c-2283-4c28-b737-db868cb45369-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x31d644c3] REGISTERED
2024-04-06 10:34:52,100 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis] (custom)
2024-04-06 10:34:52,100 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2024-04-06 10:34:52,100 [main] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2024-04-06 10:34:52,100 [cc1e4d3c-2283-4c28-b737-db868cb45369-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x31d644c3] BIND: 0.0.0.0/0.0.0.0:15026
2024-04-06 10:34:52,101 [cc1e4d3c-2283-4c28-b737-db868cb45369-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x31d644c3, L:/0.0.0.0:15026] ACTIVE
2024-04-06 10:34:52,101 [cc1e4d3c-2283-4c28-b737-db868cb45369-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - cc1e4d3c-2283-4c28-b737-db868cb45369: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7
2024-04-06 10:34:52,101 [cc1e4d3c-2283-4c28-b737-db868cb45369-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - cc1e4d3c-2283-4c28-b737-db868cb45369: addNew group-82A21D15CBF7:[] returns group-82A21D15CBF7:java.util.concurrent.CompletableFuture@45048e14[Not completed]
2024-04-06 10:34:52,101 [cc1e4d3c-2283-4c28-b737-db868cb45369-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - cc1e4d3c-2283-4c28-b737-db868cb45369: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/b495966f-4ec9-40fc-9038-a7988bf88c1c
2024-04-06 10:34:52,101 [cc1e4d3c-2283-4c28-b737-db868cb45369-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:addNew(100)) - cc1e4d3c-2283-4c28-b737-db868cb45369: addNew group-A7988BF88C1C:[] returns group-A7988BF88C1C:java.util.concurrent.CompletableFuture@413b026c[Not completed]
2024-04-06 10:34:52,102 [cc1e4d3c-2283-4c28-b737-db868cb45369-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(264)) - cc1e4d3c-2283-4c28-b737-db868cb45369: found a subdirectory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/tmp
2024-04-06 10:34:52,102 [cc1e4d3c-2283-4c28-b737-db868cb45369-impl-thread1] INFO  server.RaftServer (RaftServerProxy.java:initGroupDir(269)) - cc1e4d3c-2283-4c28-b737-db868cb45369: The directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/ratis/tmp is not a group directory; ignoring it. 
2024-04-06 10:34:52,102 [main] INFO  replication.ReplicationServer (ReplicationServer.java:<init>(86)) - Initializing replication server with thread count = 10 queue length = 4096
2024-04-06 10:34:52,102 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - cc1e4d3c-2283-4c28-b737-db868cb45369: new RaftServerImpl for group-82A21D15CBF7:[] with ContainerStateMachine:uninitialized
2024-04-06 10:34:52,102 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:34:52,102 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-04-06 10:34:52,103 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-04-06 10:34:52,103 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-04-06 10:34:52,103 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:34:52,103 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-04-06 10:34:52,103 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:34:52,103 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-82A21D15CBF7: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-04-06 10:34:52,103 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-04-06 10:34:52,103 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-04-06 10:34:52,103 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-04-06 10:34:52,103 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-04-06 10:34:52,103 [main] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(141)) - GrpcServer channel type EpollServerSocketChannel
2024-04-06 10:34:52,104 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-04-06 10:34:52,104 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-04-06 10:34:52,105 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:build(157)) - Initializing replication supervisor with thread count = 10
2024-04-06 10:34:52,105 [main] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:nodeStateUpdated(312)) - Node state updated to IN_SERVICE, scaling executor pool size to 10
2024-04-06 10:34:52,107 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:34:52,107 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:34:52,107 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-04-06 10:34:52,107 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-04-06 10:34:52,107 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-04-06 10:34:52,107 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-04-06 10:34:52,108 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(223)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:15020
2024-04-06 10:34:52,108 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(110)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2024-04-06 10:34:52,108 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(256)) - cc1e4d3c-2283-4c28-b737-db868cb45369: new RaftServerImpl for group-A7988BF88C1C:[] with ContainerStateMachine:uninitialized
2024-04-06 10:34:52,108 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2024-04-06 10:34:52,108 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2024-04-06 10:34:52,108 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2024-04-06 10:34:52,108 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2024-04-06 10:34:52,108 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2024-04-06 10:34:52,108 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.member.majority-add = false (default)
2024-04-06 10:34:52,109 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2024-04-06 10:34:52,109 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServer$Division (ServerState.java:<init>(113)) - cc1e4d3c-2283-4c28-b737-db868cb45369@group-A7988BF88C1C: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
2024-04-06 10:34:52,109 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2024-04-06 10:34:52,109 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.timeout = 10s (default)
2024-04-06 10:34:52,109 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2024-04-06 10:34:52,109 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100ms (default)
2024-04-06 10:34:52,109 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.option = DEFAULT (default)
2024-04-06 10:34:52,109 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.read.read-after-write-consistent.write-index-cache.expiry-time = 60s (default)
2024-04-06 10:34:52,109 [main] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2024-04-06 10:34:52,110 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(86)) - Http request log for http.requests.hddsDatanode is not defined
2024-04-06 10:34:52,111 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1036)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2024-04-06 10:34:52,111 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2024-04-06 10:34:52,111 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2024-04-06 10:34:52,111 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2024-04-06 10:34:52,111 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2024-04-06 10:34:52,112 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2024-04-06 10:34:52,112 [cc1e4d3c-2283-4c28-b737-db868cb45369-groupManagement] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2024-04-06 10:34:52,112 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1012)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2024-04-06 10:34:52,112 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-04-06 10:34:52,112 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1020)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-04-06 10:34:52,112 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(189)) - HTTP server of hddsDatanode uses base directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/meta/webserver
2024-04-06 10:34:52,113 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1236)) - Jetty bound to port 15020
2024-04-06 10:34:52,113 [main] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 1.8.0_402-b06
2024-04-06 10:34:52,114 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2024-04-06 10:34:52,114 [main] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2024-04-06 10:34:52,114 [main] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2024-04-06 10:34:52,115 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@71357e64{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2024-04-06 10:34:52,116 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@68f500cd{static,/static,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/static,AVAILABLE}
2024-04-06 10:34:52,118 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@9dcfe2f{hddsDatanode,/,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode}
2024-04-06 10:34:52,120 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@d02ed56{HTTP/1.1, (http/1.1)}{0.0.0.0:15020}
2024-04-06 10:34:52,121 [main] INFO  server.Server (Server.java:doStart(415)) - Started @99920ms
2024-04-06 10:34:52,121 [main] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2024-04-06 10:34:52,121 [main] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(354)) - HTTP server of hddsDatanode listening at http://0.0.0.0:15020
2024-04-06 10:34:52,122 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2024-04-06 10:34:52,122 [main] INFO  ipc.Server (Server.java:<init>(1287)) - Listener at 0.0.0.0:15021
2024-04-06 10:34:52,122 [Socket Reader #1 for port 15021] INFO  ipc.Server (Server.java:run(1323)) - Starting Socket Reader #1 for port 15021
2024-04-06 10:34:52,124 [main] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(327)) - Datanode start with admins: [runner]
2024-04-06 10:34:52,124 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:start(77)) - RPC server for Client /0.0.0.0:15021
2024-04-06 10:34:52,125 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1562)) - IPC Server Responder: starting
2024-04-06 10:34:52,125 [IPC Server listener on 15021] INFO  ipc.Server (Server.java:run(1402)) - IPC Server listener on 15021: starting
2024-04-06 10:34:52,128 [cc1e4d3c-2283-4c28-b737-db868cb45369-DatanodeStateMachineDaemonThread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$1(555)) - Ozone container server started.
2024-04-06 10:34:52,130 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(396)) - Shutting down the Mini Ozone Cluster
2024-04-06 10:34:52,130 [cc1e4d3c-2283-4c28-b737-db868cb45369-DatanodeStateMachineTaskThread-0] INFO  statemachine.SCMConnectionManager (SCMConnectionManager.java:addReconServer(186)) - Adding Recon Server : /0.0.0.0:15009
2024-04-06 10:34:52,131 [main] INFO  db.CodecTestUtil (CodecTestUtil.java:gc(50)) - gc 0
2024-04-06 10:34:52,371 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: remove  FOLLOWER a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7:t1, leader=59c3495a-7636-40f9-8dfa-c28be8e98abd, voted=59c3495a-7636-40f9-8dfa-c28be8e98abd, raftlog=Memoized:a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-SegmentedRaftLog:OPENED:c0, conf=0: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null RUNNING
2024-04-06 10:34:52,372 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7: shutdown
2024-04-06 10:34:52,372 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-82A21D15CBF7,id=a40aef6e-dfc7-4141-9a41-17d72bf4eeff
2024-04-06 10:34:52,372 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: shutdown a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-FollowerState
2024-04-06 10:34:52,372 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-StateMachineUpdater: set stopIndex = 0
2024-04-06 10:34:52,373 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:52,373 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-82A21D15CBF7: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7/sm/snapshot.1_0
2024-04-06 10:34:52,382 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] INFO  scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(68)) - Unknown pipeline PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7. Trying to get from SCM.
2024-04-06 10:34:52,372 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-FollowerState was interrupted
2024-04-06 10:34:52,382 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-82A21D15CBF7: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7/sm/snapshot.1_0 took: 9 ms
2024-04-06 10:34:52,381 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:52,383 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-04-06 10:34:52,385 [cc1e4d3c-2283-4c28-b737-db868cb45369-DatanodeStateMachineTaskThread-0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(139)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/meta/datanode.id
2024-04-06 10:34:52,381 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 is not found
2024-04-06 10:34:52,383 [IPC Server handler 25 on default port 15000] INFO  ipc.Server (Server.java:logException(3109)) - IPC Server handler 25 on default port 15000, call Call#911 Retry#0 org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol.submitRequest from fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net:53534 / 10.1.0.10:53534
org.apache.hadoop.hdds.scm.pipeline.PipelineNotFoundException: PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 not found
	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateMap.getPipeline(PipelineStateMap.java:158)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineStateManagerImpl.getPipeline(PipelineStateManagerImpl.java:138)
	at sun.reflect.GeneratedMethodAccessor26.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invokeLocal(SCMHAInvocationHandler.java:92)
	at org.apache.hadoop.hdds.scm.ha.SCMHAInvocationHandler.invoke(SCMHAInvocationHandler.java:75)
	at com.sun.proxy.$Proxy39.getPipeline(Unknown Source)
	at org.apache.hadoop.hdds.scm.pipeline.PipelineManagerImpl.getPipeline(PipelineManagerImpl.java:335)
	at org.apache.hadoop.hdds.scm.server.SCMClientProtocolServer.getPipeline(SCMClientProtocolServer.java:761)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.getPipeline(StorageContainerLocationProtocolServerSideTranslatorPB.java:960)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.processRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:607)
	at org.apache.hadoop.hdds.server.OzoneProtocolMessageDispatcher.processRequest(OzoneProtocolMessageDispatcher.java:89)
	at org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocolServerSideTranslatorPB.submitRequest(StorageContainerLocationProtocolServerSideTranslatorPB.java:232)
	at org.apache.hadoop.hdds.protocol.proto.StorageContainerLocationProtocolProtos$StorageContainerLocationProtocolService$2.callBlockingMethod(StorageContainerLocationProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:484)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:595)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:573)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1227)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1094)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1017)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:3048)
2024-04-06 10:34:52,386 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:innerGetAndApplyDeltaUpdatesFromOM(485)) - Number of updates received from OM : 0, SequenceNumber diff: 0, SequenceNumber Lag from OM 0, isDBUpdateSuccess: true
2024-04-06 10:34:52,387 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(438)) - Delta updates received from OM : 1 loops, 0 records
2024-04-06 10:34:52,388 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 17 milliseconds to process 2 existing database records.
2024-04-06 10:34:52,386 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-StateMachineUpdater: Took a snapshot at index 0
2024-04-06 10:34:52,388 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-04-06 10:34:52,389 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7: applyIndex: 0
2024-04-06 10:34:52,389 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-04-06 10:34:52,392 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] ERROR scm.ReconPipelineReportHandler (ReconPipelineReportHandler.java:processPipelineReport(79)) - Could not find pipeline PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7 at SCM.
2024-04-06 10:34:52,392 [Recon-EventQueue-PipelineReportForReconPipelineReportHandler] ERROR pipeline.PipelineReportHandler (PipelineReportHandler.java:onMessage(98)) - Could not find pipeline id: "25178013-1aaf-49ea-9109-82a21d15cbf7"
uuid128 {
  mostSigBits: 2672745723408108010
  leastSigBits: -7995716030635324425
}

2024-04-06 10:34:52,396 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 8 milliseconds for processing 2 containers.
2024-04-06 10:34:52,396 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:52,396 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:52,396 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:52,396 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:52,396 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:52,396 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:52,396 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:52,460 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  server.RaftServer (RaftServerProxy.java:remove(111)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: remove    LEADER 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7:t1, leader=59c3495a-7636-40f9-8dfa-c28be8e98abd, voted=59c3495a-7636-40f9-8dfa-c28be8e98abd, raftlog=Memoized:59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-SegmentedRaftLog:OPENED:c0, conf=0: peers:[59c3495a-7636-40f9-8dfa-c28be8e98abd|10.1.0.10:15016, a40aef6e-dfc7-4141-9a41-17d72bf4eeff|10.1.0.10:15043, cc1e4d3c-2283-4c28-b737-db868cb45369|10.1.0.10:15025]|listeners:[], old=null RUNNING
2024-04-06 10:34:52,461 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7: shutdown
2024-04-06 10:34:52,461 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-82A21D15CBF7,id=59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:34:52,461 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: shutdown 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-LeaderStateImpl
2024-04-06 10:34:52,461 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-PendingRequests: sendNotLeaderResponses
2024-04-06 10:34:52,461 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7->a40aef6e-dfc7-4141-9a41-17d72bf4eeff-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7->a40aef6e-dfc7-4141-9a41-17d72bf4eeff-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-04-06 10:34:52,461 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7->cc1e4d3c-2283-4c28-b737-db868cb45369-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(289)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7->cc1e4d3c-2283-4c28-b737-db868cb45369-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2024-04-06 10:34:52,462 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-StateMachineUpdater: set stopIndex = 0
2024-04-06 10:34:52,462 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-82A21D15CBF7: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7/sm/snapshot.1_0
2024-04-06 10:34:52,463 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: Completed APPEND_ENTRIES, lastRequest: null
2024-04-06 10:34:52,463 [grpc-default-executor-4] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "59c3495a-7636-40f9-8dfa-c28be8e98abd"
  replyId: "a40aef6e-dfc7-4141-9a41-17d72bf4eeff"
  raftGroupId {
    id: "%\027\200\023\032\257I\352\221\t\202\242\035\025\313\367"
  }
  callId: 14
  success: true
}
term: 1
nextIndex: 1
matchIndex: 18446744073709551615
isHearbeat: true

2024-04-06 10:34:52,463 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-82A21D15CBF7: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7/sm/snapshot.1_0 took: 1 ms
2024-04-06 10:34:52,463 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-StateMachineUpdater: Took a snapshot at index 0
2024-04-06 10:34:52,463 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-04-06 10:34:52,463 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7: applyIndex: 0
2024-04-06 10:34:52,464 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-04-06 10:34:52,465 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(157)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: Completed APPEND_ENTRIES, lastRequest: 59c3495a-7636-40f9-8dfa-c28be8e98abd->a40aef6e-dfc7-4141-9a41-17d72bf4eeff#1-t1,previous=(t:0, i:0),leaderCommit=-1,initializing? false,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "59c3495a-7636-40f9-8dfa-c28be8e98abd"
address: "10.1.0.10:15016"
priority: 1
dataStreamAddress: "10.1.0.10:15017"
clientAddress: "10.1.0.10:15014"
adminAddress: "10.1.0.10:15015"
startupRole: FOLLOWER
,id: "a40aef6e-dfc7-4141-9a41-17d72bf4eeff"
address: "10.1.0.10:15043"
dataStreamAddress: "10.1.0.10:15044"
clientAddress: "10.1.0.10:15041"
adminAddress: "10.1.0.10:15042"
startupRole: FOLLOWER
,id: "cc1e4d3c-2283-4c28-b737-db868cb45369"
address: "10.1.0.10:15025"
dataStreamAddress: "10.1.0.10:15026"
clientAddress: "10.1.0.10:15023"
adminAddress: "10.1.0.10:15024"
startupRole: FOLLOWER
, old:)
2024-04-06 10:34:52,465 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:lambda$onCompleted$5(159)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: Completed APPEND_ENTRIES, lastReply: null
2024-04-06 10:34:52,465 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7->a40aef6e-dfc7-4141-9a41-17d72bf4eeff-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-04-06 10:34:52,467 [grpc-default-executor-0] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(546)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7->a40aef6e-dfc7-4141-9a41-17d72bf4eeff-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2024-04-06 10:34:52,476 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(412)) - Stopping the Mini Ozone Cluster
2024-04-06 10:34:52,476 [main] INFO  om.OzoneManager (OzoneManager.java:stop(2232)) - om1[localhost:15004]: Stopping Ozone Manager
2024-04-06 10:34:52,477 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15004
2024-04-06 10:34:52,478 [IPC Server listener on 15004] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15004
2024-04-06 10:34:52,478 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-04-06 10:34:52,479 [main] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:stop(594)) - Stopping org.apache.hadoop.ozone.om.ratis.OzoneManagerRatisServer@746ea728 at port 15007
2024-04-06 10:34:52,479 [main] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(416)) - om1: close
2024-04-06 10:34:52,479 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - om1: shutdown server GrpcServerProtocolService now
2024-04-06 10:34:52,479 [om1-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - om1@group-C5BA1605619E: shutdown
2024-04-06 10:34:52,479 [om1-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2024-04-06 10:34:52,480 [om1-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - om1: shutdown om1@group-C5BA1605619E-LeaderStateImpl
2024-04-06 10:34:52,480 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - om1: shutdown server GrpcServerProtocolService successfully
2024-04-06 10:34:52,480 [om1-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - om1@group-C5BA1605619E-PendingRequests: sendNotLeaderResponses
2024-04-06 10:34:52,485 [om1-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - om1@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 12
2024-04-06 10:34:52,485 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshotImpl(481)) -  applied = (t:1, i:11)
2024-04-06 10:34:52,485 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshotImpl(482)) -  skipped = 11
2024-04-06 10:34:52,485 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshotImpl(483)) - notified = (t:1, i:12)
2024-04-06 10:34:52,485 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshotImpl(484)) - snapshot = (t:1, i:12)
2024-04-06 10:34:52,487 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7-SegmentedRaftLogWorker close()
2024-04-06 10:34:52,488 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7
2024-04-06 10:34:52,488 [59c3495a-7636-40f9-8dfa-c28be8e98abd-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7
org.apache.ratis.protocol.exceptions.GroupMismatchException: 59c3495a-7636-40f9-8dfa-c28be8e98abd: group-82A21D15CBF7 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-04-06 10:34:52,496 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - om1@group-C5BA1605619E-StateMachineUpdater: Took a snapshot at index 12
2024-04-06 10:34:52,496 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - om1@group-C5BA1605619E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 12
2024-04-06 10:34:52,496 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(527)) - Stopping OzoneManagerStateMachine:om1:group-C5BA1605619E.
2024-04-06 10:34:52,496 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(517)) - Stopping OMDoubleBuffer flush thread
2024-04-06 10:34:52,496 [om1-OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:canFlush(581)) - OMDoubleBuffer flush thread om1-OMDoubleBufferFlushThread is interrupted and will exit.
2024-04-06 10:34:52,497 [om1-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(427)) - om1@group-C5BA1605619E: applyIndex: 11
2024-04-06 10:34:52,497 [om1@group-C5BA1605619E-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - om1@group-C5BA1605619E-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-04-06 10:34:52,504 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-PipelineCommandHandlerThread-0] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7-SegmentedRaftLogWorker close()
2024-04-06 10:34:52,507 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-PipelineCommandHandlerThread-0] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(496)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-82A21D15CBF7: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/25178013-1aaf-49ea-9109-82a21d15cbf7
2024-04-06 10:34:52,507 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-PipelineCommandHandlerThread-0] ERROR commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:lambda$handle$2(137)) - Can't close pipeline PipelineID=25178013-1aaf-49ea-9109-82a21d15cbf7
org.apache.ratis.protocol.exceptions.GroupMismatchException: a40aef6e-dfc7-4141-9a41-17d72bf4eeff: group-82A21D15CBF7 not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:154)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:364)
	at org.apache.ratis.server.impl.RaftServerProxy.getImpl(RaftServerProxy.java:373)
	at org.apache.ratis.server.impl.RaftServerProxy.getDivision(RaftServerProxy.java:386)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.getRaftPeersInPipeline(XceiverServerRatis.java:951)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.ClosePipelineCommandHandler.lambda$handle$2(ClosePipelineCommandHandler.java:114)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1640)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-04-06 10:34:52,634 [UnderReplicatedProcessor] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:chooseNodeInternal(672)) - No available node in (scope="/" excludedScope="[/default-rack/d1715241-1ffa-4146-b219-94c9c0fc171f, /default-rack/59c3495a-7636-40f9-8dfa-c28be8e98abd]" excludedNodes="[d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)]"  ancestorGen="1").
2024-04-06 10:34:52,634 [UnderReplicatedProcessor] WARN  algorithms.SCMContainerPlacementRackAware (SCMContainerPlacementRackAware.java:chooseNode(485)) - Failed to find the datanode for container. excludedNodes:[d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10)], affinityNode:
2024-04-06 10:34:52,634 [UnderReplicatedProcessor] INFO  scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:isValidNode(518)) - Datanode ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) is not chosen. Required metadata size is 0 and required data size is 5368709120 and NodeStatus is OperationalState: DECOMMISSIONED Health: HEALTHY OperationStateExpiry: 0
2024-04-06 10:34:52,635 [UnderReplicatedProcessor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(679)) - Sending command [replicateContainerCommand: containerId=1, replicaIndex=0, targetNode=a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10), priority=NORMAL] for container ContainerInfo{id=#1, state=CLOSED, stateEnterTime=2024-04-06T10:33:53.584Z, pipelineID=PipelineID=b4229e37-69d0-4c7f-a467-673fb5e812e7, owner=omServiceIdDefault} to d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) with datanode deadline 1712400262635 and scm deadline 1712400292635
2024-04-06 10:34:52,635 [UnderReplicatedProcessor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(138)) - Processed 1 containers with health state counts {UNDER_REPLICATED=1}, failed processing 0, deferred due to load 0
2024-04-06 10:34:52,647 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-04-06 10:34:52,999 [om1-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker close()
2024-04-06 10:34:52,999 [JvmPauseMonitor1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-om1: Stopped
2024-04-06 10:34:53,000 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service KeyDeletingService
2024-04-06 10:34:53,000 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service DirectoryDeletingService
2024-04-06 10:34:53,000 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service OpenKeyCleanupService
2024-04-06 10:34:53,001 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SstFilteringService
2024-04-06 10:34:53,001 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SnapshotDeletingService
2024-04-06 10:34:53,001 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service MultipartUploadCleanupService
2024-04-06 10:34:53,001 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SnapshotDirectoryCleaningService
2024-04-06 10:34:53,002 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@7181f2ac{ozoneManager,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2024-04-06 10:34:53,003 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@287d872b{HTTP/1.1, (http/1.1)}{0.0.0.0:15005}
2024-04-06 10:34:53,003 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-04-06 10:34:53,003 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@44c7d474{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2024-04-06 10:34:53,003 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5c2bc446{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-04-06 10:34:53,004 [main] INFO  rocksdiff.RocksDBCheckpointDiffer (RocksDBCheckpointDiffer.java:close(310)) - Shutting down CompactionDagPruningService.
2024-04-06 10:34:53,006 [main] INFO  snapshot.SnapshotDiffManager (SnapshotDiffManager.java:closeExecutorService(1657)) - Shutting down executorService: 'SnapDiffExecutor'
2024-04-06 10:34:53,006 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SnapshotDiffCleanupService
2024-04-06 10:34:53,008 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(471)) - Stopping the HddsDatanodes
2024-04-06 10:34:53,019 [ForkJoinPool.commonPool-worker-2] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-04-06 10:34:53,020 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-04-06 10:34:53,021 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-04-06 10:34:53,021 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-04-06 10:34:53,021 [ForkJoinPool.commonPool-worker-3] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-04-06 10:34:53,022 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-04-06 10:34:53,022 [ForkJoinPool.commonPool-worker-1] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-4675313e-af28-48bb-b976-c300dd20b142/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-0073f244-62c3-44f0-a0dd-f946c3c303ab/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-94805b0f-2d69-4e9a-b453-7c1f770fc019/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-db18787f-e7de-4e98-b685-d88b6726d128/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-efa4f3ca-3766-4044-9fcf-6b2e56cb6fe0/container.db]
2024-04-06 10:34:53,021 [ForkJoinPool.commonPool-worker-2] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/data-0/hdds) is shutting down. 
2024-04-06 10:34:53,023 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-04-06 10:34:53,024 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/data-0/hdds, DS-4675313e-af28-48bb-b976-c300dd20b142) exiting.
2024-04-06 10:34:53,022 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-04-06 10:34:53,022 [main] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-04-06 10:34:53,024 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-04-06 10:34:53,024 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-04-06 10:34:53,025 [main] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/data-0/hdds) is shutting down. 
2024-04-06 10:34:53,026 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-04-06 10:34:53,026 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/data-0/hdds, DS-94805b0f-2d69-4e9a-b453-7c1f770fc019) exiting.
2024-04-06 10:34:53,025 [ForkJoinPool.commonPool-worker-3] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/data-0/hdds) is shutting down. 
2024-04-06 10:34:53,027 [ForkJoinPool.commonPool-worker-2] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(416)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: close
2024-04-06 10:34:53,027 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-04-06 10:34:53,027 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/data-0/hdds, DS-efa4f3ca-3766-4044-9fcf-6b2e56cb6fe0) exiting.
2024-04-06 10:34:53,027 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-04-06 10:34:53,027 [main] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(416)) - d1715241-1ffa-4146-b219-94c9c0fc171f: close
2024-04-06 10:34:53,027 [59c3495a-7636-40f9-8dfa-c28be8e98abd-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F: shutdown
2024-04-06 10:34:53,027 [ForkJoinPool.commonPool-worker-1] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-0073f244-62c3-44f0-a0dd-f946c3c303ab/container.db from cache
2024-04-06 10:34:53,028 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(451)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-2/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-0073f244-62c3-44f0-a0dd-f946c3c303ab/container.db for volume DS-0073f244-62c3-44f0-a0dd-f946c3c303ab
2024-04-06 10:34:53,028 [59c3495a-7636-40f9-8dfa-c28be8e98abd-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-8188EE38776F,id=59c3495a-7636-40f9-8dfa-c28be8e98abd
2024-04-06 10:34:53,028 [59c3495a-7636-40f9-8dfa-c28be8e98abd-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: shutdown 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-LeaderStateImpl
2024-04-06 10:34:53,028 [59c3495a-7636-40f9-8dfa-c28be8e98abd-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-PendingRequests: sendNotLeaderResponses
2024-04-06 10:34:53,029 [59c3495a-7636-40f9-8dfa-c28be8e98abd-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-StateMachineUpdater: set stopIndex = 0
2024-04-06 10:34:53,029 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-8188EE38776F: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/9db4cf61-9812-4683-bf84-8188ee38776f/sm/snapshot.1_0
2024-04-06 10:34:53,030 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-8188EE38776F: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/ratis/9db4cf61-9812-4683-bf84-8188ee38776f/sm/snapshot.1_0 took: 1 ms
2024-04-06 10:34:53,030 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-StateMachineUpdater: Took a snapshot at index 0
2024-04-06 10:34:53,031 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-04-06 10:34:53,034 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - d1715241-1ffa-4146-b219-94c9c0fc171f: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-04-06 10:34:53,034 [d1715241-1ffa-4146-b219-94c9c0fc171f-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146: shutdown
2024-04-06 10:34:53,035 [d1715241-1ffa-4146-b219-94c9c0fc171f-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-89087E71B146,id=d1715241-1ffa-4146-b219-94c9c0fc171f
2024-04-06 10:34:53,035 [d1715241-1ffa-4146-b219-94c9c0fc171f-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - d1715241-1ffa-4146-b219-94c9c0fc171f: shutdown d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-LeaderStateImpl
2024-04-06 10:34:53,035 [d1715241-1ffa-4146-b219-94c9c0fc171f-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-PendingRequests: sendNotLeaderResponses
2024-04-06 10:34:53,035 [d1715241-1ffa-4146-b219-94c9c0fc171f-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-StateMachineUpdater: set stopIndex = 0
2024-04-06 10:34:53,035 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-89087E71B146: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/62748d4a-78e9-4857-a2b6-89087e71b146/sm/snapshot.1_0
2024-04-06 10:34:53,036 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-89087E71B146: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/ratis/62748d4a-78e9-4857-a2b6-89087e71b146/sm/snapshot.1_0 took: 0 ms
2024-04-06 10:34:53,036 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-StateMachineUpdater: Took a snapshot at index 0
2024-04-06 10:34:53,036 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-04-06 10:34:53,037 [Thread-1063] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff Close channels
2024-04-06 10:34:53,037 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-04-06 10:34:53,038 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-04-06 10:34:53,041 [Thread-1064] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - d1715241-1ffa-4146-b219-94c9c0fc171f Close channels
2024-04-06 10:34:53,041 [Thread-1065] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2 Close channels
2024-04-06 10:34:53,042 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - d1715241-1ffa-4146-b219-94c9c0fc171f: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-04-06 10:34:53,042 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - d1715241-1ffa-4146-b219-94c9c0fc171f: shutdown server GrpcServerProtocolService now
2024-04-06 10:34:53,043 [Thread-1066] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - cc1e4d3c-2283-4c28-b737-db868cb45369 Close channels
2024-04-06 10:34:53,043 [59c3495a-7636-40f9-8dfa-c28be8e98abd-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(427)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F: applyIndex: 0
2024-04-06 10:34:53,043 [d1715241-1ffa-4146-b219-94c9c0fc171f-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(427)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146: applyIndex: 0
2024-04-06 10:34:53,044 [59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-04-06 10:34:53,045 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - d1715241-1ffa-4146-b219-94c9c0fc171f: shutdown server GrpcServerProtocolService successfully
2024-04-06 10:34:53,047 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - d1715241-1ffa-4146-b219-94c9c0fc171f: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-04-06 10:34:53,046 [ForkJoinPool.commonPool-worker-3] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(416)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: close
2024-04-06 10:34:53,047 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-04-06 10:34:53,047 [d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-04-06 10:34:53,046 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(638)) - Ozone container server stopped.
2024-04-06 10:34:53,054 [main] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - d1715241-1ffa-4146-b219-94c9c0fc171f: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-04-06 10:34:53,054 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-04-06 10:34:53,054 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: shutdown server GrpcServerProtocolService now
2024-04-06 10:34:53,056 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-04-06 10:34:53,056 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: shutdown server GrpcServerProtocolService now
2024-04-06 10:34:53,058 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(481)) - Attempting to stop container services.
2024-04-06 10:34:53,058 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: shutdown server GrpcServerProtocolService successfully
2024-04-06 10:34:53,058 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-04-06 10:34:53,059 [ContainerMetadataScanner] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-04-06 10:34:53,059 [ContainerMetadataScanner] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - Thread[ContainerMetadataScanner,5,main] exiting.
2024-04-06 10:34:53,059 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.BackgroundContainerDataScanner (BackgroundContainerDataScanner.java:shutdown(141)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/data-0/hdds) is shutting down. 
2024-04-06 10:34:53,059 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/data-0/hdds)] WARN  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:handleRemainingSleep(134)) - Background container scan was interrupted.
2024-04-06 10:34:53,059 [ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/data-0/hdds)] INFO  ozoneimpl.AbstractBackgroundContainerScanner (AbstractBackgroundContainerScanner.java:run(61)) - ContainerDataScanner(/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/data-0/hdds, DS-db18787f-e7de-4e98-b685-d88b6726d128) exiting.
2024-04-06 10:34:53,062 [d1715241-1ffa-4146-b219-94c9c0fc171f-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x776ff116, L:/0.0.0.0:15035] CLOSE
2024-04-06 10:34:53,062 [d1715241-1ffa-4146-b219-94c9c0fc171f-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x776ff116, L:/0.0.0.0:15035] INACTIVE
2024-04-06 10:34:53,062 [d1715241-1ffa-4146-b219-94c9c0fc171f-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x776ff116, L:/0.0.0.0:15035] UNREGISTERED
2024-04-06 10:34:53,065 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@9dcfe2f{hddsDatanode,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode}
2024-04-06 10:34:53,065 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$9(416)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: close
2024-04-06 10:34:53,065 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: shutdown server GrpcServerProtocolService successfully
2024-04-06 10:34:53,065 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-04-06 10:34:53,065 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@d02ed56{HTTP/1.1, (http/1.1)}{0.0.0.0:15020}
2024-04-06 10:34:53,065 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-04-06 10:34:53,075 [ForkJoinPool.commonPool-worker-3] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-04-06 10:34:53,079 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService now
2024-04-06 10:34:53,079 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@68f500cd{static,/static,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/static,STOPPED}
2024-04-06 10:34:53,079 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$3(526)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D: shutdown
2024-04-06 10:34:53,079 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-2D61D60DE43D,id=a40aef6e-dfc7-4141-9a41-17d72bf4eeff
2024-04-06 10:34:53,079 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(94)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: shutdown a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-LeaderStateImpl
2024-04-06 10:34:53,079 [Thread-1133] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd Close channels
2024-04-06 10:34:53,079 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(289)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-PendingRequests: sendNotLeaderResponses
2024-04-06 10:34:53,080 [Thread-1135] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(103)) - ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2 Close channels
2024-04-06 10:34:53,080 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(157)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-StateMachineUpdater: set stopIndex = 0
2024-04-06 10:34:53,080 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(355)) - group-2D61D60DE43D: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/97b25c4a-3cf1-4ab4-a703-2d61d60de43d/sm/snapshot.1_0
2024-04-06 10:34:53,080 [ForkJoinPool.commonPool-worker-2] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-04-06 10:34:53,081 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(366)) - group-2D61D60DE43D: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/ratis/97b25c4a-3cf1-4ab4-a703-2d61d60de43d/sm/snapshot.1_0 took: 1 ms
2024-04-06 10:34:53,081 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(295)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-StateMachineUpdater: Took a snapshot at index 0
2024-04-06 10:34:53,081 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(98)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2024-04-06 10:34:53,081 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(427)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D: applyIndex: 0
2024-04-06 10:34:53,081 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-cacheEviction-AwaitToRun] INFO  util.AwaitToRun (AwaitToRun.java:run(49)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-cacheEviction-AwaitToRun-AwaitForSignal is interrupted
2024-04-06 10:34:53,086 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@71357e64{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-04-06 10:34:53,086 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: shutdown server org.apache.ratis.grpc.server.GrpcClientProtocolService successfully
2024-04-06 10:34:53,087 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: shutdown server GrpcServerProtocolService now
2024-04-06 10:34:53,092 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: shutdown server GrpcServerProtocolService successfully
2024-04-06 10:34:53,092 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(311)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService now
2024-04-06 10:34:53,095 [ForkJoinPool.commonPool-worker-1] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-04-06 10:34:53,096 [ForkJoinPool.commonPool-worker-1] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15021
2024-04-06 10:34:53,096 [59c3495a-7636-40f9-8dfa-c28be8e98abd-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x233533c1, L:/0.0.0.0:15017] CLOSE
2024-04-06 10:34:53,097 [59c3495a-7636-40f9-8dfa-c28be8e98abd-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x233533c1, L:/0.0.0.0:15017] INACTIVE
2024-04-06 10:34:53,097 [59c3495a-7636-40f9-8dfa-c28be8e98abd-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x233533c1, L:/0.0.0.0:15017] UNREGISTERED
2024-04-06 10:34:53,099 [IPC Server listener on 15021] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15021
2024-04-06 10:34:53,099 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-04-06 10:34:53,111 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd606ca47, L:/0.0.0.0:15053] CLOSE
2024-04-06 10:34:53,111 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(320)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff: shutdown server org.apache.ratis.grpc.server.GrpcAdminProtocolService successfully
2024-04-06 10:34:53,111 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd606ca47, L:/0.0.0.0:15053] INACTIVE
2024-04-06 10:34:53,111 [ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xd606ca47, L:/0.0.0.0:15053] UNREGISTERED
2024-04-06 10:34:53,115 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xfad1c7c9, L:/0.0.0.0:15044] CLOSE
2024-04-06 10:34:53,115 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xfad1c7c9, L:/0.0.0.0:15044] INACTIVE
2024-04-06 10:34:53,115 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xfad1c7c9, L:/0.0.0.0:15044] UNREGISTERED
2024-04-06 10:34:53,128 [JvmPauseMonitor7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2: Stopped
2024-04-06 10:34:53,395 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(501)) - Syncing data from Ozone Manager.
2024-04-06 10:34:53,395 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(511)) - Obtaining delta updates from Ozone Manager
2024-04-06 10:34:53,395 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getAndApplyDeltaUpdatesFromOM(418)) - OriginalFromSequenceNumber : 22 
2024-04-06 10:34:53,398 [Recon-SyncOM-2] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(422)) - com.google.protobuf.ServiceException: java.io.EOFException: End of File Exception between local host is: "fv-az526-218/10.1.0.10"; destination host is: "localhost":15004; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException, while invoking $Proxy81.submitRequest over nodeId=null,nodeAddress=localhost:15004. Trying to failover after sleeping for 2000ms. Current retry count: 0.
2024-04-06 10:34:53,400 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 3 milliseconds to process 2 existing database records.
2024-04-06 10:34:53,402 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 2 containers.
2024-04-06 10:34:53,402 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:53,402 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:53,402 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:53,402 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:53,402 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:53,402 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:53,402 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:53,540 [59c3495a-7636-40f9-8dfa-c28be8e98abd-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-8188EE38776F-SegmentedRaftLogWorker close()
2024-04-06 10:34:53,540 [JvmPauseMonitor3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-59c3495a-7636-40f9-8dfa-c28be8e98abd: Stopped
2024-04-06 10:34:53,648 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2024-04-06 10:34:53,824 [d1715241-1ffa-4146-b219-94c9c0fc171f-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - d1715241-1ffa-4146-b219-94c9c0fc171f@group-89087E71B146-SegmentedRaftLogWorker close()
2024-04-06 10:34:53,824 [JvmPauseMonitor5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-d1715241-1ffa-4146-b219-94c9c0fc171f: Stopped
2024-04-06 10:34:53,843 [a40aef6e-dfc7-4141-9a41-17d72bf4eeff-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(245)) - a40aef6e-dfc7-4141-9a41-17d72bf4eeff@group-2D61D60DE43D-SegmentedRaftLogWorker close()
2024-04-06 10:34:53,844 [JvmPauseMonitor6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-a40aef6e-dfc7-4141-9a41-17d72bf4eeff: Stopped
2024-04-06 10:34:54,405 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 3 milliseconds to process 2 existing database records.
2024-04-06 10:34:54,406 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 2 containers.
2024-04-06 10:34:54,406 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:54,406 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:54,406 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:54,406 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:54,407 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:54,407 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:54,407 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:54,648 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-04-06 10:34:55,131 [ForkJoinPool.commonPool-worker-3] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-4675313e-af28-48bb-b976-c300dd20b142/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-94805b0f-2d69-4e9a-b453-7c1f770fc019/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-db18787f-e7de-4e98-b685-d88b6726d128/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-efa4f3ca-3766-4044-9fcf-6b2e56cb6fe0/container.db]
2024-04-06 10:34:55,133 [ForkJoinPool.commonPool-worker-3] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-efa4f3ca-3766-4044-9fcf-6b2e56cb6fe0/container.db from cache
2024-04-06 10:34:55,133 [ForkJoinPool.commonPool-worker-3] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(451)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-5/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-efa4f3ca-3766-4044-9fcf-6b2e56cb6fe0/container.db for volume DS-efa4f3ca-3766-4044-9fcf-6b2e56cb6fe0
2024-04-06 10:34:55,134 [ForkJoinPool.commonPool-worker-3] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-04-06 10:34:55,134 [ForkJoinPool.commonPool-worker-3] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-04-06 10:34:55,135 [ForkJoinPool.commonPool-worker-3] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(638)) - Ozone container server stopped.
2024-04-06 10:34:55,137 [ForkJoinPool.commonPool-worker-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@415d089d{hddsDatanode,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode}
2024-04-06 10:34:55,137 [ForkJoinPool.commonPool-worker-3] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@7bab2266{HTTP/1.1, (http/1.1)}{0.0.0.0:15047}
2024-04-06 10:34:55,137 [ForkJoinPool.commonPool-worker-3] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-04-06 10:34:55,138 [ForkJoinPool.commonPool-worker-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@6a989646{static,/static,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/static,STOPPED}
2024-04-06 10:34:55,139 [ForkJoinPool.commonPool-worker-3] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@529dcc4b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-04-06 10:34:55,139 [ForkJoinPool.commonPool-worker-3] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-04-06 10:34:55,140 [ForkJoinPool.commonPool-worker-3] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15048
2024-04-06 10:34:55,140 [IPC Server listener on 15048] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15048
2024-04-06 10:34:55,140 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-04-06 10:34:55,387 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) moved to stale state. Finalizing its pipelines [PipelineID=97b25c4a-3cf1-4ab4-a703-2d61d60de43d]
2024-04-06 10:34:55,387 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=97b25c4a-3cf1-4ab4-a703-2d61d60de43d moved to CLOSED state
2024-04-06 10:34:55,399 [Recon-SyncOM-2] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(422)) - com.google.protobuf.ServiceException: java.net.ConnectException: Call From fv-az526-218/10.1.0.10 to localhost:15004 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy81.submitRequest over nodeId=null,nodeAddress=localhost:15004 after 1 failover attempts. Trying to failover after sleeping for 4000ms. Current retry count: 1.
2024-04-06 10:34:55,409 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:triggerContainerHealthCheck(140)) - Container Health task thread took 3 milliseconds to process 2 existing database records.
2024-04-06 10:34:55,411 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(166)) - Container Health task thread took 1 milliseconds for processing 2 containers.
2024-04-06 10:34:55,411 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MISSING **Container State Stats:** 
	
2024-04-06 10:34:55,411 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - OVER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:55,411 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - EMPTY_MISSING **Container State Stats:** 
	
2024-04-06 10:34:55,411 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - NEGATIVE_SIZE **Container State Stats:** 
	
2024-04-06 10:34:55,411 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - UNDER_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:55,411 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:lambda$logUnhealthyContainerStats$3(204)) - MIS_REPLICATED **Container State Stats:** 
	
2024-04-06 10:34:55,411 [ContainerHealthTask] INFO  fsck.ContainerHealthTask (ContainerHealthTask.java:checkAndProcessContainers(179)) - Container Health task thread took 1 iterations to fetch all containers using batched approach with batch size of 1000
2024-04-06 10:34:55,482 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) moved to stale state. Finalizing its pipelines [PipelineID=9db4cf61-9812-4683-bf84-8188ee38776f]
2024-04-06 10:34:55,487 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode 59c3495a-7636-40f9-8dfa-c28be8e98abd(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) moved to stale state. Finalizing its pipelines [PipelineID=9db4cf61-9812-4683-bf84-8188ee38776f]
2024-04-06 10:34:55,487 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=9db4cf61-9812-4683-bf84-8188ee38776f moved to CLOSED state
2024-04-06 10:34:55,488 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=9db4cf61-9812-4683-bf84-8188ee38776f moved to CLOSED state
2024-04-06 10:34:55,489 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 3 pipelines in house.
2024-04-06 10:34:55,492 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 3 milliseconds.
2024-04-06 10:34:55,493 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode a40aef6e-dfc7-4141-9a41-17d72bf4eeff(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) moved to stale state. Finalizing its pipelines [PipelineID=97b25c4a-3cf1-4ab4-a703-2d61d60de43d]
2024-04-06 10:34:55,494 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 3 pipelines in house.
2024-04-06 10:34:55,496 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 3 milliseconds.
2024-04-06 10:34:55,543 [ForkJoinPool.commonPool-worker-2] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-4675313e-af28-48bb-b976-c300dd20b142/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-94805b0f-2d69-4e9a-b453-7c1f770fc019/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-db18787f-e7de-4e98-b685-d88b6726d128/container.db]
2024-04-06 10:34:55,544 [timer1] WARN  server.GrpcLogAppender (GrpcLogAppender.java:lambda$resetClient$1(217)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7->cc1e4d3c-2283-4c28-b737-db868cb45369-GrpcLogAppender: Follower failed (request=null, errorCount=14); keep nextIndex (1) unchanged and retry. (Repeated 4 times in the last 5.000s)
2024-04-06 10:34:55,544 [timer0] WARN  server.GrpcLogAppender (LogUtils.java:warn(121)) - 59c3495a-7636-40f9-8dfa-c28be8e98abd@group-82A21D15CBF7->cc1e4d3c-2283-4c28-b737-db868cb45369-AppendLogResponseHandler: Failed appendEntries (Repeated 4 times in the last 5.002s): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2024-04-06 10:34:55,545 [ForkJoinPool.commonPool-worker-2] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-4675313e-af28-48bb-b976-c300dd20b142/container.db from cache
2024-04-06 10:34:55,545 [ForkJoinPool.commonPool-worker-2] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(451)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-1/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-4675313e-af28-48bb-b976-c300dd20b142/container.db for volume DS-4675313e-af28-48bb-b976-c300dd20b142
2024-04-06 10:34:55,545 [ForkJoinPool.commonPool-worker-2] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-04-06 10:34:55,546 [ForkJoinPool.commonPool-worker-2] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-04-06 10:34:55,546 [ForkJoinPool.commonPool-worker-2] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(638)) - Ozone container server stopped.
2024-04-06 10:34:55,548 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@317ed949{hddsDatanode,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode}
2024-04-06 10:34:55,548 [ForkJoinPool.commonPool-worker-2] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@3c437652{HTTP/1.1, (http/1.1)}{0.0.0.0:15011}
2024-04-06 10:34:55,548 [ForkJoinPool.commonPool-worker-2] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-04-06 10:34:55,549 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@53c1ab44{static,/static,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/static,STOPPED}
2024-04-06 10:34:55,549 [ForkJoinPool.commonPool-worker-2] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@4153239b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-04-06 10:34:55,550 [ForkJoinPool.commonPool-worker-2] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-04-06 10:34:55,551 [ForkJoinPool.commonPool-worker-2] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15012
2024-04-06 10:34:55,551 [IPC Server listener on 15012] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15012
2024-04-06 10:34:55,551 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-04-06 10:34:55,648 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(399)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2024-04-06 10:34:55,687 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) moved to stale state. Finalizing its pipelines []
2024-04-06 10:34:55,782 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode ceb25050-cf9f-4852-a13e-a5ff0cf3b4d2(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) moved to stale state. Finalizing its pipelines []
2024-04-06 10:34:55,783 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 3 pipelines in house.
2024-04-06 10:34:55,785 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 3 milliseconds.
2024-04-06 10:34:55,827 [main] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-94805b0f-2d69-4e9a-b453-7c1f770fc019/container.db, /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-db18787f-e7de-4e98-b685-d88b6726d128/container.db]
2024-04-06 10:34:55,828 [main] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-94805b0f-2d69-4e9a-b453-7c1f770fc019/container.db from cache
2024-04-06 10:34:55,828 [main] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(451)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-3/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-94805b0f-2d69-4e9a-b453-7c1f770fc019/container.db for volume DS-94805b0f-2d69-4e9a-b453-7c1f770fc019
2024-04-06 10:34:55,828 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-04-06 10:34:55,829 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-04-06 10:34:55,829 [main] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(638)) - Ozone container server stopped.
2024-04-06 10:34:55,830 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@67b19b53{hddsDatanode,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode}
2024-04-06 10:34:55,830 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@1d2133d3{HTTP/1.1, (http/1.1)}{0.0.0.0:15029}
2024-04-06 10:34:55,831 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-04-06 10:34:55,831 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@1f7d0816{static,/static,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/static,STOPPED}
2024-04-06 10:34:55,831 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@541ac2ba{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-04-06 10:34:55,832 [main] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-04-06 10:34:55,832 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15030
2024-04-06 10:34:55,835 [IPC Server listener on 15030] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15030
2024-04-06 10:34:55,835 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-04-06 10:34:55,846 [ForkJoinPool.commonPool-worker-0] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:shutdownCache(116)) - Skip clearing cache in mini cluster mode. Entries left: [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-db18787f-e7de-4e98-b685-d88b6726d128/container.db]
2024-04-06 10:34:55,847 [ForkJoinPool.commonPool-worker-0] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:removeDB(110)) - Removed db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-db18787f-e7de-4e98-b685-d88b6726d128/container.db from cache
2024-04-06 10:34:55,847 [ForkJoinPool.commonPool-worker-0] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(451)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9e1941cb-56ba-429e-854d-1e52595ce6ec/ozone-meta/datanode-4/data-0/hdds/9e1941cb-56ba-429e-854d-1e52595ce6ec/DS-db18787f-e7de-4e98-b685-d88b6726d128/container.db for volume DS-db18787f-e7de-4e98-b685-d88b6726d128
2024-04-06 10:34:55,848 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service BlockDeletingService
2024-04-06 10:34:55,848 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service StaleRecoveringContainerScrubbingService
2024-04-06 10:34:55,848 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(638)) - Ozone container server stopped.
2024-04-06 10:34:55,850 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@40e55d45{hddsDatanode,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode}
2024-04-06 10:34:55,850 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@4b4eece8{HTTP/1.1, (http/1.1)}{0.0.0.0:15038}
2024-04-06 10:34:55,850 [ForkJoinPool.commonPool-worker-0] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-04-06 10:34:55,851 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@10295010{static,/static,file:///home/runner/work/ozone/ozone/hadoop-hdds/container-service/target/classes/webapps/static,STOPPED}
2024-04-06 10:34:55,852 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@35fb66e5{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-04-06 10:34:55,852 [ForkJoinPool.commonPool-worker-0] INFO  ozone.HddsDatanodeClientProtocolServer (HddsDatanodeClientProtocolServer.java:stop(83)) - Stopping the RPC server for Client Protocol
2024-04-06 10:34:55,853 [ForkJoinPool.commonPool-worker-0] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15039
2024-04-06 10:34:55,853 [IPC Server listener on 15039] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15039
2024-04-06 10:34:55,854 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-04-06 10:34:55,854 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(486)) - Stopping the StorageContainerManager
2024-04-06 10:34:55,854 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1653)) - Container Balancer is not running.
2024-04-06 10:34:55,854 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stopReplicationManager(1786)) - Stopping Replication Manager Service.
2024-04-06 10:34:55,854 [main] INFO  replication.ReplicationManager (ReplicationManager.java:stop(328)) - Stopping Replication Monitor Thread.
2024-04-06 10:34:55,855 [UnderReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(180)) - UnderReplicatedProcessor interrupted. Exiting...
2024-04-06 10:34:55,855 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(935)) - Replication Monitor Thread is stopped
2024-04-06 10:34:55,855 [OverReplicatedProcessor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(180)) - OverReplicatedProcessor interrupted. Exiting...
2024-04-06 10:34:55,855 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1662)) - Stopping the Datanode Admin Monitor.
2024-04-06 10:34:55,855 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1669)) - Stopping datanode service RPC server
2024-04-06 10:34:55,856 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(425)) - Stopping the RPC server for DataNodes
2024-04-06 10:34:55,856 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15002
2024-04-06 10:34:55,857 [IPC Server listener on 15002] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15002
2024-04-06 10:34:55,858 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-04-06 10:34:55,882 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) moved to stale state. Finalizing its pipelines [PipelineID=62748d4a-78e9-4857-a2b6-89087e71b146]
2024-04-06 10:34:55,883 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=62748d4a-78e9-4857-a2b6-89087e71b146 moved to CLOSED state
2024-04-06 10:34:55,884 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.ReconPipelineManager (ReconPipelineManager.java:initializePipelines(105)) - Recon has 3 pipelines in house.
2024-04-06 10:34:55,885 [Recon-EventQueue-StaleNodeForReconStaleNodeHandler] INFO  scm.PipelineSyncTask (PipelineSyncTask.java:triggerPipelineSyncTask(94)) - Pipeline sync Thread took 3 milliseconds.
2024-04-06 10:34:55,887 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(57)) - Datanode d1715241-1ffa-4146-b219-94c9c0fc171f(fv-az526-218.pah0jnozfufetaq2ul10ticbdc.dx.internal.cloudapp.net/10.1.0.10) moved to stale state. Finalizing its pipelines [PipelineID=62748d4a-78e9-4857-a2b6-89087e71b146]
2024-04-06 10:34:55,887 [SCMHeartbeatProcessor-0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(878)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2024-04-06 10:34:55,887 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1677)) - Stopping block service RPC server
2024-04-06 10:34:55,887 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(518)) - Pipeline PipelineID=62748d4a-78e9-4857-a2b6-89087e71b146 moved to CLOSED state
2024-04-06 10:34:55,888 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(171)) - Stopping the RPC server for Block Protocol
2024-04-06 10:34:55,888 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15001
2024-04-06 10:34:55,892 [IPC Server listener on 15001] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15001
2024-04-06 10:34:55,892 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-04-06 10:34:55,892 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1684)) - Stopping the StorageContainerLocationProtocol RPC server
2024-04-06 10:34:55,892 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(213)) - Stopping the RPC server for Client Protocol
2024-04-06 10:34:55,893 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15000
2024-04-06 10:34:55,896 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1691)) - Stopping Storage Container Manager HTTP server.
2024-04-06 10:34:55,896 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-04-06 10:34:55,896 [IPC Server listener on 15000] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15000
2024-04-06 10:34:55,897 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@16a4e4c9{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2024-04-06 10:34:55,898 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@6517bc6b{HTTP/1.1, (http/1.1)}{0.0.0.0:15003}
2024-04-06 10:34:55,899 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-04-06 10:34:55,899 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@28f5a003{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2024-04-06 10:34:55,899 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@4c43c37d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-04-06 10:34:55,900 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1699)) - Stopping SCM LayoutVersionManager Service.
2024-04-06 10:34:55,901 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1711)) - Stopping Block Manager Service.
2024-04-06 10:34:55,901 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SCMBlockDeletingService
2024-04-06 10:34:55,901 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SCMBlockDeletingService
2024-04-06 10:34:55,901 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1731)) - Stopping SCM Event Queue.
2024-04-06 10:34:55,903 [JvmPauseMonitor0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-81d466ec-566f-42e5-9a02-20848490241e: Stopped
2024-04-06 10:34:55,903 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1742)) - Stopping SCM HA services.
2024-04-06 10:34:55,904 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(152)) - Stopping RatisPipelineUtilsThread.
2024-04-06 10:34:55,904 [RatisPipelineUtilsThread-0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(183)) - RatisPipelineUtilsThread is interrupted.
2024-04-06 10:34:55,904 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(128)) - Stopping BackgroundPipelineScrubber Service.
2024-04-06 10:34:55,904 [BackgroundPipelineScrubber] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(112)) - BackgroundPipelineScrubber is interrupted, exit
2024-04-06 10:34:55,905 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2024-04-06 10:34:55,907 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2024-04-06 10:34:55,907 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2024-04-06 10:34:55,907 [main] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(148)) - RatisPipelineUtilsThread is not running, just ignore.
2024-04-06 10:34:55,907 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(123)) - BackgroundPipelineScrubber Service is not running, skip stop.
2024-04-06 10:34:55,907 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(128)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2024-04-06 10:34:55,908 [ExpiredContainerReplicaOpScrubber] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(112)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2024-04-06 10:34:55,908 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(160)) - Shutting down service SCMBlockDeletingService
2024-04-06 10:34:55,908 [main] INFO  replication.ReplicationManager (ReplicationManager.java:stop(338)) - Replication Monitor Thread is not running.
2024-04-06 10:34:55,908 [main] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(327)) - Cannot stop Container Balancer because it's not running or stopping
2024-04-06 10:34:55,908 [LeaseManager#LeaseMonitor] WARN  lease.LeaseManager (LeaseManager.java:run(287)) - Lease manager is interrupted. Shutting down...
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1039)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1328)
	at java.util.concurrent.Semaphore.tryAcquire(Semaphore.java:409)
	at org.apache.hadoop.ozone.lease.LeaseManager$LeaseMonitor.run(LeaseManager.java:285)
	at java.lang.Thread.run(Thread.java:750)
2024-04-06 10:34:55,908 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1777)) - Stopping SCM MetadataStore.
2024-04-06 10:34:55,910 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopRecon(501)) - Stopping Recon
2024-04-06 10:34:55,910 [main] INFO  recon.ReconServer (ReconServer.java:stop(235)) - Stopping Recon server
2024-04-06 10:34:55,915 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@22dac77c{recon,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/recon/target/classes/webapps/recon}
2024-04-06 10:34:55,916 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@2ec993d6{HTTP/1.1, (http/1.1)}{0.0.0.0:15008}
2024-04-06 10:34:55,916 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2024-04-06 10:34:55,916 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@46872fde{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/recon/target/classes/webapps/static,STOPPED}
2024-04-06 10:34:55,916 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@3e848f48{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2024-04-06 10:34:55,917 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(425)) - Stopping the RPC server for DataNodes
2024-04-06 10:34:55,917 [main] INFO  ipc.Server (Server.java:stop(3523)) - Stopping server on 15009
2024-04-06 10:34:55,920 [IPC Server listener on 15009] INFO  ipc.Server (Server.java:run(1434)) - Stopping IPC Server listener on 15009
2024-04-06 10:34:55,920 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1567)) - Stopping IPC Server Responder
2024-04-06 10:34:55,982 [SCMHeartbeatProcessor-0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(878)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2024-04-06 10:34:55,983 [main] INFO  scm.ReconScmTask (ReconScmTask.java:stop(72)) - Stopping ContainerSizeCountTask Thread.
2024-04-06 10:34:55,983 [main] INFO  scm.ReconScmTask (ReconScmTask.java:stop(72)) - Stopping ContainerHealthTask Thread.
2024-04-06 10:34:55,983 [main] INFO  scm.ReconScmTask (ReconScmTask.java:stop(72)) - Stopping PipelineSyncTask Thread.
2024-04-06 10:34:55,983 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:stop(462)) - Stopping SCM Event Queue.
2024-04-06 10:34:55,984 [main] INFO  scm.ReconStorageContainerManagerFacade (ReconStorageContainerManagerFacade.java:stop(470)) - Flushing container replica history to DB.
2024-04-06 10:34:55,985 [ContainerSizeCountTask] INFO  tasks.ContainerSizeCountTask (ContainerSizeCountTask.java:process(200)) - Completed a 'process' run of ContainerSizeCountTask.
2024-04-06 10:34:55,986 [ContainerSizeCountTask] INFO  tasks.ContainerSizeCountTask (ContainerSizeCountTask.java:run(114)) - Elapsed Time in milliseconds for Process() execution: 2
2024-04-06 10:34:55,987 [main] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:stop(303)) - Stopping Ozone Manager Service Provider.
2024-04-06 10:34:55,987 [main] INFO  tasks.ReconTaskControllerImpl (ReconTaskControllerImpl.java:stop(230)) - Stopping Recon Task Controller.
2024-04-06 10:34:55,988 [main] INFO  recon.ReconServer (ReconServer.java:stop(260)) - Closing Recon Container Key DB.
2024-04-06 10:34:55,988 [Recon-SyncOM-2] WARN  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(528)) - Unable to get and apply delta updates from OM.
2024-04-06 10:34:55,988 [Recon-SyncOM-2] INFO  impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:syncDataFromOM(537)) - Obtaining full snapshot from Ozone Manager
2024-04-06 10:34:55,989 [JvmPauseMonitor2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(152)) - JvmPauseMonitor-Recon: Stopped
2024-04-06 10:34:55,989 [Recon-SyncOM-2] ERROR impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:getOzoneManagerDBSnapshot(373)) - Unable to obtain Ozone Manager DB Snapshot. 
java.nio.channels.ClosedByInterruptException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:658)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:191)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:600)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:652)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:773)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:347)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1632)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1410)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:250)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:132)
	at com.sun.proxy.$Proxy81.submitRequest(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor99.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:433)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:166)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:158)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:96)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:362)
	at com.sun.proxy.$Proxy81.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransport.submitRequest(Hadoop3OmTransport.java:80)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.submitRequest(OzoneManagerProtocolClientSideTranslatorPB.java:345)
	at org.apache.hadoop.ozone.om.protocolPB.OzoneManagerProtocolClientSideTranslatorPB.getServiceList(OzoneManagerProtocolClientSideTranslatorPB.java:1801)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerSnapshotUrl(OzoneManagerServiceProviderImpl.java:322)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$getOzoneManagerDBSnapshot$1(OzoneManagerServiceProviderImpl.java:357)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:551)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:531)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.getOzoneManagerDBSnapshot(OzoneManagerServiceProviderImpl.java:355)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.updateReconOmDBWithNewSnapshot(OzoneManagerServiceProviderImpl.java:387)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.syncDataFromOM(OzoneManagerServiceProviderImpl.java:539)
	at org.apache.hadoop.ozone.recon.spi.impl.OzoneManagerServiceProviderImpl.lambda$startSyncDataFromOM$0(OzoneManagerServiceProviderImpl.java:267)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2024-04-06 10:34:55,990 [Recon-SyncOM-2] ERROR impl.OzoneManagerServiceProviderImpl (OzoneManagerServiceProviderImpl.java:updateReconOmDBWithNewSnapshot(400)) - Null snapshot location got from OM.
2024-04-06 10:34:56,111 [shutdown-hook-0] INFO  recon.ReconServer (StringUtils.java:lambda$startupShutdownMessage$0(144)) - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down ReconServer at fv-az526-218/10.1.0.10
************************************************************/
